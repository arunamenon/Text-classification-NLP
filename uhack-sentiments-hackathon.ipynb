{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06bc110b",
    "papermill": {
     "duration": 0.024935,
     "end_time": "2021-12-27T11:31:45.520504",
     "exception": false,
     "start_time": "2021-12-27T11:31:45.495569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddb3bd9b",
    "papermill": {
     "duration": 0.025286,
     "end_time": "2021-12-27T11:31:45.569922",
     "exception": false,
     "start_time": "2021-12-27T11:31:45.544636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img style=\"-webkit-user-select: none;margin: auto;cursor: zoom-out;background-color: hsl(0, 0%, 90%);transition: background-color 300ms;\" src=\"https://machinehack-be.s3.amazonaws.com/uhack_sentiments_20_decode_code_words/Ugam_large%281%29.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAI2O7AQTB6JBT4VSA%2F20220103%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20220103T150348Z&X-Amz-Expires=172800&X-Amz-SignedHeaders=host&X-Amz-Signature=aec5f03e2119dbba2d697dcfbf0b81764c497a0b73e008c2003ef6c8863915de\" width=\"1024\" height=\"168\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "033b46b6",
    "papermill": {
     "duration": 0.023498,
     "end_time": "2021-12-27T11:31:45.619828",
     "exception": false,
     "start_time": "2021-12-27T11:31:45.59633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The challenge here is to analyze and deep dive into the natural language text (reviews) and bucket them based on their topics of discussion. Furthermore, analyzing the overall sentiment will also help the business to make tangible decisions.\n",
    "\n",
    "The data set provided to you has a mix of customer reviews for products across categories and retailers. We would like you to model on the data to bucket the future reviews in their respective topics (Note: A review can talk about multiple topics)\n",
    "\n",
    "Overall polarity (positive/negative sentiment)\n",
    "\n",
    " \n",
    "\n",
    "Train: 6136 rows x 14 columns\n",
    "Test: 2631 rows x 14 columns \n",
    " \n",
    "\n",
    "Topics (Components, Delivery and Customer Support, Design and Aesthetics, Dimensions, Features, Functionality, Installation, Material, Price, Quality and Usability)\n",
    "Polarity (Positive/Negative)\n",
    "Note: The target variables are all encoded in the train dataset for convenience. Please submit the test results in the similar encoded fashion for us to evaluate your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78f34efb",
    "papermill": {
     "duration": 0.023146,
     "end_time": "2021-12-27T11:31:45.666271",
     "exception": false,
     "start_time": "2021-12-27T11:31:45.643125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:40:53.313481Z",
     "iopub.status.busy": "2021-12-31T14:40:53.312343Z",
     "iopub.status.idle": "2021-12-31T14:41:58.907975Z",
     "shell.execute_reply": "2021-12-31T14:41:58.907257Z",
     "shell.execute_reply.started": "2021-12-31T14:40:53.313402Z"
    },
    "id": "r5_sDVcxUnC1",
    "outputId": "99ff333c-e458-4efa-834f-ae55032c7068"
   },
   "outputs": [],
   "source": [
    "# !pip install clean-text --user\n",
    "# !pip install optuna --user\n",
    "# !pip install boostaroota --user\n",
    "# !pip install transformers --user\n",
    "# !pip install sentencepiece --user\n",
    "# !pip install wordninja --user\n",
    "# !pip install autocorrect --user\n",
    "# !pip install language_tool_python --user\n",
    "# !pip install pyspellchecker\n",
    "# !pip install plotly --user\n",
    "# !pip install cufflinks --user\n",
    "# !pip install gensim --user\n",
    "# !pip install torch --user\n",
    "# !pip install matplotlib_venn --user\n",
    "# !pip install shap --user\n",
    "# !pip install h2o --user\n",
    "# !pip install fasttext --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:58.910751Z",
     "iopub.status.busy": "2021-12-31T14:41:58.910465Z",
     "iopub.status.idle": "2021-12-31T14:41:58.931683Z",
     "shell.execute_reply": "2021-12-31T14:41:58.930756Z",
     "shell.execute_reply.started": "2021-12-31T14:41:58.910721Z"
    },
    "id": "640d1f34",
    "outputId": "a10c3a05-cf5b-47ff-fcab-e52dc29ed1c4",
    "papermill": {
     "duration": 1.629494,
     "end_time": "2021-12-27T11:31:47.322145",
     "exception": false,
     "start_time": "2021-12-27T11:31:45.692651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from flashtext import KeywordProcessor\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "from gensim import models\n",
    "# from fuzzywuzzy import fuzz\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_venn as venn\n",
    "from matplotlib_venn import venn3, venn3_circles, venn3_unweighted\n",
    "from tqdm import tqdm\n",
    "# from unidecode import unidecode\n",
    "from sklearn.decomposition import PCA   \n",
    "import re\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# from biobert_embedding.embedding import BiobertEmbedding\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "\n",
    "from nltk import ngrams\n",
    "from cleantext import clean\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, precision_recall_curve, auc, f1_score, \\\n",
    "    average_precision_score, accuracy_score, roc_curve\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from optuna.samplers import TPESampler\n",
    "import functools\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\n",
    "from sklearn import metrics\n",
    "import optuna\n",
    "from boostaroota import BoostARoota\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection as sk_model_selection\n",
    "from xgboost import plot_tree\n",
    "import shap\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import language_tool_python\n",
    "import wordninja\n",
    "from autocorrect import Speller\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "    \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import Concatenate, LSTM, GRU\n",
    "from tensorflow.keras.layers import Bidirectional, Multiply\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "import csv\n",
    "import fasttext\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:58.933450Z",
     "iopub.status.busy": "2021-12-31T14:41:58.932832Z",
     "iopub.status.idle": "2021-12-31T14:41:58.949296Z",
     "shell.execute_reply": "2021-12-31T14:41:58.948156Z",
     "shell.execute_reply.started": "2021-12-31T14:41:58.933404Z"
    },
    "id": "cNCu9hGkWV5o"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import io\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "from transformers import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8b36726",
    "papermill": {
     "duration": 0.025487,
     "end_time": "2021-12-27T11:31:47.371879",
     "exception": false,
     "start_time": "2021-12-27T11:31:47.346392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:58.951681Z",
     "iopub.status.busy": "2021-12-31T14:41:58.951277Z",
     "iopub.status.idle": "2021-12-31T14:41:59.017156Z",
     "shell.execute_reply": "2021-12-31T14:41:59.016102Z",
     "shell.execute_reply.started": "2021-12-31T14:41:58.951641Z"
    },
    "id": "bc599438",
    "papermill": {
     "duration": 0.133695,
     "end_time": "2021-12-27T11:31:47.529039",
     "exception": false,
     "start_time": "2021-12-27T11:31:47.395344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = './Inputs/'\n",
    "output_filepath = './Outputs/'\n",
    "train_data = pd.read_csv(filepath + r'/train.csv')\n",
    "test_data = pd.read_csv(filepath + r'/test.csv')\n",
    "submission_data = pd.read_csv(filepath + r'/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dbbd4a1",
    "papermill": {
     "duration": 0.023574,
     "end_time": "2021-12-27T11:31:47.576856",
     "exception": false,
     "start_time": "2021-12-27T11:31:47.553282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:59.018966Z",
     "iopub.status.busy": "2021-12-31T14:41:59.018750Z",
     "iopub.status.idle": "2021-12-31T14:41:59.036514Z",
     "shell.execute_reply": "2021-12-31T14:41:59.035509Z",
     "shell.execute_reply.started": "2021-12-31T14:41:59.018941Z"
    },
    "id": "6869932a",
    "outputId": "e36d5b71-b5bd-4e6c-f42e-ae7a4555f92a",
    "papermill": {
     "duration": 0.053984,
     "end_time": "2021-12-27T11:31:47.654818",
     "exception": false,
     "start_time": "2021-12-27T11:31:47.600834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6136, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Review</th>\n",
       "      <th>Components</th>\n",
       "      <th>Delivery and Customer Support</th>\n",
       "      <th>Design and Aesthetics</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Features</th>\n",
       "      <th>Functionality</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Material</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Usability</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>For some reason everybody complains and I'm co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I like everything about it, great choice of sp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent ceiling fan brace. Easy to install a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Work great easy to use . No issues at all with...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I would recommend this product because it is p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                             Review  Components  \\\n",
       "0   0  For some reason everybody complains and I'm co...           0   \n",
       "1   1  I like everything about it, great choice of sp...           0   \n",
       "2   2  Excellent ceiling fan brace. Easy to install a...           0   \n",
       "3   3  Work great easy to use . No issues at all with...           0   \n",
       "4   4  I would recommend this product because it is p...           0   \n",
       "\n",
       "   Delivery and Customer Support  Design and Aesthetics  Dimensions  Features  \\\n",
       "0                              0                      0           0         0   \n",
       "1                              0                      0           0         1   \n",
       "2                              0                      0           0         0   \n",
       "3                              0                      0           0         0   \n",
       "4                              0                      0           0         0   \n",
       "\n",
       "   Functionality  Installation  Material  Price  Quality  Usability  Polarity  \n",
       "0              0             0         0      0        0          1         0  \n",
       "1              1             0         0      0        0          0         1  \n",
       "2              0             1         0      0        1          0         1  \n",
       "3              1             0         0      0        0          1         1  \n",
       "4              0             0         0      0        1          0         1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:59.038292Z",
     "iopub.status.busy": "2021-12-31T14:41:59.038041Z",
     "iopub.status.idle": "2021-12-31T14:41:59.061070Z",
     "shell.execute_reply": "2021-12-31T14:41:59.060023Z",
     "shell.execute_reply.started": "2021-12-31T14:41:59.038260Z"
    },
    "id": "ecda1041",
    "outputId": "90343028-fe29-4b43-e85e-6feb8d01e85c",
    "papermill": {
     "duration": 0.049075,
     "end_time": "2021-12-27T11:31:47.729482",
     "exception": false,
     "start_time": "2021-12-27T11:31:47.680407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2631, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Review</th>\n",
       "      <th>Components</th>\n",
       "      <th>Delivery and Customer Support</th>\n",
       "      <th>Design and Aesthetics</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Features</th>\n",
       "      <th>Functionality</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Material</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Usability</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Made of very thin cheap metal broke on very fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>As good as the brand names, no jams or misfire...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>unit was easy to use, with understandable in s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I am the new family plumber. Works well. No pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Seems to be holding up well.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                             Review  Components  \\\n",
       "0   0  Made of very thin cheap metal broke on very fi...         NaN   \n",
       "1   1  As good as the brand names, no jams or misfire...         NaN   \n",
       "2   2  unit was easy to use, with understandable in s...         NaN   \n",
       "3   3  I am the new family plumber. Works well. No pr...         NaN   \n",
       "4   4                       Seems to be holding up well.         NaN   \n",
       "\n",
       "   Delivery and Customer Support  Design and Aesthetics  Dimensions  Features  \\\n",
       "0                            NaN                    NaN         NaN       NaN   \n",
       "1                            NaN                    NaN         NaN       NaN   \n",
       "2                            NaN                    NaN         NaN       NaN   \n",
       "3                            NaN                    NaN         NaN       NaN   \n",
       "4                            NaN                    NaN         NaN       NaN   \n",
       "\n",
       "   Functionality  Installation  Material  Price  Quality  Usability  Polarity  \n",
       "0            NaN           NaN       NaN    NaN      NaN        NaN       NaN  \n",
       "1            NaN           NaN       NaN    NaN      NaN        NaN       NaN  \n",
       "2            NaN           NaN       NaN    NaN      NaN        NaN       NaN  \n",
       "3            NaN           NaN       NaN    NaN      NaN        NaN       NaN  \n",
       "4            NaN           NaN       NaN    NaN      NaN        NaN       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:59.063395Z",
     "iopub.status.busy": "2021-12-31T14:41:59.062451Z",
     "iopub.status.idle": "2021-12-31T14:41:59.077260Z",
     "shell.execute_reply": "2021-12-31T14:41:59.076184Z",
     "shell.execute_reply.started": "2021-12-31T14:41:59.063354Z"
    },
    "id": "e112321c",
    "outputId": "285355e2-e827-4909-d656-8fafa933bf41",
    "papermill": {
     "duration": 0.048992,
     "end_time": "2021-12-27T11:31:47.804216",
     "exception": false,
     "start_time": "2021-12-27T11:31:47.755224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2631, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Components</th>\n",
       "      <th>Delivery and Customer Support</th>\n",
       "      <th>Design and Aesthetics</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Features</th>\n",
       "      <th>Functionality</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Material</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Usability</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Components  Delivery and Customer Support  Design and Aesthetics  \\\n",
       "0           0                              0                      0   \n",
       "1           0                              0                      0   \n",
       "2           0                              0                      0   \n",
       "3           0                              0                      0   \n",
       "4           0                              0                      0   \n",
       "\n",
       "   Dimensions  Features  Functionality  Installation  Material  Price  \\\n",
       "0           0         0              0             0         0      0   \n",
       "1           0         0              0             0         0      0   \n",
       "2           0         0              0             0         0      0   \n",
       "3           0         0              0             0         0      0   \n",
       "4           0         0              0             0         0      0   \n",
       "\n",
       "   Quality  Usability  Polarity  \n",
       "0        0          0         0  \n",
       "1        0          0         0  \n",
       "2        0          0         0  \n",
       "3        0          0         0  \n",
       "4        0          0         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(submission_data.shape)\n",
    "submission_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:59.079108Z",
     "iopub.status.busy": "2021-12-31T14:41:59.078456Z",
     "iopub.status.idle": "2021-12-31T14:41:59.088681Z",
     "shell.execute_reply": "2021-12-31T14:41:59.087994Z",
     "shell.execute_reply.started": "2021-12-31T14:41:59.079071Z"
    },
    "id": "3ae9c929",
    "papermill": {
     "duration": 0.036018,
     "end_time": "2021-12-27T11:31:47.86807",
     "exception": false,
     "start_time": "2021-12-27T11:31:47.832052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = [x for x in train_data.columns.tolist() if x not in ['Id','Review','Polarity']]\n",
    "polarity = 'Polarity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef8b3b04",
    "papermill": {
     "duration": 0.026461,
     "end_time": "2021-12-27T11:31:47.921364",
     "exception": false,
     "start_time": "2021-12-27T11:31:47.894903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Distribution by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T16:27:04.293036Z",
     "iopub.status.busy": "2021-12-31T16:27:04.292696Z",
     "iopub.status.idle": "2021-12-31T16:27:04.420480Z",
     "shell.execute_reply": "2021-12-31T16:27:04.419464Z",
     "shell.execute_reply.started": "2021-12-31T16:27:04.293003Z"
    },
    "id": "14c2f0b0",
    "outputId": "7efe9c56-5b8b-4366-b5da-b3db4ab3048b",
    "papermill": {
     "duration": 1.218355,
     "end_time": "2021-12-27T11:31:49.167261",
     "exception": false,
     "start_time": "2021-12-27T11:31:47.948906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797a3e91037e4dfa8153937c1b5ff84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='category', options=('All', 'Components', 'Delivery and Customer Suâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def distr_by_length(category):\n",
    "    data = train_data.copy()\n",
    "    if category!='All':\n",
    "        data = data[data[category]==1].reset_index(drop = True)\n",
    "    print('\\n# Reviews:', data.shape[0])\n",
    "    print('Average polarity:', data['Polarity'].mean() * 100,'%\\n')\n",
    "    temp = data['Review'].apply(lambda x: len(x.split())).reset_index()\n",
    "    display(temp[['Review']].describe().reset_index())\n",
    "    fig = px.histogram(temp, x=\"Review\")\n",
    "    fig.show()\n",
    "    \n",
    "w = widgets.interactive(distr_by_length, category = ['All'] + categories)\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a4293e5",
    "papermill": {
     "duration": 0.026933,
     "end_time": "2021-12-27T11:31:49.2277",
     "exception": false,
     "start_time": "2021-12-27T11:31:49.200767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Distribution of categories and polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:59.206408Z",
     "iopub.status.busy": "2021-12-31T14:41:59.205878Z",
     "iopub.status.idle": "2021-12-31T14:41:59.217904Z",
     "shell.execute_reply": "2021-12-31T14:41:59.216876Z",
     "shell.execute_reply.started": "2021-12-31T14:41:59.206347Z"
    },
    "id": "1da4bfd2",
    "outputId": "5c424c0a-3e56-4a3d-8eeb-24e546903f63",
    "papermill": {
     "duration": 0.041002,
     "end_time": "2021-12-27T11:31:49.29579",
     "exception": false,
     "start_time": "2021-12-27T11:31:49.254788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[categories].sum(axis = 1).min(), train_data[categories].sum(axis = 1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:59.219633Z",
     "iopub.status.busy": "2021-12-31T14:41:59.219227Z",
     "iopub.status.idle": "2021-12-31T14:41:59.236144Z",
     "shell.execute_reply": "2021-12-31T14:41:59.235024Z",
     "shell.execute_reply.started": "2021-12-31T14:41:59.219566Z"
    },
    "id": "1bbd3d3c",
    "outputId": "d6cf18a2-9ef2-4ee4-ab05-94a2c84425a9",
    "papermill": {
     "duration": 0.043942,
     "end_time": "2021-12-27T11:31:49.366925",
     "exception": false,
     "start_time": "2021-12-27T11:31:49.322983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>6136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.777379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>std</td>\n",
       "      <td>0.416040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     Polarity\n",
       "0  count  6136.000000\n",
       "1   mean     0.777379\n",
       "2    std     0.416040\n",
       "3    min     0.000000\n",
       "4    25%     1.000000\n",
       "5    50%     1.000000\n",
       "6    75%     1.000000\n",
       "7    max     1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Polarity'].describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:59.239395Z",
     "iopub.status.busy": "2021-12-31T14:41:59.239048Z",
     "iopub.status.idle": "2021-12-31T14:41:59.393127Z",
     "shell.execute_reply": "2021-12-31T14:41:59.392172Z",
     "shell.execute_reply.started": "2021-12-31T14:41:59.239345Z"
    },
    "id": "f9c85da0",
    "papermill": {
     "duration": 0.183533,
     "end_time": "2021-12-27T11:31:49.578362",
     "exception": false,
     "start_time": "2021-12-27T11:31:49.394829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "overlap_df = pd.DataFrame(data = None, columns = ['Category'] + categories + ['# Reviews', '% of all reviews'])\n",
    "perc_overlap_df = pd.DataFrame(data = None, columns = ['Category'] + categories)\n",
    "for col in categories:\n",
    "    n = train_data.groupby([col]).size().reset_index().sort_values(by = col).iloc[-1][0]\n",
    "    temp = train_data[train_data[col]==1][categories].sum(axis = 0).reset_index().T\n",
    "    temp = temp.iloc[1:,:]\n",
    "    temp.columns = categories\n",
    "    temp['Category'] = col\n",
    "    overlap_df = pd.concat([overlap_df, temp], axis = 0).reset_index(drop = True)\n",
    "    overlap_df['# Reviews'].iloc[overlap_df.shape[0]-1] = n\n",
    "    overlap_df['% of all reviews'].iloc[overlap_df.shape[0]-1] = n/train_data.shape[0] * 100\n",
    "    for x in temp.columns:\n",
    "        if x!= 'Category':\n",
    "            temp[x] = temp[x]/n * 100\n",
    "    perc_overlap_df = pd.concat([perc_overlap_df, temp], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:59.395166Z",
     "iopub.status.busy": "2021-12-31T14:41:59.394852Z",
     "iopub.status.idle": "2021-12-31T14:41:59.416070Z",
     "shell.execute_reply": "2021-12-31T14:41:59.415114Z",
     "shell.execute_reply.started": "2021-12-31T14:41:59.395123Z"
    },
    "id": "05fd1afd",
    "outputId": "781fa93c-2643-4e9d-95c3-504f52bae876",
    "papermill": {
     "duration": 0.050174,
     "end_time": "2021-12-27T11:31:49.655573",
     "exception": false,
     "start_time": "2021-12-27T11:31:49.605399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Components</th>\n",
       "      <th>Delivery and Customer Support</th>\n",
       "      <th>Design and Aesthetics</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Features</th>\n",
       "      <th>Functionality</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Material</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Usability</th>\n",
       "      <th># Reviews</th>\n",
       "      <th>% of all reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Components</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>67</td>\n",
       "      <td>21</td>\n",
       "      <td>274</td>\n",
       "      <td>4.46545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delivery and Customer Support</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>2.91721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Design and Aesthetics</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>650</td>\n",
       "      <td>117</td>\n",
       "      <td>9</td>\n",
       "      <td>130</td>\n",
       "      <td>68</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "      <td>199</td>\n",
       "      <td>150</td>\n",
       "      <td>650</td>\n",
       "      <td>10.59322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dimensions</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>695</td>\n",
       "      <td>17</td>\n",
       "      <td>161</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>160</td>\n",
       "      <td>152</td>\n",
       "      <td>695</td>\n",
       "      <td>11.326597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Features</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>313</td>\n",
       "      <td>116</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>84</td>\n",
       "      <td>49</td>\n",
       "      <td>313</td>\n",
       "      <td>5.101043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Functionality</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>130</td>\n",
       "      <td>161</td>\n",
       "      <td>116</td>\n",
       "      <td>2538</td>\n",
       "      <td>178</td>\n",
       "      <td>24</td>\n",
       "      <td>231</td>\n",
       "      <td>553</td>\n",
       "      <td>323</td>\n",
       "      <td>2538</td>\n",
       "      <td>41.362451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Installation</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>178</td>\n",
       "      <td>762</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>248</td>\n",
       "      <td>90</td>\n",
       "      <td>762</td>\n",
       "      <td>12.418514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Material</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>155</td>\n",
       "      <td>8</td>\n",
       "      <td>73</td>\n",
       "      <td>23</td>\n",
       "      <td>155</td>\n",
       "      <td>2.526076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Price</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>231</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>854</td>\n",
       "      <td>273</td>\n",
       "      <td>77</td>\n",
       "      <td>854</td>\n",
       "      <td>13.917862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quality</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>199</td>\n",
       "      <td>160</td>\n",
       "      <td>84</td>\n",
       "      <td>553</td>\n",
       "      <td>248</td>\n",
       "      <td>73</td>\n",
       "      <td>273</td>\n",
       "      <td>2177</td>\n",
       "      <td>345</td>\n",
       "      <td>2177</td>\n",
       "      <td>35.47914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Usability</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>152</td>\n",
       "      <td>49</td>\n",
       "      <td>323</td>\n",
       "      <td>90</td>\n",
       "      <td>23</td>\n",
       "      <td>77</td>\n",
       "      <td>345</td>\n",
       "      <td>1229</td>\n",
       "      <td>1229</td>\n",
       "      <td>20.029335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Category Components Delivery and Customer Support  \\\n",
       "0                      Components        274                             0   \n",
       "1   Delivery and Customer Support          0                           179   \n",
       "2           Design and Aesthetics         10                             0   \n",
       "3                      Dimensions          0                             0   \n",
       "4                        Features          0                             0   \n",
       "5                   Functionality         80                            31   \n",
       "6                    Installation         19                             0   \n",
       "7                        Material          0                             0   \n",
       "8                           Price         11                            26   \n",
       "9                         Quality         67                            49   \n",
       "10                      Usability         21                             0   \n",
       "\n",
       "   Design and Aesthetics Dimensions Features Functionality Installation  \\\n",
       "0                     10          0        0            80           19   \n",
       "1                      0          0        0            31            0   \n",
       "2                    650        117        9           130           68   \n",
       "3                    117        695       17           161           30   \n",
       "4                      9         17      313           116           25   \n",
       "5                    130        161      116          2538          178   \n",
       "6                     68         30       25           178          762   \n",
       "7                     18          0        0            24            8   \n",
       "8                     37         36       29           231           55   \n",
       "9                    199        160       84           553          248   \n",
       "10                   150        152       49           323           90   \n",
       "\n",
       "   Material Price Quality Usability # Reviews % of all reviews  \n",
       "0         0    11      67        21       274          4.46545  \n",
       "1         0    26      49         0       179          2.91721  \n",
       "2        18    37     199       150       650         10.59322  \n",
       "3         0    36     160       152       695        11.326597  \n",
       "4         0    29      84        49       313         5.101043  \n",
       "5        24   231     553       323      2538        41.362451  \n",
       "6         8    55     248        90       762        12.418514  \n",
       "7       155     8      73        23       155         2.526076  \n",
       "8         8   854     273        77       854        13.917862  \n",
       "9        73   273    2177       345      2177         35.47914  \n",
       "10       23    77     345      1229      1229        20.029335  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:59.418115Z",
     "iopub.status.busy": "2021-12-31T14:41:59.417777Z",
     "iopub.status.idle": "2021-12-31T14:41:59.446681Z",
     "shell.execute_reply": "2021-12-31T14:41:59.445821Z",
     "shell.execute_reply.started": "2021-12-31T14:41:59.418071Z"
    },
    "id": "385ea330",
    "outputId": "ec076af5-10de-4e55-949b-df960710e36e",
    "papermill": {
     "duration": 0.12027,
     "end_time": "2021-12-27T11:31:49.80404",
     "exception": false,
     "start_time": "2021-12-27T11:31:49.68377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_1ea51_row0_col5,#T_1ea51_row0_col9,#T_1ea51_row1_col9,#T_1ea51_row2_col5,#T_1ea51_row2_col9,#T_1ea51_row2_col10,#T_1ea51_row3_col5,#T_1ea51_row3_col9,#T_1ea51_row3_col10,#T_1ea51_row4_col5,#T_1ea51_row4_col9,#T_1ea51_row5_col9,#T_1ea51_row6_col5,#T_1ea51_row6_col9,#T_1ea51_row7_col9,#T_1ea51_row8_col5,#T_1ea51_row8_col9,#T_1ea51_row9_col5,#T_1ea51_row10_col5,#T_1ea51_row10_col9{\n",
       "            background-color :  yellow;\n",
       "        }</style><table id=\"T_1ea51_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Components</th>        <th class=\"col_heading level0 col1\" >Delivery and Customer Support</th>        <th class=\"col_heading level0 col2\" >Design and Aesthetics</th>        <th class=\"col_heading level0 col3\" >Dimensions</th>        <th class=\"col_heading level0 col4\" >Features</th>        <th class=\"col_heading level0 col5\" >Functionality</th>        <th class=\"col_heading level0 col6\" >Installation</th>        <th class=\"col_heading level0 col7\" >Material</th>        <th class=\"col_heading level0 col8\" >Price</th>        <th class=\"col_heading level0 col9\" >Quality</th>        <th class=\"col_heading level0 col10\" >Usability</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_1ea51_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_1ea51_row0_col0\" class=\"data row0 col0\" >100.000000</td>\n",
       "                        <td id=\"T_1ea51_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row0_col2\" class=\"data row0 col2\" >3.649635</td>\n",
       "                        <td id=\"T_1ea51_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row0_col5\" class=\"data row0 col5\" >29.197080</td>\n",
       "                        <td id=\"T_1ea51_row0_col6\" class=\"data row0 col6\" >6.934307</td>\n",
       "                        <td id=\"T_1ea51_row0_col7\" class=\"data row0 col7\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row0_col8\" class=\"data row0 col8\" >4.014599</td>\n",
       "                        <td id=\"T_1ea51_row0_col9\" class=\"data row0 col9\" >24.452555</td>\n",
       "                        <td id=\"T_1ea51_row0_col10\" class=\"data row0 col10\" >7.664234</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1ea51_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_1ea51_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row1_col1\" class=\"data row1 col1\" >100.000000</td>\n",
       "                        <td id=\"T_1ea51_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row1_col5\" class=\"data row1 col5\" >17.318436</td>\n",
       "                        <td id=\"T_1ea51_row1_col6\" class=\"data row1 col6\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row1_col7\" class=\"data row1 col7\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row1_col8\" class=\"data row1 col8\" >14.525140</td>\n",
       "                        <td id=\"T_1ea51_row1_col9\" class=\"data row1 col9\" >27.374302</td>\n",
       "                        <td id=\"T_1ea51_row1_col10\" class=\"data row1 col10\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1ea51_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_1ea51_row2_col0\" class=\"data row2 col0\" >1.538462</td>\n",
       "                        <td id=\"T_1ea51_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row2_col2\" class=\"data row2 col2\" >100.000000</td>\n",
       "                        <td id=\"T_1ea51_row2_col3\" class=\"data row2 col3\" >18.000000</td>\n",
       "                        <td id=\"T_1ea51_row2_col4\" class=\"data row2 col4\" >1.384615</td>\n",
       "                        <td id=\"T_1ea51_row2_col5\" class=\"data row2 col5\" >20.000000</td>\n",
       "                        <td id=\"T_1ea51_row2_col6\" class=\"data row2 col6\" >10.461538</td>\n",
       "                        <td id=\"T_1ea51_row2_col7\" class=\"data row2 col7\" >2.769231</td>\n",
       "                        <td id=\"T_1ea51_row2_col8\" class=\"data row2 col8\" >5.692308</td>\n",
       "                        <td id=\"T_1ea51_row2_col9\" class=\"data row2 col9\" >30.615385</td>\n",
       "                        <td id=\"T_1ea51_row2_col10\" class=\"data row2 col10\" >23.076923</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1ea51_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_1ea51_row3_col0\" class=\"data row3 col0\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row3_col2\" class=\"data row3 col2\" >16.834532</td>\n",
       "                        <td id=\"T_1ea51_row3_col3\" class=\"data row3 col3\" >100.000000</td>\n",
       "                        <td id=\"T_1ea51_row3_col4\" class=\"data row3 col4\" >2.446043</td>\n",
       "                        <td id=\"T_1ea51_row3_col5\" class=\"data row3 col5\" >23.165468</td>\n",
       "                        <td id=\"T_1ea51_row3_col6\" class=\"data row3 col6\" >4.316547</td>\n",
       "                        <td id=\"T_1ea51_row3_col7\" class=\"data row3 col7\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row3_col8\" class=\"data row3 col8\" >5.179856</td>\n",
       "                        <td id=\"T_1ea51_row3_col9\" class=\"data row3 col9\" >23.021583</td>\n",
       "                        <td id=\"T_1ea51_row3_col10\" class=\"data row3 col10\" >21.870504</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1ea51_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_1ea51_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row4_col2\" class=\"data row4 col2\" >2.875399</td>\n",
       "                        <td id=\"T_1ea51_row4_col3\" class=\"data row4 col3\" >5.431310</td>\n",
       "                        <td id=\"T_1ea51_row4_col4\" class=\"data row4 col4\" >100.000000</td>\n",
       "                        <td id=\"T_1ea51_row4_col5\" class=\"data row4 col5\" >37.060703</td>\n",
       "                        <td id=\"T_1ea51_row4_col6\" class=\"data row4 col6\" >7.987220</td>\n",
       "                        <td id=\"T_1ea51_row4_col7\" class=\"data row4 col7\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row4_col8\" class=\"data row4 col8\" >9.265176</td>\n",
       "                        <td id=\"T_1ea51_row4_col9\" class=\"data row4 col9\" >26.837061</td>\n",
       "                        <td id=\"T_1ea51_row4_col10\" class=\"data row4 col10\" >15.654952</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1ea51_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_1ea51_row5_col0\" class=\"data row5 col0\" >3.152088</td>\n",
       "                        <td id=\"T_1ea51_row5_col1\" class=\"data row5 col1\" >1.221434</td>\n",
       "                        <td id=\"T_1ea51_row5_col2\" class=\"data row5 col2\" >5.122143</td>\n",
       "                        <td id=\"T_1ea51_row5_col3\" class=\"data row5 col3\" >6.343578</td>\n",
       "                        <td id=\"T_1ea51_row5_col4\" class=\"data row5 col4\" >4.570528</td>\n",
       "                        <td id=\"T_1ea51_row5_col5\" class=\"data row5 col5\" >100.000000</td>\n",
       "                        <td id=\"T_1ea51_row5_col6\" class=\"data row5 col6\" >7.013396</td>\n",
       "                        <td id=\"T_1ea51_row5_col7\" class=\"data row5 col7\" >0.945626</td>\n",
       "                        <td id=\"T_1ea51_row5_col8\" class=\"data row5 col8\" >9.101655</td>\n",
       "                        <td id=\"T_1ea51_row5_col9\" class=\"data row5 col9\" >21.788810</td>\n",
       "                        <td id=\"T_1ea51_row5_col10\" class=\"data row5 col10\" >12.726556</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1ea51_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_1ea51_row6_col0\" class=\"data row6 col0\" >2.493438</td>\n",
       "                        <td id=\"T_1ea51_row6_col1\" class=\"data row6 col1\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row6_col2\" class=\"data row6 col2\" >8.923885</td>\n",
       "                        <td id=\"T_1ea51_row6_col3\" class=\"data row6 col3\" >3.937008</td>\n",
       "                        <td id=\"T_1ea51_row6_col4\" class=\"data row6 col4\" >3.280840</td>\n",
       "                        <td id=\"T_1ea51_row6_col5\" class=\"data row6 col5\" >23.359580</td>\n",
       "                        <td id=\"T_1ea51_row6_col6\" class=\"data row6 col6\" >100.000000</td>\n",
       "                        <td id=\"T_1ea51_row6_col7\" class=\"data row6 col7\" >1.049869</td>\n",
       "                        <td id=\"T_1ea51_row6_col8\" class=\"data row6 col8\" >7.217848</td>\n",
       "                        <td id=\"T_1ea51_row6_col9\" class=\"data row6 col9\" >32.545932</td>\n",
       "                        <td id=\"T_1ea51_row6_col10\" class=\"data row6 col10\" >11.811024</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1ea51_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_1ea51_row7_col0\" class=\"data row7 col0\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row7_col1\" class=\"data row7 col1\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row7_col2\" class=\"data row7 col2\" >11.612903</td>\n",
       "                        <td id=\"T_1ea51_row7_col3\" class=\"data row7 col3\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row7_col4\" class=\"data row7 col4\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row7_col5\" class=\"data row7 col5\" >15.483871</td>\n",
       "                        <td id=\"T_1ea51_row7_col6\" class=\"data row7 col6\" >5.161290</td>\n",
       "                        <td id=\"T_1ea51_row7_col7\" class=\"data row7 col7\" >100.000000</td>\n",
       "                        <td id=\"T_1ea51_row7_col8\" class=\"data row7 col8\" >5.161290</td>\n",
       "                        <td id=\"T_1ea51_row7_col9\" class=\"data row7 col9\" >47.096774</td>\n",
       "                        <td id=\"T_1ea51_row7_col10\" class=\"data row7 col10\" >14.838710</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1ea51_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_1ea51_row8_col0\" class=\"data row8 col0\" >1.288056</td>\n",
       "                        <td id=\"T_1ea51_row8_col1\" class=\"data row8 col1\" >3.044496</td>\n",
       "                        <td id=\"T_1ea51_row8_col2\" class=\"data row8 col2\" >4.332553</td>\n",
       "                        <td id=\"T_1ea51_row8_col3\" class=\"data row8 col3\" >4.215457</td>\n",
       "                        <td id=\"T_1ea51_row8_col4\" class=\"data row8 col4\" >3.395785</td>\n",
       "                        <td id=\"T_1ea51_row8_col5\" class=\"data row8 col5\" >27.049180</td>\n",
       "                        <td id=\"T_1ea51_row8_col6\" class=\"data row8 col6\" >6.440281</td>\n",
       "                        <td id=\"T_1ea51_row8_col7\" class=\"data row8 col7\" >0.936768</td>\n",
       "                        <td id=\"T_1ea51_row8_col8\" class=\"data row8 col8\" >100.000000</td>\n",
       "                        <td id=\"T_1ea51_row8_col9\" class=\"data row8 col9\" >31.967213</td>\n",
       "                        <td id=\"T_1ea51_row8_col10\" class=\"data row8 col10\" >9.016393</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1ea51_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_1ea51_row9_col0\" class=\"data row9 col0\" >3.077630</td>\n",
       "                        <td id=\"T_1ea51_row9_col1\" class=\"data row9 col1\" >2.250804</td>\n",
       "                        <td id=\"T_1ea51_row9_col2\" class=\"data row9 col2\" >9.141020</td>\n",
       "                        <td id=\"T_1ea51_row9_col3\" class=\"data row9 col3\" >7.349564</td>\n",
       "                        <td id=\"T_1ea51_row9_col4\" class=\"data row9 col4\" >3.858521</td>\n",
       "                        <td id=\"T_1ea51_row9_col5\" class=\"data row9 col5\" >25.401929</td>\n",
       "                        <td id=\"T_1ea51_row9_col6\" class=\"data row9 col6\" >11.391824</td>\n",
       "                        <td id=\"T_1ea51_row9_col7\" class=\"data row9 col7\" >3.353238</td>\n",
       "                        <td id=\"T_1ea51_row9_col8\" class=\"data row9 col8\" >12.540193</td>\n",
       "                        <td id=\"T_1ea51_row9_col9\" class=\"data row9 col9\" >100.000000</td>\n",
       "                        <td id=\"T_1ea51_row9_col10\" class=\"data row9 col10\" >15.847497</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1ea51_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_1ea51_row10_col0\" class=\"data row10 col0\" >1.708706</td>\n",
       "                        <td id=\"T_1ea51_row10_col1\" class=\"data row10 col1\" >0.000000</td>\n",
       "                        <td id=\"T_1ea51_row10_col2\" class=\"data row10 col2\" >12.205045</td>\n",
       "                        <td id=\"T_1ea51_row10_col3\" class=\"data row10 col3\" >12.367779</td>\n",
       "                        <td id=\"T_1ea51_row10_col4\" class=\"data row10 col4\" >3.986981</td>\n",
       "                        <td id=\"T_1ea51_row10_col5\" class=\"data row10 col5\" >26.281530</td>\n",
       "                        <td id=\"T_1ea51_row10_col6\" class=\"data row10 col6\" >7.323027</td>\n",
       "                        <td id=\"T_1ea51_row10_col7\" class=\"data row10 col7\" >1.871440</td>\n",
       "                        <td id=\"T_1ea51_row10_col8\" class=\"data row10 col8\" >6.265256</td>\n",
       "                        <td id=\"T_1ea51_row10_col9\" class=\"data row10 col9\" >28.071603</td>\n",
       "                        <td id=\"T_1ea51_row10_col10\" class=\"data row10 col10\" >100.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1010cba0a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_overlap_df[categories].style.applymap(lambda x: 'background-color : yellow' if x>=20 and x!=100 else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lQgLjQYXl6X"
   },
   "source": [
    "#### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:59.448347Z",
     "iopub.status.busy": "2021-12-31T14:41:59.448095Z",
     "iopub.status.idle": "2021-12-31T14:41:59.457912Z",
     "shell.execute_reply": "2021-12-31T14:41:59.456906Z",
     "shell.execute_reply.started": "2021-12-31T14:41:59.448317Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_spelling(x):\n",
    "    #remove all punctuations before finding possible misspelled words\n",
    "    s = re.sub(r'[^\\w\\s]','',x)\n",
    "#     print(\"Text without punctuations:\\n\",s)\n",
    "    wordlist=s.split()\n",
    "    spell = SpellChecker()\n",
    "    # find those words that may be misspelled\n",
    "    misspelled = list(spell.unknown(wordlist))\n",
    "\n",
    "    return ' '.join([spell.correction(i) if i in misspelled else i for i in x.split(' ')])\n",
    "\n",
    "def fix_fullstops(x):\n",
    "    matches = re.findall('(\\.[a-zA-Z]+)', x)\n",
    "    for i in range(0, len(matches)):\n",
    "        x = x.replace(matches[i], '. ' + matches[i][1:])\n",
    "\n",
    "    matches = re.findall('[a-zA-Z]\\s+\\.', x)\n",
    "    for i in range(0, len(matches)):\n",
    "        x = x.replace(matches[i], matches[i].replace(' ',''))\n",
    "        \n",
    "    return x\n",
    "\n",
    "def fix_combined_words(x):\n",
    "    matches = re.findall('[a-z][a-z][A-Z]',x)\n",
    "\n",
    "    for i in matches:\n",
    "        x = x.replace(i, i[0:2] + \" \" + i[2])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T14:41:59.459876Z",
     "iopub.status.busy": "2021-12-31T14:41:59.459497Z",
     "iopub.status.idle": "2021-12-31T15:00:44.048555Z",
     "shell.execute_reply": "2021-12-31T15:00:44.047640Z",
     "shell.execute_reply.started": "2021-12-31T14:41:59.459834Z"
    }
   },
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "\n",
    "# # Remove reduntant spaces\n",
    "# train_data['Review v1'] = train_data['Review'].progress_apply(lambda x: re.sub(' +', ' ',x))\n",
    "# test_data['Review v1'] = test_data['Review'].progress_apply(lambda x: re.sub(' +', ' ',x))\n",
    "\n",
    "# # Remove multiple fullstops\n",
    "# train_data['Review v1'] = train_data['Review v1'].progress_apply(lambda x: re.sub(r'\\.+', \".\", x))\n",
    "# test_data['Review v1'] = test_data['Review v1'].progress_apply(lambda x: re.sub(r'\\.+', \".\", x))\n",
    "\n",
    "# # Correct spelling\n",
    "# train_data['Review v1'] = train_data['Review v1'].apply(lambda x: correct_spelling(x))\n",
    "# test_data['Review v1'] = test_data['Review v1'].apply(lambda x: correct_spelling(x))\n",
    "\n",
    "# # Fix fullstops\n",
    "# train_data['Review v1'] = train_data['Review v1'].apply(lambda x: fix_fullstops(x))\n",
    "# test_data['Review v1'] = test_data['Review v1'].apply(lambda x: fix_fullstops(x))\n",
    "\n",
    "# # Break combined words\n",
    "# train_data['Review v1'] = train_data['Review v1'].progress_apply(lambda x: fix_combined_words(x))\n",
    "# test_data['Review v1'] = test_data['Review v1'].progress_apply(lambda x: fix_combined_words(x))\n",
    "\n",
    "# train_data['Review'] = train_data['Review'].str.replace('([â€œâ€Â¨Â«Â»Â®Â´Â·ÂºÂ½Â¾Â¿Â¡Â§Â£â‚¤â€˜â€™])', '')\n",
    "\n",
    "# # Break combined words\n",
    "# # train_data['Review v1'] = train_data['Review v1'].progress_apply(lambda x: ' '.join(wordninja.split(x)))\n",
    "# # test_data['Review v1'] = test_data['Review v1'].progress_apply(lambda x: ' '.join(wordninja.split(x)))\n",
    "\n",
    "# # Correct spelling mistakes and grammar\n",
    "# # tool = language_tool_python.LanguageTool('en-US')\n",
    "# # train_data['Review v1'] = train_data['Review v1'].progress_apply(lambda x: tool.correct(x))\n",
    "# # test_data['Review v1'] = test_data['Review v1'].progress_apply(lambda x: tool.correct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(train_data, output_filepath + 'train_data.pkl')\n",
    "# joblib.dump(test_data, output_filepath + 'test_data.pkl')\n",
    "train_data = joblib.load(output_filepath + 'train_data.pkl')\n",
    "test_data = joblib.load(output_filepath + 'test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6136, 15) (2631, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Review</th>\n",
       "      <th>Components</th>\n",
       "      <th>Delivery and Customer Support</th>\n",
       "      <th>Design and Aesthetics</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Features</th>\n",
       "      <th>Functionality</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Material</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Usability</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Review v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>For some reason everybody complains and I'm co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>For some reason everybody complains and I'm co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I like everything about it, great choice of sp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I like everything about it, great choice of sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent ceiling fan brace. Easy to install a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Excellent ceiling fan brace. Easy to install a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Work great easy to use . No issues at all with...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Work great easy to use. No issues at all with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I would recommend this product because it is p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I would recommend this product because it is p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                             Review  Components  \\\n",
       "0   0  For some reason everybody complains and I'm co...           0   \n",
       "1   1  I like everything about it, great choice of sp...           0   \n",
       "2   2  Excellent ceiling fan brace. Easy to install a...           0   \n",
       "3   3  Work great easy to use . No issues at all with...           0   \n",
       "4   4  I would recommend this product because it is p...           0   \n",
       "\n",
       "   Delivery and Customer Support  Design and Aesthetics  Dimensions  Features  \\\n",
       "0                              0                      0           0         0   \n",
       "1                              0                      0           0         1   \n",
       "2                              0                      0           0         0   \n",
       "3                              0                      0           0         0   \n",
       "4                              0                      0           0         0   \n",
       "\n",
       "   Functionality  Installation  Material  Price  Quality  Usability  Polarity  \\\n",
       "0              0             0         0      0        0          1         0   \n",
       "1              1             0         0      0        0          0         1   \n",
       "2              0             1         0      0        1          0         1   \n",
       "3              1             0         0      0        0          1         1   \n",
       "4              0             0         0      0        1          0         1   \n",
       "\n",
       "                                           Review v1  \n",
       "0  For some reason everybody complains and I'm co...  \n",
       "1  I like everything about it, great choice of sp...  \n",
       "2  Excellent ceiling fan brace. Easy to install a...  \n",
       "3  Work great easy to use. No issues at all with ...  \n",
       "4  I would recommend this product because it is p...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:00:44.050360Z",
     "iopub.status.busy": "2021-12-31T15:00:44.050109Z",
     "iopub.status.idle": "2021-12-31T15:00:44.054795Z",
     "shell.execute_reply": "2021-12-31T15:00:44.053811Z",
     "shell.execute_reply.started": "2021-12-31T15:00:44.050331Z"
    }
   },
   "outputs": [],
   "source": [
    "# tool = language_tool_python.LanguageTool('en-US')\n",
    "# tool.correct(train_data['Review'].iloc[6134])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:00:44.056821Z",
     "iopub.status.busy": "2021-12-31T15:00:44.056144Z",
     "iopub.status.idle": "2021-12-31T15:00:44.076352Z",
     "shell.execute_reply": "2021-12-31T15:00:44.075776Z",
     "shell.execute_reply.started": "2021-12-31T15:00:44.056787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"this is a below average camera . The only thing that i can say is decent about it is that in comparison to the kami doorbell on the APP that thus camera hasnt gone offline a million times like the peice of junk doorbell that keeps goimg offline every hour This company's products arent very good at all.. ill be sending back bith the doorbell camera and this camera.. neither the camera or the doorbell is worth the money\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"this is a below average camera. The only thing that i can say is decent about it is that in comparison to the kami doorbell on the APP that thus camera hasnt gone offline a million times like the peice of junk doorbell that keeps going offline every hour This company's products arent very good at all. ill be sending back with the doorbell camera and this camera. neither the camera or the doorbell is worth the money\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 6134\n",
    "print('\\n')\n",
    "display(train_data['Review'].iloc[idx])\n",
    "print('\\n')\n",
    "display(train_data['Review v1'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:00:44.077790Z",
     "iopub.status.busy": "2021-12-31T15:00:44.077523Z",
     "iopub.status.idle": "2021-12-31T15:00:44.091682Z",
     "shell.execute_reply": "2021-12-31T15:00:44.090817Z",
     "shell.execute_reply.started": "2021-12-31T15:00:44.077759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seem to work well, fairly sharp.A little hard to do 1 1/4 inch.Overall a decent PvP pipe cutter.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seem to work well, fairly sharp. A little hard to do 1 1/4 inch. Overall a decent PvP pipe cutter.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 12\n",
    "print('\\n')\n",
    "display(train_data['Review'].iloc[idx])\n",
    "print('\\n')\n",
    "display(train_data['Review v1'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:00:44.093965Z",
     "iopub.status.busy": "2021-12-31T15:00:44.093641Z",
     "iopub.status.idle": "2021-12-31T15:01:05.968615Z",
     "shell.execute_reply": "2021-12-31T15:01:05.967823Z",
     "shell.execute_reply.started": "2021-12-31T15:00:44.093922Z"
    },
    "id": "r8tSABxQXh4I"
   },
   "outputs": [],
   "source": [
    "train_data['Review cleaned for tf-idf']=train_data['Review v1'].apply(lambda x : clean(x,\n",
    "                                                                                    fix_unicode=True,               # fix various unicode errors\n",
    "                                                                                    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "                                                                                    lower=True,                     # lowercase text\n",
    "                                                                                    no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "                                                                                    no_urls=True,                  # replace all URLs with a special token\n",
    "                                                                                    no_emails=True,                # replace all email addresses with a special token\n",
    "                                                                                    no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "                                                                                    no_numbers=True,               # replace all numbers with a special token\n",
    "                                                                                    no_digits=True,                # replace all digits with a special token\n",
    "                                                                                    no_currency_symbols=True,      # replace all currency symbols with a special token\n",
    "                                                                                    no_punct=True,                 # remove punctuations\n",
    "                                                                        ))\n",
    "\n",
    "test_data['Review cleaned for tf-idf']=test_data['Review v1'].apply(lambda x : clean(x,\n",
    "                                                                                    fix_unicode=True,               # fix various unicode errors\n",
    "                                                                                    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "                                                                                    lower=True,                     # lowercase text\n",
    "                                                                                    no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "                                                                                    no_urls=True,                  # replace all URLs with a special token\n",
    "                                                                                    no_emails=True,                # replace all email addresses with a special token\n",
    "                                                                                    no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "                                                                                    no_numbers=True,               # replace all numbers with a special token\n",
    "                                                                                    no_digits=True,                # replace all digits with a special token\n",
    "                                                                                    no_currency_symbols=True,      # replace all currency symbols with a special token\n",
    "                                                                                    no_punct=True,                 # remove punctuations\n",
    "                                                                        ))\n",
    "\n",
    "\n",
    "train_data['Review cleaned for transformers']=train_data['Review v1'].apply(lambda x : clean(x,\n",
    "                                                                          lower=False,\n",
    "                                                                          no_line_breaks=True,\n",
    "                                                                          no_urls=True,\n",
    "                                                                          no_emails=True, \n",
    "                                                                          no_phone_numbers=True,\n",
    "#                                                                           no_punct=True\n",
    "                                                                        ))\n",
    "\n",
    "test_data['Review cleaned for transformers']=test_data['Review v1'].apply(lambda x : clean(x,\n",
    "                                                                          lower=False,\n",
    "                                                                          no_line_breaks=True,\n",
    "                                                                          no_urls=True,\n",
    "                                                                          no_emails=True, \n",
    "                                                                          no_phone_numbers=True,\n",
    "#                                                                           no_punct=True\n",
    "                                                                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:01:05.970107Z",
     "iopub.status.busy": "2021-12-31T15:01:05.969883Z",
     "iopub.status.idle": "2021-12-31T15:01:06.932744Z",
     "shell.execute_reply": "2021-12-31T15:01:06.931875Z",
     "shell.execute_reply.started": "2021-12-31T15:01:05.970080Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Stemming\n",
    "# ps = PorterStemmer()\n",
    "# train_data['Review cleaned for tf-idf'] = train_data['Review cleaned for tf-idf'].apply(lambda x: ' '.join([ps.stem(word) for word in x.split(' ')]))\n",
    "# test_data['Review cleaned for tf-idf'] = test_data['Review cleaned for tf-idf'].apply(lambda x: ' '.join([ps.stem(word) for word in x.split(' ')]))\n",
    "\n",
    "# Lemmitize\n",
    "lmtzr = WordNetLemmatizer()\n",
    "train_data['Review cleaned for tf-idf'] = train_data['Review cleaned for tf-idf'].apply(lambda x: ' '.join([lmtzr.lemmatize(word) for word in x.split(' ')]))\n",
    "test_data['Review cleaned for tf-idf'] = test_data['Review cleaned for tf-idf'].apply(lambda x: ' '.join([lmtzr.lemmatize(word) for word in x.split(' ')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:01:06.934604Z",
     "iopub.status.busy": "2021-12-31T15:01:06.934326Z",
     "iopub.status.idle": "2021-12-31T15:01:06.944337Z",
     "shell.execute_reply": "2021-12-31T15:01:06.943482Z",
     "shell.execute_reply.started": "2021-12-31T15:01:06.934554Z"
    },
    "id": "l1co3K4oXiCd",
    "outputId": "6d3099a1-69c1-44db-a15d-03dbf539a938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Yellow sprinkler made from pretty thin plastic. Although that doesn't stop it from being sturdy and seemingly tough. It hooked up to my hose with no problem or leaks which is a plusSee more\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yellow sprinkler made from pretty thin plastic although that doesnt stop it from being sturdy and seemingly tough it hooked up to my hose with no problem or leak which is a plus see more'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 9\n",
    "print('\\n')\n",
    "display(train_data['Review'].iloc[idx])\n",
    "print('\\n')\n",
    "display(train_data['Review cleaned for tf-idf'].iloc[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8c9ef70",
    "papermill": {
     "duration": 0.030061,
     "end_time": "2021-12-27T11:31:49.863491",
     "exception": false,
     "start_time": "2021-12-27T11:31:49.83343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:01:06.945928Z",
     "iopub.status.busy": "2021-12-31T15:01:06.945662Z",
     "iopub.status.idle": "2021-12-31T15:01:06.955062Z",
     "shell.execute_reply": "2021-12-31T15:01:06.954336Z",
     "shell.execute_reply.started": "2021-12-31T15:01:06.945899Z"
    }
   },
   "outputs": [],
   "source": [
    "category = 'Usability'\n",
    "model_logloss_on_valid_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:01:06.957532Z",
     "iopub.status.busy": "2021-12-31T15:01:06.957293Z",
     "iopub.status.idle": "2021-12-31T15:01:06.973888Z",
     "shell.execute_reply": "2021-12-31T15:01:06.973154Z",
     "shell.execute_reply.started": "2021-12-31T15:01:06.957503Z"
    }
   },
   "outputs": [],
   "source": [
    "def classification_metrics(y_true, y_prob):\n",
    "    '''\n",
    "     Calculates classification metrics\n",
    "    :param y_true: true label\n",
    "    :param y_prob: probabilitites of true label\n",
    "    :param thrshold: threshold\n",
    "    :return: metrics\n",
    "    '''\n",
    "    \n",
    "    # calculating auroc values\n",
    "    fpr_rf, tpr_rf,thresholds = roc_curve(y_true, y_prob)\n",
    "    roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "    optimal_idx = np.argmax(tpr_rf - fpr_rf)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "        \n",
    "#         print(optimal_threshold)\n",
    "#         print(\"=====\"*20) \n",
    "#     if optimal_cal==False:\n",
    "#         optimal_threshold = thrshold   \n",
    "     \n",
    "    # generating prediction on the basis of certain threshold\n",
    "    y_pred = np.where(y_prob >= optimal_threshold, 1, 0)\n",
    "\n",
    "    # calculating tp,tn,fp,fn from confusion metrics\n",
    "    tn, fp, fn, tp = (confusion_matrix(y_true, y_pred)).ravel()\n",
    "\n",
    "    # calculating auprc\n",
    "    average_precision = average_precision_score(y_true, y_prob)\n",
    "\n",
    "    # calculating precision,recall and f1 sscore and accuracy\n",
    "    precision = (precision_score(y_true, y_pred))\n",
    "    recall = (recall_score(y_true, y_pred))\n",
    "    accuracy = (accuracy_score(y_true, y_pred))\n",
    "    f1_accuracy = (f1_score(y_true, y_pred))\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "    kappa_score = cohen_kappa_score(y_true, y_pred, labels=None, weights=None)\n",
    "    binary_cross_entropy=log_loss(y_true, y_prob)\n",
    "    # creating dictionary of classification metric\n",
    "    target_mean=np.mean(y_true)\n",
    "    classification_metric_dict = {\"True_negatives\": tn,\n",
    "                                  \"False_positives\": fp,\n",
    "                                  \"False_negatives\": fn,\n",
    "                                  \"True_positives\": tp,\n",
    "                                  \"Accuracy\": accuracy,\n",
    "                                  \"Recall\": recall,\n",
    "                                  \"Precision\": precision,\n",
    "                                  \"f1_score\": f1_accuracy,\n",
    "                                  \"PR_AUC\": average_precision,\n",
    "                                  \"ROC_AUC\": roc_auc_rf,\n",
    "                                  \"Kappa Score\": kappa_score,\n",
    "                                  \"binary_cross_entropy\":binary_cross_entropy,\n",
    "                                  \"target_imbalance\":target_mean,\n",
    "                                  \"target_size\":len(y_true),\n",
    "                                  'optimal_threshold':optimal_threshold\n",
    "                                  }\n",
    "\n",
    "    return classification_metric_dict, optimal_threshold\n",
    "\n",
    "def classification_metrics_train(y_true, y_prob,threshold):\n",
    "    '''\n",
    "     Calculates classification metrics\n",
    "    :param y_true: true label\n",
    "    :param y_prob: probabilitites of true label\n",
    "    :param thrshold: threshold\n",
    "    :return: metrics\n",
    "    '''\n",
    "    \n",
    "    # calculating auroc values\n",
    "    fpr_rf, tpr_rf,thresholds = roc_curve(y_true, y_prob)\n",
    "    roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "#     optimal_idx = np.argmax(tpr_rf - fpr_rf)\n",
    "    optimal_threshold = threshold\n",
    "        \n",
    "#         print(optimal_threshold)\n",
    "#         print(\"=====\"*20) \n",
    "#     if optimal_cal==False:\n",
    "#         optimal_threshold = thrshold   \n",
    "     \n",
    "    # generating prediction on the basis of certain threshold\n",
    "    y_pred = np.where(y_prob >= optimal_threshold, 1, 0)\n",
    "\n",
    "    # calculating tp,tn,fp,fn from confusion metrics\n",
    "    tn, fp, fn, tp = (confusion_matrix(y_true, y_pred)).ravel()\n",
    "\n",
    "    # calculating auprc\n",
    "    average_precision = average_precision_score(y_true, y_prob)\n",
    "\n",
    "    # calculating precision,recall and f1 sscore and accuracy\n",
    "    precision = (precision_score(y_true, y_pred))\n",
    "    recall = (recall_score(y_true, y_pred))\n",
    "    accuracy = (accuracy_score(y_true, y_pred))\n",
    "    f1_accuracy = (f1_score(y_true, y_pred))\n",
    "    from sklearn.metrics import cohen_kappa_score\n",
    "    kappa_score = cohen_kappa_score(y_true, y_pred, labels=None, weights=None)\n",
    "    binary_cross_entropy=log_loss(y_true, y_prob)\n",
    "    # creating dictionary of classification metric\n",
    "    target_mean=np.mean(y_true)\n",
    "    classification_metric_dict = {\"True_negatives\": tn,\n",
    "                                  \"False_positives\": fp,\n",
    "                                  \"False_negatives\": fn,\n",
    "                                  \"True_positives\": tp,\n",
    "                                  \"Accuracy\": accuracy,\n",
    "                                  \"Recall\": recall,\n",
    "                                  \"Precision\": precision,\n",
    "                                  \"f1_score\": f1_accuracy,\n",
    "                                  \"PR_AUC\": average_precision,\n",
    "                                  \"ROC_AUC\": roc_auc_rf,\n",
    "                                  \"Kappa Score\": kappa_score,\n",
    "                                  \"binary_cross_entropy\":binary_cross_entropy,\n",
    "                                  \"target_imbalance\":target_mean,\n",
    "                                  \"target_size\":len(y_true),\n",
    "                                  'optimal_thresh':optimal_threshold\n",
    "                                  }\n",
    "\n",
    "    return classification_metric_dict, optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:01:06.975731Z",
     "iopub.status.busy": "2021-12-31T15:01:06.975211Z",
     "iopub.status.idle": "2021-12-31T15:01:06.993379Z",
     "shell.execute_reply": "2021-12-31T15:01:06.992458Z",
     "shell.execute_reply.started": "2021-12-31T15:01:06.975696Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_bert_embeddings(data,column_name,hf_model):\n",
    "    sentences=data[column_name].tolist()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(hf_model)\n",
    "    model = AutoModel.from_pretrained(hf_model)\n",
    "\n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "    #Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        sentence_embeddings = model_output[0][:,0] #Take the first token ([CLS]) from each sentence \n",
    "\n",
    "\n",
    "    df=pd.DataFrame(sentence_embeddings)\n",
    "    cols = [\"bert_vector\"+\"_\"+str(i) for i in np.arange(0,df.shape[1],1)]\n",
    "    df.columns=cols\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_embeddings_all_tokens(data,column_name,hf_model):\n",
    "    sentences=data[column_name].tolist()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(hf_model)\n",
    "    model = AutoModel.from_pretrained(hf_model)\n",
    "\n",
    "    #Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "    #Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        sentence_embeddings = model_output\n",
    "\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:01:06.995373Z",
     "iopub.status.busy": "2021-12-31T15:01:06.994679Z",
     "iopub.status.idle": "2021-12-31T15:01:21.498560Z",
     "shell.execute_reply": "2021-12-31T15:01:21.497485Z",
     "shell.execute_reply.started": "2021-12-31T15:01:06.995340Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "sample_data_with_embeddings = generate_bert_embeddings(train_data.head(10),'Review cleaned for transformers','bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:01:21.500655Z",
     "iopub.status.busy": "2021-12-31T15:01:21.500385Z",
     "iopub.status.idle": "2021-12-31T15:01:21.564377Z",
     "shell.execute_reply": "2021-12-31T15:01:21.563510Z",
     "shell.execute_reply.started": "2021-12-31T15:01:21.500621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_vector_0</th>\n",
       "      <th>bert_vector_1</th>\n",
       "      <th>bert_vector_2</th>\n",
       "      <th>bert_vector_3</th>\n",
       "      <th>bert_vector_4</th>\n",
       "      <th>bert_vector_5</th>\n",
       "      <th>bert_vector_6</th>\n",
       "      <th>bert_vector_7</th>\n",
       "      <th>bert_vector_8</th>\n",
       "      <th>bert_vector_9</th>\n",
       "      <th>...</th>\n",
       "      <th>bert_vector_758</th>\n",
       "      <th>bert_vector_759</th>\n",
       "      <th>bert_vector_760</th>\n",
       "      <th>bert_vector_761</th>\n",
       "      <th>bert_vector_762</th>\n",
       "      <th>bert_vector_763</th>\n",
       "      <th>bert_vector_764</th>\n",
       "      <th>bert_vector_765</th>\n",
       "      <th>bert_vector_766</th>\n",
       "      <th>bert_vector_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(0.2107)</td>\n",
       "      <td>tensor(0.2158)</td>\n",
       "      <td>tensor(0.5855)</td>\n",
       "      <td>tensor(-0.0907)</td>\n",
       "      <td>tensor(-0.2704)</td>\n",
       "      <td>tensor(-0.0747)</td>\n",
       "      <td>tensor(0.7379)</td>\n",
       "      <td>tensor(0.5830)</td>\n",
       "      <td>tensor(-0.0008)</td>\n",
       "      <td>tensor(-0.3145)</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(0.0529)</td>\n",
       "      <td>tensor(-0.1027)</td>\n",
       "      <td>tensor(0.4311)</td>\n",
       "      <td>tensor(-0.0566)</td>\n",
       "      <td>tensor(0.1803)</td>\n",
       "      <td>tensor(-0.1710)</td>\n",
       "      <td>tensor(-0.2593)</td>\n",
       "      <td>tensor(-0.5233)</td>\n",
       "      <td>tensor(0.3661)</td>\n",
       "      <td>tensor(0.2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(-0.0143)</td>\n",
       "      <td>tensor(0.0696)</td>\n",
       "      <td>tensor(0.4433)</td>\n",
       "      <td>tensor(-0.4125)</td>\n",
       "      <td>tensor(-0.3873)</td>\n",
       "      <td>tensor(-0.1219)</td>\n",
       "      <td>tensor(0.5172)</td>\n",
       "      <td>tensor(0.5470)</td>\n",
       "      <td>tensor(-0.0646)</td>\n",
       "      <td>tensor(-0.3856)</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(-0.0455)</td>\n",
       "      <td>tensor(-0.3467)</td>\n",
       "      <td>tensor(0.3907)</td>\n",
       "      <td>tensor(-0.0726)</td>\n",
       "      <td>tensor(0.1909)</td>\n",
       "      <td>tensor(-0.3983)</td>\n",
       "      <td>tensor(-0.1877)</td>\n",
       "      <td>tensor(-0.4139)</td>\n",
       "      <td>tensor(-0.1814)</td>\n",
       "      <td>tensor(0.3416)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(-0.6205)</td>\n",
       "      <td>tensor(0.0264)</td>\n",
       "      <td>tensor(0.0105)</td>\n",
       "      <td>tensor(-0.1495)</td>\n",
       "      <td>tensor(0.1507)</td>\n",
       "      <td>tensor(-0.1211)</td>\n",
       "      <td>tensor(-0.2142)</td>\n",
       "      <td>tensor(0.5498)</td>\n",
       "      <td>tensor(0.1476)</td>\n",
       "      <td>tensor(-0.2173)</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(-0.2133)</td>\n",
       "      <td>tensor(-0.3121)</td>\n",
       "      <td>tensor(0.0672)</td>\n",
       "      <td>tensor(-0.2336)</td>\n",
       "      <td>tensor(-0.0394)</td>\n",
       "      <td>tensor(0.0042)</td>\n",
       "      <td>tensor(-0.2783)</td>\n",
       "      <td>tensor(0.2061)</td>\n",
       "      <td>tensor(-0.0538)</td>\n",
       "      <td>tensor(0.1289)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(-0.1411)</td>\n",
       "      <td>tensor(-0.1596)</td>\n",
       "      <td>tensor(0.0088)</td>\n",
       "      <td>tensor(-0.0330)</td>\n",
       "      <td>tensor(-0.2143)</td>\n",
       "      <td>tensor(-0.3719)</td>\n",
       "      <td>tensor(0.2877)</td>\n",
       "      <td>tensor(0.4825)</td>\n",
       "      <td>tensor(0.2281)</td>\n",
       "      <td>tensor(-0.1451)</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(-0.0117)</td>\n",
       "      <td>tensor(-0.3318)</td>\n",
       "      <td>tensor(0.2371)</td>\n",
       "      <td>tensor(0.0192)</td>\n",
       "      <td>tensor(0.0743)</td>\n",
       "      <td>tensor(-0.2631)</td>\n",
       "      <td>tensor(-0.5102)</td>\n",
       "      <td>tensor(-0.4481)</td>\n",
       "      <td>tensor(-0.0046)</td>\n",
       "      <td>tensor(0.3295)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(-0.0320)</td>\n",
       "      <td>tensor(-0.4658)</td>\n",
       "      <td>tensor(-0.1238)</td>\n",
       "      <td>tensor(-0.3555)</td>\n",
       "      <td>tensor(-0.1672)</td>\n",
       "      <td>tensor(-0.2361)</td>\n",
       "      <td>tensor(0.2732)</td>\n",
       "      <td>tensor(0.6692)</td>\n",
       "      <td>tensor(-0.0600)</td>\n",
       "      <td>tensor(-0.2513)</td>\n",
       "      <td>...</td>\n",
       "      <td>tensor(-0.2384)</td>\n",
       "      <td>tensor(-0.0466)</td>\n",
       "      <td>tensor(-0.2053)</td>\n",
       "      <td>tensor(-0.1565)</td>\n",
       "      <td>tensor(-0.0702)</td>\n",
       "      <td>tensor(0.0777)</td>\n",
       "      <td>tensor(-0.5283)</td>\n",
       "      <td>tensor(-0.2277)</td>\n",
       "      <td>tensor(0.3763)</td>\n",
       "      <td>tensor(0.4081)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bert_vector_0    bert_vector_1    bert_vector_2    bert_vector_3  \\\n",
       "0   tensor(0.2107)   tensor(0.2158)   tensor(0.5855)  tensor(-0.0907)   \n",
       "1  tensor(-0.0143)   tensor(0.0696)   tensor(0.4433)  tensor(-0.4125)   \n",
       "2  tensor(-0.6205)   tensor(0.0264)   tensor(0.0105)  tensor(-0.1495)   \n",
       "3  tensor(-0.1411)  tensor(-0.1596)   tensor(0.0088)  tensor(-0.0330)   \n",
       "4  tensor(-0.0320)  tensor(-0.4658)  tensor(-0.1238)  tensor(-0.3555)   \n",
       "\n",
       "     bert_vector_4    bert_vector_5    bert_vector_6   bert_vector_7  \\\n",
       "0  tensor(-0.2704)  tensor(-0.0747)   tensor(0.7379)  tensor(0.5830)   \n",
       "1  tensor(-0.3873)  tensor(-0.1219)   tensor(0.5172)  tensor(0.5470)   \n",
       "2   tensor(0.1507)  tensor(-0.1211)  tensor(-0.2142)  tensor(0.5498)   \n",
       "3  tensor(-0.2143)  tensor(-0.3719)   tensor(0.2877)  tensor(0.4825)   \n",
       "4  tensor(-0.1672)  tensor(-0.2361)   tensor(0.2732)  tensor(0.6692)   \n",
       "\n",
       "     bert_vector_8    bert_vector_9  ...  bert_vector_758  bert_vector_759  \\\n",
       "0  tensor(-0.0008)  tensor(-0.3145)  ...   tensor(0.0529)  tensor(-0.1027)   \n",
       "1  tensor(-0.0646)  tensor(-0.3856)  ...  tensor(-0.0455)  tensor(-0.3467)   \n",
       "2   tensor(0.1476)  tensor(-0.2173)  ...  tensor(-0.2133)  tensor(-0.3121)   \n",
       "3   tensor(0.2281)  tensor(-0.1451)  ...  tensor(-0.0117)  tensor(-0.3318)   \n",
       "4  tensor(-0.0600)  tensor(-0.2513)  ...  tensor(-0.2384)  tensor(-0.0466)   \n",
       "\n",
       "   bert_vector_760  bert_vector_761  bert_vector_762  bert_vector_763  \\\n",
       "0   tensor(0.4311)  tensor(-0.0566)   tensor(0.1803)  tensor(-0.1710)   \n",
       "1   tensor(0.3907)  tensor(-0.0726)   tensor(0.1909)  tensor(-0.3983)   \n",
       "2   tensor(0.0672)  tensor(-0.2336)  tensor(-0.0394)   tensor(0.0042)   \n",
       "3   tensor(0.2371)   tensor(0.0192)   tensor(0.0743)  tensor(-0.2631)   \n",
       "4  tensor(-0.2053)  tensor(-0.1565)  tensor(-0.0702)   tensor(0.0777)   \n",
       "\n",
       "   bert_vector_764  bert_vector_765  bert_vector_766 bert_vector_767  \n",
       "0  tensor(-0.2593)  tensor(-0.5233)   tensor(0.3661)  tensor(0.2006)  \n",
       "1  tensor(-0.1877)  tensor(-0.4139)  tensor(-0.1814)  tensor(0.3416)  \n",
       "2  tensor(-0.2783)   tensor(0.2061)  tensor(-0.0538)  tensor(0.1289)  \n",
       "3  tensor(-0.5102)  tensor(-0.4481)  tensor(-0.0046)  tensor(0.3295)  \n",
       "4  tensor(-0.5283)  tensor(-0.2277)   tensor(0.3763)  tensor(0.4081)  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_with_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T16:37:58.792350Z",
     "iopub.status.busy": "2021-12-31T16:37:58.791994Z",
     "iopub.status.idle": "2021-12-31T16:37:59.141702Z",
     "shell.execute_reply": "2021-12-31T16:37:59.140692Z",
     "shell.execute_reply.started": "2021-12-31T16:37:58.792312Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate_bert_embeddings(train_data,'Review cleaned for transformers','emilyalsentzer/bert-base-uncased')\n",
    "vectorizer = TfidfVectorizer(stop_words='english',ngram_range=(1, 1))\n",
    "\n",
    "train_df, valid_df  = sk_model_selection.train_test_split(\n",
    "    train_data, \n",
    "    test_size=0.2, \n",
    "    random_state=SEED,\n",
    "    stratify = train_data[category])\n",
    "\n",
    "X_train = train_df['Review cleaned for tf-idf']\n",
    "y_train = train_df[category]\n",
    "X_valid = valid_df['Review cleaned for tf-idf']\n",
    "y_valid = valid_df[category]\n",
    "\n",
    "X_train = pd.DataFrame(vectorizer.fit_transform(X_train).todense())\n",
    "X_valid = pd.DataFrame(vectorizer.transform(X_valid).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T16:38:04.748138Z",
     "iopub.status.busy": "2021-12-31T16:38:04.747854Z",
     "iopub.status.idle": "2021-12-31T16:38:04.780085Z",
     "shell.execute_reply": "2021-12-31T16:38:04.779137Z",
     "shell.execute_reply.started": "2021-12-31T16:38:04.748108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6013</th>\n",
       "      <th>6014</th>\n",
       "      <th>6015</th>\n",
       "      <th>6016</th>\n",
       "      <th>6017</th>\n",
       "      <th>6018</th>\n",
       "      <th>6019</th>\n",
       "      <th>6020</th>\n",
       "      <th>6021</th>\n",
       "      <th>6022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 6023 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  6013  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   6014  6015  6016  6017  6018  6019  6020  6021  6022  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 6023 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:01:21.793455Z",
     "iopub.status.busy": "2021-12-31T15:01:21.792803Z",
     "iopub.status.idle": "2021-12-31T15:02:01.030705Z",
     "shell.execute_reply": "2021-12-31T15:02:01.029878Z",
     "shell.execute_reply.started": "2021-12-31T15:01:21.793421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA39klEQVR4nO3deXwV1f3/8deHsIRAgLCIQNhFlrATEFwouCIq1hVQq7YurZXW2mpdf6LUfrtpa2ltKbUutXVB1BapC2IBlYISkH2XNawhrAkQCDm/P2ZyuQlJuIHczE3u+/l45MHM3Jl733dyuZ/MzJlzzDmHiIhIrKkRdAAREZGSqECJiEhMUoESEZGYpAIlIiIxSQVKRERikgqUiIjEpKgVKDN70cx2mtnSUh43MxtvZmvNbLGZ9Y1WFhERqXqieQT1MjCsjMcvBzr5P3cDf45iFhERqWKiVqCcc58Cu8tY5Wrg784zF2hkZi2ilUdERKqWmgG+ditgc9h8pr9sW/EVzexuvKMs6tWr169Lly6VElBERKJv/vz5u5xzzYovD7JARcw5NxGYCJCenu4yMjICTiQiIhXFzDaWtDzIVnxbgNZh86n+MhERkUAL1BTgVr8130Bgn3PuhNN7IiISn6J2is/MXgeGAE3NLBMYC9QCcM5NAN4HhgNrgYPAt6OVRUREqp6oFSjn3OiTPO6Ae6P1+iIiUrWpJwkREYlJKlAiIhKTVKBERCQmqUCJiEhMqhI36oqISPAOHz1G1oE8tu8/zNa9hzh6zHHeWU1o0bBuVF5PBUpEJI4dPVbAzgN5bNlziG37DpF1II+sA3ms35XLzgN5HMkvYOu+Q+w9eLTE7f/yrX4qUCIiEjnnHFk5XuHZtPsgm3cfZMveQ2zde5js3Dz25B5l54HDHD3mSty+VoKRWDOBJvVr0yu1Ec2S61C/Tk2aN0gkNaUuZzZMJCWpNqkp0SlOoAIlIlLlHCtw7DxwmI3ZB9mwK5eNuw+SuecQO/YfDh0JFZRcdwBoUq82zRsk0qt1Q85ITqRZch3OSK5DakoSqSl1aZZch8RaCZX3hkqhAiUiEmMOHD7K+l25rMvKZf2uXDbvOciWPYfYsvcQ2/Yd5lgp1SexVg3aNE5iYIcmnNkwkdRGdUltnETbxkmkNk6ieXIdaiZUnbZxKlAiIpVs78EjrN2Zw9dZOazblctm/wgoc88hduceKXGbWglGy0Z16d8uhVaNkmjduC5tmyTRrkk92japR0pSLcyskt9JdKlAiYhUsMNHj7EhO5clmfvYkJ3L5t2HvNNwuw+SXUoBSk6sSatGdenXNoW2jZNo17QeHZrWo13TejRvkEhCjepVfCKhAiUicgr2HjzCmp05LN2yj5XbDrBp90Ey9x5k8+5DJa5fr3YCrRsn0a9tSqj4dDyjPh2a1qNxvdrV7uinIqhAiYiUYnfuEVZu38/q7QdYtnU/q3fmlHkU1KJhIgM7NKZt43q0aZJEtxYN6NIimebJidSIwyOg06UCJSJx7fDRYyzftp+V2w6wZucBVmzbz6rtB9hTyn0/zRvU4YJOTencPJkOzerTqXl9urVoQL06+jqtaNqjIlLtFd4TtGDjHlZsO8DarBxWbz/Amp05Ja7fomEiA9on0/XMZNJaNaRz82TObp5M3drBN72OJypQIlJtFBQ4Nu0+SMbGPazYtp81O3P4emcOW/aeeF2oYd1a9EptSPum9Uhr2ZDebRpxdvNkGtatFUByKYkKlIhUOQUFjg3ZuSzcvJc5X2ezflcuizP3ceRYwQnrtm5cl8FnN+OsZvXpkdqAvm1SaJ2SpGtCVYAKlIjEtJ0HDjNv/R4yNu5mSeY+Vu84wP7D+Ses16JhIm2bJNG3TQq9WjeiX9sUmtavE0BiqSgqUCISE47kF7Bw814WbNrD/77OZmN2LhuzD56wXqOkWpx3VhO6ntmAAe0b06dNCs2SVYiqIxUoEal0u3LyyNiwm1mrd7FmxwEyNu4pcb30tim0b1qP8zs1pW+bFFJT6up+oTiiAiUiUeOcI3PPIWatzmL+xj0s2ryXdbtyT1ivbZMkOjStx8AOTejfvjE9WjWkVhXqM06iQwVKRCrMxuxcZqzcycLNe5m7bjfb9x8+YZ0uZybTM7UhAzs0YWCHJrRsFL3hGqRqU4ESkVOybd8hZq/N5pMVO1izM4e1xe4pqlOzBt1aNOC8s5rQr20K557VlAaJasItkVOBEpGTys3LZ9bqLOZ8nc2cddknFCPwrhd1bdGAC7ucwTkdGpNUW18vcnr0CRKRIgoKHIsy9/Lhsu18tXEvizL3kpdf9P6is86oz8AOjRnUoSnnd2qqm1slKlSgROLcvoNH+XDZNj5evoN5G/aw71DRPuiaN6hDervGDOzQhEu6NufMhokBJZV4owIlEmfW7jzAv77ayqdrslicue+Exzs3T+bcs5owvEcL+rZJictxiCQ2qECJVGMFBY4vN+xmyqKtfL5mF5t2F73xNal2Av3bNebirmdwRc+WNK5XO6CkIidSgRKpRvKPFfDpmiymLtrGZ2t3kXUgr8jjLRomct5ZTbmqV0vO7dhE9xpJTFOBEqnCjhU4Pl2dxZRFW5m5aucJYxh1bFaPi7o256qeLeneqoF6YZAqRQVKpApxzjF33W7eWZDJjFU72ZVTdGTXLmcmc0m35nyzTys6NqsfUEqRiqECJRLj1uw4wOtfbubjFdvZvLvouEadm3sF6dq+reiggiTVjAqUSIzZk3uESRmb+c+SbSe0smvbJImLujTnxv6pdDmzQUAJRSqHCpRIwAoKHDNX7+TNeZuZsTKryKB7KUm1GNr5DG7s35pz2jfWNSSJKypQIgHYuf8w/5i7kalLtrEuq2jv3ud2bMI1fVpxVa+WJNZKCCihSPBUoEQqgXOOOeuy+ecXm5i2bDtHj7nQY60b12V4jxZ8a2BbUlOSAkwpEltUoESi5PDRY/zrqy28mbGZrzbtLfLY4LObcdOA1lzctTk1dS+SSImiWqDMbBjweyABeME598tij7cBXgEa+es87Jx7P5qZRKJpT+4R/jF3I5MXZBYZrjwlqRZX9WrJrYPacdYZam0nEomoFSgzSwCeBy4BMoF5ZjbFObc8bLXHgUnOuT+bWTfgfaBdtDKJRMP2fYf562fr+NdXW8jOPX5fUqcz6nNdv1RuOqeNxkESOQXRPIIaAKx1zq0DMLM3gKuB8ALlgMK2sg2BrVHMI1Jh1mXl8H/vr2D6ip1Flqe3TWH0gDZc3bulTt2JnKZoFqhWwOaw+UzgnGLrPAlMM7MfAPWAi6OYR+S0bN59kHFTl/Px8h1FlvdMbcgPLuzExV3PUDNwkQoUdCOJ0cDLzrlnzWwQ8KqZdXfOFRkdzczuBu4GaNOmTQAxJV7tysnj5/9ZwbtfbSmyvEPTejx4WWcu79EioGQi1V80C9QWoHXYfKq/LNwdwDAA59wcM0sEmgJFzps45yYCEwHS09MdIlF0+Ogxfvfxav7y6boiy1NT6vLTYV24qmcLHSmJVIJoFqh5QCcza49XmEYBNxVbZxNwEfCymXUFEoGsKGYSKZFzjrcyMvnVhyuLNHRISarF/ZeczS3ntKWGBu4TqVRRK1DOuXwzGwN8hNeE/EXn3DIzGwdkOOemAD8B/mpm9+M1mLjdOacjJKk0y7fu59F3l7Bw894iy787uAP3X3K2enIQCVBUr0H59zS9X2zZE2HTy4HzoplBpLjDR4/xyw9W8vL/NhRZfnHX5jz9ze6c2TAxmGAiUkTQjSREKs3na3bx6LtLigx73qZxEj+/pjsXdGoWYDIRKYkKlFRrh48eY9zU5bz2xaYiy7/7jQ785JLO1K6pe5VEYpUKlFRLCzfv5ceTFhbpKTytZQOevbGXxlESqSJUoKTacM7x51lf8+sPVxVZPmboWfzo4k7q2UGkilGBkipvT+4RHpy8qEi3Q+2aJPHMDb1Ib9c4wGQicjpUoKTKWrplH2NeW8CGsF7Dr+jZgl9c20Ods4pUAyctUGaWCvwBOB/vXqXPgPucc5lRziZSoqmLt/LjSYs4kn+8R6zHr+jKHee3Vw8PItVIJEdQLwGvATf487f4yy6JViiR4kq6vtQsuQ7jR/VhUMcmASYTkWiJpEA1c869FDb/spn9KEp5RIrIP1bA0/9ZUeSm2h6tGvKnm/vSurGGRxepziIpUNlmdgvwuj8/GsiOXiQRyMs/xsNvLynSi/jFXc/gdyN7k6zrSyJxIZIC9R28a1C/w7sG9T/g29EMJfHr8NFj/HjSQt5fsj20bGR6a56+pju11ExcJK6ctEA55zYCIyohi8Sxw0ePcf+bC/lg6fHCdOf57Xl0eFf1Ii4Sp0otUGb2U+fcr83sD3hHTkU4534Y1WQSF47kF/Dg5EX8e+HW0LLvD+nIg5d1Vos8kThX1hHUCv/fjMoIIvGloMDxxJSl/GPu8T7yvveNjjw0TIVJRDylFijn3Hv+5EHn3Fvhj5nZDSVsInJSzjn++N+1PPvx6tCy2wa1ZexVaTqVJyJFRNJI4hHgrQiWiZTp3wu3cN8bC0PzI3q15Nkbe6nxg4iUqKxrUJcDw4FWZjY+7KEGQH60g0n1sWjzXkb/dS4HjxwDYGCHxvz11nQ1FxeRMpV1BLUV7/rTCGB+2PIDwP3RDCXVQ3ZOHrf87UtWbNsPQNsmSfzzznNITdENtiJycmVdg1oELDKz15xzRysxk1RxBQWOR95ZwpsZmwEwgzfuGsg5HdQlkYhELpJrUO3M7BdANyCxcKFzrkPUUkmV9a+vtvCjNxeG5p8akcZt57YLLI+IVF2RdhY7Fq8niaF4vUjoqrYUsXn3Qa750//YlZMHwJU9W/D7UX1IUMs8ETlFkRSous65T8zM/F4lnjSz+cATUc4mVUBBgeOBtxbxjt9nXouGibx9z7m0bFQ34GQiUtVFUqDyzKwGsMbMxgBbgPrRjSVVwScrdnDHK8fv4/7D6D5c1atlgIlEpDqJpEDdByQBPwR+hnea77ZohpLYlpuXz6iJc1myZR8Aw3ucyR9G99XpPBGpUGUWKDNLAEY65x4AclAv5nHvzzO/5lcfrgSgdkINpvzgPLqc2SDgVCJSHZVZoJxzx8zs/MoKI7Fr+77DDPzFJ6H5MUPP4oHLOgeYSESqu0hO8X1lZlPwujbKLVzonHsnaqkkptz8wlxmrz0+RuWMB4bQvmm9ABOJSDyIpEAl4o2ge2HYMgeoQFVz+w4epde4aaH5Dk3r8d8HhgQXSETiSiQDFuq6Uxwa+++lvDJnY2h+2v2DObt5coCJRCTeRHIEJXGkoMDR4dH3Q/NJtRNYPm5YgIlEJF6pQEnIp6uzuPXFL0PzL9yazsXdmgeYSETimQqUADDsuU9Zuf1AaH7d/w3XAIIiEqiT9qlnZs3N7G9m9oE/383M7oh+NKkMR/ILaPfwf0LF6bq+qWz45RUqTiISuEg6fX0Z+Ago7MNmNfCjKOWRSjRrdRZnP/5BaH7mA0N49sZeASYSETkuklN8TZ1zk8zsEQDnXL6ZHYtyLomy21/6kpmrskLz638xHDMdNYlI7IikQOWaWRO8e58ws4HAvqimkqhxztH+keOt9L7ZuyXPjeoTYCIRkZJFUqB+DEwBOprZbKAZcH1UU0lU7D14hN7jPg7Nv33PufRrmxJgIhGR0kVyo+4CM/sG0BkwYJWGgK96Pl6+g7v+fnxojNVPX07tmhp3UkRiVySt+O4F6jvnljnnlgL1zez7kTy5mQ0zs1VmttbMHi5lnRvNbLmZLTOz18oXXyLx08mLihSnDb+8QsVJRGJeJN9Sdznn9hbOOOf2AHedbCN/qI7ngcuBbsBoM+tWbJ1OwCPAec65NNQ6sML1GTeNSRmZAFzVqyUbfnlFwIlERCITyTWoBH+498JGEglA7Qi2GwCsdc6t87d7A7gaWB62zl3A837Rwzm3szzhpXTFG0OMH92HERrtVkSqkEgK1IfAm2b2F3/+u/6yk2kFbA6bzwTOKbbO2QB+44sE4Enn3AnPbWZ3A3cDtGnTJoKXjm9HjxXQ6bHj9zd9/tBQUlOSAkwkIlJ+kRSoh/CK0j3+/MfACxX4+p2AIUAq8KmZ9Qg/pQjgnJsITARIT093FfTa1VLxlnqrnh5GnZoJASYSETk1kbTiKwD+7P+Uxxagddh8qr8sXCbwhd8qcL2ZrcYrWPPK+VoCfJ2Vw0XPzgrN6+ZbEanKImnFd56ZfWxmq81snZmtN7N1ETz3PKCTmbU3s9rAKLz7qcL9C+/oCTNrinfKL5LnlmJmr91VpDht+OUVKk4iUqVFcorvb8D9wHwg4i6O/C6RxuD145cAvOicW2Zm44AM59wU/7FLzWy5/9wPOueyS39WKcm7X2Vy/5uLAGhavzYZj18ScCIRkdNnfuO80lcw+8I5V7xxQ2DS09NdRkbGyVeMEy/NXs9T73kNI/u2acQ73z8v4EQiIuVjZvOdc+nFl0dyBDXDzH4DvAPkFS50zi2owHxyCp6fsZbffLQKgMu7n8mfb+kXcCIRkYoTSYEqPHoKr24OuLDi40ikxn+yht9+vBqAUf1b88vregacSESkYkXSim9oZQSRyP1p5tpQcbr93HY8OSIt4EQiIhUvoiHfzewKIA1ILFzmnBsXrVBSupdmr+fXH3qn9VScRKQ6i6SZ+QRgJPADvN7MbwDaRjmXlOCdBZmhBhE3n9NGxUlEqrVIOos91zl3K7DHOfcUMAi/iyKpPLNWZ/HjSV5T8mv6tOLn1/QIOJGISHRFUqAO+f8eNLOWwFGgRfQiSXErtu3nthe/BOCCTk353cjewQYSEakEkVyDmmpmjYDfAAvwWvBVVF98chJZB/K4/PefAdCxWT1evSNmbkkTEYmqSFrx/cyffNvMpgKJzrl90Y0lAIePHqP/z6cDUMPgk58MCTaQiEglKrVAmdmFzrn/mtm1JTyGc+6d6EaLbwUFji7/7/jII+t+oYEGRSS+lHUE9Q3gv8BVJTzm8HqWkCjp8OjxwQbX/2J4gElERIJRaoFyzo01sxrAB865SZWYKe71/dnx8ZzW/Pxy9UouInGpzFZ8/lhQP62kLAI8+NYiduceAeDLxy6iVkIkDS1FRKqfSL79ppvZA2bW2swaF/5EPVkc+nDpdt6anwnAq3cM4IzkxJNsISJSfUXSzHyk/++9Ycsc0KHi48Sv7Jw8vveP+QDcPbgDF3RqFnAiEZFgRdLMvH1lBIlnzjn6Pe01J2/RMJFHh3cNOJGISPAi7Sy2O9CNop3F/j1aoeJN+0eOt9ib88hFASYREYkdJy1QZjYWGIJXoN4HLgc+B1SgKsADby0KTa9++vIAk4iIxJZIGklcD1wEbHfOfRvoBTSMaqo4sXDzXib7jSL+fe951K6pFnsiIoUi6izWb26eb2YNgJ1A6+jGqv6OFTi++fxsAG5MT6VX60bBBhIRiTGRXIPK8DuL/SswH8gB5kQzVDzoGNZTxK+v7xVgEhGR2BRJK77v+5MTzOxDoIFzbnF0Y1VvT05ZFpr++v/UjZGISEkiGVF3ipndZGb1nHMbVJxOz9a9h3j5fxsA77pTQg11YyQiUpJIrkE9C5wPLDezyWZ2vZmpi4NTdO4v/wvAN85uputOIiJliOQU3yxglpklABcCdwEvAg2inK3audpvFAHwyncGBJhERCT2RXqjbl28YTdGAn2BV6IZqjpaumUfizbvBWDhE5cEG0ZEpAqI5EbdScAA4EPgj8Asv9m5RMg5x5V/+ByA7w7uQKOk2gEnEhGJfZEcQf0NGO2cOxbtMNVV+Km9R9TPnohIRCK5BvVRZQSprr7OymFx5j4Aljx5acBpRESqDvWtE2UXPTsLgNvPbUdyYq2A04iIVB0qUFH06LtLQtNPjkgLMImISNVT6ik+M+tb1obOuQUVH6f6yM3L57UvNgHw2U+HBpxGRKTqKesa1LP+v4lAOrAIMKAnkAEMim60qi1trHfprsuZybRunBRwGhGRqqfUU3zOuaHOuaHANqCvcy7dOdcP6ANsqayAVdHstbtC0x/cd0GASUREqq5IrkF1ds6FLqY455YCaitdhptf+AKAX13XAzP1tScicioiuQ9qsZm9APzDn78ZUIexpRj33vLQ9Mj+bQJMIiJStUVSoL4N3APc589/Cvw5aomqsGMFjhdnrwfUMEJE5HSd9BSfc+4wMAF42Dl3jXPud/6ykzKzYWa2yszWmtnDZax3nZk5M0uPPHrsucrvzqhh3VpqGCEicpoiGQ9qBLAQry8+zKy3mU2JYLsE4HngcqAbMNrMupWwXjLe0dkX5UoeY3Ly8lm+bT8AXz52UcBpRESqvkgaSYzF6yx2L4BzbiHQPoLtBgBrnXPrnHNHgDeAq0tY72fAr4CIjspiVZ9x0wAY2rkZdWomBJxGRKTqi6RAHXXO7Su2zEWwXStgc9h8pr8sxL8ZuLVz7j9lPZGZ3W1mGWaWkZWVFcFLV67t+w5z9Ji3S168vX/AaUREqodICtQyM7sJSDCzTmb2B+B/p/vCZlYD+C3wk5Ot65yb6N+Hld6sWbPTfekKN/AXnwBw5/nt1axcRKSCRFKgfgCkAXnA68B+4EcRbLcFaB02n0rRG3yTge7ATDPbAAwEplS1hhIbduWGph+/8oRLbCIicooiGW7jIPCY/1Me84BOZtYerzCNAm4Ke959QNPCeTObCTzgnMso5+sEasgzMwF48LLOwQYREalmIhlR92zgAaBd+PrOuQvL2s45l29mY4CPgATgRefcMjMbB2Q4507aEjDWhR893Tv0rACTiIhUP5HcqPsW3n1QLwDlGlXXOfc+8H6xZU+Usu6Q8jx3LCg8enpoWJdgg4iIVEORFKh855x6jihm275Doel7hnQMMImISPUUSSOJ98zs+2bWwswaF/5EPVmMG/KbmQDcO1TFSUQkGiI5grrN//fBsGUO6FDxcaqGnLx88vILAHjwMp3eExGJhkha8UXSa0RcuWHCHACu6tUy4CQiItVXWUO+X+ic+6+ZXVvS4865d6IXK3YdK3Cs8Pvce25k72DDiIhUY2UdQX0D+C9wVQmPOSAuC9STU5YB0OmM+iTUUK8RIiLRUmqBcs6N9f/9duXFiX2vzt0IwOTvnRtwEhGR6i2SRhKY2RV43R0lFi5zzo2LVqhYNX35jtB0w6RaASYREan+IhkPagIwEq9PPgNuANpGOVdMuvPvXi9Mb31vUMBJRESqv0jugzrXOXcrsMc59xQwCDg7urFiz+7cI6Hp/u3i/jYwEZGoi6RAFXaZcNDMWgJHgRbRixSb7nxlHgB3XaBW9yIilSGSa1BTzawR8BtgAV4LvheiGSoWLdi0F1C/eyIilSWSG3V/5k++bWZTgcQSRtit1t5btBWAxvVqUzMhkoNOERE5XWXdqFviDbr+Y3F1o+4PXv8KgFfvGBBwEhGR+FHWEVRJN+gWipsbdQ8fPT7CSFrLhgEmERGJL2XdqKsbdIFxU5cDMEL97omIVKpI7oNqYmbjzWyBmc03s9+bWZPKCBcLXvtiEwC/vK5HwElEROJLJFf83wCygOuA6/3pN6MZKlZkHcgLTSfVjqjTDRERqSCRfOu2CGvJB/C0mY2MVqBY8vi/lgDw4GWdA04iIhJ/IjmCmmZmo8yshv9zI/BRtIPFgo+WeX3vfe8bGjVXRKSyRVKg7gJeA/L8nzeA75rZATPbH81wQdq5/zAACTVMw2qIiAQgkht1kysjSKx5+j8rAJ3eExEJSiSt+O4oNp9gZmOjFyk2TPF7j7jjfPW9JyIShEhO8V1kZu+bWQsz6w7MBar1UVVOXn5oupa6NhIRCUQkp/hu8lvtLQFygZucc7OjnixAf565FtDRk4hIkCI5xdcJuA94G9gIfMvMkqIdLEh/+3w9AD+48KyAk4iIxK9Izl+9B/w/59x3gW8Aa4B5UU0VoIICx+GjBQA0SqodcBoRkfgVyY26A5xz+wGccw541szei26s4MxYtROAoZ2bBZxERCS+lXoEZWY/BXDO7TezG4o9fHs0QwXpjzO8609jdHpPRCRQZZ3iGxU2/Uixx4ZFIUtM+MofObdf28bBBhERiXNlFSgrZbqk+Wph78EjAJzZIDHgJCIiUlaBcqVMlzRfLby9YAsAN/ZvHXASEREpq5FEL7+vPQPqhvW7Z0C1PMT45xcbAbj5nDYBJxERkbJG1E2ozCCxYF1WLgDNdYpPRCRw6sfHV3j96awz6gecREREQAUq5L3F2wC4okeLgJOIiAioQIW87xeo6/qmBpxEREQgygXKzIaZ2SozW2tmD5fw+I/NbLmZLTazT8ysbTTzlGXOumwA2jSp1t0MiohUGVErUGaWADwPXA50A0abWbdiq30FpDvnegKTgV9HK09ZjhV4reYbJdUK4uVFRKQE0TyCGgCsdc6tc84dwRsq/urwFZxzM5xzB/3ZuUAg59cWbt4DwHBdfxIRiRnRLFCtgM1h85n+stLcAXwQxTylem+Rd/3pws5nBPHyIiJSgkh6M486M7sFSMcbzqOkx+8G7gZo06bib6L9dHUWAOd3alrhzy0iIqcmmkdQW4DwPoNS/WVFmNnFwGPACOdcXklP5Jyb6JxLd86lN2tW8cNgrNvl3aCbWCvu7k0WEYlZ0SxQ84BOZtbezGrj9Y4+JXwFM+sD/AWvOO2MYpZS5eUfA6BXasMgXl5EREoRtQLlnMsHxgAfASuASc65ZWY2zsxG+Kv9BqgPvGVmC81sSilPFzWFw2ukt9PwGiIisSSq16Ccc+8D7xdb9kTY9MXRfP1IzPXvfzq3Y5OAk4iISLi470niy/W7ATi3oxpIiIjEkrgvUIs27wWgbm01kBARiSVxX6ByjxyjRUMNryEiEmti4j6ooGTneK3ae6oFn1Sio0ePkpmZyeHDh4OOIlKpEhMTSU1NpVatyLqVi+sCtaCwBV9bteCTypOZmUlycjLt2rXDzIKOI1IpnHNkZ2eTmZlJ+/btI9omrk/xzd/o9cHXv70KlFSew4cP06RJExUniStmRpMmTcp15iCuC9SyrfsASGvZIOAkEm9UnCQelfdzH9cFatX2AwDUSojr3SAiEpPi+pt554E8mtSrHXQMkUq3fft2Ro0aRceOHenXrx/Dhw9n9erVUX3NIUOGkJGRUeY6zz33HAcPHgzNDx8+nL1790Y1V3lE8h7uvPNOli9fXiGv165dO3bt2lUhzxWuIjNGU1w3kgDo2Kx+0BFEKpVzjmuuuYbbbruNN954A4BFixaxY8cOzj777ECzPffcc9xyyy0kJXkjW7///vsn2SL2vPDCC0FHKNOxY8diPmOhuD2C2rzb+yutm64/SYCeem8ZI/8yp0J/nnpvWZmvOWPGDGrVqsX3vve90LJevXpxwQUXMHPmTK688srQ8jFjxvDyyy8D3l/zjzzyCL179yY9PZ0FCxZw2WWX0bFjRyZMmABQ5vbh7rnnHtLT00lLS2Ps2LEAjB8/nq1btzJ06FCGDh0aes1du3bx8MMP8/zzz4e2f/LJJ3nmmWcA+M1vfkP//v3p2bNn6LmKmzZtGoMGDaJv377ccMMN5OTksHHjRjp16sSuXbsoKCjgggsuYNq0aWzYsIEuXbpw880307VrV66//voiR3VlvQcoepRVv359HnvsMXr16sXAgQPZsWMHAFlZWVx33XX079+f/v37M3v2bACys7O59NJLSUtL484778Q5d8LrTpgwgQcffDA0//LLLzNmzBgAvvnNb9KvXz/S0tKYOHFiaJ369evzk5/8hF69ejFnzpwiGUt7H+3atWPs2LH07duXHj16sHLlSgBycnL49re/TY8ePejZsydvv/12qfv4dMVtgSpsIKF7oCTeLF26lH79+p3Stm3atGHhwoVccMEF3H777UyePJm5c+eWWhhK8/Of/5yMjAwWL17MrFmzWLx4MT/84Q9p2bIlM2bMYMaMGUXWHzlyJJMmTQrNT5o0iZEjRzJt2jTWrFnDl19+ycKFC5k/fz6ffvppkW137drF008/zfTp01mwYAHp6en89re/pW3btjz00EPcc889PPvss3Tr1o1LL70UgFWrVvH973+fFStW0KBBA/70pz9F9B6Ky83NZeDAgSxatIjBgwfz17/+FYD77ruP+++/n3nz5vH2229z5513AvDUU09x/vnns2zZMq655ho2bdp0wnNed911vPvuu6H5N998k1GjRgHw4osvMn/+fDIyMhg/fjzZ2dmhHOeccw6LFi3i/PPPj/h9NG3alAULFnDPPfeE/iD42c9+RsOGDVmyZAmLFy/mwgsvLHUfn664PcW3artX3ds1rRdwEolnY69KCzpCuYwY4Q1E0KNHD3JyckhOTiY5OZk6deqU61rRpEmTmDhxIvn5+Wzbto3ly5fTs2fPUtfv06cPO3fuZOvWrWRlZZGSkkLr1q35/e9/z7Rp0+jTpw/g/XW/Zs0aBg8eHNp27ty5LF++nPPOOw+AI0eOMGjQIMC7FvPWW28xYcIEFi5cGNqmdevWofVvueUWxo8fzwMPPFDu91C7du3QEWW/fv34+OOPAZg+fXqRa0D79+8nJyeHTz/9lHfeeQeAK664gpSUlBP2RbNmzejQoQNz586lU6dOrFy5MpR1/PjxoeK1efNm1qxZQ5MmTUhISOC6664r9+/i2muvDWUvzDV9+vTQqWGAlJQUpk6dWuo+Ph1xW6Cycry2+J2bJwecRKRypaWlMXny5BIfq1mzJgUFBaH54ves1KlTB4AaNWqEpgvn8/PzT7o9wPr163nmmWeYN28eKSkp3H777RHdG3PDDTcwefJktm/fzsiRIwHvetojjzzCd7/73VK3c85xySWX8Prrr5/w2MGDB8nMzAQIFVw4sTl08flI30OtWrVC2yYkJJCfnw9AQUEBc+fOJTHx1LpZGzVqFJMmTaJLly5cc801mBkzZ85k+vTpzJkzh6SkJIYMGRLKlJiYSELCif2Nnux9FP6Ow7OXpKx9fDri9hTf1zu9UXTr1YnbGi1x6sILLyQvL6/INYrFixfz2Wef0bZtW5YvX05eXh579+7lk08+KddzR7L9/v37qVevHg0bNmTHjh188MEHoceSk5M5cOBAic89cuRI3njjDSZPnswNN9wAwGWXXcaLL74Yut6xZcsWdu4sOvbpwIEDmT17NmvXrgW8012FLRYfeughbr75ZsaNG8ddd90V2mbTpk3MmTMHgNdee+2E02JlvYdIXHrppfzhD38IzRcevQ0ePJjXXnsNgA8++IA9e/aUuP0111zDv//9b15//fXQ6b19+/aRkpJCUlISK1euZO7cuSfNcSrv45JLLilyPXDPnj1l7uPTEbcFaumWfTRLrnPyFUWqGTPj3XffZfr06XTs2JG0tDQeeeQRzjzzTFq3bs2NN95I9+7dufHGG0OnziIVyfa9evWiT58+dOnShZtuuil0Wgjg7rvvZtiwYaFGEuHS0tI4cOAArVq1okWLFoD3RX/TTTcxaNAgevTowfXXX39CgWvWrBkvv/wyo0ePpmfPngwaNIiVK1cya9Ys5s2bFypStWvX5qWXXgKgc+fOPP/883Tt2pU9e/Zwzz33RPweIjF+/HgyMjLo2bMn3bp1CzUyGTt2LJ9++ilpaWm88847tGnTpsTtU1JS6Nq1Kxs3bmTAgAEADBs2jPz8fLp27crDDz/MwIEDT5rjVN7H448/zp49e+jevTu9evVixowZpe7j02UltRKJZenp6e5k9yFEot3D/6F147p89tMLKyCVSORWrFhB165dg44hpdiwYQNXXnklS5cuDTpKtVTS59/M5jvn0ouvG5dHUMcKvKLcqlHdgJOIiEhp4rJAZed6w2yc017DvItIUe3atdPRU4yIywKVuecQAA3rRjYmiYiIVL64LFBrd3otflJTdIpPRCRWxWWB+tovUJ10D5SISMyKywJVSI0kRERiV1zepfq/r73+qWrXjOv6LDHidx9X7DAX919y8h7J69evX67OPGfOnMkzzzzD1KlTmTJlCsuXL+fhhx8udf0nnniCwYMHc/HFF5f6PKeiXbt2ZGRk0LRp01Pa/mSGDBnCM888Q3r6CS2eQ+68805+/OMf061bt9N+vWi9n4rMGKS4LFBHjxVQXz1IiJySESNGhPrkK824ceMqKU3li/WhKqrScBonE5eHEFkH8kisdWK/VCLxZubMmQwZMoTrr78+NMRE4c37H374IV26dKFv376hjkLh+PAO+/bto23btqG+93Jzc2ndujVHjx4N9XRe1vOED5kB0L17dzZs2ACUPmxEaTScRtUcTuNk4rJAZeceIb3tib0Ei8Sjr776iueee47ly5ezbt06Zs+ezeHDh7nrrrt47733mD9/Ptu3bz9hu4YNG9K7d29mzZoFwNSpU7nsssuoVev47RuRPE9JShs2oiQaTqPqDqdxMnFXoI7ke3/t5eSV3jOvSDwZMGAAqamp1KhRg969e7NhwwZWrlxJ+/bt6dSpE2bGLbfcUuK2I0eO5M033wTgjTfeCPUyXijS5ylu/PjxoaOSwmEjShM+nEbv3r155ZVX2LhxI+Bdi9m/fz8TJkwocrRWfDiNzz///ITnnTRpEn379qVPnz4sW7asxCHSiw+nUXgEOH36dMaMGUPv3r0ZMWJEkeE0CvdBJMNpZGdnnzCcRkn75WTDaZT2PsKH0wjPfu+994bWSUlJKXMfR1PcXYgp7OZoUEf1IiECFBk242TDKhQ3YsQIHn30UXbv3s38+fO58MLI+7YsbWiOsoaNKImG06i6w2mcTNwdQa3f5Q2zkasjKJFSdenShQ0bNvD1118DlPrFVL9+ffr37899993HlVdeecKXZFnP065dOxYsWADAggULWL9+PVD+YSM0nEbpYn04jZOJuyOofP8vtj5tdA1KYkMkzcIrW2JiIhMnTuSKK64gKSmJCy64oMxxmm644QZmzpxZrue57rrr+Pvf/05aWhrnnHMOZ5/t7Ydhw4YxYcIEunbtSufOnU86bET4UA95eV4/m08//TTbtm1j3rx5zJ49m4SEBN5++21eeuklhg4dGhpO4zvf+Q7dunUrcziN8NOBkRo/fjz33nsvPXv2JD8/n8GDBzNhwgTGjh3L6NGjSUtL49xzzz3pcBrLly8vMpxGefbLqb6Pxx9/nHvvvZfu3buTkJDA2LFjufbaa0vcx4W/s2iJu+E2XvtiE4++u4SJ3+rHpWlnVmAykchouI1gaTiNYGm4jTLUSvDOF6ubIxGR2BZ3BWrbPu8CYc0adpI1RaQ60nAaVUfcFajduUcAaJSkoTYkOFXt1LpIRSjv5z7uClTtmjWoU7MGyYkqUBKMxMREsrOzVaQkrjjnyM7OLlfT+7hrxbdw097QvVAiQUhNTSUzM5OsrKygo4hUqsTERFJTUyNeP+4KVL06CTRvcGo3z4lUhFq1atG+ffugY4jEvKie4jOzYWa2yszWmtkJffObWR0ze9N//AszaxfNPAC/ur4nV/VqEe2XERGR0xS1AmVmCcDzwOVAN2C0mRUfnOQOYI9z7izgd8CvopWn0BnJidSpmcDvPl5d4ePwiIhIxYnmKb4BwFrn3DoAM3sDuBoI73HxauBJf3oy8EczM1eJV4/Di1ThHf1lFa7yrCMiIqcumgWqFbA5bD4TOKe0dZxz+Wa2D2gC7ApfyczuBu72Z3PMbNVpZmta/DUAfhzBhhW1TjmUmDUGKWfFqypZq0pOqDpZq0pOqJisbUtaWCUaSTjnJgInH7UsQmaWUVK3GrGoqmRVzopXVbJWlZxQdbJWlZwQ3azRbCSxBWgdNp/qLytxHTOrCTQESh+ZTERE4kY0C9Q8oJOZtTez2sAoYEqxdaYAt/nT1wP/rczrTyIiEruidorPv6Y0BvgISABedM4tM7NxQIZzbgrwN+BVM1sL7MYrYpWhwk4XVoKqklU5K15VyVpVckLVyVpVckIUs1a54TZERCQ+xF1ffCIiUjWoQImISEyKuwJ1su6XKjlLazObYWbLzWyZmd3nL3/SzLaY2UL/Z3jYNo/42VeZ2WWVmHWDmS3x82T4yxqb2cdmtsb/N8VfbmY23s+52Mz6VmLOzmH7baGZ7TezH8XCPjWzF81sp5ktDVtW7n1oZrf5668xs9tKeq0oZf2Nma3087xrZo385e3M7FDYvp0Qtk0//3Oz1n8/FToQWyk5y/27rozvhVKyvhmWc4OZLfSXB7lPS/teqvzPqnMubn7wGmt8DXQAagOLgG4B5mkB9PWnk4HVeN1CPQk8UML63fzMdYD2/ntJqKSsG4CmxZb9GnjYn34Y+JU/PRz4ADBgIPBFgL/v7Xg3AQa+T4HBQF9g6anuQ6AxsM7/N8WfTqmkrJcCNf3pX4VlbRe+XrHn+dLPb/77ubwScpbrd11Z3wslZS32+LPAEzGwT0v7Xqr0z2q8HUGFul9yzh0BCrtfCoRzbptzboE/fQBYgde7RmmuBt5wzuU559YDa/HeU1CuBl7xp18Bvhm2/O/OMxdoZGZB9NB7EfC1c25jGetU2j51zn2K11q1+OuXZx9eBnzsnNvtnNsDfAwMq4yszrlpzrl8f3Yu3r2NpfLzNnDOzXXeN9bfOf7+opazDKX9rivle6GsrP5R0I3A62U9RyXt09K+lyr9sxpvBaqk7pfKKgiVxrye3PsAX/iLxviHyy8WHkoTbH4HTDOz+eZ1PQXQ3Dm3zZ/eDjT3p2NlP4+i6H/4WNunUP59GHTeQt/B+6u5UHsz+8rMZpnZBf6yVnj5ClVm1vL8rmNhn14A7HDOrQlbFvg+Lfa9VOmf1XgrUDHJzOoDbwM/cs7tB/4MdAR6A9vwDv2Ddr5zri9e7/T3mtng8Af9v+Zi5p4F824OHwG85S+KxX1aRKztw9KY2WNAPvBPf9E2oI1zrg9eV5SvmVmDoPJRBX7XJRhN0T+mAt+nJXwvhVTWZzXeClQk3S9VKjOrhfch+Kdz7h0A59wO59wx51wB8FeOn3IKLL9zbov/707gXT/TjsJTd/6/O4POGeZyYIFzbgfE5j71lXcfBprXzG4HrgRu9r+k8E+ZZfvT8/Gu55zt5wo/DVgpWU/hdx30Pq0JXAu8Wbgs6H1a0vcSAXxW461ARdL9UqXxzzv/DVjhnPtt2PLw6zXXAIWtfqYAo8wb6LE90Anvgmm0c9Yzs+TCabyL5Usp2lXVbcC/w3Le6rfuGQjsCzs1UFmK/EUaa/s0THn34UfApWaW4p+6utRfFnVmNgz4KTDCOXcwbHkz88Z/w8w64O3DdX7e/WY20P+s3xr2/qKZs7y/66C/Fy4GVjrnQqfugtynpX0vEcRntSJbf1SFH7wWJ6vx/iJ5LOAs5+MdJi8GFvo/w4FXgSX+8ilAi7BtHvOzr6KCW++UkbMDXsumRcCywv2GNzTKJ8AaYDrQ2F9ueINVfu2/j/RK3q/18Dodbhi2LPB9ilcwtwFH8c7H33Eq+xDv+s9a/+fblZh1Ld41hcLP6gR/3ev8z8VCYAFwVdjzpOMViK+BP+L3XhPlnOX+XVfG90JJWf3lLwPfK7ZukPu0tO+lSv+sqqsjERGJSfF2ik9ERKoIFSgREYlJKlAiIhKTVKBERCQmqUCJiEhMUoGSmGNmx8zrwXmpmb1lZkmlrPe/U3z+dDMbfxr5ck5126rEvF7gS9v3L5hZt3I+X1zsN6k4amYuMcfMcpxz9f3pfwLzXdEbmWu6452WBpqvOjOzDXj3tOyqoOeLi/0mFUdHUBLrPgPOMrMhZvaZmU0BlsPxv8j9x2aa2WTzxiv6p383PGbW38z+Z2aLzOxLM0v215/qP/6kmb1qZnPMG7PmLn95fTP7xMwWmDf2zkl7tzazW83roHSRmb3qL2tnZv/1l39iZm385S+b2Z/NbK6ZrfMzvWhmK8zs5bDnzDGz35k3Ls8nZtbMX97b37ZwbKbCsXlmmtmv/Pe62vxORs0swbzxnOb523y3rH1nZj8EWgIzzGxGCe91ppmlh2X8uf++55pZc395e3+/LjGzp4tt/2BYlqf8Zdf479HMrIWf/8yIPiVSPUXjjmn96Od0foAc/9+aeN2p3AMMAXKB9iWsNwTYh9fXVw1gDt7d8LXxxqDp76/XwH/OIcBUf9mTeD1k1AWa4vWU0NJfr4G/TlO8O+Et/HWLZU7D64mgqT9feJf9e8Bt/vR3gH/50y/jDetgeMMV7Ad6+PnnA7399Rxev3cATwB/9KcXA9/wp8cBz/nTM4Fn/enhwHR/+m7gcX+6DpCBNyZSifvOX28DxcYAC3u/M/F7DPAzXuVP/zrsdaYAt/rT94b9vi4FJvrvvQYwFRjsP/YPYIy/bHTQn0X9BPujIyiJRXXNG1k0A9iE1y8YwJfOG8enJF865zKd10HoQrwB3zoD25xz8wCcc/tdyacG/+2cO+S8U1kz8DoXNeD/zGwxXrcurTg+vEBJLgTe8p8D51zhuD+DgNf86VfxCmeh95xzDq97mB3OuSV+/mV+foACjnci+g/gfDNrCDRyzs3yl7+CNxheocLOPeeHPc+leP2lLcQbOqEJXv9uUPK+K48jeAWl+Guex/H+EF8NW/9S/+crvG58uoRl+QHwCJDnnCtzbCSp/moGHUCkBIecc73DF/hn7HLL2CYvbPoY5ftsF78Q64CbgWZAP+fcUf96TGI5njMShZkLKJq/gNLzR3LRuPC5wveDAT9wzhXprNPMhnB6+w7gqF9oS9q+pLwG/MI595cSHkvFe//NzayGXzQlTukISqqzVUALM+sP4F9/KunL92ozSzSzJninvOYBDYGdfnEaijdsfFn+C9zgPwdm1thf/j+83rHBK3qflfM91ACu96dvAj53zu0D9tjxQey+BcwqaeMwHwH3mDeMAmZ2tnk905flAN6Q36dqNkXfe3iW75g33hBm1srMzvB/Ny/i9US/Am8cJIljOoKSass5d8TMRgJ/MLO6wCG8oQ2KW4x3aq8p8DPn3FbzWg++Z2ZL8E41rjzJay0zs58Ds8zsGN7pq9vxTlm9ZGYPAlnAt8v5NnKBAWb2ON74OyP95bcBE8xrBr4ugud9Ae/U2wLzDkezOPlQ4ROBD81sq3NuaDlzA9yHN9DeQ4QNCeGcm2ZmXYE5/pFxDnAL8D3gM+fc52a2CJhnZv9xzq04hdeWakDNzCWumdmTeBfvnwk6S0lMTbMljukUn4iIxCQdQYmISEzSEZSIiMQkFSgREYlJKlAiIhKTVKBERCQmqUCJiEhM+v/OiUZ2axEw7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PCA - Alternatives include TSNE, UMAP, Autoencoder\n",
    "pca = PCA(2000,random_state=SEED)  \n",
    "projected_df = pca.fit_transform(X_train)\n",
    "\n",
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "#\n",
    "# Cumulative sum of eigenvalues; This will be used to create step plot\n",
    "# for visualizing the variance explained by each principal component.\n",
    "#\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "#\n",
    "# Create the visualization plot\n",
    "#\n",
    "plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:02:01.032765Z",
     "iopub.status.busy": "2021-12-31T15:02:01.032266Z",
     "iopub.status.idle": "2021-12-31T15:02:03.334598Z",
     "shell.execute_reply": "2021-12-31T15:02:03.333552Z",
     "shell.execute_reply.started": "2021-12-31T15:02:01.032722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA - 0</th>\n",
       "      <th>PCA - 1</th>\n",
       "      <th>PCA - 2</th>\n",
       "      <th>PCA - 3</th>\n",
       "      <th>PCA - 4</th>\n",
       "      <th>PCA - 5</th>\n",
       "      <th>PCA - 6</th>\n",
       "      <th>PCA - 7</th>\n",
       "      <th>PCA - 8</th>\n",
       "      <th>PCA - 9</th>\n",
       "      <th>...</th>\n",
       "      <th>PCA - 1990</th>\n",
       "      <th>PCA - 1991</th>\n",
       "      <th>PCA - 1992</th>\n",
       "      <th>PCA - 1993</th>\n",
       "      <th>PCA - 1994</th>\n",
       "      <th>PCA - 1995</th>\n",
       "      <th>PCA - 1996</th>\n",
       "      <th>PCA - 1997</th>\n",
       "      <th>PCA - 1998</th>\n",
       "      <th>PCA - 1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.041646</td>\n",
       "      <td>-0.080712</td>\n",
       "      <td>0.033904</td>\n",
       "      <td>0.032722</td>\n",
       "      <td>-0.038233</td>\n",
       "      <td>-0.020025</td>\n",
       "      <td>-0.200216</td>\n",
       "      <td>0.081064</td>\n",
       "      <td>-0.033132</td>\n",
       "      <td>0.044063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002955</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.006786</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.024472</td>\n",
       "      <td>-0.006315</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>0.002424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.158496</td>\n",
       "      <td>0.371309</td>\n",
       "      <td>-0.297177</td>\n",
       "      <td>0.269914</td>\n",
       "      <td>0.030916</td>\n",
       "      <td>0.521685</td>\n",
       "      <td>0.068578</td>\n",
       "      <td>-0.248325</td>\n",
       "      <td>-0.077062</td>\n",
       "      <td>-0.054536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004670</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>-0.004122</td>\n",
       "      <td>-0.001800</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>-0.001872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.072638</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>0.079080</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>-0.019635</td>\n",
       "      <td>-0.017076</td>\n",
       "      <td>-0.029879</td>\n",
       "      <td>0.067680</td>\n",
       "      <td>0.086410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>-0.001979</td>\n",
       "      <td>-0.006232</td>\n",
       "      <td>-0.006230</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>0.022925</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.004453</td>\n",
       "      <td>0.020175</td>\n",
       "      <td>-0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.145436</td>\n",
       "      <td>-0.039918</td>\n",
       "      <td>-0.069726</td>\n",
       "      <td>0.081624</td>\n",
       "      <td>-0.060567</td>\n",
       "      <td>-0.091155</td>\n",
       "      <td>-0.010074</td>\n",
       "      <td>-0.146854</td>\n",
       "      <td>0.017126</td>\n",
       "      <td>0.196201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002123</td>\n",
       "      <td>-0.000574</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>-0.007999</td>\n",
       "      <td>-0.003640</td>\n",
       "      <td>-0.003367</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>-0.000883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.043084</td>\n",
       "      <td>0.027176</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.026430</td>\n",
       "      <td>0.070938</td>\n",
       "      <td>0.033849</td>\n",
       "      <td>-0.028300</td>\n",
       "      <td>0.058087</td>\n",
       "      <td>0.030560</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018106</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>-0.003687</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>0.029497</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>-0.005289</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.007589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PCA - 0   PCA - 1   PCA - 2   PCA - 3   PCA - 4   PCA - 5   PCA - 6  \\\n",
       "0 -0.041646 -0.080712  0.033904  0.032722 -0.038233 -0.020025 -0.200216   \n",
       "1  0.158496  0.371309 -0.297177  0.269914  0.030916  0.521685  0.068578   \n",
       "2 -0.072638  0.013650  0.079080  0.023285  0.008711 -0.019635 -0.017076   \n",
       "3 -0.145436 -0.039918 -0.069726  0.081624 -0.060567 -0.091155 -0.010074   \n",
       "4 -0.043084  0.027176  0.005135  0.026430  0.070938  0.033849 -0.028300   \n",
       "\n",
       "    PCA - 7   PCA - 8   PCA - 9  ...  PCA - 1990  PCA - 1991  PCA - 1992  \\\n",
       "0  0.081064 -0.033132  0.044063  ...   -0.002955    0.005698    0.006786   \n",
       "1 -0.248325 -0.077062 -0.054536  ...   -0.004670    0.001630   -0.000465   \n",
       "2 -0.029879  0.067680  0.086410  ...    0.008694   -0.001979   -0.006232   \n",
       "3 -0.146854  0.017126  0.196201  ...   -0.002123   -0.000574    0.007664   \n",
       "4  0.058087  0.030560  0.012002  ...   -0.018106    0.006509   -0.003687   \n",
       "\n",
       "   PCA - 1993  PCA - 1994  PCA - 1995  PCA - 1996  PCA - 1997  PCA - 1998  \\\n",
       "0    0.002265    0.024472   -0.006315   -0.000714    0.003465    0.011979   \n",
       "1    0.002502   -0.004122   -0.001800    0.000629    0.004008    0.001782   \n",
       "2   -0.006230    0.011396    0.022925    0.001473    0.004453    0.020175   \n",
       "3    0.006250   -0.007999   -0.003640   -0.003367    0.000244    0.001276   \n",
       "4   -0.000060    0.029497   -0.000156    0.008789   -0.005289   -0.000192   \n",
       "\n",
       "   PCA - 1999  \n",
       "0    0.002424  \n",
       "1   -0.001872  \n",
       "2   -0.001667  \n",
       "3   -0.000883  \n",
       "4    0.007589  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(pca.transform(X_train))\n",
    "X_train.columns = ['PCA - ' + str(x) for x in X_train.columns]\n",
    "display(X_train.head())\n",
    "\n",
    "X_valid = pd.DataFrame(pca.transform(X_valid))\n",
    "X_valid.columns = ['PCA - ' + str(x) for x in X_valid.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:02:03.337084Z",
     "iopub.status.busy": "2021-12-31T15:02:03.336434Z",
     "iopub.status.idle": "2021-12-31T15:02:03.348211Z",
     "shell.execute_reply": "2021-12-31T15:02:03.347294Z",
     "shell.execute_reply.started": "2021-12-31T15:02:03.337024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4908, 2000) (1228, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20.02852485737571, 20.03257328990228)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape)\n",
    "y_train.sum()/len(y_train) * 100, y_valid.sum()/len(y_valid) * 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:02:03.350662Z",
     "iopub.status.busy": "2021-12-31T15:02:03.350054Z",
     "iopub.status.idle": "2021-12-31T15:02:18.826108Z",
     "shell.execute_reply": "2021-12-31T15:02:18.825089Z",
     "shell.execute_reply.started": "2021-12-31T15:02:03.350615Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 1000, solver = 'lbfgs', random_state = SEED, class_weight = 'balanced' )\n",
    "parameters = {'C':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "clf_lr = GridSearchCV(lr, parameters, cv = 5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:02:18.834521Z",
     "iopub.status.busy": "2021-12-31T15:02:18.831447Z",
     "iopub.status.idle": "2021-12-31T15:02:18.850291Z",
     "shell.execute_reply": "2021-12-31T15:02:18.849314Z",
     "shell.execute_reply.started": "2021-12-31T15:02:18.834433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight='balanced',\n",
       "                                          max_iter=1000, random_state=42),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:02:18.853110Z",
     "iopub.status.busy": "2021-12-31T15:02:18.852378Z",
     "iopub.status.idle": "2021-12-31T15:02:18.860404Z",
     "shell.execute_reply": "2021-12-31T15:02:18.859571Z",
     "shell.execute_reply.started": "2021-12-31T15:02:18.853062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', max_iter=1000,\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:02:18.862767Z",
     "iopub.status.busy": "2021-12-31T15:02:18.862190Z",
     "iopub.status.idle": "2021-12-31T15:02:19.060948Z",
     "shell.execute_reply": "2021-12-31T15:02:19.060040Z",
     "shell.execute_reply.started": "2021-12-31T15:02:18.862723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation data log loss: 0.25372128365146596\n",
      "Optimal threhsold: 0.36188326545933114\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True_negatives</th>\n",
       "      <th>False_positives</th>\n",
       "      <th>False_negatives</th>\n",
       "      <th>True_positives</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Kappa Score</th>\n",
       "      <th>binary_cross_entropy</th>\n",
       "      <th>target_imbalance</th>\n",
       "      <th>target_size</th>\n",
       "      <th>optimal_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Usability</th>\n",
       "      <td>880</td>\n",
       "      <td>102</td>\n",
       "      <td>44</td>\n",
       "      <td>202</td>\n",
       "      <td>0.881107</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.664474</td>\n",
       "      <td>0.734545</td>\n",
       "      <td>0.850423</td>\n",
       "      <td>0.932538</td>\n",
       "      <td>0.659039</td>\n",
       "      <td>0.253721</td>\n",
       "      <td>0.200326</td>\n",
       "      <td>1228</td>\n",
       "      <td>0.361883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           True_negatives  False_positives  False_negatives  True_positives  \\\n",
       "Usability             880              102               44             202   \n",
       "\n",
       "           Accuracy    Recall  Precision  f1_score    PR_AUC   ROC_AUC  \\\n",
       "Usability  0.881107  0.821138   0.664474  0.734545  0.850423  0.932538   \n",
       "\n",
       "           Kappa Score  binary_cross_entropy  target_imbalance  target_size  \\\n",
       "Usability     0.659039              0.253721          0.200326         1228   \n",
       "\n",
       "           optimal_threshold  \n",
       "Usability           0.361883  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train data log loss: 0.11248758132965464\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True_negatives</th>\n",
       "      <th>False_positives</th>\n",
       "      <th>False_negatives</th>\n",
       "      <th>True_positives</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Kappa Score</th>\n",
       "      <th>binary_cross_entropy</th>\n",
       "      <th>target_imbalance</th>\n",
       "      <th>target_size</th>\n",
       "      <th>optimal_thresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Usability</th>\n",
       "      <td>3742</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>983</td>\n",
       "      <td>0.962714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.843053</td>\n",
       "      <td>0.914844</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.997478</td>\n",
       "      <td>0.891197</td>\n",
       "      <td>0.112488</td>\n",
       "      <td>0.200285</td>\n",
       "      <td>4908</td>\n",
       "      <td>0.361883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           True_negatives  False_positives  False_negatives  True_positives  \\\n",
       "Usability            3742              183                0             983   \n",
       "\n",
       "           Accuracy  Recall  Precision  f1_score    PR_AUC   ROC_AUC  \\\n",
       "Usability  0.962714     1.0   0.843053  0.914844  0.982817  0.997478   \n",
       "\n",
       "           Kappa Score  binary_cross_entropy  target_imbalance  target_size  \\\n",
       "Usability     0.891197              0.112488          0.200285         4908   \n",
       "\n",
       "           optimal_thresh  \n",
       "Usability        0.361883  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_preds_lr = clf_lr.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "report_valid, t = classification_metrics(y_valid, y_preds_lr)\n",
    "print('\\nValidation data log loss:', log_loss(y_valid, y_preds_lr))\n",
    "model_logloss_on_valid_data['logistic regression'] = log_loss(y_valid, y_preds_lr)\n",
    "print('Optimal threhsold:',t)\n",
    "display(pd.DataFrame(report_valid,[category]))\n",
    "\n",
    "y_preds_lr = clf_lr.best_estimator_.predict_proba(X_train)[:,1]\n",
    "report_train,_ = classification_metrics_train(y_train, y_preds_lr, t)\n",
    "print('\\nTrain data log loss:', log_loss(y_train, y_preds_lr))\n",
    "display(pd.DataFrame(report_train,[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:02:19.063341Z",
     "iopub.status.busy": "2021-12-31T15:02:19.062741Z",
     "iopub.status.idle": "2021-12-31T15:02:19.072497Z",
     "shell.execute_reply": "2021-12-31T15:02:19.071538Z",
     "shell.execute_reply.started": "2021-12-31T15:02:19.063292Z"
    }
   },
   "outputs": [],
   "source": [
    "# ROC Curve: Area Under the Curve\n",
    "def auc_roc_plot(y_test, y_preds):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,y_preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(roc_auc)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:02:19.074983Z",
     "iopub.status.busy": "2021-12-31T15:02:19.074383Z",
     "iopub.status.idle": "2021-12-31T15:02:19.322376Z",
     "shell.execute_reply": "2021-12-31T15:02:19.321379Z",
     "shell.execute_reply.started": "2021-12-31T15:02:19.074937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9325377113241602\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_preds_lr = clf_lr.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "auc_roc_plot(y_valid, y_preds_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:02:19.324568Z",
     "iopub.status.busy": "2021-12-31T15:02:19.324223Z",
     "iopub.status.idle": "2021-12-31T15:02:20.429551Z",
     "shell.execute_reply": "2021-12-31T15:02:20.428648Z",
     "shell.execute_reply.started": "2021-12-31T15:02:19.324513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2631, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Usability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.087104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.013034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Usability\n",
       "0   0   0.017764\n",
       "1   1   0.009158\n",
       "2   2   0.999965\n",
       "3   3   0.087104\n",
       "4   4   0.013034"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = pd.DataFrame(vectorizer.transform(test_data['Review cleaned for tf-idf']).todense())\n",
    "X_test = pd.DataFrame(pca.transform(X_test))\n",
    "X_test.columns = ['PCA - ' + str(x) for x in X_test.columns]\n",
    "\n",
    "submission_data = test_data[['Id']]\n",
    "submission_data[category] = clf_lr.best_estimator_.predict_proba(X_test)[:,1]\n",
    "submission_data.to_csv(output_filepath + category.replace(' ','_') + '_submission_lr.csv', index=False)\n",
    "print(submission_data.shape)\n",
    "display(submission_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:02:20.431498Z",
     "iopub.status.busy": "2021-12-31T15:02:20.430905Z",
     "iopub.status.idle": "2021-12-31T15:03:48.910110Z",
     "shell.execute_reply": "2021-12-31T15:03:48.909010Z",
     "shell.execute_reply.started": "2021-12-31T15:02:20.431452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4908, 2000) 983 0.20028524857375712\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state=SEED, class_weight='balanced',probability=True, verbose=True, max_iter = 1000)\n",
    "parameters = {'C':[0.1, 1, 10]}\n",
    "\n",
    "print(X_train.shape, y_train.sum(), y_train.sum()/X_train.shape[0])\n",
    "\n",
    "oversample = ''\n",
    "if oversample=='ADASYN':\n",
    "    oversampler = ADASYN(sampling_strategy=0.5,random_state=SEED,n_neighbors=5)\n",
    "    X_train,y_train=oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    print(X_train.shape, y_train.sum(), y_train.sum()/X_train.shape[0])\n",
    "\n",
    "clf_svc = GridSearchCV(svc, parameters, cv = 2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:03:48.911805Z",
     "iopub.status.busy": "2021-12-31T15:03:48.911265Z",
     "iopub.status.idle": "2021-12-31T15:03:52.498258Z",
     "shell.execute_reply": "2021-12-31T15:03:52.497405Z",
     "shell.execute_reply.started": "2021-12-31T15:03:48.911757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data log loss: 0.31119568740257436\n",
      "Optimal threhsold: 0.5367246287199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True_negatives</th>\n",
       "      <th>False_positives</th>\n",
       "      <th>False_negatives</th>\n",
       "      <th>True_positives</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Kappa Score</th>\n",
       "      <th>binary_cross_entropy</th>\n",
       "      <th>target_imbalance</th>\n",
       "      <th>target_size</th>\n",
       "      <th>optimal_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loan Status</th>\n",
       "      <td>893</td>\n",
       "      <td>89</td>\n",
       "      <td>36</td>\n",
       "      <td>210</td>\n",
       "      <td>0.898208</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.702341</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.87438</td>\n",
       "      <td>0.94163</td>\n",
       "      <td>0.706024</td>\n",
       "      <td>0.311196</td>\n",
       "      <td>0.200326</td>\n",
       "      <td>1228</td>\n",
       "      <td>0.536725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             True_negatives  False_positives  False_negatives  True_positives  \\\n",
       "Loan Status             893               89               36             210   \n",
       "\n",
       "             Accuracy    Recall  Precision  f1_score   PR_AUC  ROC_AUC  \\\n",
       "Loan Status  0.898208  0.853659   0.702341  0.770642  0.87438  0.94163   \n",
       "\n",
       "             Kappa Score  binary_cross_entropy  target_imbalance  target_size  \\\n",
       "Loan Status     0.706024              0.311196          0.200326         1228   \n",
       "\n",
       "             optimal_threshold  \n",
       "Loan Status           0.536725  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data log loss: 0.09453725987311734\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True_negatives</th>\n",
       "      <th>False_positives</th>\n",
       "      <th>False_negatives</th>\n",
       "      <th>True_positives</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Kappa Score</th>\n",
       "      <th>binary_cross_entropy</th>\n",
       "      <th>target_imbalance</th>\n",
       "      <th>target_size</th>\n",
       "      <th>optimal_thresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loan Status</th>\n",
       "      <td>3894</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>983</td>\n",
       "      <td>0.993684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.969428</td>\n",
       "      <td>0.984477</td>\n",
       "      <td>0.992489</td>\n",
       "      <td>0.999307</td>\n",
       "      <td>0.980513</td>\n",
       "      <td>0.094537</td>\n",
       "      <td>0.200285</td>\n",
       "      <td>4908</td>\n",
       "      <td>0.536725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             True_negatives  False_positives  False_negatives  True_positives  \\\n",
       "Loan Status            3894               31                0             983   \n",
       "\n",
       "             Accuracy  Recall  Precision  f1_score    PR_AUC   ROC_AUC  \\\n",
       "Loan Status  0.993684     1.0   0.969428  0.984477  0.992489  0.999307   \n",
       "\n",
       "             Kappa Score  binary_cross_entropy  target_imbalance  target_size  \\\n",
       "Loan Status     0.980513              0.094537          0.200285         4908   \n",
       "\n",
       "             optimal_thresh  \n",
       "Loan Status        0.536725  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_preds_svc = clf_svc.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "report_valid, t = classification_metrics(y_valid, y_preds_svc)\n",
    "print('Validation data log loss:', log_loss(y_valid, y_preds_svc))\n",
    "model_logloss_on_valid_data['SVM'] = log_loss(y_valid, y_preds_svc)\n",
    "print('Optimal threhsold:',t)\n",
    "display(pd.DataFrame(report_valid,['Loan Status']))\n",
    "\n",
    "y_preds_svc = clf_svc.best_estimator_.predict_proba(X_train)[:,1]\n",
    "report_train,_ = classification_metrics_train(y_train, y_preds_svc, t)\n",
    "print('Train data log loss:', log_loss(y_train, y_preds_svc))\n",
    "display(pd.DataFrame(report_train,['Loan Status']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:03:52.499657Z",
     "iopub.status.busy": "2021-12-31T15:03:52.499396Z",
     "iopub.status.idle": "2021-12-31T15:03:53.396437Z",
     "shell.execute_reply": "2021-12-31T15:03:53.395701Z",
     "shell.execute_reply.started": "2021-12-31T15:03:52.499624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9416302386038118\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_preds_svc = clf_svc.best_estimator_.predict_proba(X_valid)[:,1]\n",
    "auc_roc_plot(y_valid, y_preds_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:03:53.398419Z",
     "iopub.status.busy": "2021-12-31T15:03:53.397861Z",
     "iopub.status.idle": "2021-12-31T15:03:56.010396Z",
     "shell.execute_reply": "2021-12-31T15:03:56.009514Z",
     "shell.execute_reply.started": "2021-12-31T15:03:53.398384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2631, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Usability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.035573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.077760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.130626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.046601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Usability\n",
       "0   0   0.035573\n",
       "1   1   0.077760\n",
       "2   2   1.000000\n",
       "3   3   0.130626\n",
       "4   4   0.046601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = pd.DataFrame(vectorizer.transform(test_data['Review cleaned for tf-idf']).todense())\n",
    "X_test = pd.DataFrame(pca.transform(X_test))\n",
    "X_test.columns = ['PCA - ' + str(x) for x in X_test.columns]\n",
    "\n",
    "submission_data = test_data[['Id']]\n",
    "submission_data[category] = clf_svc.best_estimator_.predict_proba(X_test)[:,1]\n",
    "submission_data.to_csv(output_filepath + category.replace(' ','_') + '_submission_svm.csv', index=False)\n",
    "print(submission_data.shape)\n",
    "display(submission_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:30:02.648795Z",
     "iopub.status.busy": "2021-12-31T15:30:02.647712Z",
     "iopub.status.idle": "2021-12-31T15:30:02.661000Z",
     "shell.execute_reply": "2021-12-31T15:30:02.660247Z",
     "shell.execute_reply.started": "2021-12-31T15:30:02.648748Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective_classification(X_train, y_train, X_val, y_val, target_value, trial):\n",
    "    \"\"\"It tries to find the best hyper-parameters for XGBOOST model for given task\n",
    "\n",
    "        Details:\n",
    "            It uses OPTUNA library which is based on Baseian-optimization to tune the hyper-params.\n",
    "\n",
    "        Args:\n",
    "            X_train: training data\n",
    "            X_test: testing data\n",
    "            y_tain: training label\n",
    "            y_val: validation label\n",
    "            trial: object of optuna for optimizing the task in hand\n",
    "\n",
    "        Returns:\n",
    "            best score till now\n",
    "\n",
    "    \"\"\"\n",
    "    if ((target_value)):\n",
    "        tree_methods = ['approx', 'hist', 'exact']\n",
    "        boosting_lists = ['gbtree', 'gblinear']\n",
    "        objective_list_reg = ['binary:logistic']  # 'reg:gamma', 'reg:tweedie'\n",
    "        boosting = trial.suggest_categorical('boosting', boosting_lists),\n",
    "        tree_method = trial.suggest_categorical('tree_method', tree_methods),\n",
    "        n_estimator = trial.suggest_int('n_estimators',20,200, 10),\n",
    "        max_depth = trial.suggest_int('max_depth',2,16),\n",
    "        reg_alpha = trial.suggest_int('reg_alpha',2,5),\n",
    "        reg_lambda = trial.suggest_int('reg_lambda',2,5),\n",
    "        min_child_weight = trial.suggest_int('min_child_weight', 1,5),\n",
    "        gamma = trial.suggest_int('gamma',2,5),\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n",
    "        objective = trial.suggest_categorical('objective', objective_list_reg),\n",
    "        colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "        colsample_bynode = trial.suggest_discrete_uniform('colsample_bynode', 0.5, 1, 0.05),\n",
    "        colsample_bylevel = trial.suggest_discrete_uniform('colsample_bylevel', 0.5, 1, 0.05),\n",
    "        subsample = trial.suggest_discrete_uniform('subsample', 0.8, 1, 0.1),\n",
    "#         scale_pos_weight = len(y_train)/sum(y_train)\n",
    "#         scale_pos_weight = trial.suggest_discrete_uniform('scale_pos_weight',10,100, 10)\n",
    "        scale_pos_weight = trial.suggest_discrete_uniform('scale_pos_weight',1,5, 0.1)\n",
    "        nthread = -1\n",
    "        \n",
    "          \n",
    "    xgboost_tune = xgb.XGBClassifier(\n",
    "        # tree_method=tree_method[0],\n",
    "        boosting=boosting[0],\n",
    "        reg_alpha=reg_alpha[0],\n",
    "        reg_lambda=reg_lambda[0],\n",
    "        gamma=gamma[0],\n",
    "        objective=objective[0],\n",
    "        colsample_bynode=colsample_bynode[0],\n",
    "        colsample_bylevel=colsample_bylevel[0],\n",
    "        n_estimators=n_estimator[0],\n",
    "        max_depth=max_depth[0],\n",
    "        min_child_weight=min_child_weight[0],\n",
    "        learning_rate=learning_rate[0],\n",
    "        subsample=subsample[0],\n",
    "        colsample_bytree=colsample_bytree[0],\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_jobs=nthread,\n",
    "        random_state=SEED)\n",
    "    \n",
    "    xgboost_tune.fit(X_train, y_train)\n",
    "    pred_val = xgboost_tune.predict_proba(X_val)[:, 1]\n",
    "\n",
    "#     pred_val[pred_val < 0] = 0\n",
    "#     pred_val = np.nan_to_num(pred_val)\n",
    "\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(y_val, pred_val)\n",
    "    roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "    binary_cross_entropy=log_loss(y_val, pred_val)\n",
    "    #average_precision = average_precision_score(y_val,pred_val)\n",
    "#     a,b=(classification_metrics(y_val,pred_val))\n",
    "    \n",
    "    #precision, recall, thresholds = precision_recall_curve(y_val,pred_val)\n",
    "    #area_under_curve = auc(recall, precision)\n",
    "\n",
    "    return binary_cross_entropy\n",
    "#     pred_val = xgboost_tune.predict(X_val)\n",
    "#     return sklearn.metrics.precision_score(y_val,pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:30:02.663037Z",
     "iopub.status.busy": "2021-12-31T15:30:02.662699Z",
     "iopub.status.idle": "2021-12-31T15:30:02.690051Z",
     "shell.execute_reply": "2021-12-31T15:30:02.689221Z",
     "shell.execute_reply.started": "2021-12-31T15:30:02.663008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Review</th>\n",
       "      <th>Components</th>\n",
       "      <th>Delivery and Customer Support</th>\n",
       "      <th>Design and Aesthetics</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Features</th>\n",
       "      <th>Functionality</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Material</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Usability</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Review v1</th>\n",
       "      <th>Review cleaned for tf-idf</th>\n",
       "      <th>Review cleaned for transformers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>928</td>\n",
       "      <td>This is a mess Ã°Å¸ËœÂ³why was the box of nails de...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a mess Ã°Å¸ËœÂ³why was the box of nails de...</td>\n",
       "      <td>this is a mess ðŸ˜³why wa the box of nail destroy...</td>\n",
       "      <td>This is a mess ðŸ˜³why was the box of nails destr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                             Review  Components  \\\n",
       "928  928  This is a mess Ã°Å¸ËœÂ³why was the box of nails de...           0   \n",
       "\n",
       "     Delivery and Customer Support  Design and Aesthetics  Dimensions  \\\n",
       "928                              1                      0           0   \n",
       "\n",
       "     Features  Functionality  Installation  Material  Price  Quality  \\\n",
       "928         0              0             0         0      0        0   \n",
       "\n",
       "     Usability  Polarity                                          Review v1  \\\n",
       "928          0         0  This is a mess Ã°Å¸ËœÂ³why was the box of nails de...   \n",
       "\n",
       "                             Review cleaned for tf-idf  \\\n",
       "928  this is a mess ðŸ˜³why wa the box of nail destroy...   \n",
       "\n",
       "                       Review cleaned for transformers  \n",
       "928  This is a mess ðŸ˜³why was the box of nails destr...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['Id']==928]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:30:02.692124Z",
     "iopub.status.busy": "2021-12-31T15:30:02.691532Z",
     "iopub.status.idle": "2021-12-31T15:30:03.139162Z",
     "shell.execute_reply": "2021-12-31T15:30:03.138146Z",
     "shell.execute_reply.started": "2021-12-31T15:30:02.692087Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate_bert_embeddings(train_data,'Review cleaned for transformers','emilyalsentzer/bert-base-uncased')\n",
    "vectorizer = TfidfVectorizer(stop_words='english',ngram_range=(1, 1))\n",
    "\n",
    "train_df, valid_df  = sk_model_selection.train_test_split(\n",
    "    train_data, \n",
    "    test_size=0.2, \n",
    "    random_state=SEED,\n",
    "    stratify = train_data[category])\n",
    "\n",
    "X_train = train_df['Review cleaned for tf-idf'].reset_index(drop = True)\n",
    "y_train = train_df[category].reset_index(drop = True)\n",
    "X_valid = valid_df['Review cleaned for tf-idf'].reset_index(drop = True)\n",
    "y_valid = valid_df[category].reset_index(drop = True)\n",
    "\n",
    "X_train = pd.DataFrame(vectorizer.fit_transform(X_train).todense())\n",
    "X_valid = pd.DataFrame(vectorizer.transform(X_valid).todense())\n",
    "\n",
    "inv_map = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "X_train.columns = ['Feature - ' + inv_map[x] for x in X_train.columns]\n",
    "X_valid.columns = ['Feature - ' + inv_map[x] for x in X_valid.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:30:03.141459Z",
     "iopub.status.busy": "2021-12-31T15:30:03.141210Z",
     "iopub.status.idle": "2021-12-31T15:41:12.186388Z",
     "shell.execute_reply": "2021-12-31T15:41:12.185308Z",
     "shell.execute_reply.started": "2021-12-31T15:30:03.141426Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # features for modelling before boostaroota: 6023\n",
      "[11:22:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:22:57,993]\u001b[0m A new study created in memory with name: no-name-4bed032b-49fd-486c-a5f2-eab750789cec\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:57] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "Total # features for modelling after boostaroota: 163\n",
      "[11:22:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:22:58,218]\u001b[0m Trial 0 finished with value: 0.26290486613591885 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 40, 'max_depth': 2, 'reg_alpha': 5, 'reg_lambda': 4, 'min_child_weight': 4, 'gamma': 2, 'learning_rate': 0.44447541666908114, 'objective': 'binary:logistic', 'colsample_bytree': 0.95, 'colsample_bynode': 0.6, 'colsample_bylevel': 0.6, 'subsample': 0.8, 'scale_pos_weight': 2.2}. Best is trial 0 with value: 0.26290486613591885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:22:58,834]\u001b[0m Trial 1 finished with value: 0.2768322061322605 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 70, 'max_depth': 7, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 1, 'gamma': 4, 'learning_rate': 0.10150667045928574, 'objective': 'binary:logistic', 'colsample_bytree': 0.5, 'colsample_bynode': 0.8, 'colsample_bylevel': 0.55, 'subsample': 0.8, 'scale_pos_weight': 4.800000000000001}. Best is trial 0 with value: 0.26290486613591885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:22:59,460]\u001b[0m Trial 2 finished with value: 0.2899354131663285 and parameters: {'boosting': 'gbtree', 'tree_method': 'exact', 'n_estimators': 100, 'max_depth': 3, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 5, 'gamma': 3, 'learning_rate': 0.13353819088790583, 'objective': 'binary:logistic', 'colsample_bytree': 0.65, 'colsample_bynode': 0.75, 'colsample_bylevel': 0.8, 'subsample': 0.8, 'scale_pos_weight': 4.9}. Best is trial 0 with value: 0.26290486613591885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:22:59,715]\u001b[0m Trial 3 finished with value: 0.2770607233830919 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 30, 'max_depth': 4, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.2558586885593425, 'objective': 'binary:logistic', 'colsample_bytree': 0.65, 'colsample_bynode': 0.65, 'colsample_bylevel': 0.75, 'subsample': 0.8, 'scale_pos_weight': 4.2}. Best is trial 0 with value: 0.26290486613591885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:22:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:04,031]\u001b[0m Trial 4 finished with value: 0.2381672520032729 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 170, 'max_depth': 12, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.015734685129393678, 'objective': 'binary:logistic', 'colsample_bytree': 0.95, 'colsample_bynode': 0.8, 'colsample_bylevel': 0.65, 'subsample': 0.8, 'scale_pos_weight': 2.2}. Best is trial 4 with value: 0.2381672520032729.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:04,449]\u001b[0m Trial 5 finished with value: 0.29047599973320865 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 40, 'max_depth': 12, 'reg_alpha': 5, 'reg_lambda': 4, 'min_child_weight': 4, 'gamma': 3, 'learning_rate': 0.07728716861851782, 'objective': 'binary:logistic', 'colsample_bytree': 0.7, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.55, 'subsample': 0.8, 'scale_pos_weight': 3.6}. Best is trial 4 with value: 0.2381672520032729.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:05,859]\u001b[0m Trial 6 finished with value: 0.24310811459291984 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 160, 'max_depth': 5, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 5, 'learning_rate': 0.23603276001278087, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.95, 'colsample_bylevel': 0.9, 'subsample': 0.8, 'scale_pos_weight': 4.6}. Best is trial 4 with value: 0.2381672520032729.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:06,441]\u001b[0m Trial 7 finished with value: 0.2677135131221738 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 60, 'max_depth': 8, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 1, 'gamma': 4, 'learning_rate': 0.05118807219845013, 'objective': 'binary:logistic', 'colsample_bytree': 0.6, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.65, 'subsample': 1.0, 'scale_pos_weight': 2.3}. Best is trial 4 with value: 0.2381672520032729.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:07,046]\u001b[0m Trial 8 finished with value: 0.23083518713360793 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 60, 'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 4, 'learning_rate': 0.07145565133513967, 'objective': 'binary:logistic', 'colsample_bytree': 0.5, 'colsample_bynode': 0.65, 'colsample_bylevel': 0.95, 'subsample': 0.8, 'scale_pos_weight': 1.5}. Best is trial 8 with value: 0.23083518713360793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:07,855]\u001b[0m Trial 9 finished with value: 0.4011954371043836 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 60, 'max_depth': 12, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 4, 'gamma': 4, 'learning_rate': 0.014236381287235733, 'objective': 'binary:logistic', 'colsample_bytree': 0.95, 'colsample_bynode': 0.65, 'colsample_bylevel': 0.6, 'subsample': 0.8, 'scale_pos_weight': 3.4000000000000004}. Best is trial 8 with value: 0.23083518713360793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:09,957]\u001b[0m Trial 10 finished with value: 0.22647737321543965 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 130, 'max_depth': 15, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 5, 'learning_rate': 0.03705159958468012, 'objective': 'binary:logistic', 'colsample_bytree': 0.5, 'colsample_bynode': 1.0, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 10 with value: 0.22647737321543965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:12,268]\u001b[0m Trial 11 finished with value: 0.23996394371510718 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 130, 'max_depth': 16, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 5, 'learning_rate': 0.03498506838903428, 'objective': 'binary:logistic', 'colsample_bytree': 0.5, 'colsample_bynode': 1.0, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 10 with value: 0.22647737321543965.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:16,499]\u001b[0m Trial 12 finished with value: 0.21828394112289437 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 200, 'max_depth': 16, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 5, 'learning_rate': 0.031239747474158183, 'objective': 'binary:logistic', 'colsample_bytree': 0.55, 'colsample_bynode': 0.9, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 12 with value: 0.21828394112289437.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:20,080]\u001b[0m Trial 13 finished with value: 0.23091788280524725 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 190, 'max_depth': 16, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 5, 'learning_rate': 0.02829181127535645, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 12 with value: 0.21828394112289437.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:22,197]\u001b[0m Trial 14 finished with value: 0.23595395784958567 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 130, 'max_depth': 14, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 5, 'learning_rate': 0.023864909454131222, 'objective': 'binary:logistic', 'colsample_bytree': 0.6, 'colsample_bynode': 0.9, 'colsample_bylevel': 1.0, 'subsample': 1.0, 'scale_pos_weight': 1.6}. Best is trial 12 with value: 0.21828394112289437.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:26,408]\u001b[0m Trial 15 finished with value: 0.3094748718852135 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 200, 'max_depth': 15, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 2, 'gamma': 5, 'learning_rate': 0.010455508942800671, 'objective': 'binary:logistic', 'colsample_bytree': 0.55, 'colsample_bynode': 1.0, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 2.7}. Best is trial 12 with value: 0.21828394112289437.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:27,937]\u001b[0m Trial 16 finished with value: 0.2158322319151767 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 100, 'max_depth': 13, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 2, 'learning_rate': 0.045961097408202235, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.75, 'subsample': 0.9, 'scale_pos_weight': 1.6}. Best is trial 16 with value: 0.2158322319151767.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:29,551]\u001b[0m Trial 17 finished with value: 0.21025988090850098 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 100, 'max_depth': 13, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 2, 'learning_rate': 0.048610240948079565, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.75, 'subsample': 1.0, 'scale_pos_weight': 1.7000000000000002}. Best is trial 17 with value: 0.21025988090850098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:31,097]\u001b[0m Trial 18 finished with value: 0.21423419221556148 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 100, 'max_depth': 11, 'reg_alpha': 5, 'reg_lambda': 3, 'min_child_weight': 3, 'gamma': 2, 'learning_rate': 0.05167042973484901, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.8, 'colsample_bylevel': 0.7, 'subsample': 1.0, 'scale_pos_weight': 1.7000000000000002}. Best is trial 17 with value: 0.21025988090850098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:32,137]\u001b[0m Trial 19 finished with value: 0.23284966879864055 and parameters: {'boosting': 'gbtree', 'tree_method': 'exact', 'n_estimators': 80, 'max_depth': 10, 'reg_alpha': 5, 'reg_lambda': 3, 'min_child_weight': 5, 'gamma': 2, 'learning_rate': 0.1282678225548514, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.75, 'colsample_bylevel': 0.7, 'subsample': 1.0, 'scale_pos_weight': 2.8}. Best is trial 17 with value: 0.21025988090850098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:33,689]\u001b[0m Trial 20 finished with value: 0.2560004600982033 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 110, 'max_depth': 10, 'reg_alpha': 5, 'reg_lambda': 3, 'min_child_weight': 2, 'gamma': 2, 'learning_rate': 0.01966367066869885, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.8, 'colsample_bylevel': 0.8, 'subsample': 1.0, 'scale_pos_weight': 1.9}. Best is trial 17 with value: 0.21025988090850098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:35,037]\u001b[0m Trial 21 finished with value: 0.21558897739355165 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 90, 'max_depth': 13, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 2, 'learning_rate': 0.04853489215661121, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.75, 'subsample': 1.0, 'scale_pos_weight': 1.7000000000000002}. Best is trial 17 with value: 0.21025988090850098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:35] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:37,056]\u001b[0m Trial 22 finished with value: 0.2236036182538961 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 90, 'max_depth': 10, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 4, 'gamma': 2, 'learning_rate': 0.04941883635107293, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.7, 'subsample': 1.0, 'scale_pos_weight': 1.9}. Best is trial 17 with value: 0.21025988090850098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:38,861]\u001b[0m Trial 23 finished with value: 0.21890739307826815 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 120, 'max_depth': 13, 'reg_alpha': 5, 'reg_lambda': 3, 'min_child_weight': 3, 'gamma': 2, 'learning_rate': 0.0644093912829747, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.75, 'subsample': 1.0, 'scale_pos_weight': 2.5}. Best is trial 17 with value: 0.21025988090850098.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:40,783]\u001b[0m Trial 24 finished with value: 0.21006702408740593 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 11, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 2, 'learning_rate': 0.09757703995874756, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.75, 'colsample_bylevel': 0.8, 'subsample': 1.0, 'scale_pos_weight': 1.8}. Best is trial 24 with value: 0.21006702408740593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:42,778]\u001b[0m Trial 25 finished with value: 0.22906078334066543 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 11, 'reg_alpha': 5, 'reg_lambda': 4, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.09939464780108048, 'objective': 'binary:logistic', 'colsample_bytree': 1.0, 'colsample_bynode': 0.7, 'colsample_bylevel': 0.8500000000000001, 'subsample': 1.0, 'scale_pos_weight': 3.2}. Best is trial 24 with value: 0.21006702408740593.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:44,067]\u001b[0m Trial 26 finished with value: 0.2087005247742678 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 7, 'reg_alpha': 5, 'reg_lambda': 3, 'min_child_weight': 3, 'gamma': 2, 'learning_rate': 0.17916626177705783, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.7, 'colsample_bylevel': 0.7, 'subsample': 1.0, 'scale_pos_weight': 1.4}. Best is trial 26 with value: 0.2087005247742678.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:45,231]\u001b[0m Trial 27 finished with value: 0.23062758973848183 and parameters: {'boosting': 'gbtree', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 6, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 4, 'gamma': 3, 'learning_rate': 0.23424394978021906, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.7, 'colsample_bylevel': 0.8, 'subsample': 1.0, 'scale_pos_weight': 1.3}. Best is trial 26 with value: 0.2087005247742678.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:48,045]\u001b[0m Trial 28 finished with value: 0.21079537072347884 and parameters: {'boosting': 'gbtree', 'tree_method': 'approx', 'n_estimators': 180, 'max_depth': 8, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 2, 'learning_rate': 0.1848495149668794, 'objective': 'binary:logistic', 'colsample_bytree': 0.7, 'colsample_bynode': 0.75, 'colsample_bylevel': 0.5, 'subsample': 1.0, 'scale_pos_weight': 1.9}. Best is trial 26 with value: 0.2087005247742678.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:48] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:49,242]\u001b[0m Trial 29 finished with value: 0.21690650167922393 and parameters: {'boosting': 'gbtree', 'tree_method': 'exact', 'n_estimators': 150, 'max_depth': 7, 'reg_alpha': 5, 'reg_lambda': 4, 'min_child_weight': 3, 'gamma': 2, 'learning_rate': 0.4696046527294612, 'objective': 'binary:logistic', 'colsample_bytree': 0.7, 'colsample_bynode': 0.6, 'colsample_bylevel': 0.65, 'subsample': 1.0, 'scale_pos_weight': 2.4000000000000004}. Best is trial 26 with value: 0.2087005247742678.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:50,965]\u001b[0m Trial 30 finished with value: 0.21794256202744605 and parameters: {'boosting': 'gbtree', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 9, 'reg_alpha': 5, 'reg_lambda': 3, 'min_child_weight': 4, 'gamma': 2, 'learning_rate': 0.3470278458833128, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.7, 'colsample_bylevel': 0.8500000000000001, 'subsample': 1.0, 'scale_pos_weight': 2.0}. Best is trial 26 with value: 0.2087005247742678.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:51] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:52,861]\u001b[0m Trial 31 finished with value: 0.20701459531311298 and parameters: {'boosting': 'gbtree', 'tree_method': 'approx', 'n_estimators': 180, 'max_depth': 8, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 2, 'learning_rate': 0.1722762942330406, 'objective': 'binary:logistic', 'colsample_bytree': 0.7, 'colsample_bynode': 0.75, 'colsample_bylevel': 0.5, 'subsample': 1.0, 'scale_pos_weight': 1.3}. Best is trial 31 with value: 0.20701459531311298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:54,678]\u001b[0m Trial 32 finished with value: 0.2115612733951415 and parameters: {'boosting': 'gbtree', 'tree_method': 'approx', 'n_estimators': 170, 'max_depth': 6, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 2, 'learning_rate': 0.154208385460161, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.75, 'colsample_bylevel': 0.5, 'subsample': 1.0, 'scale_pos_weight': 1.3}. Best is trial 31 with value: 0.20701459531311298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:56,372]\u001b[0m Trial 33 finished with value: 0.21173219967038895 and parameters: {'boosting': 'gbtree', 'tree_method': 'approx', 'n_estimators': 170, 'max_depth': 8, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.09619390664250298, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.7, 'colsample_bylevel': 0.6, 'subsample': 1.0, 'scale_pos_weight': 1.4}. Best is trial 31 with value: 0.20701459531311298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:58,565]\u001b[0m Trial 34 finished with value: 0.21487586806601836 and parameters: {'boosting': 'gbtree', 'tree_method': 'approx', 'n_estimators': 180, 'max_depth': 7, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 2, 'learning_rate': 0.16955905170325597, 'objective': 'binary:logistic', 'colsample_bytree': 0.65, 'colsample_bynode': 0.6, 'colsample_bylevel': 0.55, 'subsample': 1.0, 'scale_pos_weight': 2.1}. Best is trial 31 with value: 0.20701459531311298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:23:59,140]\u001b[0m Trial 35 finished with value: 0.24320385143682605 and parameters: {'boosting': 'gbtree', 'tree_method': 'approx', 'n_estimators': 120, 'max_depth': 2, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 5, 'gamma': 3, 'learning_rate': 0.31932309559229877, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.75, 'colsample_bylevel': 0.8, 'subsample': 1.0, 'scale_pos_weight': 1.2}. Best is trial 31 with value: 0.20701459531311298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:23:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:00,542]\u001b[0m Trial 36 finished with value: 0.20930022417811497 and parameters: {'boosting': 'gbtree', 'tree_method': 'exact', 'n_estimators': 160, 'max_depth': 4, 'reg_alpha': 2, 'reg_lambda': 2, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 0.12119910869147758, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.8, 'colsample_bylevel': 0.7, 'subsample': 0.9, 'scale_pos_weight': 1.8}. Best is trial 31 with value: 0.20701459531311298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:01,745]\u001b[0m Trial 37 finished with value: 0.22424834096331775 and parameters: {'boosting': 'gbtree', 'tree_method': 'exact', 'n_estimators': 160, 'max_depth': 4, 'reg_alpha': 2, 'reg_lambda': 5, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.12534354489459695, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.8, 'colsample_bylevel': 0.7, 'subsample': 0.9, 'scale_pos_weight': 2.7}. Best is trial 31 with value: 0.20701459531311298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:02,947]\u001b[0m Trial 38 finished with value: 0.2423326356089234 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 180, 'max_depth': 4, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08620734714535232, 'objective': 'binary:logistic', 'colsample_bytree': 0.7, 'colsample_bynode': 0.65, 'colsample_bylevel': 0.65, 'subsample': 0.9, 'scale_pos_weight': 3.7}. Best is trial 31 with value: 0.20701459531311298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:04,332]\u001b[0m Trial 39 finished with value: 0.21165698176592662 and parameters: {'boosting': 'gbtree', 'tree_method': 'exact', 'n_estimators': 160, 'max_depth': 5, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 0.20202516074623508, 'objective': 'binary:logistic', 'colsample_bytree': 1.0, 'colsample_bynode': 0.7, 'colsample_bylevel': 0.6, 'subsample': 0.9, 'scale_pos_weight': 2.1}. Best is trial 31 with value: 0.20701459531311298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:05,236]\u001b[0m Trial 40 finished with value: 0.2598149623331117 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 140, 'max_depth': 2, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 2, 'learning_rate': 0.31841598578471547, 'objective': 'binary:logistic', 'colsample_bytree': 0.65, 'colsample_bynode': 0.8, 'colsample_bylevel': 0.55, 'subsample': 0.9, 'scale_pos_weight': 4.5}. Best is trial 31 with value: 0.20701459531311298.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:07,375]\u001b[0m Trial 41 finished with value: 0.20353780182022357 and parameters: {'boosting': 'gbtree', 'tree_method': 'exact', 'n_estimators': 190, 'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 2, 'learning_rate': 0.12059413140154945, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.8, 'subsample': 1.0, 'scale_pos_weight': 1.7000000000000002}. Best is trial 41 with value: 0.20353780182022357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:11,270]\u001b[0m Trial 42 finished with value: 0.2071146193090887 and parameters: {'boosting': 'gbtree', 'tree_method': 'exact', 'n_estimators': 190, 'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 2, 'learning_rate': 0.1173369546552223, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.8, 'colsample_bylevel': 0.9, 'subsample': 1.0, 'scale_pos_weight': 1.5}. Best is trial 41 with value: 0.20353780182022357.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:13,555]\u001b[0m Trial 43 finished with value: 0.20036764368141852 and parameters: {'boosting': 'gbtree', 'tree_method': 'exact', 'n_estimators': 190, 'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 2, 'learning_rate': 0.13501485026599017, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:13] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:15,676]\u001b[0m Trial 44 finished with value: 0.20391219735436797 and parameters: {'boosting': 'gbtree', 'tree_method': 'exact', 'n_estimators': 190, 'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 2, 'learning_rate': 0.21063567182961868, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.95, 'colsample_bylevel': 0.9, 'subsample': 1.0, 'scale_pos_weight': 1.4}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:18,060]\u001b[0m Trial 45 finished with value: 0.2067265183852943 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 190, 'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.27254137967822056, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.95, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:21,489]\u001b[0m Trial 46 finished with value: 0.20695939913607453 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 190, 'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.2258270566061955, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.95, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:23,953]\u001b[0m Trial 47 finished with value: 0.2072351229747193 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 200, 'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.28103135294619236, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.95, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:26,666]\u001b[0m Trial 48 finished with value: 0.20701916519012484 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 190, 'max_depth': 10, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.3992996864692055, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.95, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:28,871]\u001b[0m Trial 49 finished with value: 0.20704864241040224 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 190, 'max_depth': 9, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.25117488676791916, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.95, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n",
      "\u001b[32m[I 2022-01-03 11:24:29,126]\u001b[0m Trial 50 finished with value: 0.22839527002290036 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 20, 'max_depth': 8, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 4, 'learning_rate': 0.1539049179660616, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 1.0, 'colsample_bylevel': 0.9, 'subsample': 0.8, 'scale_pos_weight': 1.5}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:24:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:31,396]\u001b[0m Trial 51 finished with value: 0.2062870204984893 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 200, 'max_depth': 8, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.20658312731214867, 'objective': 'binary:logistic', 'colsample_bytree': 0.7, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:34,868]\u001b[0m Trial 52 finished with value: 0.2028244707588537 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 200, 'max_depth': 10, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.2134034782199184, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:37,777]\u001b[0m Trial 53 finished with value: 0.2032032974856126 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 200, 'max_depth': 11, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.21006561074959865, 'objective': 'binary:logistic', 'colsample_bytree': 0.7, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.5}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:40,469]\u001b[0m Trial 54 finished with value: 0.20217273976230624 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 200, 'max_depth': 11, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.14735442426494333, 'objective': 'binary:logistic', 'colsample_bytree': 0.7, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.6}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:44,161]\u001b[0m Trial 55 finished with value: 0.20388660615944101 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 200, 'max_depth': 12, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.14931160007028443, 'objective': 'binary:logistic', 'colsample_bytree': 0.6, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.6}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:47,013]\u001b[0m Trial 56 finished with value: 0.20406370877791863 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 200, 'max_depth': 12, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.14261073763121085, 'objective': 'binary:logistic', 'colsample_bytree': 0.6, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.6}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:49,668]\u001b[0m Trial 57 finished with value: 0.21115118824438486 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 200, 'max_depth': 11, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.08098879492808242, 'objective': 'binary:logistic', 'colsample_bytree': 0.65, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 2.3}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:52,498]\u001b[0m Trial 58 finished with value: 0.20574941914771297 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 170, 'max_depth': 12, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.06311333006820796, 'objective': 'binary:logistic', 'colsample_bytree': 0.55, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.7000000000000002}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:55,907]\u001b[0m Trial 59 finished with value: 0.23008507826226743 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 200, 'max_depth': 10, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.14443966413161072, 'objective': 'binary:logistic', 'colsample_bytree': 0.6, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.8, 'subsample': 0.8, 'scale_pos_weight': 3.9000000000000004}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:55] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:55] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:24:58,293]\u001b[0m Trial 60 finished with value: 0.2083730515182103 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 180, 'max_depth': 11, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.10888527873855236, 'objective': 'binary:logistic', 'colsample_bytree': 0.6, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 2.2}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:24:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:24:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:00,662]\u001b[0m Trial 61 finished with value: 0.2030584505218436 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 190, 'max_depth': 10, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.20517575085868406, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.5}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:03,068]\u001b[0m Trial 62 finished with value: 0.2034331034680871 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 200, 'max_depth': 10, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.18643621225319176, 'objective': 'binary:logistic', 'colsample_bytree': 0.7, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.6}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:06,178]\u001b[0m Trial 63 finished with value: 0.20467892563894258 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 180, 'max_depth': 10, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.19877538599497316, 'objective': 'binary:logistic', 'colsample_bytree': 0.65, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.5}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:08,487]\u001b[0m Trial 64 finished with value: 0.2051496569545794 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 190, 'max_depth': 10, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.2902896742308501, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.8, 'subsample': 0.9, 'scale_pos_weight': 1.8}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:11,397]\u001b[0m Trial 65 finished with value: 0.20830900975842792 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 200, 'max_depth': 11, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.16901992114009595, 'objective': 'binary:logistic', 'colsample_bytree': 0.7, 'colsample_bynode': 0.9, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 2.0}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:12,048]\u001b[0m Trial 66 finished with value: 0.2081118677936173 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 50, 'max_depth': 11, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.3658439474235638, 'objective': 'binary:logistic', 'colsample_bytree': 0.7, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:14,269]\u001b[0m Trial 67 finished with value: 0.20931969632558428 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 170, 'max_depth': 10, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 2, 'gamma': 3, 'learning_rate': 0.2376425467342113, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.8500000000000001, 'colsample_bylevel': 0.8, 'subsample': 0.9, 'scale_pos_weight': 1.8}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:17,992]\u001b[0m Trial 68 finished with value: 0.20717271284203284 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 180, 'max_depth': 12, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 3, 'gamma': 3, 'learning_rate': 0.10635833986247645, 'objective': 'binary:logistic', 'colsample_bytree': 0.7, 'colsample_bynode': 0.8, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:18] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:20,712]\u001b[0m Trial 69 finished with value: 0.2025952294915581 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 190, 'max_depth': 14, 'reg_alpha': 3, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.13795245709821394, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.6}. Best is trial 43 with value: 0.20036764368141852.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:23,300]\u001b[0m Trial 70 finished with value: 0.19957443999645302 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 170, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1370332362529673, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 70 with value: 0.19957443999645302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:25,995]\u001b[0m Trial 71 finished with value: 0.2000353841296115 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 200, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1833928792359684, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 70 with value: 0.19957443999645302.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:29,308]\u001b[0m Trial 72 finished with value: 0.1976410082442055 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 170, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.13608812171538895, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 72 with value: 0.1976410082442055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:32,091]\u001b[0m Trial 73 finished with value: 0.19888784871959955 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 170, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.13779774920594826, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 72 with value: 0.1976410082442055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:34,679]\u001b[0m Trial 74 finished with value: 0.19824305327430197 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 170, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.13256775575825513, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 72 with value: 0.1976410082442055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:38,397]\u001b[0m Trial 75 finished with value: 0.20081925851669077 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 170, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.13412566709146784, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.5, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 72 with value: 0.1976410082442055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:41,482]\u001b[0m Trial 76 finished with value: 0.2004774055452805 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 170, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08839098195456074, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.55, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 72 with value: 0.1976410082442055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:44,190]\u001b[0m Trial 77 finished with value: 0.19884865564682463 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 160, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09097508939007481, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.55, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 72 with value: 0.1976410082442055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:46,780]\u001b[0m Trial 78 finished with value: 0.20053988871170686 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 160, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.07269137037509892, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.55, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 72 with value: 0.1976410082442055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:50,710]\u001b[0m Trial 79 finished with value: 0.20002013464088184 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 170, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 4, 'learning_rate': 0.0885771232526828, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.55, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 72 with value: 0.1976410082442055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:50] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:53,508]\u001b[0m Trial 80 finished with value: 0.20109858195804034 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 4, 'learning_rate': 0.06235195922687437, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 72 with value: 0.1976410082442055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:53] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:56,817]\u001b[0m Trial 81 finished with value: 0.2021467480398957 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 170, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 4, 'learning_rate': 0.08793089850778363, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.55, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 72 with value: 0.1976410082442055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:25:59,200]\u001b[0m Trial 82 finished with value: 0.20147070165417166 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 160, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 4, 'learning_rate': 0.0928429641939986, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.5, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 72 with value: 0.1976410082442055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:25:59] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:25:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:03,192]\u001b[0m Trial 83 finished with value: 0.19858383252482606 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 160, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.10974092944363745, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 72 with value: 0.1976410082442055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:06,112]\u001b[0m Trial 84 finished with value: 0.19756648566570825 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 160, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.11350605311833616, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 84 with value: 0.19756648566570825.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:08,486]\u001b[0m Trial 85 finished with value: 0.1968023451727721 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 150, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.11221839384000654, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:12,381]\u001b[0m Trial 86 finished with value: 0.19747372908086944 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 150, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.109052641129437, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:14,896]\u001b[0m Trial 87 finished with value: 0.19861627610950922 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.11174244254109232, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:17,469]\u001b[0m Trial 88 finished with value: 0.19764004721448844 and parameters: {'boosting': 'gblinear', 'tree_method': 'exact', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1095598063580367, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:20,381]\u001b[0m Trial 89 finished with value: 0.19783573432640456 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.10927391804405695, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:23,697]\u001b[0m Trial 90 finished with value: 0.19815418660088596 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.10884995346093881, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:23] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:26,080]\u001b[0m Trial 91 finished with value: 0.1976109135255873 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.11200892204239185, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:28,271]\u001b[0m Trial 92 finished with value: 0.19779288918553498 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 120, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.10202283143783814, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:30,673]\u001b[0m Trial 93 finished with value: 0.19879940979058341 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 120, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.10213167565006444, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:33,975]\u001b[0m Trial 94 finished with value: 0.19965358881404205 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.12350441236352466, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:36,165]\u001b[0m Trial 95 finished with value: 0.2151752873858534 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 110, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.07319953219488248, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 3.1}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:38,597]\u001b[0m Trial 96 finished with value: 0.200309772744429 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 120, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.07779382311772057, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.6, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:38] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:41,202]\u001b[0m Trial 97 finished with value: 0.1989538525799987 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09918117377156736, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:44,996]\u001b[0m Trial 98 finished with value: 0.19956736853770937 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 150, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.15998077203211986, 'objective': 'binary:logistic', 'colsample_bytree': 0.95, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:47,069]\u001b[0m Trial 99 finished with value: 0.19858556471807512 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1254679947351247, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:49,580]\u001b[0m Trial 100 finished with value: 0.19751226740467578 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.11707412732618962, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:52,296]\u001b[0m Trial 101 finished with value: 0.19859041012626397 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.11580684077826221, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:56,058]\u001b[0m Trial 102 finished with value: 0.1985107693481426 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 150, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.10256295747998294, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:26:58,806]\u001b[0m Trial 103 finished with value: 0.19827082943351762 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.12406082280719301, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:26:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:00,905]\u001b[0m Trial 104 finished with value: 0.20078933384672948 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 120, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 5, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08262580457590955, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.5}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:03,163]\u001b[0m Trial 105 finished with value: 0.19974705969447615 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.06744504746556534, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:06,692]\u001b[0m Trial 106 finished with value: 0.19875068214482322 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 150, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09617987243232276, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:09,287]\u001b[0m Trial 107 finished with value: 0.20072969945575375 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.054940452532330736, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.5, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.7000000000000002}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:12,110]\u001b[0m Trial 108 finished with value: 0.19754030804926415 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 150, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.11443364269225136, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.6, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:14,986]\u001b[0m Trial 109 finished with value: 0.19789715996467136 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 150, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1149473771282474, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.6, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:15] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:19,008]\u001b[0m Trial 110 finished with value: 0.22384667076043033 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 150, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.15876954072329658, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.6, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 4.800000000000001}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:19] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:19] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:21,910]\u001b[0m Trial 111 finished with value: 0.1991787430969088 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.11677173952065838, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.65, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:21] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:24,108]\u001b[0m Trial 112 finished with value: 0.19934621275590692 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 110, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.10696499035739035, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.55, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:26,683]\u001b[0m Trial 113 finished with value: 0.1991872848595526 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 150, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.11289939710734723, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.65, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.5}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:30,209]\u001b[0m Trial 114 finished with value: 0.19740290767953092 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09946366482119115, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:30] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:30] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:32,383]\u001b[0m Trial 115 finished with value: 0.1972984288521839 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 120, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08204225974898322, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:34,399]\u001b[0m Trial 116 finished with value: 0.19919667249478715 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 120, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.0789465548342476, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:36,567]\u001b[0m Trial 117 finished with value: 0.19947962574994477 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09638514094824312, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:36] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:36] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:40,102]\u001b[0m Trial 118 finished with value: 0.198496810703596 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.0828651768506573, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:41,864]\u001b[0m Trial 119 finished with value: 0.2325254006075054 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 120, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 5, 'gamma': 3, 'learning_rate': 0.10177663672360607, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 3.4000000000000004}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:43,907]\u001b[0m Trial 120 finished with value: 0.21158328813467334 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 110, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09257003036824248, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 2.9000000000000004}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:43] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:43] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:46,301]\u001b[0m Trial 121 finished with value: 0.19936702419216487 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.12846333310801686, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:46] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:49,111]\u001b[0m Trial 122 finished with value: 0.19906889884171444 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 160, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.11860420799153394, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:52,709]\u001b[0m Trial 123 finished with value: 0.1993105541861613 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 150, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1449103048191106, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.6, 'colsample_bylevel': 1.0, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:56,336]\u001b[0m Trial 124 finished with value: 0.26837182728761766 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 150, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.011632830051475645, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.5}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:27:58,594]\u001b[0m Trial 125 finished with value: 0.19747720920201695 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1037873680637243, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:27:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:01,888]\u001b[0m Trial 126 finished with value: 0.2008214572502197 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.05715981996114857, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.6}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:01] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:03,798]\u001b[0m Trial 127 finished with value: 0.2084976780772094 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 100, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.10193498314480262, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 2.6}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:05,997]\u001b[0m Trial 128 finished with value: 0.19919689001928081 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 130, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.07443537990287498, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:08,396]\u001b[0m Trial 129 finished with value: 0.1978001393118406 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08555274179685567, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:12,390]\u001b[0m Trial 130 finished with value: 0.19902549382657153 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.06878316397143353, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:14,889]\u001b[0m Trial 131 finished with value: 0.19735709251835942 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08565707247169127, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:17,515]\u001b[0m Trial 132 finished with value: 0.19709427602185658 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08495572630061968, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:20,602]\u001b[0m Trial 133 finished with value: 0.19896889523775937 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 160, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.0901427022756483, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:24,409]\u001b[0m Trial 134 finished with value: 0.1993690096023902 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.0804641479799902, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:24] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:27,202]\u001b[0m Trial 135 finished with value: 0.19987416039418174 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 150, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09777911264470268, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.5}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:27] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:29,275]\u001b[0m Trial 136 finished with value: 0.19714859666694137 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.12874826087744765, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:29] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:31,279]\u001b[0m Trial 137 finished with value: 0.19823614165038234 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.13193665575758048, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:34,493]\u001b[0m Trial 138 finished with value: 0.22323156276309 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 5, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.15937821596566398, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 4.1}. Best is trial 85 with value: 0.1968023451727721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:36,992]\u001b[0m Trial 139 finished with value: 0.196644048159487 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.12773260577038137, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 139 with value: 0.196644048159487.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:39,604]\u001b[0m Trial 140 finished with value: 0.19650695918632993 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.11956738681434458, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:42,175]\u001b[0m Trial 141 finished with value: 0.197590897283714 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.12377454872716226, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:42] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:45,287]\u001b[0m Trial 142 finished with value: 0.1984135915369026 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1234928411992276, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:45] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:47,175]\u001b[0m Trial 143 finished with value: 0.22842453723524603 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 13, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 4, 'gamma': 3, 'learning_rate': 0.12151069025010522, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:49,597]\u001b[0m Trial 144 finished with value: 0.1972196667632604 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.14821594075641303, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:52,600]\u001b[0m Trial 145 finished with value: 0.19846781876001884 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.15509726621863906, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:54,899]\u001b[0m Trial 146 finished with value: 0.199737337168385 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.13943090426945723, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:28:58,298]\u001b[0m Trial 147 finished with value: 0.20060595700590103 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.043830656911992505, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:28:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:28:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:00,779]\u001b[0m Trial 148 finished with value: 0.19825936715514475 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.17362608906741772, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:03,107]\u001b[0m Trial 149 finished with value: 0.19798249950183477 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.14620870213020803, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:03] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:05,282]\u001b[0m Trial 150 finished with value: 0.19713856853887513 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09256289825019065, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:08,581]\u001b[0m Trial 151 finished with value: 0.19929170440533578 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09535180228752664, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:08] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:11,700]\u001b[0m Trial 152 finished with value: 0.1972067310127463 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.0873185803981406, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:11] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:14,184]\u001b[0m Trial 153 finished with value: 0.20001137706205394 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08506498010047817, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:16,572]\u001b[0m Trial 154 finished with value: 0.1976107259755742 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.07696891149092486, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:20,699]\u001b[0m Trial 155 finished with value: 0.19811847180291914 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09265382057495444, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:22,926]\u001b[0m Trial 156 finished with value: 0.21754455674403264 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 13, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.020795574993927417, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:23] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:25,505]\u001b[0m Trial 157 finished with value: 0.19854795505787196 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 140, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.10175200977295408, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:28,088]\u001b[0m Trial 158 finished with value: 0.19881352031351665 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.07064893867260617, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:32,100]\u001b[0m Trial 159 finished with value: 0.197968491252985 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08750189599117646, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:32] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:34,507]\u001b[0m Trial 160 finished with value: 0.19831851319901353 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 140, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.10794422056634294, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:36,978]\u001b[0m Trial 161 finished with value: 0.19707173827416732 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.13103053456065838, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:40,792]\u001b[0m Trial 162 finished with value: 0.19781222292191747 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1320320661884039, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:40] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:41,827]\u001b[0m Trial 163 finished with value: 0.21122061139570264 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 3, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1167566295656796, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:44,273]\u001b[0m Trial 164 finished with value: 0.19884765044867944 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.10618115351640751, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:47,266]\u001b[0m Trial 165 finished with value: 0.19839302876642648 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 140, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.0927275316894498, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:49,204]\u001b[0m Trial 166 finished with value: 0.20097981002151433 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 130, 'max_depth': 16, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1150367558696601, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:52,573]\u001b[0m Trial 167 finished with value: 0.19750318833223335 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.12943138567456633, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:56,079]\u001b[0m Trial 168 finished with value: 0.19860653467863154 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.12768226106320066, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:56] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:29:58,290]\u001b[0m Trial 169 finished with value: 0.19891665119856766 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 140, 'max_depth': 14, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1479373820744461, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:29:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:29:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:00,677]\u001b[0m Trial 170 finished with value: 0.19997037433206138 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 140, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.06243206498084579, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:04,084]\u001b[0m Trial 171 finished with value: 0.19710774378166973 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.13223606143390287, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:05,281]\u001b[0m Trial 172 finished with value: 0.1984423163130042 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 70, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.13681916772964028, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:05] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:07,687]\u001b[0m Trial 173 finished with value: 0.19872977738025985 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.130013984156885, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:07] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:10,611]\u001b[0m Trial 174 finished with value: 0.19793090908879155 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.10070017583264851, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.4}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:10] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:14,381]\u001b[0m Trial 175 finished with value: 0.19804450759553452 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.16251600325267143, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:17,179]\u001b[0m Trial 176 finished with value: 0.1978239414201752 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 150, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08036897338724361, 'objective': 'binary:logistic', 'colsample_bytree': 0.9, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:17] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:19,989]\u001b[0m Trial 177 finished with value: 0.20001809521129277 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 160, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.1204341264952431, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.8500000000000001, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:22,079]\u001b[0m Trial 178 finished with value: 0.20463988805380848 and parameters: {'boosting': 'gblinear', 'tree_method': 'hist', 'n_estimators': 130, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 5, 'learning_rate': 0.14603126896441032, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.75, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:22] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:26,325]\u001b[0m Trial 179 finished with value: 0.1981897820075458 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 170, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.11011485775757084, 'objective': 'binary:logistic', 'colsample_bytree': 0.8500000000000001, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.5}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:26] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:26] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:28,912]\u001b[0m Trial 180 finished with value: 0.19668400542831796 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08559510101313168, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:28] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:31,610]\u001b[0m Trial 181 finished with value: 0.19719112244152529 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08665552457752537, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:31] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:33,881]\u001b[0m Trial 182 finished with value: 0.19777151943542404 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.07516879995342886, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:33] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:37,097]\u001b[0m Trial 183 finished with value: 0.19741653635148385 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08604362943474114, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:37] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:37] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:39,196]\u001b[0m Trial 184 finished with value: 0.19837481361595422 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08532380987847468, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:39] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:39] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:41,799]\u001b[0m Trial 185 finished with value: 0.19683875876072346 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.0818644868319687, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:41] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:44,622]\u001b[0m Trial 186 finished with value: 0.19767269405160184 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.06549899783317945, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:44] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:47,894]\u001b[0m Trial 187 finished with value: 0.1974863634810325 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08023040961626475, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:47] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:49,816]\u001b[0m Trial 188 finished with value: 0.19994661352045057 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 120, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.07193931693735801, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:49] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:52,493]\u001b[0m Trial 189 finished with value: 0.1979084600730881 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09145198903456313, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:52] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:54,692]\u001b[0m Trial 190 finished with value: 0.19718802551032083 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08412696554572006, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:54] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:30:58,284]\u001b[0m Trial 191 finished with value: 0.1977039640852787 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08542523845242468, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.3}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:30:58] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:30:58] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:31:00,485]\u001b[0m Trial 192 finished with value: 0.19814619731616095 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.07848605581404171, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:00] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:31:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:31:02,699]\u001b[0m Trial 193 finished with value: 0.19706824547778026 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09467859306478767, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:02] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:31:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:31:04,769]\u001b[0m Trial 194 finished with value: 0.19655425215810415 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09396482263233545, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:04] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:31:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:31:06,678]\u001b[0m Trial 195 finished with value: 0.19769546814742178 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 120, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09277810712971987, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:06] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:31:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:31:09,699]\u001b[0m Trial 196 finished with value: 0.19784342244203756 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.08607717340225057, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.1}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:09] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:31:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:31:12,106]\u001b[0m Trial 197 finished with value: 0.20013766149240955 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.07722774557816393, 'objective': 'binary:logistic', 'colsample_bytree': 0.75, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:12] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:31:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:31:14,194]\u001b[0m Trial 198 finished with value: 0.1990362275353897 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 130, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.06828273891652942, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:14] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:31:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:31:16,774]\u001b[0m Trial 199 finished with value: 0.199254965449832 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 16, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.09607080137831678, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.5, 'colsample_bylevel': 0.9, 'subsample': 0.9, 'scale_pos_weight': 1.2}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:16] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:31:16] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-03 11:31:20,386]\u001b[0m Trial 200 finished with value: 0.19861275372049902 and parameters: {'boosting': 'gblinear', 'tree_method': 'approx', 'n_estimators': 140, 'max_depth': 15, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1, 'gamma': 3, 'learning_rate': 0.084666278086602, 'objective': 'binary:logistic', 'colsample_bytree': 0.8, 'colsample_bynode': 0.55, 'colsample_bylevel': 0.95, 'subsample': 0.9, 'scale_pos_weight': 1.0}. Best is trial 140 with value: 0.19650695918632993.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:20] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:31:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', boosting='gblinear',\n",
       "              colsample_bylevel=0.9, colsample_bynode=0.5, colsample_bytree=0.8,\n",
       "              enable_categorical=False, gamma=3, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.11956738681434458, max_delta_step=0, max_depth=15,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=160, n_jobs=64, num_parallel_tree=1,\n",
       "              predictor='auto', random_state=42, reg_alpha=2, reg_lambda=3,\n",
       "              scale_pos_weight=1.1, subsample=0.9, tree_method='hist',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total # features for modelling before boostaroota:', X_train.shape[1])\n",
    "\n",
    "br = BoostARoota(metric='logloss', silent = True)\n",
    "br.fit(X_train,y_train)\n",
    "X_train=X_train[br.keep_vars_.tolist()]\n",
    "X_valid=X_valid[br.keep_vars_.tolist()]\n",
    "print('Total # features for modelling after boostaroota:', len(br.keep_vars_.tolist()))\n",
    "\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler(seed=SEED))\n",
    "study.optimize(\n",
    "    functools.partial(objective_classification, X_train, y_train, X_valid, y_valid,'Binary'),\n",
    "            timeout=500)\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(**study.best_params, random_state=SEED)\n",
    "model_xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:12.188521Z",
     "iopub.status.busy": "2021-12-31T15:41:12.188187Z",
     "iopub.status.idle": "2021-12-31T15:41:12.299803Z",
     "shell.execute_reply": "2021-12-31T15:41:12.298861Z",
     "shell.execute_reply.started": "2021-12-31T15:41:12.188476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data log loss: 0.1987134065002761\n",
      "Optimal threshold: 0.25204068\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True_negatives</th>\n",
       "      <th>False_positives</th>\n",
       "      <th>False_negatives</th>\n",
       "      <th>True_positives</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Kappa Score</th>\n",
       "      <th>binary_cross_entropy</th>\n",
       "      <th>target_imbalance</th>\n",
       "      <th>target_size</th>\n",
       "      <th>optimal_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Usability</th>\n",
       "      <td>908</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>215</td>\n",
       "      <td>0.914495</td>\n",
       "      <td>0.873984</td>\n",
       "      <td>0.743945</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.890878</td>\n",
       "      <td>0.948804</td>\n",
       "      <td>0.74953</td>\n",
       "      <td>0.198713</td>\n",
       "      <td>0.200326</td>\n",
       "      <td>1228</td>\n",
       "      <td>0.252041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           True_negatives  False_positives  False_negatives  True_positives  \\\n",
       "Usability             908               74               31             215   \n",
       "\n",
       "           Accuracy    Recall  Precision  f1_score    PR_AUC   ROC_AUC  \\\n",
       "Usability  0.914495  0.873984   0.743945  0.803738  0.890878  0.948804   \n",
       "\n",
       "           Kappa Score  binary_cross_entropy  target_imbalance  target_size  \\\n",
       "Usability      0.74953              0.198713          0.200326         1228   \n",
       "\n",
       "           optimal_threshold  \n",
       "Usability           0.252041  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data log loss: 0.14627622582157657\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True_negatives</th>\n",
       "      <th>False_positives</th>\n",
       "      <th>False_negatives</th>\n",
       "      <th>True_positives</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Kappa Score</th>\n",
       "      <th>binary_cross_entropy</th>\n",
       "      <th>target_imbalance</th>\n",
       "      <th>target_size</th>\n",
       "      <th>optimal_thresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Usability</th>\n",
       "      <td>3664</td>\n",
       "      <td>261</td>\n",
       "      <td>62</td>\n",
       "      <td>921</td>\n",
       "      <td>0.934189</td>\n",
       "      <td>0.936928</td>\n",
       "      <td>0.779188</td>\n",
       "      <td>0.850808</td>\n",
       "      <td>0.946532</td>\n",
       "      <td>0.979946</td>\n",
       "      <td>0.809048</td>\n",
       "      <td>0.146276</td>\n",
       "      <td>0.200285</td>\n",
       "      <td>4908</td>\n",
       "      <td>0.252041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           True_negatives  False_positives  False_negatives  True_positives  \\\n",
       "Usability            3664              261               62             921   \n",
       "\n",
       "           Accuracy    Recall  Precision  f1_score    PR_AUC   ROC_AUC  \\\n",
       "Usability  0.934189  0.936928   0.779188  0.850808  0.946532  0.979946   \n",
       "\n",
       "           Kappa Score  binary_cross_entropy  target_imbalance  target_size  \\\n",
       "Usability     0.809048              0.146276          0.200285         4908   \n",
       "\n",
       "           optimal_thresh  \n",
       "Usability        0.252041  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model_xgb.predict_proba(X_valid)[:,1]\n",
    "report_valid, t = classification_metrics(y_valid, y_predicted)\n",
    "print('Validation data log loss:', log_loss(y_valid, y_predicted))\n",
    "model_logloss_on_valid_data['XGBoost'] = log_loss(y_valid, y_predicted)\n",
    "print('Optimal threshold:',t)\n",
    "display(pd.DataFrame(report_valid,[category]))\n",
    "\n",
    "y_predicted = model_xgb.predict_proba(X_train)[:,1]\n",
    "report_train, _ = classification_metrics_train(y_train, y_predicted, t)\n",
    "print('Train data log loss:', log_loss(y_train, y_predicted))\n",
    "pd.DataFrame(report_train,[category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:12.301312Z",
     "iopub.status.busy": "2021-12-31T15:41:12.301036Z",
     "iopub.status.idle": "2021-12-31T15:41:12.351035Z",
     "shell.execute_reply": "2021-12-31T15:41:12.350443Z",
     "shell.execute_reply.started": "2021-12-31T15:41:12.301278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model ..  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XGBoost_model.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Saving model .. \",end=\" \")\n",
    "joblib.dump(model_xgb,\"XGBoost_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:12.352889Z",
     "iopub.status.busy": "2021-12-31T15:41:12.352402Z",
     "iopub.status.idle": "2021-12-31T15:41:12.393772Z",
     "shell.execute_reply": "2021-12-31T15:41:12.392767Z",
     "shell.execute_reply.started": "2021-12-31T15:41:12.352855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire data log loss: 0.15677049861711814\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model_xgb.predict_proba(pd.concat([X_train, X_valid], axis = 0))[:,1]\n",
    "print('Entire data log loss:', log_loss(pd.concat([y_train, y_valid], axis = 0), y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:12.395774Z",
     "iopub.status.busy": "2021-12-31T15:41:12.395065Z",
     "iopub.status.idle": "2021-12-31T15:41:12.402972Z",
     "shell.execute_reply": "2021-12-31T15:41:12.401924Z",
     "shell.execute_reply.started": "2021-12-31T15:41:12.395726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 15)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.n_estimators, model_xgb.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:12.404616Z",
     "iopub.status.busy": "2021-12-31T15:41:12.404369Z",
     "iopub.status.idle": "2021-12-31T15:41:13.411719Z",
     "shell.execute_reply": "2021-12-31T15:41:13.410561Z",
     "shell.execute_reply.started": "2021-12-31T15:41:12.404560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align='center'><img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABkAAAAWCAYAAAA1vze2AAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAdxJREFUeNq0Vt1Rg0AQJjcpgBJiBWIFkgoMFYhPPAIVECogPuYpdJBYgXQQrMCUkA50V7+d2ZwXuXPGm9khHLu3f9+3l1nkWNvtNqfHLgpfQ1EUS3tz5nAQ0+NIsiAZSc6eDlI8M3J00B/mDuUKDk6kfOebAgW3pkdD0pFcODGW4gKKvOrAUm04MA4QDt1OEIXU9hDigfS5rC1eS5T90gltck1Xrizo257kgySZcNRzgCSxCvgiE9nckPJo2b/B2AcEkk2OwL8bD8gmOKR1GPbaCUqxEgTq0tLvgb6zfo7+DgYGkkWL2tqLDV4RSITfbHPPfJKIrWz4nJQTMPAWA7IbD6imcNaDeDfgk+4No+wZr40BL3g9eQJJCFqRQ54KiSt72lsLpE3o3MCBSxDuq4yOckU2hKXRuwBH3OyMR4g1UpyTYw6mlmBqNdUXRM1NfyF5EPI6JkcpIDBIX8jX6DR/6ckAZJ0wEAdLR8DEk6OfC1Pp8BKo6TQIwPJbvJ6toK5lmuvJoRtfK6Ym1iRYIarRo2UyYHvRN5qpakR3yoizWrouoyuXXQqI185LCw07op5ZyCRGL99h24InP0e9xdQukEKVmhzrqZuRIfwISB//cP3Wk3f8f/yR+BRgAHu00HjLcEQBAAAAAElFTkSuQmCC' /></div><script charset='utf-8'>!function(t){function e(r){if(n[r])return n[r].exports;var i=n[r]={i:r,l:!1,exports:{}};return t[r].call(i.exports,i,i.exports,e),i.l=!0,i.exports}var n={};return e.m=t,e.c=n,e.i=function(t){return t},e.d=function(t,n,r){e.o(t,n)||Object.defineProperty(t,n,{configurable:!1,enumerable:!0,get:r})},e.n=function(t){var n=t&&t.__esModule?function(){return t.default}:function(){return t};return e.d(n,\"a\",n),n},e.o=function(t,e){return Object.prototype.hasOwnProperty.call(t,e)},e.p=\"\",e(e.s=410)}([function(t,e,n){\"use strict\";function r(t,e,n,r,o,a,u,c){if(i(e),!t){var s;if(void 0===e)s=new Error(\"Minified exception occurred; use the non-minified dev environment for the full error message and additional helpful warnings.\");else{var l=[n,r,o,a,u,c],f=0;s=new Error(e.replace(/%s/g,function(){return l[f++]})),s.name=\"Invariant Violation\"}throw s.framesToPop=1,s}}var i=function(t){};t.exports=r},function(t,e,n){\"use strict\";var r=n(8),i=r;t.exports=i},function(t,e,n){\"use strict\";function r(t){for(var e=arguments.length-1,n=\"Minified React error #\"+t+\"; visit http://facebook.github.io/react/docs/error-decoder.html?invariant=\"+t,r=0;r<e;r++)n+=\"&args[]=\"+encodeURIComponent(arguments[r+1]);n+=\" for the full message or use the non-minified dev environment for full errors and additional helpful warnings.\";var i=new Error(n);throw i.name=\"Invariant Violation\",i.framesToPop=1,i}t.exports=r},function(t,e,n){\"use strict\";function r(t){if(null===t||void 0===t)throw new TypeError(\"Object.assign cannot be called with null or undefined\");return Object(t)}function i(){try{if(!Object.assign)return!1;var t=new String(\"abc\");if(t[5]=\"de\",\"5\"===Object.getOwnPropertyNames(t)[0])return!1;for(var e={},n=0;n<10;n++)e[\"_\"+String.fromCharCode(n)]=n;var r=Object.getOwnPropertyNames(e).map(function(t){return e[t]});if(\"0123456789\"!==r.join(\"\"))return!1;var i={};return\"abcdefghijklmnopqrst\".split(\"\").forEach(function(t){i[t]=t}),\"abcdefghijklmnopqrst\"===Object.keys(Object.assign({},i)).join(\"\")}catch(t){return!1}}/*\n",
       "object-assign\n",
       "(c) Sindre Sorhus\n",
       "@license MIT\n",
       "*/\n",
       "var o=Object.getOwnPropertySymbols,a=Object.prototype.hasOwnProperty,u=Object.prototype.propertyIsEnumerable;t.exports=i()?Object.assign:function(t,e){for(var n,i,c=r(t),s=1;s<arguments.length;s++){n=Object(arguments[s]);for(var l in n)a.call(n,l)&&(c[l]=n[l]);if(o){i=o(n);for(var f=0;f<i.length;f++)u.call(n,i[f])&&(c[i[f]]=n[i[f]])}}return c}},function(t,e,n){\"use strict\";function r(t,e){return 1===t.nodeType&&t.getAttribute(d)===String(e)||8===t.nodeType&&t.nodeValue===\" react-text: \"+e+\" \"||8===t.nodeType&&t.nodeValue===\" react-empty: \"+e+\" \"}function i(t){for(var e;e=t._renderedComponent;)t=e;return t}function o(t,e){var n=i(t);n._hostNode=e,e[g]=n}function a(t){var e=t._hostNode;e&&(delete e[g],t._hostNode=null)}function u(t,e){if(!(t._flags&v.hasCachedChildNodes)){var n=t._renderedChildren,a=e.firstChild;t:for(var u in n)if(n.hasOwnProperty(u)){var c=n[u],s=i(c)._domID;if(0!==s){for(;null!==a;a=a.nextSibling)if(r(a,s)){o(c,a);continue t}f(\"32\",s)}}t._flags|=v.hasCachedChildNodes}}function c(t){if(t[g])return t[g];for(var e=[];!t[g];){if(e.push(t),!t.parentNode)return null;t=t.parentNode}for(var n,r;t&&(r=t[g]);t=e.pop())n=r,e.length&&u(r,t);return n}function s(t){var e=c(t);return null!=e&&e._hostNode===t?e:null}function l(t){if(void 0===t._hostNode?f(\"33\"):void 0,t._hostNode)return t._hostNode;for(var e=[];!t._hostNode;)e.push(t),t._hostParent?void 0:f(\"34\"),t=t._hostParent;for(;e.length;t=e.pop())u(t,t._hostNode);return t._hostNode}var f=n(2),p=n(21),h=n(157),d=(n(0),p.ID_ATTRIBUTE_NAME),v=h,g=\"__reactInternalInstance$\"+Math.random().toString(36).slice(2),m={getClosestInstanceFromNode:c,getInstanceFromNode:s,getNodeFromInstance:l,precacheChildNodes:u,precacheNode:o,uncacheNode:a};t.exports=m},function(t,e,n){\"use strict\";function r(t,e,n,a){function u(e){return t(e=new Date(+e)),e}return u.floor=u,u.ceil=function(n){return t(n=new Date(n-1)),e(n,1),t(n),n},u.round=function(t){var e=u(t),n=u.ceil(t);return t-e<n-t?e:n},u.offset=function(t,n){return e(t=new Date(+t),null==n?1:Math.floor(n)),t},u.range=function(n,r,i){var o=[];if(n=u.ceil(n),i=null==i?1:Math.floor(i),!(n<r&&i>0))return o;do o.push(new Date(+n));while(e(n,i),t(n),n<r);return o},u.filter=function(n){return r(function(e){if(e>=e)for(;t(e),!n(e);)e.setTime(e-1)},function(t,r){if(t>=t)for(;--r>=0;)for(;e(t,1),!n(t););})},n&&(u.count=function(e,r){return i.setTime(+e),o.setTime(+r),t(i),t(o),Math.floor(n(i,o))},u.every=function(t){return t=Math.floor(t),isFinite(t)&&t>0?t>1?u.filter(a?function(e){return a(e)%t===0}:function(e){return u.count(0,e)%t===0}):u:null}),u}e.a=r;var i=new Date,o=new Date},function(t,e,n){\"use strict\";var r=!(\"undefined\"==typeof window||!window.document||!window.document.createElement),i={canUseDOM:r,canUseWorkers:\"undefined\"!=typeof Worker,canUseEventListeners:r&&!(!window.addEventListener&&!window.attachEvent),canUseViewport:r&&!!window.screen,isInWorker:!r};t.exports=i},function(t,e,n){\"use strict\";function r(t,e){this._groups=t,this._parents=e}function i(){return new r([[document.documentElement]],D)}var o=n(272),a=n(273),u=n(261),c=n(255),s=n(131),l=n(260),f=n(265),p=n(268),h=n(275),d=n(253),v=n(267),g=n(266),m=n(274),y=n(259),_=n(258),b=n(252),x=n(276),w=n(269),C=n(254),M=n(277),k=n(262),E=n(270),T=n(264),S=n(251),P=n(263),N=n(271),A=n(256),O=n(70),I=n(257);n.d(e,\"c\",function(){return D}),e.b=r;var D=[null];r.prototype=i.prototype={constructor:r,select:o.a,selectAll:a.a,filter:u.a,data:c.a,enter:s.a,exit:l.a,merge:f.a,order:p.a,sort:h.a,call:d.a,nodes:v.a,node:g.a,size:m.a,empty:y.a,each:_.a,attr:b.a,style:x.a,property:w.a,classed:C.a,text:M.a,html:k.a,raise:E.a,lower:T.a,append:S.a,insert:P.a,remove:N.a,datum:A.a,on:O.c,dispatch:I.a},e.a=i},function(t,e,n){\"use strict\";function r(t){return function(){return t}}var i=function(){};i.thatReturns=r,i.thatReturnsFalse=r(!1),i.thatReturnsTrue=r(!0),i.thatReturnsNull=r(null),i.thatReturnsThis=function(){return this},i.thatReturnsArgument=function(t){return t},t.exports=i},function(t,e,n){\"use strict\";var r=null;t.exports={debugTool:r}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(59);n.d(e,\"color\",function(){return r.a}),n.d(e,\"rgb\",function(){return r.b}),n.d(e,\"hsl\",function(){return r.c});var i=n(210);n.d(e,\"lab\",function(){return i.a}),n.d(e,\"hcl\",function(){return i.b});var o=n(209);n.d(e,\"cubehelix\",function(){return o.a})},function(t,e,n){\"use strict\";function r(){T.ReactReconcileTransaction&&x?void 0:l(\"123\")}function i(){this.reinitializeTransaction(),this.dirtyComponentsLength=null,this.callbackQueue=p.getPooled(),this.reconcileTransaction=T.ReactReconcileTransaction.getPooled(!0)}function o(t,e,n,i,o,a){return r(),x.batchedUpdates(t,e,n,i,o,a)}function a(t,e){return t._mountOrder-e._mountOrder}function u(t){var e=t.dirtyComponentsLength;e!==m.length?l(\"124\",e,m.length):void 0,m.sort(a),y++;for(var n=0;n<e;n++){var r=m[n],i=r._pendingCallbacks;r._pendingCallbacks=null;var o;if(d.logTopLevelRenders){var u=r;r._currentElement.type.isReactTopLevelWrapper&&(u=r._renderedComponent),o=\"React update: \"+u.getName(),console.time(o)}if(v.performUpdateIfNecessary(r,t.reconcileTransaction,y),o&&console.timeEnd(o),i)for(var c=0;c<i.length;c++)t.callbackQueue.enqueue(i[c],r.getPublicInstance())}}function c(t){return r(),x.isBatchingUpdates?(m.push(t),void(null==t._updateBatchNumber&&(t._updateBatchNumber=y+1))):void x.batchedUpdates(c,t)}function s(t,e){x.isBatchingUpdates?void 0:l(\"125\"),_.enqueue(t,e),b=!0}var l=n(2),f=n(3),p=n(155),h=n(17),d=n(160),v=n(24),g=n(53),m=(n(0),[]),y=0,_=p.getPooled(),b=!1,x=null,w={initialize:function(){this.dirtyComponentsLength=m.length},close:function(){this.dirtyComponentsLength!==m.length?(m.splice(0,this.dirtyComponentsLength),k()):m.length=0}},C={initialize:function(){this.callbackQueue.reset()},close:function(){this.callbackQueue.notifyAll()}},M=[w,C];f(i.prototype,g,{getTransactionWrappers:function(){return M},destructor:function(){this.dirtyComponentsLength=null,p.release(this.callbackQueue),this.callbackQueue=null,T.ReactReconcileTransaction.release(this.reconcileTransaction),this.reconcileTransaction=null},perform:function(t,e,n){return g.perform.call(this,this.reconcileTransaction.perform,this.reconcileTransaction,t,e,n)}}),h.addPoolingTo(i);var k=function(){for(;m.length||b;){if(m.length){var t=i.getPooled();t.perform(u,null,t),i.release(t)}if(b){b=!1;var e=_;_=p.getPooled(),e.notifyAll(),p.release(e)}}},E={injectReconcileTransaction:function(t){t?void 0:l(\"126\"),T.ReactReconcileTransaction=t},injectBatchingStrategy:function(t){t?void 0:l(\"127\"),\"function\"!=typeof t.batchedUpdates?l(\"128\"):void 0,\"boolean\"!=typeof t.isBatchingUpdates?l(\"129\"):void 0,x=t}},T={ReactReconcileTransaction:null,batchedUpdates:o,enqueueUpdate:c,flushBatchedUpdates:k,injection:E,asap:s};t.exports=T},function(t,e,n){\"use strict\";var r=n(102);n.d(e,\"c\",function(){return r.a});var i=n(18);n.d(e,\"f\",function(){return i.a});var o=n(103);n.d(e,\"d\",function(){return o.a});var a=(n(185),n(104),n(105),n(186),n(197),n(198),n(108),n(188),n(189),n(190),n(191),n(106),n(192),n(193),n(57));n.d(e,\"e\",function(){return a.a});var u=n(107);n.d(e,\"g\",function(){return u.a});var c=(n(194),n(195),n(196),n(109));n.d(e,\"a\",function(){return c.a}),n.d(e,\"b\",function(){return c.b});n(110),n(111),n(199)},function(t,e,n){\"use strict\";n.d(e,\"e\",function(){return r}),n.d(e,\"d\",function(){return i}),n.d(e,\"c\",function(){return o}),n.d(e,\"b\",function(){return a}),n.d(e,\"a\",function(){return u});var r=1e3,i=6e4,o=36e5,a=864e5,u=6048e5},function(t,e,n){\"use strict\";function r(t,e,n,r){this.dispatchConfig=t,this._targetInst=e,this.nativeEvent=n;var i=this.constructor.Interface;for(var o in i)if(i.hasOwnProperty(o)){var u=i[o];u?this[o]=u(n):\"target\"===o?this.target=r:this[o]=n[o]}var c=null!=n.defaultPrevented?n.defaultPrevented:n.returnValue===!1;return c?this.isDefaultPrevented=a.thatReturnsTrue:this.isDefaultPrevented=a.thatReturnsFalse,this.isPropagationStopped=a.thatReturnsFalse,this}var i=n(3),o=n(17),a=n(8),u=(n(1),\"function\"==typeof Proxy,[\"dispatchConfig\",\"_targetInst\",\"nativeEvent\",\"isDefaultPrevented\",\"isPropagationStopped\",\"_dispatchListeners\",\"_dispatchInstances\"]),c={type:null,target:null,currentTarget:a.thatReturnsNull,eventPhase:null,bubbles:null,cancelable:null,timeStamp:function(t){return t.timeStamp||Date.now()},defaultPrevented:null,isTrusted:null};i(r.prototype,{preventDefault:function(){this.defaultPrevented=!0;var t=this.nativeEvent;t&&(t.preventDefault?t.preventDefault():\"unknown\"!=typeof t.returnValue&&(t.returnValue=!1),this.isDefaultPrevented=a.thatReturnsTrue)},stopPropagation:function(){var t=this.nativeEvent;t&&(t.stopPropagation?t.stopPropagation():\"unknown\"!=typeof t.cancelBubble&&(t.cancelBubble=!0),this.isPropagationStopped=a.thatReturnsTrue)},persist:function(){this.isPersistent=a.thatReturnsTrue},isPersistent:a.thatReturnsFalse,destructor:function(){var t=this.constructor.Interface;for(var e in t)this[e]=null;for(var n=0;n<u.length;n++)this[u[n]]=null}}),r.Interface=c,r.augmentClass=function(t,e){var n=this,r=function(){};r.prototype=n.prototype;var a=new r;i(a,t.prototype),t.prototype=a,t.prototype.constructor=t,t.Interface=i({},n.Interface,e),t.augmentClass=n.augmentClass,o.addPoolingTo(t,o.fourArgumentPooler)},o.addPoolingTo(r,o.fourArgumentPooler),t.exports=r},function(t,e,n){\"use strict\";var r={current:null};t.exports=r},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return i}),n.d(e,\"b\",function(){return o});var r=Array.prototype,i=r.map,o=r.slice},function(t,e,n){\"use strict\";var r=n(2),i=(n(0),function(t){var e=this;if(e.instancePool.length){var n=e.instancePool.pop();return e.call(n,t),n}return new e(t)}),o=function(t,e){var n=this;if(n.instancePool.length){var r=n.instancePool.pop();return n.call(r,t,e),r}return new n(t,e)},a=function(t,e,n){var r=this;if(r.instancePool.length){var i=r.instancePool.pop();return r.call(i,t,e,n),i}return new r(t,e,n)},u=function(t,e,n,r){var i=this;if(i.instancePool.length){var o=i.instancePool.pop();return i.call(o,t,e,n,r),o}return new i(t,e,n,r)},c=function(t){var e=this;t instanceof e?void 0:r(\"25\"),t.destructor(),e.instancePool.length<e.poolSize&&e.instancePool.push(t)},s=10,l=i,f=function(t,e){var n=t;return n.instancePool=[],n.getPooled=e||l,n.poolSize||(n.poolSize=s),n.release=c,n},p={addPoolingTo:f,oneArgumentPooler:i,twoArgumentPooler:o,threeArgumentPooler:a,fourArgumentPooler:u};t.exports=p},function(t,e,n){\"use strict\";e.a=function(t,e){return t<e?-1:t>e?1:t>=e?0:NaN}},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";function r(t){if(g){var e=t.node,n=t.children;if(n.length)for(var r=0;r<n.length;r++)m(e,n[r],null);else null!=t.html?f(e,t.html):null!=t.text&&h(e,t.text)}}function i(t,e){t.parentNode.replaceChild(e.node,t),r(e)}function o(t,e){g?t.children.push(e):t.node.appendChild(e.node)}function a(t,e){g?t.html=e:f(t.node,e)}function u(t,e){g?t.text=e:h(t.node,e)}function c(){return this.node.nodeName}function s(t){return{node:t,children:[],html:null,text:null,toString:c}}var l=n(82),f=n(55),p=n(90),h=n(171),d=1,v=11,g=\"undefined\"!=typeof document&&\"number\"==typeof document.documentMode||\"undefined\"!=typeof navigator&&\"string\"==typeof navigator.userAgent&&/\\bEdge\\/\\d/.test(navigator.userAgent),m=p(function(t,e,n){e.node.nodeType===v||e.node.nodeType===d&&\"object\"===e.node.nodeName.toLowerCase()&&(null==e.node.namespaceURI||e.node.namespaceURI===l.html)?(r(e),t.insertBefore(e.node,n)):(t.insertBefore(e.node,n),r(e))});s.insertTreeBefore=m,s.replaceChildWithTree=i,s.queueChild=o,s.queueHTML=a,s.queueText=u,t.exports=s},function(t,e,n){\"use strict\";function r(t,e){return(t&e)===e}var i=n(2),o=(n(0),{MUST_USE_PROPERTY:1,HAS_BOOLEAN_VALUE:4,HAS_NUMERIC_VALUE:8,HAS_POSITIVE_NUMERIC_VALUE:24,HAS_OVERLOADED_BOOLEAN_VALUE:32,injectDOMPropertyConfig:function(t){var e=o,n=t.Properties||{},a=t.DOMAttributeNamespaces||{},c=t.DOMAttributeNames||{},s=t.DOMPropertyNames||{},l=t.DOMMutationMethods||{};t.isCustomAttribute&&u._isCustomAttributeFunctions.push(t.isCustomAttribute);for(var f in n){u.properties.hasOwnProperty(f)?i(\"48\",f):void 0;var p=f.toLowerCase(),h=n[f],d={attributeName:p,attributeNamespace:null,propertyName:f,mutationMethod:null,mustUseProperty:r(h,e.MUST_USE_PROPERTY),hasBooleanValue:r(h,e.HAS_BOOLEAN_VALUE),hasNumericValue:r(h,e.HAS_NUMERIC_VALUE),hasPositiveNumericValue:r(h,e.HAS_POSITIVE_NUMERIC_VALUE),hasOverloadedBooleanValue:r(h,e.HAS_OVERLOADED_BOOLEAN_VALUE)};if(d.hasBooleanValue+d.hasNumericValue+d.hasOverloadedBooleanValue<=1?void 0:i(\"50\",f),c.hasOwnProperty(f)){var v=c[f];d.attributeName=v}a.hasOwnProperty(f)&&(d.attributeNamespace=a[f]),s.hasOwnProperty(f)&&(d.propertyName=s[f]),l.hasOwnProperty(f)&&(d.mutationMethod=l[f]),u.properties[f]=d}}}),a=\":A-Z_a-z\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u02FF\\\\u0370-\\\\u037D\\\\u037F-\\\\u1FFF\\\\u200C-\\\\u200D\\\\u2070-\\\\u218F\\\\u2C00-\\\\u2FEF\\\\u3001-\\\\uD7FF\\\\uF900-\\\\uFDCF\\\\uFDF0-\\\\uFFFD\",u={ID_ATTRIBUTE_NAME:\"data-reactid\",ROOT_ATTRIBUTE_NAME:\"data-reactroot\",ATTRIBUTE_NAME_START_CHAR:a,ATTRIBUTE_NAME_CHAR:a+\"\\\\-.0-9\\\\u00B7\\\\u0300-\\\\u036F\\\\u203F-\\\\u2040\",properties:{},getPossibleStandardName:null,_isCustomAttributeFunctions:[],isCustomAttribute:function(t){for(var e=0;e<u._isCustomAttributeFunctions.length;e++){var n=u._isCustomAttributeFunctions[e];if(n(t))return!0}return!1},injection:o};t.exports=u},function(t,e,n){\"use strict\";function r(t){return\"button\"===t||\"input\"===t||\"select\"===t||\"textarea\"===t}function i(t,e,n){switch(t){case\"onClick\":case\"onClickCapture\":case\"onDoubleClick\":case\"onDoubleClickCapture\":case\"onMouseDown\":case\"onMouseDownCapture\":case\"onMouseMove\":case\"onMouseMoveCapture\":case\"onMouseUp\":case\"onMouseUpCapture\":return!(!n.disabled||!r(e));default:return!1}}var o=n(2),a=n(83),u=n(50),c=n(87),s=n(165),l=n(166),f=(n(0),{}),p=null,h=function(t,e){t&&(u.executeDispatchesInOrder(t,e),t.isPersistent()||t.constructor.release(t))},d=function(t){return h(t,!0)},v=function(t){return h(t,!1)},g=function(t){return\".\"+t._rootNodeID},m={injection:{injectEventPluginOrder:a.injectEventPluginOrder,injectEventPluginsByName:a.injectEventPluginsByName},putListener:function(t,e,n){\"function\"!=typeof n?o(\"94\",e,typeof n):void 0;var r=g(t),i=f[e]||(f[e]={});i[r]=n;var u=a.registrationNameModules[e];u&&u.didPutListener&&u.didPutListener(t,e,n)},getListener:function(t,e){var n=f[e];if(i(e,t._currentElement.type,t._currentElement.props))return null;var r=g(t);return n&&n[r]},deleteListener:function(t,e){var n=a.registrationNameModules[e];n&&n.willDeleteListener&&n.willDeleteListener(t,e);var r=f[e];if(r){var i=g(t);delete r[i]}},deleteAllListeners:function(t){var e=g(t);for(var n in f)if(f.hasOwnProperty(n)&&f[n][e]){var r=a.registrationNameModules[n];r&&r.willDeleteListener&&r.willDeleteListener(t,n),delete f[n][e]}},extractEvents:function(t,e,n,r){for(var i,o=a.plugins,u=0;u<o.length;u++){var c=o[u];if(c){var l=c.extractEvents(t,e,n,r);l&&(i=s(i,l))}}return i},enqueueEvents:function(t){t&&(p=s(p,t))},processEventQueue:function(t){var e=p;p=null,t?l(e,d):l(e,v),p?o(\"95\"):void 0,c.rethrowCaughtError()},__purge:function(){f={}},__getListenerBank:function(){return f}};t.exports=m},function(t,e,n){\"use strict\";function r(t,e,n){var r=e.dispatchConfig.phasedRegistrationNames[n];return m(t,r)}function i(t,e,n){var i=r(t,n,e);i&&(n._dispatchListeners=v(n._dispatchListeners,i),n._dispatchInstances=v(n._dispatchInstances,t))}function o(t){t&&t.dispatchConfig.phasedRegistrationNames&&d.traverseTwoPhase(t._targetInst,i,t)}function a(t){if(t&&t.dispatchConfig.phasedRegistrationNames){var e=t._targetInst,n=e?d.getParentInstance(e):null;d.traverseTwoPhase(n,i,t)}}function u(t,e,n){if(n&&n.dispatchConfig.registrationName){var r=n.dispatchConfig.registrationName,i=m(t,r);i&&(n._dispatchListeners=v(n._dispatchListeners,i),n._dispatchInstances=v(n._dispatchInstances,t))}}function c(t){t&&t.dispatchConfig.registrationName&&u(t._targetInst,null,t)}function s(t){g(t,o)}function l(t){g(t,a)}function f(t,e,n,r){d.traverseEnterLeave(n,r,u,t,e)}function p(t){g(t,c)}var h=n(22),d=n(50),v=n(165),g=n(166),m=(n(1),h.getListener),y={accumulateTwoPhaseDispatches:s,accumulateTwoPhaseDispatchesSkipTarget:l,accumulateDirectDispatches:p,accumulateEnterLeaveDispatches:f};t.exports=y},function(t,e,n){\"use strict\";function r(){i.attachRefs(this,this._currentElement)}var i=n(368),o=(n(9),n(1),{mountComponent:function(t,e,n,i,o,a){var u=t.mountComponent(e,n,i,o,a);return t._currentElement&&null!=t._currentElement.ref&&e.getReactMountReady().enqueue(r,t),u},getHostNode:function(t){return t.getHostNode()},unmountComponent:function(t,e){i.detachRefs(t,t._currentElement),t.unmountComponent(e)},receiveComponent:function(t,e,n,o){var a=t._currentElement;if(e!==a||o!==t._context){var u=i.shouldUpdateRefs(a,e);u&&i.detachRefs(t,a),t.receiveComponent(e,n,o),u&&t._currentElement&&null!=t._currentElement.ref&&n.getReactMountReady().enqueue(r,t)}},performUpdateIfNecessary:function(t,e,n){t._updateBatchNumber===n&&t.performUpdateIfNecessary(e)}});t.exports=o},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o=n(93),a={view:function(t){if(t.view)return t.view;var e=o(t);if(e.window===e)return e;var n=e.ownerDocument;return n?n.defaultView||n.parentWindow:window},detail:function(t){return t.detail||0}};i.augmentClass(r,a),t.exports=r},function(t,e,n){\"use strict\";var r=n(3),i=n(401),o=n(97),a=n(406),u=n(402),c=n(403),s=n(27),l=n(404),f=n(407),p=n(408),h=(n(1),s.createElement),d=s.createFactory,v=s.cloneElement,g=r,m={Children:{map:i.map,forEach:i.forEach,count:i.count,toArray:i.toArray,only:p},Component:o,PureComponent:a,createElement:h,cloneElement:v,isValidElement:s.isValidElement,PropTypes:l,createClass:u.createClass,createFactory:d,createMixin:function(t){return t},DOM:c,version:f,__spread:g};t.exports=m},function(t,e,n){\"use strict\";function r(t){return void 0!==t.ref}function i(t){return void 0!==t.key}var o=n(3),a=n(15),u=(n(1),n(176),Object.prototype.hasOwnProperty),c=n(174),s={key:!0,ref:!0,__self:!0,__source:!0},l=function(t,e,n,r,i,o,a){var u={$$typeof:c,type:t,key:e,ref:n,props:a,_owner:o};return u};l.createElement=function(t,e,n){var o,c={},f=null,p=null,h=null,d=null;if(null!=e){r(e)&&(p=e.ref),i(e)&&(f=\"\"+e.key),h=void 0===e.__self?null:e.__self,d=void 0===e.__source?null:e.__source;for(o in e)u.call(e,o)&&!s.hasOwnProperty(o)&&(c[o]=e[o])}var v=arguments.length-2;if(1===v)c.children=n;else if(v>1){for(var g=Array(v),m=0;m<v;m++)g[m]=arguments[m+2];c.children=g}if(t&&t.defaultProps){var y=t.defaultProps;for(o in y)void 0===c[o]&&(c[o]=y[o])}return l(t,f,p,h,d,a.current,c)},l.createFactory=function(t){var e=l.createElement.bind(null,t);return e.type=t,e},l.cloneAndReplaceKey=function(t,e){var n=l(t.type,e,t.ref,t._self,t._source,t._owner,t.props);return n},l.cloneElement=function(t,e,n){var c,f=o({},t.props),p=t.key,h=t.ref,d=t._self,v=t._source,g=t._owner;if(null!=e){r(e)&&(h=e.ref,g=a.current),i(e)&&(p=\"\"+e.key);var m;t.type&&t.type.defaultProps&&(m=t.type.defaultProps);for(c in e)u.call(e,c)&&!s.hasOwnProperty(c)&&(void 0===e[c]&&void 0!==m?f[c]=m[c]:f[c]=e[c])}var y=arguments.length-2;if(1===y)f.children=n;else if(y>1){for(var _=Array(y),b=0;b<y;b++)_[b]=arguments[b+2];f.children=_}return l(t.type,p,h,d,v,g,f)},l.isValidElement=function(t){return\"object\"==typeof t&&null!==t&&t.$$typeof===c},t.exports=l},function(t,e,n){\"use strict\";function r(t){for(var e=arguments.length-1,n=\"Minified React error #\"+t+\"; visit http://facebook.github.io/react/docs/error-decoder.html?invariant=\"+t,r=0;r<e;r++)n+=\"&args[]=\"+encodeURIComponent(arguments[r+1]);n+=\" for the full message or use the non-minified dev environment for full errors and additional helpful warnings.\";var i=new Error(n);throw i.name=\"Invariant Violation\",i.framesToPop=1,i}t.exports=r},function(t,e,n){\"use strict\";e.a=function(t){return null===t?NaN:+t}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(211);n.d(e,\"formatDefaultLocale\",function(){return r.a}),n.d(e,\"format\",function(){return r.b}),n.d(e,\"formatPrefix\",function(){return r.c});var i=n(117);n.d(e,\"formatLocale\",function(){return i.a});var o=n(115);n.d(e,\"formatSpecifier\",function(){return o.a});var a=n(215);n.d(e,\"precisionFixed\",function(){return a.a});var u=n(216);n.d(e,\"precisionPrefix\",function(){return u.a});var c=n(217);n.d(e,\"precisionRound\",function(){return c.a})},function(t,e,n){\"use strict\";var r=n(63);n.d(e,\"b\",function(){return r.a});var i=(n(118),n(62),n(119),n(121),n(43));n.d(e,\"a\",function(){return i.a});var o=(n(122),n(223));n.d(e,\"c\",function(){return o.a});var a=(n(124),n(225),n(227),n(123),n(220),n(221),n(219),n(218));n.d(e,\"d\",function(){return a.a});n(222)},function(t,e,n){\"use strict\";function r(t,e){return function(n){return t+n*e}}function i(t,e,n){return t=Math.pow(t,n),e=Math.pow(e,n)-t,n=1/n,function(r){return Math.pow(t+r*e,n)}}function o(t,e){var i=e-t;return i?r(t,i>180||i<-180?i-360*Math.round(i/360):i):n.i(c.a)(isNaN(t)?e:t)}function a(t){return 1===(t=+t)?u:function(e,r){return r-e?i(e,r,t):n.i(c.a)(isNaN(e)?r:e)}}function u(t,e){var i=e-t;return i?r(t,i):n.i(c.a)(isNaN(t)?e:t)}var c=n(120);e.b=o,e.c=a,e.a=u},function(t,e,n){\"use strict\";e.a=function(t){return t.match(/.{6}/g).map(function(t){return\"#\"+t})}},function(t,e,n){\"use strict\";function r(t){var e=t.domain;return t.ticks=function(t){var r=e();return n.i(o.a)(r[0],r[r.length-1],null==t?10:t)},t.tickFormat=function(t,r){return n.i(c.a)(e(),t,r)},t.nice=function(r){var i=e(),a=i.length-1,u=null==r?10:r,c=i[0],s=i[a],l=n.i(o.b)(c,s,u);return l&&(l=n.i(o.b)(Math.floor(c/l)*l,Math.ceil(s/l)*l,u),i[0]=Math.floor(c/l)*l,i[a]=Math.ceil(s/l)*l,e(i)),t},t}function i(){var t=n.i(u.a)(u.b,a.a);return t.copy=function(){return n.i(u.c)(t,i())},r(t)}var o=n(12),a=n(31),u=n(45),c=n(243);e.b=r,e.a=i},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return r}),n.d(e,\"b\",function(){return i}),n.d(e,\"d\",function(){return o}),n.d(e,\"c\",function(){return a});var r=1e-12,i=Math.PI,o=i/2,a=2*i},function(t,e,n){\"use strict\";e.a=function(t,e){if((r=t.length)>1)for(var n,r,i=1,o=t[e[0]],a=o.length;i<r;++i){n=o,o=t[e[i]];for(var u=0;u<a;++u)o[u][1]+=o[u][0]=isNaN(n[u][1])?n[u][0]:n[u][1]}}},function(t,e,n){\"use strict\";e.a=function(t){for(var e=t.length,n=new Array(e);--e>=0;)n[e]=e;return n}},function(t,e,n){\"use strict\";var r={};t.exports=r},function(t,e,n){(function(t,r){var i;(function(){function o(t,e){return t.set(e[0],e[1]),t}function a(t,e){return t.add(e),t}function u(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}function c(t,e,n,r){for(var i=-1,o=null==t?0:t.length;++i<o;){var a=t[i];e(r,a,n(a),t)}return r}function s(t,e){for(var n=-1,r=null==t?0:t.length;++n<r&&e(t[n],n,t)!==!1;);return t}function l(t,e){for(var n=null==t?0:t.length;n--&&e(t[n],n,t)!==!1;);return t}function f(t,e){for(var n=-1,r=null==t?0:t.length;++n<r;)if(!e(t[n],n,t))return!1;return!0}function p(t,e){for(var n=-1,r=null==t?0:t.length,i=0,o=[];++n<r;){var a=t[n];e(a,n,t)&&(o[i++]=a)}return o}function h(t,e){var n=null==t?0:t.length;return!!n&&M(t,e,0)>-1}function d(t,e,n){for(var r=-1,i=null==t?0:t.length;++r<i;)if(n(e,t[r]))return!0;return!1}function v(t,e){for(var n=-1,r=null==t?0:t.length,i=Array(r);++n<r;)i[n]=e(t[n],n,t);return i}function g(t,e){for(var n=-1,r=e.length,i=t.length;++n<r;)t[i+n]=e[n];return t}function m(t,e,n,r){var i=-1,o=null==t?0:t.length;for(r&&o&&(n=t[++i]);++i<o;)n=e(n,t[i],i,t);return n}function y(t,e,n,r){var i=null==t?0:t.length;for(r&&i&&(n=t[--i]);i--;)n=e(n,t[i],i,t);return n}function _(t,e){for(var n=-1,r=null==t?0:t.length;++n<r;)if(e(t[n],n,t))return!0;return!1}function b(t){return t.split(\"\")}function x(t){return t.match(ze)||[]}function w(t,e,n){var r;return n(t,function(t,n,i){if(e(t,n,i))return r=n,!1}),r}function C(t,e,n,r){for(var i=t.length,o=n+(r?1:-1);r?o--:++o<i;)if(e(t[o],o,t))return o;return-1}function M(t,e,n){return e===e?Z(t,e,n):C(t,E,n)}function k(t,e,n,r){for(var i=n-1,o=t.length;++i<o;)if(r(t[i],e))return i;return-1}function E(t){return t!==t}function T(t,e){var n=null==t?0:t.length;return n?O(t,e)/n:Ut}function S(t){return function(e){return null==e?it:e[t]}}function P(t){return function(e){return null==t?it:t[e]}}function N(t,e,n,r,i){return i(t,function(t,i,o){n=r?(r=!1,t):e(n,t,i,o)}),n}function A(t,e){var n=t.length;for(t.sort(e);n--;)t[n]=t[n].value;return t}function O(t,e){for(var n,r=-1,i=t.length;++r<i;){var o=e(t[r]);o!==it&&(n=n===it?o:n+o)}return n}function I(t,e){for(var n=-1,r=Array(t);++n<t;)r[n]=e(n);return r}function D(t,e){return v(e,function(e){return[e,t[e]]})}function R(t){return function(e){return t(e)}}function L(t,e){return v(e,function(e){return t[e]})}function U(t,e){return t.has(e)}function F(t,e){for(var n=-1,r=t.length;++n<r&&M(e,t[n],0)>-1;);return n}function j(t,e){for(var n=t.length;n--&&M(e,t[n],0)>-1;);return n}function B(t,e){for(var n=t.length,r=0;n--;)t[n]===e&&++r;return r}function W(t){return\"\\\\\"+nr[t]}function V(t,e){return null==t?it:t[e]}function z(t){return Kn.test(t)}function H(t){return Gn.test(t)}function q(t){for(var e,n=[];!(e=t.next()).done;)n.push(e.value);return n}function Y(t){var e=-1,n=Array(t.size);return t.forEach(function(t,r){n[++e]=[r,t]}),n}function K(t,e){return function(n){return t(e(n))}}function G(t,e){for(var n=-1,r=t.length,i=0,o=[];++n<r;){var a=t[n];a!==e&&a!==ft||(t[n]=ft,o[i++]=n)}return o}function $(t){var e=-1,n=Array(t.size);return t.forEach(function(t){n[++e]=t}),n}function X(t){var e=-1,n=Array(t.size);return t.forEach(function(t){n[++e]=[t,t]}),n}function Z(t,e,n){for(var r=n-1,i=t.length;++r<i;)if(t[r]===e)return r;return-1}function Q(t,e,n){for(var r=n+1;r--;)if(t[r]===e)return r;return r}function J(t){return z(t)?et(t):_r(t)}function tt(t){return z(t)?nt(t):b(t)}function et(t){for(var e=qn.lastIndex=0;qn.test(t);)++e;return e}function nt(t){return t.match(qn)||[]}function rt(t){return t.match(Yn)||[]}var it,ot=\"4.17.4\",at=200,ut=\"Unsupported core-js use. Try https://npms.io/search?q=ponyfill.\",ct=\"Expected a function\",st=\"__lodash_hash_undefined__\",lt=500,ft=\"__lodash_placeholder__\",pt=1,ht=2,dt=4,vt=1,gt=2,mt=1,yt=2,_t=4,bt=8,xt=16,wt=32,Ct=64,Mt=128,kt=256,Et=512,Tt=30,St=\"...\",Pt=800,Nt=16,At=1,Ot=2,It=3,Dt=1/0,Rt=9007199254740991,Lt=1.7976931348623157e308,Ut=NaN,Ft=4294967295,jt=Ft-1,Bt=Ft>>>1,Wt=[[\"ary\",Mt],[\"bind\",mt],[\"bindKey\",yt],[\"curry\",bt],[\"curryRight\",xt],[\"flip\",Et],[\"partial\",wt],[\"partialRight\",Ct],[\"rearg\",kt]],Vt=\"[object Arguments]\",zt=\"[object Array]\",Ht=\"[object AsyncFunction]\",qt=\"[object Boolean]\",Yt=\"[object Date]\",Kt=\"[object DOMException]\",Gt=\"[object Error]\",$t=\"[object Function]\",Xt=\"[object GeneratorFunction]\",Zt=\"[object Map]\",Qt=\"[object Number]\",Jt=\"[object Null]\",te=\"[object Object]\",ee=\"[object Promise]\",ne=\"[object Proxy]\",re=\"[object RegExp]\",ie=\"[object Set]\",oe=\"[object String]\",ae=\"[object Symbol]\",ue=\"[object Undefined]\",ce=\"[object WeakMap]\",se=\"[object WeakSet]\",le=\"[object ArrayBuffer]\",fe=\"[object DataView]\",pe=\"[object Float32Array]\",he=\"[object Float64Array]\",de=\"[object Int8Array]\",ve=\"[object Int16Array]\",ge=\"[object Int32Array]\",me=\"[object Uint8Array]\",ye=\"[object Uint8ClampedArray]\",_e=\"[object Uint16Array]\",be=\"[object Uint32Array]\",xe=/\\b__p \\+= '';/g,we=/\\b(__p \\+=) '' \\+/g,Ce=/(__e\\(.*?\\)|\\b__t\\)) \\+\\n'';/g,Me=/&(?:amp|lt|gt|quot|#39);/g,ke=/[&<>\"']/g,Ee=RegExp(Me.source),Te=RegExp(ke.source),Se=/<%-([\\s\\S]+?)%>/g,Pe=/<%([\\s\\S]+?)%>/g,Ne=/<%=([\\s\\S]+?)%>/g,Ae=/\\.|\\[(?:[^[\\]]*|([\"'])(?:(?!\\1)[^\\\\]|\\\\.)*?\\1)\\]/,Oe=/^\\w*$/,Ie=/^\\./,De=/[^.[\\]]+|\\[(?:(-?\\d+(?:\\.\\d+)?)|([\"'])((?:(?!\\2)[^\\\\]|\\\\.)*?)\\2)\\]|(?=(?:\\.|\\[\\])(?:\\.|\\[\\]|$))/g,Re=/[\\\\^$.*+?()[\\]{}|]/g,Le=RegExp(Re.source),Ue=/^\\s+|\\s+$/g,Fe=/^\\s+/,je=/\\s+$/,Be=/\\{(?:\\n\\/\\* \\[wrapped with .+\\] \\*\\/)?\\n?/,We=/\\{\\n\\/\\* \\[wrapped with (.+)\\] \\*/,Ve=/,? & /,ze=/[^\\x00-\\x2f\\x3a-\\x40\\x5b-\\x60\\x7b-\\x7f]+/g,He=/\\\\(\\\\)?/g,qe=/\\$\\{([^\\\\}]*(?:\\\\.[^\\\\}]*)*)\\}/g,Ye=/\\w*$/,Ke=/^[-+]0x[0-9a-f]+$/i,Ge=/^0b[01]+$/i,$e=/^\\[object .+?Constructor\\]$/,Xe=/^0o[0-7]+$/i,Ze=/^(?:0|[1-9]\\d*)$/,Qe=/[\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\xff\\u0100-\\u017f]/g,Je=/($^)/,tn=/['\\n\\r\\u2028\\u2029\\\\]/g,en=\"\\\\ud800-\\\\udfff\",nn=\"\\\\u0300-\\\\u036f\",rn=\"\\\\ufe20-\\\\ufe2f\",on=\"\\\\u20d0-\\\\u20ff\",an=nn+rn+on,un=\"\\\\u2700-\\\\u27bf\",cn=\"a-z\\\\xdf-\\\\xf6\\\\xf8-\\\\xff\",sn=\"\\\\xac\\\\xb1\\\\xd7\\\\xf7\",ln=\"\\\\x00-\\\\x2f\\\\x3a-\\\\x40\\\\x5b-\\\\x60\\\\x7b-\\\\xbf\",fn=\"\\\\u2000-\\\\u206f\",pn=\" \\\\t\\\\x0b\\\\f\\\\xa0\\\\ufeff\\\\n\\\\r\\\\u2028\\\\u2029\\\\u1680\\\\u180e\\\\u2000\\\\u2001\\\\u2002\\\\u2003\\\\u2004\\\\u2005\\\\u2006\\\\u2007\\\\u2008\\\\u2009\\\\u200a\\\\u202f\\\\u205f\\\\u3000\",hn=\"A-Z\\\\xc0-\\\\xd6\\\\xd8-\\\\xde\",dn=\"\\\\ufe0e\\\\ufe0f\",vn=sn+ln+fn+pn,gn=\"['â€™]\",mn=\"[\"+en+\"]\",yn=\"[\"+vn+\"]\",_n=\"[\"+an+\"]\",bn=\"\\\\d+\",xn=\"[\"+un+\"]\",wn=\"[\"+cn+\"]\",Cn=\"[^\"+en+vn+bn+un+cn+hn+\"]\",Mn=\"\\\\ud83c[\\\\udffb-\\\\udfff]\",kn=\"(?:\"+_n+\"|\"+Mn+\")\",En=\"[^\"+en+\"]\",Tn=\"(?:\\\\ud83c[\\\\udde6-\\\\uddff]){2}\",Sn=\"[\\\\ud800-\\\\udbff][\\\\udc00-\\\\udfff]\",Pn=\"[\"+hn+\"]\",Nn=\"\\\\u200d\",An=\"(?:\"+wn+\"|\"+Cn+\")\",On=\"(?:\"+Pn+\"|\"+Cn+\")\",In=\"(?:\"+gn+\"(?:d|ll|m|re|s|t|ve))?\",Dn=\"(?:\"+gn+\"(?:D|LL|M|RE|S|T|VE))?\",Rn=kn+\"?\",Ln=\"[\"+dn+\"]?\",Un=\"(?:\"+Nn+\"(?:\"+[En,Tn,Sn].join(\"|\")+\")\"+Ln+Rn+\")*\",Fn=\"\\\\d*(?:(?:1st|2nd|3rd|(?![123])\\\\dth)\\\\b)\",jn=\"\\\\d*(?:(?:1ST|2ND|3RD|(?![123])\\\\dTH)\\\\b)\",Bn=Ln+Rn+Un,Wn=\"(?:\"+[xn,Tn,Sn].join(\"|\")+\")\"+Bn,Vn=\"(?:\"+[En+_n+\"?\",_n,Tn,Sn,mn].join(\"|\")+\")\",zn=RegExp(gn,\"g\"),Hn=RegExp(_n,\"g\"),qn=RegExp(Mn+\"(?=\"+Mn+\")|\"+Vn+Bn,\"g\"),Yn=RegExp([Pn+\"?\"+wn+\"+\"+In+\"(?=\"+[yn,Pn,\"$\"].join(\"|\")+\")\",On+\"+\"+Dn+\"(?=\"+[yn,Pn+An,\"$\"].join(\"|\")+\")\",Pn+\"?\"+An+\"+\"+In,Pn+\"+\"+Dn,jn,Fn,bn,Wn].join(\"|\"),\"g\"),Kn=RegExp(\"[\"+Nn+en+an+dn+\"]\"),Gn=/[a-z][A-Z]|[A-Z]{2,}[a-z]|[0-9][a-zA-Z]|[a-zA-Z][0-9]|[^a-zA-Z0-9 ]/,$n=[\"Array\",\"Buffer\",\"DataView\",\"Date\",\"Error\",\"Float32Array\",\"Float64Array\",\"Function\",\"Int8Array\",\"Int16Array\",\"Int32Array\",\"Map\",\"Math\",\"Object\",\"Promise\",\"RegExp\",\"Set\",\"String\",\"Symbol\",\"TypeError\",\"Uint8Array\",\"Uint8ClampedArray\",\"Uint16Array\",\"Uint32Array\",\"WeakMap\",\"_\",\"clearTimeout\",\"isFinite\",\"parseInt\",\"setTimeout\"],Xn=-1,Zn={};Zn[pe]=Zn[he]=Zn[de]=Zn[ve]=Zn[ge]=Zn[me]=Zn[ye]=Zn[_e]=Zn[be]=!0,Zn[Vt]=Zn[zt]=Zn[le]=Zn[qt]=Zn[fe]=Zn[Yt]=Zn[Gt]=Zn[$t]=Zn[Zt]=Zn[Qt]=Zn[te]=Zn[re]=Zn[ie]=Zn[oe]=Zn[ce]=!1;var Qn={};Qn[Vt]=Qn[zt]=Qn[le]=Qn[fe]=Qn[qt]=Qn[Yt]=Qn[pe]=Qn[he]=Qn[de]=Qn[ve]=Qn[ge]=Qn[Zt]=Qn[Qt]=Qn[te]=Qn[re]=Qn[ie]=Qn[oe]=Qn[ae]=Qn[me]=Qn[ye]=Qn[_e]=Qn[be]=!0,Qn[Gt]=Qn[$t]=Qn[ce]=!1;var Jn={\"Ã€\":\"A\",\"Ã\":\"A\",\"Ã‚\":\"A\",\"Ãƒ\":\"A\",\"Ã„\":\"A\",\"Ã…\":\"A\",\"Ã \":\"a\",\"Ã¡\":\"a\",\"Ã¢\":\"a\",\"Ã£\":\"a\",\"Ã¤\":\"a\",\"Ã¥\":\"a\",\"Ã‡\":\"C\",\"Ã§\":\"c\",\"Ã\":\"D\",\"Ã°\":\"d\",\"Ãˆ\":\"E\",\"Ã‰\":\"E\",\"ÃŠ\":\"E\",\"Ã‹\":\"E\",\"Ã¨\":\"e\",\"Ã©\":\"e\",\"Ãª\":\"e\",\"Ã«\":\"e\",\"ÃŒ\":\"I\",\"Ã\":\"I\",\"ÃŽ\":\"I\",\"Ã\":\"I\",\"Ã¬\":\"i\",\"Ã­\":\"i\",\"Ã®\":\"i\",\"Ã¯\":\"i\",\"Ã‘\":\"N\",\"Ã±\":\"n\",\"Ã’\":\"O\",\"Ã“\":\"O\",\"Ã”\":\"O\",\"Ã•\":\"O\",\"Ã–\":\"O\",\"Ã˜\":\"O\",\"Ã²\":\"o\",\"Ã³\":\"o\",\"Ã´\":\"o\",\"Ãµ\":\"o\",\"Ã¶\":\"o\",\"Ã¸\":\"o\",\"Ã™\":\"U\",\"Ãš\":\"U\",\"Ã›\":\"U\",\"Ãœ\":\"U\",\"Ã¹\":\"u\",\"Ãº\":\"u\",\"Ã»\":\"u\",\"Ã¼\":\"u\",\"Ã\":\"Y\",\"Ã½\":\"y\",\"Ã¿\":\"y\",\"Ã†\":\"Ae\",\"Ã¦\":\"ae\",\"Ãž\":\"Th\",\"Ã¾\":\"th\",\"ÃŸ\":\"ss\",\"Ä€\":\"A\",\"Ä‚\":\"A\",\"Ä„\":\"A\",\"Ä\":\"a\",\"Äƒ\":\"a\",\"Ä…\":\"a\",\"Ä†\":\"C\",\"Äˆ\":\"C\",\"ÄŠ\":\"C\",\"ÄŒ\":\"C\",\"Ä‡\":\"c\",\"Ä‰\":\"c\",\"Ä‹\":\"c\",\"Ä\":\"c\",\"ÄŽ\":\"D\",\"Ä\":\"D\",\"Ä\":\"d\",\"Ä‘\":\"d\",\"Ä’\":\"E\",\"Ä”\":\"E\",\"Ä–\":\"E\",\"Ä˜\":\"E\",\"Äš\":\"E\",\"Ä“\":\"e\",\"Ä•\":\"e\",\"Ä—\":\"e\",\"Ä™\":\"e\",\"Ä›\":\"e\",\"Äœ\":\"G\",\"Äž\":\"G\",\"Ä \":\"G\",\"Ä¢\":\"G\",\"Ä\":\"g\",\"ÄŸ\":\"g\",\"Ä¡\":\"g\",\"Ä£\":\"g\",\"Ä¤\":\"H\",\"Ä¦\":\"H\",\"Ä¥\":\"h\",\"Ä§\":\"h\",\"Ä¨\":\"I\",\"Äª\":\"I\",\"Ä¬\":\"I\",\"Ä®\":\"I\",\"Ä°\":\"I\",\"Ä©\":\"i\",\"Ä«\":\"i\",\"Ä­\":\"i\",\"Ä¯\":\"i\",\"Ä±\":\"i\",\"Ä´\":\"J\",\"Äµ\":\"j\",\"Ä¶\":\"K\",\"Ä·\":\"k\",\"Ä¸\":\"k\",\"Ä¹\":\"L\",\"Ä»\":\"L\",\"Ä½\":\"L\",\"Ä¿\":\"L\",\"Å\":\"L\",\"Äº\":\"l\",\"Ä¼\":\"l\",\"Ä¾\":\"l\",\"Å€\":\"l\",\"Å‚\":\"l\",\"Åƒ\":\"N\",\"Å…\":\"N\",\"Å‡\":\"N\",\"ÅŠ\":\"N\",\"Å„\":\"n\",\"Å†\":\"n\",\"Åˆ\":\"n\",\"Å‹\":\"n\",\"ÅŒ\":\"O\",\"ÅŽ\":\"O\",\"Å\":\"O\",\"Å\":\"o\",\"Å\":\"o\",\"Å‘\":\"o\",\"Å”\":\"R\",\"Å–\":\"R\",\"Å˜\":\"R\",\"Å•\":\"r\",\"Å—\":\"r\",\"Å™\":\"r\",\"Åš\":\"S\",\"Åœ\":\"S\",\"Åž\":\"S\",\"Å \":\"S\",\"Å›\":\"s\",\"Å\":\"s\",\"ÅŸ\":\"s\",\"Å¡\":\"s\",\"Å¢\":\"T\",\"Å¤\":\"T\",\"Å¦\":\"T\",\"Å£\":\"t\",\"Å¥\":\"t\",\"Å§\":\"t\",\"Å¨\":\"U\",\"Åª\":\"U\",\"Å¬\":\"U\",\"Å®\":\"U\",\"Å°\":\"U\",\"Å²\":\"U\",\"Å©\":\"u\",\"Å«\":\"u\",\"Å­\":\"u\",\"Å¯\":\"u\",\"Å±\":\"u\",\"Å³\":\"u\",\"Å´\":\"W\",\"Åµ\":\"w\",\"Å¶\":\"Y\",\"Å·\":\"y\",\"Å¸\":\"Y\",\"Å¹\":\"Z\",\"Å»\":\"Z\",\"Å½\":\"Z\",\"Åº\":\"z\",\"Å¼\":\"z\",\"Å¾\":\"z\",\"Ä²\":\"IJ\",\n",
       "\"Ä³\":\"ij\",\"Å’\":\"Oe\",\"Å“\":\"oe\",\"Å‰\":\"'n\",\"Å¿\":\"s\"},tr={\"&\":\"&amp;\",\"<\":\"&lt;\",\">\":\"&gt;\",'\"':\"&quot;\",\"'\":\"&#39;\"},er={\"&amp;\":\"&\",\"&lt;\":\"<\",\"&gt;\":\">\",\"&quot;\":'\"',\"&#39;\":\"'\"},nr={\"\\\\\":\"\\\\\",\"'\":\"'\",\"\\n\":\"n\",\"\\r\":\"r\",\"\\u2028\":\"u2028\",\"\\u2029\":\"u2029\"},rr=parseFloat,ir=parseInt,or=\"object\"==typeof t&&t&&t.Object===Object&&t,ar=\"object\"==typeof self&&self&&self.Object===Object&&self,ur=or||ar||Function(\"return this\")(),cr=\"object\"==typeof e&&e&&!e.nodeType&&e,sr=cr&&\"object\"==typeof r&&r&&!r.nodeType&&r,lr=sr&&sr.exports===cr,fr=lr&&or.process,pr=function(){try{return fr&&fr.binding&&fr.binding(\"util\")}catch(t){}}(),hr=pr&&pr.isArrayBuffer,dr=pr&&pr.isDate,vr=pr&&pr.isMap,gr=pr&&pr.isRegExp,mr=pr&&pr.isSet,yr=pr&&pr.isTypedArray,_r=S(\"length\"),br=P(Jn),xr=P(tr),wr=P(er),Cr=function t(e){function n(t){if(sc(t)&&!xp(t)&&!(t instanceof b)){if(t instanceof i)return t;if(bl.call(t,\"__wrapped__\"))return aa(t)}return new i(t)}function r(){}function i(t,e){this.__wrapped__=t,this.__actions__=[],this.__chain__=!!e,this.__index__=0,this.__values__=it}function b(t){this.__wrapped__=t,this.__actions__=[],this.__dir__=1,this.__filtered__=!1,this.__iteratees__=[],this.__takeCount__=Ft,this.__views__=[]}function P(){var t=new b(this.__wrapped__);return t.__actions__=Bi(this.__actions__),t.__dir__=this.__dir__,t.__filtered__=this.__filtered__,t.__iteratees__=Bi(this.__iteratees__),t.__takeCount__=this.__takeCount__,t.__views__=Bi(this.__views__),t}function Z(){if(this.__filtered__){var t=new b(this);t.__dir__=-1,t.__filtered__=!0}else t=this.clone(),t.__dir__*=-1;return t}function et(){var t=this.__wrapped__.value(),e=this.__dir__,n=xp(t),r=e<0,i=n?t.length:0,o=No(0,i,this.__views__),a=o.start,u=o.end,c=u-a,s=r?u:a-1,l=this.__iteratees__,f=l.length,p=0,h=Xl(c,this.__takeCount__);if(!n||!r&&i==c&&h==c)return xi(t,this.__actions__);var d=[];t:for(;c--&&p<h;){s+=e;for(var v=-1,g=t[s];++v<f;){var m=l[v],y=m.iteratee,_=m.type,b=y(g);if(_==Ot)g=b;else if(!b){if(_==At)continue t;break t}}d[p++]=g}return d}function nt(t){var e=-1,n=null==t?0:t.length;for(this.clear();++e<n;){var r=t[e];this.set(r[0],r[1])}}function ze(){this.__data__=uf?uf(null):{},this.size=0}function en(t){var e=this.has(t)&&delete this.__data__[t];return this.size-=e?1:0,e}function nn(t){var e=this.__data__;if(uf){var n=e[t];return n===st?it:n}return bl.call(e,t)?e[t]:it}function rn(t){var e=this.__data__;return uf?e[t]!==it:bl.call(e,t)}function on(t,e){var n=this.__data__;return this.size+=this.has(t)?0:1,n[t]=uf&&e===it?st:e,this}function an(t){var e=-1,n=null==t?0:t.length;for(this.clear();++e<n;){var r=t[e];this.set(r[0],r[1])}}function un(){this.__data__=[],this.size=0}function cn(t){var e=this.__data__,n=In(e,t);if(n<0)return!1;var r=e.length-1;return n==r?e.pop():Dl.call(e,n,1),--this.size,!0}function sn(t){var e=this.__data__,n=In(e,t);return n<0?it:e[n][1]}function ln(t){return In(this.__data__,t)>-1}function fn(t,e){var n=this.__data__,r=In(n,t);return r<0?(++this.size,n.push([t,e])):n[r][1]=e,this}function pn(t){var e=-1,n=null==t?0:t.length;for(this.clear();++e<n;){var r=t[e];this.set(r[0],r[1])}}function hn(){this.size=0,this.__data__={hash:new nt,map:new(nf||an),string:new nt}}function dn(t){var e=Eo(this,t).delete(t);return this.size-=e?1:0,e}function vn(t){return Eo(this,t).get(t)}function gn(t){return Eo(this,t).has(t)}function mn(t,e){var n=Eo(this,t),r=n.size;return n.set(t,e),this.size+=n.size==r?0:1,this}function yn(t){var e=-1,n=null==t?0:t.length;for(this.__data__=new pn;++e<n;)this.add(t[e])}function _n(t){return this.__data__.set(t,st),this}function bn(t){return this.__data__.has(t)}function xn(t){var e=this.__data__=new an(t);this.size=e.size}function wn(){this.__data__=new an,this.size=0}function Cn(t){var e=this.__data__,n=e.delete(t);return this.size=e.size,n}function Mn(t){return this.__data__.get(t)}function kn(t){return this.__data__.has(t)}function En(t,e){var n=this.__data__;if(n instanceof an){var r=n.__data__;if(!nf||r.length<at-1)return r.push([t,e]),this.size=++n.size,this;n=this.__data__=new pn(r)}return n.set(t,e),this.size=n.size,this}function Tn(t,e){var n=xp(t),r=!n&&bp(t),i=!n&&!r&&Cp(t),o=!n&&!r&&!i&&Sp(t),a=n||r||i||o,u=a?I(t.length,hl):[],c=u.length;for(var s in t)!e&&!bl.call(t,s)||a&&(\"length\"==s||i&&(\"offset\"==s||\"parent\"==s)||o&&(\"buffer\"==s||\"byteLength\"==s||\"byteOffset\"==s)||Fo(s,c))||u.push(s);return u}function Sn(t){var e=t.length;return e?t[ni(0,e-1)]:it}function Pn(t,e){return na(Bi(t),jn(e,0,t.length))}function Nn(t){return na(Bi(t))}function An(t,e,n){(n===it||$u(t[e],n))&&(n!==it||e in t)||Un(t,e,n)}function On(t,e,n){var r=t[e];bl.call(t,e)&&$u(r,n)&&(n!==it||e in t)||Un(t,e,n)}function In(t,e){for(var n=t.length;n--;)if($u(t[n][0],e))return n;return-1}function Dn(t,e,n,r){return _f(t,function(t,i,o){e(r,t,n(t),o)}),r}function Rn(t,e){return t&&Wi(e,Hc(e),t)}function Ln(t,e){return t&&Wi(e,qc(e),t)}function Un(t,e,n){\"__proto__\"==e&&Fl?Fl(t,e,{configurable:!0,enumerable:!0,value:n,writable:!0}):t[e]=n}function Fn(t,e){for(var n=-1,r=e.length,i=al(r),o=null==t;++n<r;)i[n]=o?it:Wc(t,e[n]);return i}function jn(t,e,n){return t===t&&(n!==it&&(t=t<=n?t:n),e!==it&&(t=t>=e?t:e)),t}function Bn(t,e,n,r,i,o){var a,u=e&pt,c=e&ht,l=e&dt;if(n&&(a=i?n(t,r,i,o):n(t)),a!==it)return a;if(!cc(t))return t;var f=xp(t);if(f){if(a=Io(t),!u)return Bi(t,a)}else{var p=Af(t),h=p==$t||p==Xt;if(Cp(t))return Si(t,u);if(p==te||p==Vt||h&&!i){if(a=c||h?{}:Do(t),!u)return c?zi(t,Ln(a,t)):Vi(t,Rn(a,t))}else{if(!Qn[p])return i?t:{};a=Ro(t,p,Bn,u)}}o||(o=new xn);var d=o.get(t);if(d)return d;o.set(t,a);var v=l?c?wo:xo:c?qc:Hc,g=f?it:v(t);return s(g||t,function(r,i){g&&(i=r,r=t[i]),On(a,i,Bn(r,e,n,i,t,o))}),a}function Wn(t){var e=Hc(t);return function(n){return Vn(n,t,e)}}function Vn(t,e,n){var r=n.length;if(null==t)return!r;for(t=fl(t);r--;){var i=n[r],o=e[i],a=t[i];if(a===it&&!(i in t)||!o(a))return!1}return!0}function qn(t,e,n){if(\"function\"!=typeof t)throw new dl(ct);return Df(function(){t.apply(it,n)},e)}function Yn(t,e,n,r){var i=-1,o=h,a=!0,u=t.length,c=[],s=e.length;if(!u)return c;n&&(e=v(e,R(n))),r?(o=d,a=!1):e.length>=at&&(o=U,a=!1,e=new yn(e));t:for(;++i<u;){var l=t[i],f=null==n?l:n(l);if(l=r||0!==l?l:0,a&&f===f){for(var p=s;p--;)if(e[p]===f)continue t;c.push(l)}else o(e,f,r)||c.push(l)}return c}function Kn(t,e){var n=!0;return _f(t,function(t,r,i){return n=!!e(t,r,i)}),n}function Gn(t,e,n){for(var r=-1,i=t.length;++r<i;){var o=t[r],a=e(o);if(null!=a&&(u===it?a===a&&!bc(a):n(a,u)))var u=a,c=o}return c}function Jn(t,e,n,r){var i=t.length;for(n=Ec(n),n<0&&(n=-n>i?0:i+n),r=r===it||r>i?i:Ec(r),r<0&&(r+=i),r=n>r?0:Tc(r);n<r;)t[n++]=e;return t}function tr(t,e){var n=[];return _f(t,function(t,r,i){e(t,r,i)&&n.push(t)}),n}function er(t,e,n,r,i){var o=-1,a=t.length;for(n||(n=Uo),i||(i=[]);++o<a;){var u=t[o];e>0&&n(u)?e>1?er(u,e-1,n,r,i):g(i,u):r||(i[i.length]=u)}return i}function nr(t,e){return t&&xf(t,e,Hc)}function or(t,e){return t&&wf(t,e,Hc)}function ar(t,e){return p(e,function(e){return oc(t[e])})}function cr(t,e){e=Ei(e,t);for(var n=0,r=e.length;null!=t&&n<r;)t=t[ra(e[n++])];return n&&n==r?t:it}function sr(t,e,n){var r=e(t);return xp(t)?r:g(r,n(t))}function fr(t){return null==t?t===it?ue:Jt:Ul&&Ul in fl(t)?Po(t):Xo(t)}function pr(t,e){return t>e}function _r(t,e){return null!=t&&bl.call(t,e)}function Cr(t,e){return null!=t&&e in fl(t)}function kr(t,e,n){return t>=Xl(e,n)&&t<$l(e,n)}function Er(t,e,n){for(var r=n?d:h,i=t[0].length,o=t.length,a=o,u=al(o),c=1/0,s=[];a--;){var l=t[a];a&&e&&(l=v(l,R(e))),c=Xl(l.length,c),u[a]=!n&&(e||i>=120&&l.length>=120)?new yn(a&&l):it}l=t[0];var f=-1,p=u[0];t:for(;++f<i&&s.length<c;){var g=l[f],m=e?e(g):g;if(g=n||0!==g?g:0,!(p?U(p,m):r(s,m,n))){for(a=o;--a;){var y=u[a];if(!(y?U(y,m):r(t[a],m,n)))continue t}p&&p.push(m),s.push(g)}}return s}function Tr(t,e,n,r){return nr(t,function(t,i,o){e(r,n(t),i,o)}),r}function Sr(t,e,n){e=Ei(e,t),t=Qo(t,e);var r=null==t?t:t[ra(ka(e))];return null==r?it:u(r,t,n)}function Pr(t){return sc(t)&&fr(t)==Vt}function Nr(t){return sc(t)&&fr(t)==le}function Ar(t){return sc(t)&&fr(t)==Yt}function Or(t,e,n,r,i){return t===e||(null==t||null==e||!sc(t)&&!sc(e)?t!==t&&e!==e:Ir(t,e,n,r,Or,i))}function Ir(t,e,n,r,i,o){var a=xp(t),u=xp(e),c=a?zt:Af(t),s=u?zt:Af(e);c=c==Vt?te:c,s=s==Vt?te:s;var l=c==te,f=s==te,p=c==s;if(p&&Cp(t)){if(!Cp(e))return!1;a=!0,l=!1}if(p&&!l)return o||(o=new xn),a||Sp(t)?mo(t,e,n,r,i,o):yo(t,e,c,n,r,i,o);if(!(n&vt)){var h=l&&bl.call(t,\"__wrapped__\"),d=f&&bl.call(e,\"__wrapped__\");if(h||d){var v=h?t.value():t,g=d?e.value():e;return o||(o=new xn),i(v,g,n,r,o)}}return!!p&&(o||(o=new xn),_o(t,e,n,r,i,o))}function Dr(t){return sc(t)&&Af(t)==Zt}function Rr(t,e,n,r){var i=n.length,o=i,a=!r;if(null==t)return!o;for(t=fl(t);i--;){var u=n[i];if(a&&u[2]?u[1]!==t[u[0]]:!(u[0]in t))return!1}for(;++i<o;){u=n[i];var c=u[0],s=t[c],l=u[1];if(a&&u[2]){if(s===it&&!(c in t))return!1}else{var f=new xn;if(r)var p=r(s,l,c,t,e,f);if(!(p===it?Or(l,s,vt|gt,r,f):p))return!1}}return!0}function Lr(t){if(!cc(t)||zo(t))return!1;var e=oc(t)?El:$e;return e.test(ia(t))}function Ur(t){return sc(t)&&fr(t)==re}function Fr(t){return sc(t)&&Af(t)==ie}function jr(t){return sc(t)&&uc(t.length)&&!!Zn[fr(t)]}function Br(t){return\"function\"==typeof t?t:null==t?Ds:\"object\"==typeof t?xp(t)?Yr(t[0],t[1]):qr(t):Vs(t)}function Wr(t){if(!Ho(t))return Gl(t);var e=[];for(var n in fl(t))bl.call(t,n)&&\"constructor\"!=n&&e.push(n);return e}function Vr(t){if(!cc(t))return $o(t);var e=Ho(t),n=[];for(var r in t)(\"constructor\"!=r||!e&&bl.call(t,r))&&n.push(r);return n}function zr(t,e){return t<e}function Hr(t,e){var n=-1,r=Xu(t)?al(t.length):[];return _f(t,function(t,i,o){r[++n]=e(t,i,o)}),r}function qr(t){var e=To(t);return 1==e.length&&e[0][2]?Yo(e[0][0],e[0][1]):function(n){return n===t||Rr(n,t,e)}}function Yr(t,e){return Bo(t)&&qo(e)?Yo(ra(t),e):function(n){var r=Wc(n,t);return r===it&&r===e?zc(n,t):Or(e,r,vt|gt)}}function Kr(t,e,n,r,i){t!==e&&xf(e,function(o,a){if(cc(o))i||(i=new xn),Gr(t,e,a,n,Kr,r,i);else{var u=r?r(t[a],o,a+\"\",t,e,i):it;u===it&&(u=o),An(t,a,u)}},qc)}function Gr(t,e,n,r,i,o,a){var u=t[n],c=e[n],s=a.get(c);if(s)return void An(t,n,s);var l=o?o(u,c,n+\"\",t,e,a):it,f=l===it;if(f){var p=xp(c),h=!p&&Cp(c),d=!p&&!h&&Sp(c);l=c,p||h||d?xp(u)?l=u:Zu(u)?l=Bi(u):h?(f=!1,l=Si(c,!0)):d?(f=!1,l=Ri(c,!0)):l=[]:mc(c)||bp(c)?(l=u,bp(u)?l=Pc(u):(!cc(u)||r&&oc(u))&&(l=Do(c))):f=!1}f&&(a.set(c,l),i(l,c,r,o,a),a.delete(c)),An(t,n,l)}function $r(t,e){var n=t.length;if(n)return e+=e<0?n:0,Fo(e,n)?t[e]:it}function Xr(t,e,n){var r=-1;e=v(e.length?e:[Ds],R(ko()));var i=Hr(t,function(t,n,i){var o=v(e,function(e){return e(t)});return{criteria:o,index:++r,value:t}});return A(i,function(t,e){return Ui(t,e,n)})}function Zr(t,e){return Qr(t,e,function(e,n){return zc(t,n)})}function Qr(t,e,n){for(var r=-1,i=e.length,o={};++r<i;){var a=e[r],u=cr(t,a);n(u,a)&&ci(o,Ei(a,t),u)}return o}function Jr(t){return function(e){return cr(e,t)}}function ti(t,e,n,r){var i=r?k:M,o=-1,a=e.length,u=t;for(t===e&&(e=Bi(e)),n&&(u=v(t,R(n)));++o<a;)for(var c=0,s=e[o],l=n?n(s):s;(c=i(u,l,c,r))>-1;)u!==t&&Dl.call(u,c,1),Dl.call(t,c,1);return t}function ei(t,e){for(var n=t?e.length:0,r=n-1;n--;){var i=e[n];if(n==r||i!==o){var o=i;Fo(i)?Dl.call(t,i,1):yi(t,i)}}return t}function ni(t,e){return t+zl(Jl()*(e-t+1))}function ri(t,e,n,r){for(var i=-1,o=$l(Vl((e-t)/(n||1)),0),a=al(o);o--;)a[r?o:++i]=t,t+=n;return a}function ii(t,e){var n=\"\";if(!t||e<1||e>Rt)return n;do e%2&&(n+=t),e=zl(e/2),e&&(t+=t);while(e);return n}function oi(t,e){return Rf(Zo(t,e,Ds),t+\"\")}function ai(t){return Sn(rs(t))}function ui(t,e){var n=rs(t);return na(n,jn(e,0,n.length))}function ci(t,e,n,r){if(!cc(t))return t;e=Ei(e,t);for(var i=-1,o=e.length,a=o-1,u=t;null!=u&&++i<o;){var c=ra(e[i]),s=n;if(i!=a){var l=u[c];s=r?r(l,c,u):it,s===it&&(s=cc(l)?l:Fo(e[i+1])?[]:{})}On(u,c,s),u=u[c]}return t}function si(t){return na(rs(t))}function li(t,e,n){var r=-1,i=t.length;e<0&&(e=-e>i?0:i+e),n=n>i?i:n,n<0&&(n+=i),i=e>n?0:n-e>>>0,e>>>=0;for(var o=al(i);++r<i;)o[r]=t[r+e];return o}function fi(t,e){var n;return _f(t,function(t,r,i){return n=e(t,r,i),!n}),!!n}function pi(t,e,n){var r=0,i=null==t?r:t.length;if(\"number\"==typeof e&&e===e&&i<=Bt){for(;r<i;){var o=r+i>>>1,a=t[o];null!==a&&!bc(a)&&(n?a<=e:a<e)?r=o+1:i=o}return i}return hi(t,e,Ds,n)}function hi(t,e,n,r){e=n(e);for(var i=0,o=null==t?0:t.length,a=e!==e,u=null===e,c=bc(e),s=e===it;i<o;){var l=zl((i+o)/2),f=n(t[l]),p=f!==it,h=null===f,d=f===f,v=bc(f);if(a)var g=r||d;else g=s?d&&(r||p):u?d&&p&&(r||!h):c?d&&p&&!h&&(r||!v):!h&&!v&&(r?f<=e:f<e);g?i=l+1:o=l}return Xl(o,jt)}function di(t,e){for(var n=-1,r=t.length,i=0,o=[];++n<r;){var a=t[n],u=e?e(a):a;if(!n||!$u(u,c)){var c=u;o[i++]=0===a?0:a}}return o}function vi(t){return\"number\"==typeof t?t:bc(t)?Ut:+t}function gi(t){if(\"string\"==typeof t)return t;if(xp(t))return v(t,gi)+\"\";if(bc(t))return mf?mf.call(t):\"\";var e=t+\"\";return\"0\"==e&&1/t==-Dt?\"-0\":e}function mi(t,e,n){var r=-1,i=h,o=t.length,a=!0,u=[],c=u;if(n)a=!1,i=d;else if(o>=at){var s=e?null:Tf(t);if(s)return $(s);a=!1,i=U,c=new yn}else c=e?[]:u;t:for(;++r<o;){var l=t[r],f=e?e(l):l;if(l=n||0!==l?l:0,a&&f===f){for(var p=c.length;p--;)if(c[p]===f)continue t;e&&c.push(f),u.push(l)}else i(c,f,n)||(c!==u&&c.push(f),u.push(l))}return u}function yi(t,e){return e=Ei(e,t),t=Qo(t,e),null==t||delete t[ra(ka(e))]}function _i(t,e,n,r){return ci(t,e,n(cr(t,e)),r)}function bi(t,e,n,r){for(var i=t.length,o=r?i:-1;(r?o--:++o<i)&&e(t[o],o,t););return n?li(t,r?0:o,r?o+1:i):li(t,r?o+1:0,r?i:o)}function xi(t,e){var n=t;return n instanceof b&&(n=n.value()),m(e,function(t,e){return e.func.apply(e.thisArg,g([t],e.args))},n)}function wi(t,e,n){var r=t.length;if(r<2)return r?mi(t[0]):[];for(var i=-1,o=al(r);++i<r;)for(var a=t[i],u=-1;++u<r;)u!=i&&(o[i]=Yn(o[i]||a,t[u],e,n));return mi(er(o,1),e,n)}function Ci(t,e,n){for(var r=-1,i=t.length,o=e.length,a={};++r<i;){var u=r<o?e[r]:it;n(a,t[r],u)}return a}function Mi(t){return Zu(t)?t:[]}function ki(t){return\"function\"==typeof t?t:Ds}function Ei(t,e){return xp(t)?t:Bo(t,e)?[t]:Lf(Ac(t))}function Ti(t,e,n){var r=t.length;return n=n===it?r:n,!e&&n>=r?t:li(t,e,n)}function Si(t,e){if(e)return t.slice();var n=t.length,r=Nl?Nl(n):new t.constructor(n);return t.copy(r),r}function Pi(t){var e=new t.constructor(t.byteLength);return new Pl(e).set(new Pl(t)),e}function Ni(t,e){var n=e?Pi(t.buffer):t.buffer;return new t.constructor(n,t.byteOffset,t.byteLength)}function Ai(t,e,n){var r=e?n(Y(t),pt):Y(t);return m(r,o,new t.constructor)}function Oi(t){var e=new t.constructor(t.source,Ye.exec(t));return e.lastIndex=t.lastIndex,e}function Ii(t,e,n){var r=e?n($(t),pt):$(t);return m(r,a,new t.constructor)}function Di(t){return gf?fl(gf.call(t)):{}}function Ri(t,e){var n=e?Pi(t.buffer):t.buffer;return new t.constructor(n,t.byteOffset,t.length)}function Li(t,e){if(t!==e){var n=t!==it,r=null===t,i=t===t,o=bc(t),a=e!==it,u=null===e,c=e===e,s=bc(e);if(!u&&!s&&!o&&t>e||o&&a&&c&&!u&&!s||r&&a&&c||!n&&c||!i)return 1;if(!r&&!o&&!s&&t<e||s&&n&&i&&!r&&!o||u&&n&&i||!a&&i||!c)return-1}return 0}function Ui(t,e,n){for(var r=-1,i=t.criteria,o=e.criteria,a=i.length,u=n.length;++r<a;){var c=Li(i[r],o[r]);if(c){if(r>=u)return c;var s=n[r];return c*(\"desc\"==s?-1:1)}}return t.index-e.index}function Fi(t,e,n,r){for(var i=-1,o=t.length,a=n.length,u=-1,c=e.length,s=$l(o-a,0),l=al(c+s),f=!r;++u<c;)l[u]=e[u];for(;++i<a;)(f||i<o)&&(l[n[i]]=t[i]);for(;s--;)l[u++]=t[i++];return l}function ji(t,e,n,r){for(var i=-1,o=t.length,a=-1,u=n.length,c=-1,s=e.length,l=$l(o-u,0),f=al(l+s),p=!r;++i<l;)f[i]=t[i];for(var h=i;++c<s;)f[h+c]=e[c];for(;++a<u;)(p||i<o)&&(f[h+n[a]]=t[i++]);return f}function Bi(t,e){var n=-1,r=t.length;for(e||(e=al(r));++n<r;)e[n]=t[n];return e}function Wi(t,e,n,r){var i=!n;n||(n={});for(var o=-1,a=e.length;++o<a;){var u=e[o],c=r?r(n[u],t[u],u,n,t):it;c===it&&(c=t[u]),i?Un(n,u,c):On(n,u,c)}return n}function Vi(t,e){return Wi(t,Pf(t),e)}function zi(t,e){return Wi(t,Nf(t),e)}function Hi(t,e){return function(n,r){var i=xp(n)?c:Dn,o=e?e():{};return i(n,t,ko(r,2),o)}}function qi(t){return oi(function(e,n){var r=-1,i=n.length,o=i>1?n[i-1]:it,a=i>2?n[2]:it;for(o=t.length>3&&\"function\"==typeof o?(i--,o):it,a&&jo(n[0],n[1],a)&&(o=i<3?it:o,i=1),e=fl(e);++r<i;){var u=n[r];u&&t(e,u,r,o)}return e})}function Yi(t,e){return function(n,r){if(null==n)return n;if(!Xu(n))return t(n,r);for(var i=n.length,o=e?i:-1,a=fl(n);(e?o--:++o<i)&&r(a[o],o,a)!==!1;);return n}}function Ki(t){return function(e,n,r){for(var i=-1,o=fl(e),a=r(e),u=a.length;u--;){var c=a[t?u:++i];if(n(o[c],c,o)===!1)break}return e}}function Gi(t,e,n){function r(){var e=this&&this!==ur&&this instanceof r?o:t;return e.apply(i?n:this,arguments)}var i=e&mt,o=Zi(t);return r}function $i(t){return function(e){e=Ac(e);var n=z(e)?tt(e):it,r=n?n[0]:e.charAt(0),i=n?Ti(n,1).join(\"\"):e.slice(1);return r[t]()+i}}function Xi(t){return function(e){return m(Ps(ss(e).replace(zn,\"\")),t,\"\")}}function Zi(t){return function(){var e=arguments;switch(e.length){case 0:return new t;case 1:return new t(e[0]);case 2:return new t(e[0],e[1]);case 3:return new t(e[0],e[1],e[2]);case 4:return new t(e[0],e[1],e[2],e[3]);case 5:return new t(e[0],e[1],e[2],e[3],e[4]);case 6:return new t(e[0],e[1],e[2],e[3],e[4],e[5]);case 7:return new t(e[0],e[1],e[2],e[3],e[4],e[5],e[6])}var n=yf(t.prototype),r=t.apply(n,e);return cc(r)?r:n}}function Qi(t,e,n){function r(){for(var o=arguments.length,a=al(o),c=o,s=Mo(r);c--;)a[c]=arguments[c];var l=o<3&&a[0]!==s&&a[o-1]!==s?[]:G(a,s);if(o-=l.length,o<n)return so(t,e,eo,r.placeholder,it,a,l,it,it,n-o);var f=this&&this!==ur&&this instanceof r?i:t;return u(f,this,a)}var i=Zi(t);return r}function Ji(t){return function(e,n,r){var i=fl(e);if(!Xu(e)){var o=ko(n,3);e=Hc(e),n=function(t){return o(i[t],t,i)}}var a=t(e,n,r);return a>-1?i[o?e[a]:a]:it}}function to(t){return bo(function(e){var n=e.length,r=n,o=i.prototype.thru;for(t&&e.reverse();r--;){var a=e[r];if(\"function\"!=typeof a)throw new dl(ct);if(o&&!u&&\"wrapper\"==Co(a))var u=new i([],!0)}for(r=u?r:n;++r<n;){a=e[r];var c=Co(a),s=\"wrapper\"==c?Sf(a):it;u=s&&Vo(s[0])&&s[1]==(Mt|bt|wt|kt)&&!s[4].length&&1==s[9]?u[Co(s[0])].apply(u,s[3]):1==a.length&&Vo(a)?u[c]():u.thru(a)}return function(){var t=arguments,r=t[0];if(u&&1==t.length&&xp(r))return u.plant(r).value();for(var i=0,o=n?e[i].apply(this,t):r;++i<n;)o=e[i].call(this,o);return o}})}function eo(t,e,n,r,i,o,a,u,c,s){function l(){for(var m=arguments.length,y=al(m),_=m;_--;)y[_]=arguments[_];if(d)var b=Mo(l),x=B(y,b);if(r&&(y=Fi(y,r,i,d)),o&&(y=ji(y,o,a,d)),m-=x,d&&m<s){var w=G(y,b);return so(t,e,eo,l.placeholder,n,y,w,u,c,s-m)}var C=p?n:this,M=h?C[t]:t;return m=y.length,u?y=Jo(y,u):v&&m>1&&y.reverse(),f&&c<m&&(y.length=c),this&&this!==ur&&this instanceof l&&(M=g||Zi(M)),M.apply(C,y)}var f=e&Mt,p=e&mt,h=e&yt,d=e&(bt|xt),v=e&Et,g=h?it:Zi(t);return l}function no(t,e){return function(n,r){return Tr(n,t,e(r),{})}}function ro(t,e){return function(n,r){var i;if(n===it&&r===it)return e;if(n!==it&&(i=n),r!==it){if(i===it)return r;\"string\"==typeof n||\"string\"==typeof r?(n=gi(n),r=gi(r)):(n=vi(n),r=vi(r)),i=t(n,r)}return i}}function io(t){return bo(function(e){return e=v(e,R(ko())),oi(function(n){var r=this;return t(e,function(t){return u(t,r,n)})})})}function oo(t,e){e=e===it?\" \":gi(e);var n=e.length;if(n<2)return n?ii(e,t):e;var r=ii(e,Vl(t/J(e)));return z(e)?Ti(tt(r),0,t).join(\"\"):r.slice(0,t)}function ao(t,e,n,r){function i(){for(var e=-1,c=arguments.length,s=-1,l=r.length,f=al(l+c),p=this&&this!==ur&&this instanceof i?a:t;++s<l;)f[s]=r[s];for(;c--;)f[s++]=arguments[++e];return u(p,o?n:this,f)}var o=e&mt,a=Zi(t);return i}function uo(t){return function(e,n,r){return r&&\"number\"!=typeof r&&jo(e,n,r)&&(n=r=it),e=kc(e),n===it?(n=e,e=0):n=kc(n),r=r===it?e<n?1:-1:kc(r),ri(e,n,r,t)}}function co(t){return function(e,n){return\"string\"==typeof e&&\"string\"==typeof n||(e=Sc(e),n=Sc(n)),t(e,n)}}function so(t,e,n,r,i,o,a,u,c,s){var l=e&bt,f=l?a:it,p=l?it:a,h=l?o:it,d=l?it:o;e|=l?wt:Ct,e&=~(l?Ct:wt),e&_t||(e&=~(mt|yt));var v=[t,e,i,h,f,d,p,u,c,s],g=n.apply(it,v);return Vo(t)&&If(g,v),g.placeholder=r,ta(g,t,e)}function lo(t){var e=ll[t];return function(t,n){if(t=Sc(t),n=null==n?0:Xl(Ec(n),292)){var r=(Ac(t)+\"e\").split(\"e\"),i=e(r[0]+\"e\"+(+r[1]+n));return r=(Ac(i)+\"e\").split(\"e\"),+(r[0]+\"e\"+(+r[1]-n))}return e(t)}}function fo(t){return function(e){var n=Af(e);return n==Zt?Y(e):n==ie?X(e):D(e,t(e))}}function po(t,e,n,r,i,o,a,u){var c=e&yt;if(!c&&\"function\"!=typeof t)throw new dl(ct);var s=r?r.length:0;if(s||(e&=~(wt|Ct),r=i=it),a=a===it?a:$l(Ec(a),0),u=u===it?u:Ec(u),s-=i?i.length:0,e&Ct){var l=r,f=i;r=i=it}var p=c?it:Sf(t),h=[t,e,n,r,i,l,f,o,a,u];if(p&&Go(h,p),t=h[0],e=h[1],n=h[2],r=h[3],i=h[4],u=h[9]=h[9]===it?c?0:t.length:$l(h[9]-s,0),!u&&e&(bt|xt)&&(e&=~(bt|xt)),e&&e!=mt)d=e==bt||e==xt?Qi(t,e,u):e!=wt&&e!=(mt|wt)||i.length?eo.apply(it,h):ao(t,e,n,r);else var d=Gi(t,e,n);var v=p?Cf:If;return ta(v(d,h),t,e)}function ho(t,e,n,r){return t===it||$u(t,ml[n])&&!bl.call(r,n)?e:t}function vo(t,e,n,r,i,o){return cc(t)&&cc(e)&&(o.set(e,t),Kr(t,e,it,vo,o),o.delete(e)),t}function go(t){return mc(t)?it:t}function mo(t,e,n,r,i,o){var a=n&vt,u=t.length,c=e.length;if(u!=c&&!(a&&c>u))return!1;var s=o.get(t);if(s&&o.get(e))return s==e;var l=-1,f=!0,p=n&gt?new yn:it;for(o.set(t,e),o.set(e,t);++l<u;){var h=t[l],d=e[l];if(r)var v=a?r(d,h,l,e,t,o):r(h,d,l,t,e,o);if(v!==it){if(v)continue;f=!1;break}if(p){if(!_(e,function(t,e){if(!U(p,e)&&(h===t||i(h,t,n,r,o)))return p.push(e)})){f=!1;break}}else if(h!==d&&!i(h,d,n,r,o)){f=!1;break}}return o.delete(t),o.delete(e),f}function yo(t,e,n,r,i,o,a){switch(n){case fe:if(t.byteLength!=e.byteLength||t.byteOffset!=e.byteOffset)return!1;t=t.buffer,e=e.buffer;case le:return!(t.byteLength!=e.byteLength||!o(new Pl(t),new Pl(e)));case qt:case Yt:case Qt:return $u(+t,+e);case Gt:return t.name==e.name&&t.message==e.message;case re:case oe:return t==e+\"\";case Zt:var u=Y;case ie:var c=r&vt;if(u||(u=$),t.size!=e.size&&!c)return!1;var s=a.get(t);if(s)return s==e;r|=gt,a.set(t,e);var l=mo(u(t),u(e),r,i,o,a);return a.delete(t),l;case ae:if(gf)return gf.call(t)==gf.call(e)}return!1}function _o(t,e,n,r,i,o){var a=n&vt,u=xo(t),c=u.length,s=xo(e),l=s.length;if(c!=l&&!a)return!1;for(var f=c;f--;){var p=u[f];if(!(a?p in e:bl.call(e,p)))return!1}var h=o.get(t);if(h&&o.get(e))return h==e;var d=!0;o.set(t,e),o.set(e,t);for(var v=a;++f<c;){p=u[f];var g=t[p],m=e[p];if(r)var y=a?r(m,g,p,e,t,o):r(g,m,p,t,e,o);if(!(y===it?g===m||i(g,m,n,r,o):y)){d=!1;break}v||(v=\"constructor\"==p)}if(d&&!v){var _=t.constructor,b=e.constructor;_!=b&&\"constructor\"in t&&\"constructor\"in e&&!(\"function\"==typeof _&&_ instanceof _&&\"function\"==typeof b&&b instanceof b)&&(d=!1)}return o.delete(t),o.delete(e),d}function bo(t){return Rf(Zo(t,it,ma),t+\"\")}function xo(t){return sr(t,Hc,Pf)}function wo(t){return sr(t,qc,Nf)}function Co(t){for(var e=t.name+\"\",n=sf[e],r=bl.call(sf,e)?n.length:0;r--;){var i=n[r],o=i.func;if(null==o||o==t)return i.name}return e}function Mo(t){var e=bl.call(n,\"placeholder\")?n:t;return e.placeholder}function ko(){var t=n.iteratee||Rs;return t=t===Rs?Br:t,arguments.length?t(arguments[0],arguments[1]):t}function Eo(t,e){var n=t.__data__;return Wo(e)?n[\"string\"==typeof e?\"string\":\"hash\"]:n.map}function To(t){for(var e=Hc(t),n=e.length;n--;){var r=e[n],i=t[r];e[n]=[r,i,qo(i)]}return e}function So(t,e){var n=V(t,e);return Lr(n)?n:it}function Po(t){var e=bl.call(t,Ul),n=t[Ul];try{t[Ul]=it;var r=!0}catch(t){}var i=Cl.call(t);return r&&(e?t[Ul]=n:delete t[Ul]),i}function No(t,e,n){for(var r=-1,i=n.length;++r<i;){var o=n[r],a=o.size;switch(o.type){case\"drop\":t+=a;break;case\"dropRight\":e-=a;break;case\"take\":e=Xl(e,t+a);break;case\"takeRight\":t=$l(t,e-a)}}return{start:t,end:e}}function Ao(t){var e=t.match(We);return e?e[1].split(Ve):[]}function Oo(t,e,n){e=Ei(e,t);for(var r=-1,i=e.length,o=!1;++r<i;){var a=ra(e[r]);if(!(o=null!=t&&n(t,a)))break;t=t[a]}return o||++r!=i?o:(i=null==t?0:t.length,!!i&&uc(i)&&Fo(a,i)&&(xp(t)||bp(t)))}function Io(t){var e=t.length,n=t.constructor(e);return e&&\"string\"==typeof t[0]&&bl.call(t,\"index\")&&(n.index=t.index,n.input=t.input),n}function Do(t){return\"function\"!=typeof t.constructor||Ho(t)?{}:yf(Al(t))}function Ro(t,e,n,r){var i=t.constructor;switch(e){case le:return Pi(t);case qt:case Yt:return new i(+t);case fe:return Ni(t,r);case pe:case he:case de:case ve:case ge:case me:case ye:case _e:case be:return Ri(t,r);case Zt:return Ai(t,r,n);case Qt:case oe:return new i(t);case re:return Oi(t);case ie:return Ii(t,r,n);case ae:return Di(t)}}function Lo(t,e){var n=e.length;if(!n)return t;var r=n-1;return e[r]=(n>1?\"& \":\"\")+e[r],e=e.join(n>2?\", \":\" \"),t.replace(Be,\"{\\n/* [wrapped with \"+e+\"] */\\n\")}function Uo(t){return xp(t)||bp(t)||!!(Rl&&t&&t[Rl])}function Fo(t,e){return e=null==e?Rt:e,!!e&&(\"number\"==typeof t||Ze.test(t))&&t>-1&&t%1==0&&t<e}function jo(t,e,n){if(!cc(n))return!1;var r=typeof e;return!!(\"number\"==r?Xu(n)&&Fo(e,n.length):\"string\"==r&&e in n)&&$u(n[e],t)}function Bo(t,e){if(xp(t))return!1;var n=typeof t;return!(\"number\"!=n&&\"symbol\"!=n&&\"boolean\"!=n&&null!=t&&!bc(t))||(Oe.test(t)||!Ae.test(t)||null!=e&&t in fl(e))}function Wo(t){var e=typeof t;return\"string\"==e||\"number\"==e||\"symbol\"==e||\"boolean\"==e?\"__proto__\"!==t:null===t}function Vo(t){var e=Co(t),r=n[e];if(\"function\"!=typeof r||!(e in b.prototype))return!1;if(t===r)return!0;var i=Sf(r);return!!i&&t===i[0]}function zo(t){return!!wl&&wl in t}function Ho(t){var e=t&&t.constructor,n=\"function\"==typeof e&&e.prototype||ml;return t===n}function qo(t){return t===t&&!cc(t)}function Yo(t,e){return function(n){return null!=n&&(n[t]===e&&(e!==it||t in fl(n)))}}function Ko(t){var e=Ru(t,function(t){return n.size===lt&&n.clear(),t}),n=e.cache;return e}function Go(t,e){var n=t[1],r=e[1],i=n|r,o=i<(mt|yt|Mt),a=r==Mt&&n==bt||r==Mt&&n==kt&&t[7].length<=e[8]||r==(Mt|kt)&&e[7].length<=e[8]&&n==bt;if(!o&&!a)return t;r&mt&&(t[2]=e[2],i|=n&mt?0:_t);var u=e[3];if(u){var c=t[3];t[3]=c?Fi(c,u,e[4]):u,t[4]=c?G(t[3],ft):e[4]}return u=e[5],u&&(c=t[5],t[5]=c?ji(c,u,e[6]):u,t[6]=c?G(t[5],ft):e[6]),u=e[7],u&&(t[7]=u),r&Mt&&(t[8]=null==t[8]?e[8]:Xl(t[8],e[8])),null==t[9]&&(t[9]=e[9]),t[0]=e[0],t[1]=i,t}function $o(t){var e=[];if(null!=t)for(var n in fl(t))e.push(n);return e}function Xo(t){return Cl.call(t)}function Zo(t,e,n){return e=$l(e===it?t.length-1:e,0),function(){for(var r=arguments,i=-1,o=$l(r.length-e,0),a=al(o);++i<o;)a[i]=r[e+i];i=-1;for(var c=al(e+1);++i<e;)c[i]=r[i];return c[e]=n(a),u(t,this,c)}}function Qo(t,e){return e.length<2?t:cr(t,li(e,0,-1))}function Jo(t,e){for(var n=t.length,r=Xl(e.length,n),i=Bi(t);r--;){var o=e[r];t[r]=Fo(o,n)?i[o]:it}return t}function ta(t,e,n){var r=e+\"\";return Rf(t,Lo(r,oa(Ao(r),n)))}function ea(t){var e=0,n=0;return function(){var r=Zl(),i=Nt-(r-n);if(n=r,i>0){if(++e>=Pt)return arguments[0]}else e=0;return t.apply(it,arguments)}}function na(t,e){var n=-1,r=t.length,i=r-1;for(e=e===it?r:e;++n<e;){var o=ni(n,i),a=t[o];t[o]=t[n],t[n]=a}return t.length=e,t}function ra(t){if(\"string\"==typeof t||bc(t))return t;var e=t+\"\";return\"0\"==e&&1/t==-Dt?\"-0\":e}function ia(t){if(null!=t){try{return _l.call(t)}catch(t){}try{return t+\"\"}catch(t){}}return\"\"}function oa(t,e){return s(Wt,function(n){var r=\"_.\"+n[0];e&n[1]&&!h(t,r)&&t.push(r)}),t.sort()}function aa(t){if(t instanceof b)return t.clone();var e=new i(t.__wrapped__,t.__chain__);return e.__actions__=Bi(t.__actions__),e.__index__=t.__index__,e.__values__=t.__values__,e}function ua(t,e,n){e=(n?jo(t,e,n):e===it)?1:$l(Ec(e),0);var r=null==t?0:t.length;if(!r||e<1)return[];for(var i=0,o=0,a=al(Vl(r/e));i<r;)a[o++]=li(t,i,i+=e);return a}function ca(t){for(var e=-1,n=null==t?0:t.length,r=0,i=[];++e<n;){var o=t[e];o&&(i[r++]=o)}return i}function sa(){var t=arguments.length;if(!t)return[];for(var e=al(t-1),n=arguments[0],r=t;r--;)e[r-1]=arguments[r];return g(xp(n)?Bi(n):[n],er(e,1))}function la(t,e,n){var r=null==t?0:t.length;return r?(e=n||e===it?1:Ec(e),li(t,e<0?0:e,r)):[]}function fa(t,e,n){var r=null==t?0:t.length;return r?(e=n||e===it?1:Ec(e),e=r-e,li(t,0,e<0?0:e)):[]}function pa(t,e){return t&&t.length?bi(t,ko(e,3),!0,!0):[]}function ha(t,e){return t&&t.length?bi(t,ko(e,3),!0):[]}function da(t,e,n,r){var i=null==t?0:t.length;return i?(n&&\"number\"!=typeof n&&jo(t,e,n)&&(n=0,r=i),Jn(t,e,n,r)):[]}function va(t,e,n){var r=null==t?0:t.length;if(!r)return-1;var i=null==n?0:Ec(n);return i<0&&(i=$l(r+i,0)),C(t,ko(e,3),i)}function ga(t,e,n){var r=null==t?0:t.length;if(!r)return-1;var i=r-1;return n!==it&&(i=Ec(n),i=n<0?$l(r+i,0):Xl(i,r-1)),C(t,ko(e,3),i,!0)}function ma(t){var e=null==t?0:t.length;return e?er(t,1):[]}function ya(t){var e=null==t?0:t.length;return e?er(t,Dt):[]}function _a(t,e){var n=null==t?0:t.length;return n?(e=e===it?1:Ec(e),er(t,e)):[]}function ba(t){for(var e=-1,n=null==t?0:t.length,r={};++e<n;){var i=t[e];r[i[0]]=i[1]}return r}function xa(t){return t&&t.length?t[0]:it}function wa(t,e,n){var r=null==t?0:t.length;if(!r)return-1;var i=null==n?0:Ec(n);return i<0&&(i=$l(r+i,0)),M(t,e,i)}function Ca(t){var e=null==t?0:t.length;return e?li(t,0,-1):[]}function Ma(t,e){return null==t?\"\":Kl.call(t,e)}function ka(t){var e=null==t?0:t.length;return e?t[e-1]:it}function Ea(t,e,n){var r=null==t?0:t.length;if(!r)return-1;var i=r;return n!==it&&(i=Ec(n),i=i<0?$l(r+i,0):Xl(i,r-1)),e===e?Q(t,e,i):C(t,E,i,!0)}function Ta(t,e){return t&&t.length?$r(t,Ec(e)):it}function Sa(t,e){return t&&t.length&&e&&e.length?ti(t,e):t}function Pa(t,e,n){return t&&t.length&&e&&e.length?ti(t,e,ko(n,2)):t}function Na(t,e,n){return t&&t.length&&e&&e.length?ti(t,e,it,n):t}function Aa(t,e){var n=[];if(!t||!t.length)return n;var r=-1,i=[],o=t.length;for(e=ko(e,3);++r<o;){var a=t[r];e(a,r,t)&&(n.push(a),i.push(r))}return ei(t,i),n}function Oa(t){return null==t?t:tf.call(t)}function Ia(t,e,n){var r=null==t?0:t.length;return r?(n&&\"number\"!=typeof n&&jo(t,e,n)?(e=0,n=r):(e=null==e?0:Ec(e),n=n===it?r:Ec(n)),li(t,e,n)):[]}function Da(t,e){return pi(t,e)}function Ra(t,e,n){return hi(t,e,ko(n,2))}function La(t,e){var n=null==t?0:t.length;if(n){var r=pi(t,e);if(r<n&&$u(t[r],e))return r}return-1}function Ua(t,e){return pi(t,e,!0)}function Fa(t,e,n){return hi(t,e,ko(n,2),!0)}function ja(t,e){var n=null==t?0:t.length;if(n){var r=pi(t,e,!0)-1;if($u(t[r],e))return r}return-1}function Ba(t){return t&&t.length?di(t):[]}function Wa(t,e){return t&&t.length?di(t,ko(e,2)):[]}function Va(t){var e=null==t?0:t.length;return e?li(t,1,e):[]}function za(t,e,n){return t&&t.length?(e=n||e===it?1:Ec(e),li(t,0,e<0?0:e)):[]}function Ha(t,e,n){var r=null==t?0:t.length;return r?(e=n||e===it?1:Ec(e),e=r-e,li(t,e<0?0:e,r)):[]}function qa(t,e){return t&&t.length?bi(t,ko(e,3),!1,!0):[]}function Ya(t,e){return t&&t.length?bi(t,ko(e,3)):[]}function Ka(t){return t&&t.length?mi(t):[]}function Ga(t,e){return t&&t.length?mi(t,ko(e,2)):[]}function $a(t,e){return e=\"function\"==typeof e?e:it,t&&t.length?mi(t,it,e):[]}function Xa(t){if(!t||!t.length)return[];var e=0;return t=p(t,function(t){if(Zu(t))return e=$l(t.length,e),!0}),I(e,function(e){return v(t,S(e))})}function Za(t,e){if(!t||!t.length)return[];var n=Xa(t);return null==e?n:v(n,function(t){return u(e,it,t)})}function Qa(t,e){return Ci(t||[],e||[],On)}function Ja(t,e){return Ci(t||[],e||[],ci)}function tu(t){var e=n(t);return e.__chain__=!0,e}function eu(t,e){return e(t),t}function nu(t,e){return e(t)}function ru(){return tu(this)}function iu(){return new i(this.value(),this.__chain__)}function ou(){this.__values__===it&&(this.__values__=Mc(this.value()));var t=this.__index__>=this.__values__.length,e=t?it:this.__values__[this.__index__++];return{done:t,value:e}}function au(){return this}function uu(t){for(var e,n=this;n instanceof r;){var i=aa(n);i.__index__=0,i.__values__=it,e?o.__wrapped__=i:e=i;var o=i;n=n.__wrapped__}return o.__wrapped__=t,e}function cu(){var t=this.__wrapped__;if(t instanceof b){var e=t;return this.__actions__.length&&(e=new b(this)),e=e.reverse(),e.__actions__.push({func:nu,args:[Oa],thisArg:it}),new i(e,this.__chain__)}return this.thru(Oa)}function su(){return xi(this.__wrapped__,this.__actions__)}function lu(t,e,n){\n",
       "var r=xp(t)?f:Kn;return n&&jo(t,e,n)&&(e=it),r(t,ko(e,3))}function fu(t,e){var n=xp(t)?p:tr;return n(t,ko(e,3))}function pu(t,e){return er(yu(t,e),1)}function hu(t,e){return er(yu(t,e),Dt)}function du(t,e,n){return n=n===it?1:Ec(n),er(yu(t,e),n)}function vu(t,e){var n=xp(t)?s:_f;return n(t,ko(e,3))}function gu(t,e){var n=xp(t)?l:bf;return n(t,ko(e,3))}function mu(t,e,n,r){t=Xu(t)?t:rs(t),n=n&&!r?Ec(n):0;var i=t.length;return n<0&&(n=$l(i+n,0)),_c(t)?n<=i&&t.indexOf(e,n)>-1:!!i&&M(t,e,n)>-1}function yu(t,e){var n=xp(t)?v:Hr;return n(t,ko(e,3))}function _u(t,e,n,r){return null==t?[]:(xp(e)||(e=null==e?[]:[e]),n=r?it:n,xp(n)||(n=null==n?[]:[n]),Xr(t,e,n))}function bu(t,e,n){var r=xp(t)?m:N,i=arguments.length<3;return r(t,ko(e,4),n,i,_f)}function xu(t,e,n){var r=xp(t)?y:N,i=arguments.length<3;return r(t,ko(e,4),n,i,bf)}function wu(t,e){var n=xp(t)?p:tr;return n(t,Lu(ko(e,3)))}function Cu(t){var e=xp(t)?Sn:ai;return e(t)}function Mu(t,e,n){e=(n?jo(t,e,n):e===it)?1:Ec(e);var r=xp(t)?Pn:ui;return r(t,e)}function ku(t){var e=xp(t)?Nn:si;return e(t)}function Eu(t){if(null==t)return 0;if(Xu(t))return _c(t)?J(t):t.length;var e=Af(t);return e==Zt||e==ie?t.size:Wr(t).length}function Tu(t,e,n){var r=xp(t)?_:fi;return n&&jo(t,e,n)&&(e=it),r(t,ko(e,3))}function Su(t,e){if(\"function\"!=typeof e)throw new dl(ct);return t=Ec(t),function(){if(--t<1)return e.apply(this,arguments)}}function Pu(t,e,n){return e=n?it:e,e=t&&null==e?t.length:e,po(t,Mt,it,it,it,it,e)}function Nu(t,e){var n;if(\"function\"!=typeof e)throw new dl(ct);return t=Ec(t),function(){return--t>0&&(n=e.apply(this,arguments)),t<=1&&(e=it),n}}function Au(t,e,n){e=n?it:e;var r=po(t,bt,it,it,it,it,it,e);return r.placeholder=Au.placeholder,r}function Ou(t,e,n){e=n?it:e;var r=po(t,xt,it,it,it,it,it,e);return r.placeholder=Ou.placeholder,r}function Iu(t,e,n){function r(e){var n=p,r=h;return p=h=it,y=e,v=t.apply(r,n)}function i(t){return y=t,g=Df(u,e),_?r(t):v}function o(t){var n=t-m,r=t-y,i=e-n;return b?Xl(i,d-r):i}function a(t){var n=t-m,r=t-y;return m===it||n>=e||n<0||b&&r>=d}function u(){var t=sp();return a(t)?c(t):void(g=Df(u,o(t)))}function c(t){return g=it,x&&p?r(t):(p=h=it,v)}function s(){g!==it&&Ef(g),y=0,p=m=h=g=it}function l(){return g===it?v:c(sp())}function f(){var t=sp(),n=a(t);if(p=arguments,h=this,m=t,n){if(g===it)return i(m);if(b)return g=Df(u,e),r(m)}return g===it&&(g=Df(u,e)),v}var p,h,d,v,g,m,y=0,_=!1,b=!1,x=!0;if(\"function\"!=typeof t)throw new dl(ct);return e=Sc(e)||0,cc(n)&&(_=!!n.leading,b=\"maxWait\"in n,d=b?$l(Sc(n.maxWait)||0,e):d,x=\"trailing\"in n?!!n.trailing:x),f.cancel=s,f.flush=l,f}function Du(t){return po(t,Et)}function Ru(t,e){if(\"function\"!=typeof t||null!=e&&\"function\"!=typeof e)throw new dl(ct);var n=function(){var r=arguments,i=e?e.apply(this,r):r[0],o=n.cache;if(o.has(i))return o.get(i);var a=t.apply(this,r);return n.cache=o.set(i,a)||o,a};return n.cache=new(Ru.Cache||pn),n}function Lu(t){if(\"function\"!=typeof t)throw new dl(ct);return function(){var e=arguments;switch(e.length){case 0:return!t.call(this);case 1:return!t.call(this,e[0]);case 2:return!t.call(this,e[0],e[1]);case 3:return!t.call(this,e[0],e[1],e[2])}return!t.apply(this,e)}}function Uu(t){return Nu(2,t)}function Fu(t,e){if(\"function\"!=typeof t)throw new dl(ct);return e=e===it?e:Ec(e),oi(t,e)}function ju(t,e){if(\"function\"!=typeof t)throw new dl(ct);return e=null==e?0:$l(Ec(e),0),oi(function(n){var r=n[e],i=Ti(n,0,e);return r&&g(i,r),u(t,this,i)})}function Bu(t,e,n){var r=!0,i=!0;if(\"function\"!=typeof t)throw new dl(ct);return cc(n)&&(r=\"leading\"in n?!!n.leading:r,i=\"trailing\"in n?!!n.trailing:i),Iu(t,e,{leading:r,maxWait:e,trailing:i})}function Wu(t){return Pu(t,1)}function Vu(t,e){return vp(ki(e),t)}function zu(){if(!arguments.length)return[];var t=arguments[0];return xp(t)?t:[t]}function Hu(t){return Bn(t,dt)}function qu(t,e){return e=\"function\"==typeof e?e:it,Bn(t,dt,e)}function Yu(t){return Bn(t,pt|dt)}function Ku(t,e){return e=\"function\"==typeof e?e:it,Bn(t,pt|dt,e)}function Gu(t,e){return null==e||Vn(t,e,Hc(e))}function $u(t,e){return t===e||t!==t&&e!==e}function Xu(t){return null!=t&&uc(t.length)&&!oc(t)}function Zu(t){return sc(t)&&Xu(t)}function Qu(t){return t===!0||t===!1||sc(t)&&fr(t)==qt}function Ju(t){return sc(t)&&1===t.nodeType&&!mc(t)}function tc(t){if(null==t)return!0;if(Xu(t)&&(xp(t)||\"string\"==typeof t||\"function\"==typeof t.splice||Cp(t)||Sp(t)||bp(t)))return!t.length;var e=Af(t);if(e==Zt||e==ie)return!t.size;if(Ho(t))return!Wr(t).length;for(var n in t)if(bl.call(t,n))return!1;return!0}function ec(t,e){return Or(t,e)}function nc(t,e,n){n=\"function\"==typeof n?n:it;var r=n?n(t,e):it;return r===it?Or(t,e,it,n):!!r}function rc(t){if(!sc(t))return!1;var e=fr(t);return e==Gt||e==Kt||\"string\"==typeof t.message&&\"string\"==typeof t.name&&!mc(t)}function ic(t){return\"number\"==typeof t&&Yl(t)}function oc(t){if(!cc(t))return!1;var e=fr(t);return e==$t||e==Xt||e==Ht||e==ne}function ac(t){return\"number\"==typeof t&&t==Ec(t)}function uc(t){return\"number\"==typeof t&&t>-1&&t%1==0&&t<=Rt}function cc(t){var e=typeof t;return null!=t&&(\"object\"==e||\"function\"==e)}function sc(t){return null!=t&&\"object\"==typeof t}function lc(t,e){return t===e||Rr(t,e,To(e))}function fc(t,e,n){return n=\"function\"==typeof n?n:it,Rr(t,e,To(e),n)}function pc(t){return gc(t)&&t!=+t}function hc(t){if(Of(t))throw new cl(ut);return Lr(t)}function dc(t){return null===t}function vc(t){return null==t}function gc(t){return\"number\"==typeof t||sc(t)&&fr(t)==Qt}function mc(t){if(!sc(t)||fr(t)!=te)return!1;var e=Al(t);if(null===e)return!0;var n=bl.call(e,\"constructor\")&&e.constructor;return\"function\"==typeof n&&n instanceof n&&_l.call(n)==Ml}function yc(t){return ac(t)&&t>=-Rt&&t<=Rt}function _c(t){return\"string\"==typeof t||!xp(t)&&sc(t)&&fr(t)==oe}function bc(t){return\"symbol\"==typeof t||sc(t)&&fr(t)==ae}function xc(t){return t===it}function wc(t){return sc(t)&&Af(t)==ce}function Cc(t){return sc(t)&&fr(t)==se}function Mc(t){if(!t)return[];if(Xu(t))return _c(t)?tt(t):Bi(t);if(Ll&&t[Ll])return q(t[Ll]());var e=Af(t),n=e==Zt?Y:e==ie?$:rs;return n(t)}function kc(t){if(!t)return 0===t?t:0;if(t=Sc(t),t===Dt||t===-Dt){var e=t<0?-1:1;return e*Lt}return t===t?t:0}function Ec(t){var e=kc(t),n=e%1;return e===e?n?e-n:e:0}function Tc(t){return t?jn(Ec(t),0,Ft):0}function Sc(t){if(\"number\"==typeof t)return t;if(bc(t))return Ut;if(cc(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=cc(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(Ue,\"\");var n=Ge.test(t);return n||Xe.test(t)?ir(t.slice(2),n?2:8):Ke.test(t)?Ut:+t}function Pc(t){return Wi(t,qc(t))}function Nc(t){return t?jn(Ec(t),-Rt,Rt):0===t?t:0}function Ac(t){return null==t?\"\":gi(t)}function Oc(t,e){var n=yf(t);return null==e?n:Rn(n,e)}function Ic(t,e){return w(t,ko(e,3),nr)}function Dc(t,e){return w(t,ko(e,3),or)}function Rc(t,e){return null==t?t:xf(t,ko(e,3),qc)}function Lc(t,e){return null==t?t:wf(t,ko(e,3),qc)}function Uc(t,e){return t&&nr(t,ko(e,3))}function Fc(t,e){return t&&or(t,ko(e,3))}function jc(t){return null==t?[]:ar(t,Hc(t))}function Bc(t){return null==t?[]:ar(t,qc(t))}function Wc(t,e,n){var r=null==t?it:cr(t,e);return r===it?n:r}function Vc(t,e){return null!=t&&Oo(t,e,_r)}function zc(t,e){return null!=t&&Oo(t,e,Cr)}function Hc(t){return Xu(t)?Tn(t):Wr(t)}function qc(t){return Xu(t)?Tn(t,!0):Vr(t)}function Yc(t,e){var n={};return e=ko(e,3),nr(t,function(t,r,i){Un(n,e(t,r,i),t)}),n}function Kc(t,e){var n={};return e=ko(e,3),nr(t,function(t,r,i){Un(n,r,e(t,r,i))}),n}function Gc(t,e){return $c(t,Lu(ko(e)))}function $c(t,e){if(null==t)return{};var n=v(wo(t),function(t){return[t]});return e=ko(e),Qr(t,n,function(t,n){return e(t,n[0])})}function Xc(t,e,n){e=Ei(e,t);var r=-1,i=e.length;for(i||(i=1,t=it);++r<i;){var o=null==t?it:t[ra(e[r])];o===it&&(r=i,o=n),t=oc(o)?o.call(t):o}return t}function Zc(t,e,n){return null==t?t:ci(t,e,n)}function Qc(t,e,n,r){return r=\"function\"==typeof r?r:it,null==t?t:ci(t,e,n,r)}function Jc(t,e,n){var r=xp(t),i=r||Cp(t)||Sp(t);if(e=ko(e,4),null==n){var o=t&&t.constructor;n=i?r?new o:[]:cc(t)&&oc(o)?yf(Al(t)):{}}return(i?s:nr)(t,function(t,r,i){return e(n,t,r,i)}),n}function ts(t,e){return null==t||yi(t,e)}function es(t,e,n){return null==t?t:_i(t,e,ki(n))}function ns(t,e,n,r){return r=\"function\"==typeof r?r:it,null==t?t:_i(t,e,ki(n),r)}function rs(t){return null==t?[]:L(t,Hc(t))}function is(t){return null==t?[]:L(t,qc(t))}function os(t,e,n){return n===it&&(n=e,e=it),n!==it&&(n=Sc(n),n=n===n?n:0),e!==it&&(e=Sc(e),e=e===e?e:0),jn(Sc(t),e,n)}function as(t,e,n){return e=kc(e),n===it?(n=e,e=0):n=kc(n),t=Sc(t),kr(t,e,n)}function us(t,e,n){if(n&&\"boolean\"!=typeof n&&jo(t,e,n)&&(e=n=it),n===it&&(\"boolean\"==typeof e?(n=e,e=it):\"boolean\"==typeof t&&(n=t,t=it)),t===it&&e===it?(t=0,e=1):(t=kc(t),e===it?(e=t,t=0):e=kc(e)),t>e){var r=t;t=e,e=r}if(n||t%1||e%1){var i=Jl();return Xl(t+i*(e-t+rr(\"1e-\"+((i+\"\").length-1))),e)}return ni(t,e)}function cs(t){return th(Ac(t).toLowerCase())}function ss(t){return t=Ac(t),t&&t.replace(Qe,br).replace(Hn,\"\")}function ls(t,e,n){t=Ac(t),e=gi(e);var r=t.length;n=n===it?r:jn(Ec(n),0,r);var i=n;return n-=e.length,n>=0&&t.slice(n,i)==e}function fs(t){return t=Ac(t),t&&Te.test(t)?t.replace(ke,xr):t}function ps(t){return t=Ac(t),t&&Le.test(t)?t.replace(Re,\"\\\\$&\"):t}function hs(t,e,n){t=Ac(t),e=Ec(e);var r=e?J(t):0;if(!e||r>=e)return t;var i=(e-r)/2;return oo(zl(i),n)+t+oo(Vl(i),n)}function ds(t,e,n){t=Ac(t),e=Ec(e);var r=e?J(t):0;return e&&r<e?t+oo(e-r,n):t}function vs(t,e,n){t=Ac(t),e=Ec(e);var r=e?J(t):0;return e&&r<e?oo(e-r,n)+t:t}function gs(t,e,n){return n||null==e?e=0:e&&(e=+e),Ql(Ac(t).replace(Fe,\"\"),e||0)}function ms(t,e,n){return e=(n?jo(t,e,n):e===it)?1:Ec(e),ii(Ac(t),e)}function ys(){var t=arguments,e=Ac(t[0]);return t.length<3?e:e.replace(t[1],t[2])}function _s(t,e,n){return n&&\"number\"!=typeof n&&jo(t,e,n)&&(e=n=it),(n=n===it?Ft:n>>>0)?(t=Ac(t),t&&(\"string\"==typeof e||null!=e&&!Ep(e))&&(e=gi(e),!e&&z(t))?Ti(tt(t),0,n):t.split(e,n)):[]}function bs(t,e,n){return t=Ac(t),n=null==n?0:jn(Ec(n),0,t.length),e=gi(e),t.slice(n,n+e.length)==e}function xs(t,e,r){var i=n.templateSettings;r&&jo(t,e,r)&&(e=it),t=Ac(t),e=Ip({},e,i,ho);var o,a,u=Ip({},e.imports,i.imports,ho),c=Hc(u),s=L(u,c),l=0,f=e.interpolate||Je,p=\"__p += '\",h=pl((e.escape||Je).source+\"|\"+f.source+\"|\"+(f===Ne?qe:Je).source+\"|\"+(e.evaluate||Je).source+\"|$\",\"g\"),d=\"//# sourceURL=\"+(\"sourceURL\"in e?e.sourceURL:\"lodash.templateSources[\"+ ++Xn+\"]\")+\"\\n\";t.replace(h,function(e,n,r,i,u,c){return r||(r=i),p+=t.slice(l,c).replace(tn,W),n&&(o=!0,p+=\"' +\\n__e(\"+n+\") +\\n'\"),u&&(a=!0,p+=\"';\\n\"+u+\";\\n__p += '\"),r&&(p+=\"' +\\n((__t = (\"+r+\")) == null ? '' : __t) +\\n'\"),l=c+e.length,e}),p+=\"';\\n\";var v=e.variable;v||(p=\"with (obj) {\\n\"+p+\"\\n}\\n\"),p=(a?p.replace(xe,\"\"):p).replace(we,\"$1\").replace(Ce,\"$1;\"),p=\"function(\"+(v||\"obj\")+\") {\\n\"+(v?\"\":\"obj || (obj = {});\\n\")+\"var __t, __p = ''\"+(o?\", __e = _.escape\":\"\")+(a?\", __j = Array.prototype.join;\\nfunction print() { __p += __j.call(arguments, '') }\\n\":\";\\n\")+p+\"return __p\\n}\";var g=eh(function(){return sl(c,d+\"return \"+p).apply(it,s)});if(g.source=p,rc(g))throw g;return g}function ws(t){return Ac(t).toLowerCase()}function Cs(t){return Ac(t).toUpperCase()}function Ms(t,e,n){if(t=Ac(t),t&&(n||e===it))return t.replace(Ue,\"\");if(!t||!(e=gi(e)))return t;var r=tt(t),i=tt(e),o=F(r,i),a=j(r,i)+1;return Ti(r,o,a).join(\"\")}function ks(t,e,n){if(t=Ac(t),t&&(n||e===it))return t.replace(je,\"\");if(!t||!(e=gi(e)))return t;var r=tt(t),i=j(r,tt(e))+1;return Ti(r,0,i).join(\"\")}function Es(t,e,n){if(t=Ac(t),t&&(n||e===it))return t.replace(Fe,\"\");if(!t||!(e=gi(e)))return t;var r=tt(t),i=F(r,tt(e));return Ti(r,i).join(\"\")}function Ts(t,e){var n=Tt,r=St;if(cc(e)){var i=\"separator\"in e?e.separator:i;n=\"length\"in e?Ec(e.length):n,r=\"omission\"in e?gi(e.omission):r}t=Ac(t);var o=t.length;if(z(t)){var a=tt(t);o=a.length}if(n>=o)return t;var u=n-J(r);if(u<1)return r;var c=a?Ti(a,0,u).join(\"\"):t.slice(0,u);if(i===it)return c+r;if(a&&(u+=c.length-u),Ep(i)){if(t.slice(u).search(i)){var s,l=c;for(i.global||(i=pl(i.source,Ac(Ye.exec(i))+\"g\")),i.lastIndex=0;s=i.exec(l);)var f=s.index;c=c.slice(0,f===it?u:f)}}else if(t.indexOf(gi(i),u)!=u){var p=c.lastIndexOf(i);p>-1&&(c=c.slice(0,p))}return c+r}function Ss(t){return t=Ac(t),t&&Ee.test(t)?t.replace(Me,wr):t}function Ps(t,e,n){return t=Ac(t),e=n?it:e,e===it?H(t)?rt(t):x(t):t.match(e)||[]}function Ns(t){var e=null==t?0:t.length,n=ko();return t=e?v(t,function(t){if(\"function\"!=typeof t[1])throw new dl(ct);return[n(t[0]),t[1]]}):[],oi(function(n){for(var r=-1;++r<e;){var i=t[r];if(u(i[0],this,n))return u(i[1],this,n)}})}function As(t){return Wn(Bn(t,pt))}function Os(t){return function(){return t}}function Is(t,e){return null==t||t!==t?e:t}function Ds(t){return t}function Rs(t){return Br(\"function\"==typeof t?t:Bn(t,pt))}function Ls(t){return qr(Bn(t,pt))}function Us(t,e){return Yr(t,Bn(e,pt))}function Fs(t,e,n){var r=Hc(e),i=ar(e,r);null!=n||cc(e)&&(i.length||!r.length)||(n=e,e=t,t=this,i=ar(e,Hc(e)));var o=!(cc(n)&&\"chain\"in n&&!n.chain),a=oc(t);return s(i,function(n){var r=e[n];t[n]=r,a&&(t.prototype[n]=function(){var e=this.__chain__;if(o||e){var n=t(this.__wrapped__),i=n.__actions__=Bi(this.__actions__);return i.push({func:r,args:arguments,thisArg:t}),n.__chain__=e,n}return r.apply(t,g([this.value()],arguments))})}),t}function js(){return ur._===this&&(ur._=kl),this}function Bs(){}function Ws(t){return t=Ec(t),oi(function(e){return $r(e,t)})}function Vs(t){return Bo(t)?S(ra(t)):Jr(t)}function zs(t){return function(e){return null==t?it:cr(t,e)}}function Hs(){return[]}function qs(){return!1}function Ys(){return{}}function Ks(){return\"\"}function Gs(){return!0}function $s(t,e){if(t=Ec(t),t<1||t>Rt)return[];var n=Ft,r=Xl(t,Ft);e=ko(e),t-=Ft;for(var i=I(r,e);++n<t;)e(n);return i}function Xs(t){return xp(t)?v(t,ra):bc(t)?[t]:Bi(Lf(Ac(t)))}function Zs(t){var e=++xl;return Ac(t)+e}function Qs(t){return t&&t.length?Gn(t,Ds,pr):it}function Js(t,e){return t&&t.length?Gn(t,ko(e,2),pr):it}function tl(t){return T(t,Ds)}function el(t,e){return T(t,ko(e,2))}function nl(t){return t&&t.length?Gn(t,Ds,zr):it}function rl(t,e){return t&&t.length?Gn(t,ko(e,2),zr):it}function il(t){return t&&t.length?O(t,Ds):0}function ol(t,e){return t&&t.length?O(t,ko(e,2)):0}e=null==e?ur:Mr.defaults(ur.Object(),e,Mr.pick(ur,$n));var al=e.Array,ul=e.Date,cl=e.Error,sl=e.Function,ll=e.Math,fl=e.Object,pl=e.RegExp,hl=e.String,dl=e.TypeError,vl=al.prototype,gl=sl.prototype,ml=fl.prototype,yl=e[\"__core-js_shared__\"],_l=gl.toString,bl=ml.hasOwnProperty,xl=0,wl=function(){var t=/[^.]+$/.exec(yl&&yl.keys&&yl.keys.IE_PROTO||\"\");return t?\"Symbol(src)_1.\"+t:\"\"}(),Cl=ml.toString,Ml=_l.call(fl),kl=ur._,El=pl(\"^\"+_l.call(bl).replace(Re,\"\\\\$&\").replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g,\"$1.*?\")+\"$\"),Tl=lr?e.Buffer:it,Sl=e.Symbol,Pl=e.Uint8Array,Nl=Tl?Tl.allocUnsafe:it,Al=K(fl.getPrototypeOf,fl),Ol=fl.create,Il=ml.propertyIsEnumerable,Dl=vl.splice,Rl=Sl?Sl.isConcatSpreadable:it,Ll=Sl?Sl.iterator:it,Ul=Sl?Sl.toStringTag:it,Fl=function(){try{var t=So(fl,\"defineProperty\");return t({},\"\",{}),t}catch(t){}}(),jl=e.clearTimeout!==ur.clearTimeout&&e.clearTimeout,Bl=ul&&ul.now!==ur.Date.now&&ul.now,Wl=e.setTimeout!==ur.setTimeout&&e.setTimeout,Vl=ll.ceil,zl=ll.floor,Hl=fl.getOwnPropertySymbols,ql=Tl?Tl.isBuffer:it,Yl=e.isFinite,Kl=vl.join,Gl=K(fl.keys,fl),$l=ll.max,Xl=ll.min,Zl=ul.now,Ql=e.parseInt,Jl=ll.random,tf=vl.reverse,ef=So(e,\"DataView\"),nf=So(e,\"Map\"),rf=So(e,\"Promise\"),of=So(e,\"Set\"),af=So(e,\"WeakMap\"),uf=So(fl,\"create\"),cf=af&&new af,sf={},lf=ia(ef),ff=ia(nf),pf=ia(rf),hf=ia(of),df=ia(af),vf=Sl?Sl.prototype:it,gf=vf?vf.valueOf:it,mf=vf?vf.toString:it,yf=function(){function t(){}return function(e){if(!cc(e))return{};if(Ol)return Ol(e);t.prototype=e;var n=new t;return t.prototype=it,n}}();n.templateSettings={escape:Se,evaluate:Pe,interpolate:Ne,variable:\"\",imports:{_:n}},n.prototype=r.prototype,n.prototype.constructor=n,i.prototype=yf(r.prototype),i.prototype.constructor=i,b.prototype=yf(r.prototype),b.prototype.constructor=b,nt.prototype.clear=ze,nt.prototype.delete=en,nt.prototype.get=nn,nt.prototype.has=rn,nt.prototype.set=on,an.prototype.clear=un,an.prototype.delete=cn,an.prototype.get=sn,an.prototype.has=ln,an.prototype.set=fn,pn.prototype.clear=hn,pn.prototype.delete=dn,pn.prototype.get=vn,pn.prototype.has=gn,pn.prototype.set=mn,yn.prototype.add=yn.prototype.push=_n,yn.prototype.has=bn,xn.prototype.clear=wn,xn.prototype.delete=Cn,xn.prototype.get=Mn,xn.prototype.has=kn,xn.prototype.set=En;var _f=Yi(nr),bf=Yi(or,!0),xf=Ki(),wf=Ki(!0),Cf=cf?function(t,e){return cf.set(t,e),t}:Ds,Mf=Fl?function(t,e){return Fl(t,\"toString\",{configurable:!0,enumerable:!1,value:Os(e),writable:!0})}:Ds,kf=oi,Ef=jl||function(t){return ur.clearTimeout(t)},Tf=of&&1/$(new of([,-0]))[1]==Dt?function(t){return new of(t)}:Bs,Sf=cf?function(t){return cf.get(t)}:Bs,Pf=Hl?function(t){return null==t?[]:(t=fl(t),p(Hl(t),function(e){return Il.call(t,e)}))}:Hs,Nf=Hl?function(t){for(var e=[];t;)g(e,Pf(t)),t=Al(t);return e}:Hs,Af=fr;(ef&&Af(new ef(new ArrayBuffer(1)))!=fe||nf&&Af(new nf)!=Zt||rf&&Af(rf.resolve())!=ee||of&&Af(new of)!=ie||af&&Af(new af)!=ce)&&(Af=function(t){var e=fr(t),n=e==te?t.constructor:it,r=n?ia(n):\"\";if(r)switch(r){case lf:return fe;case ff:return Zt;case pf:return ee;case hf:return ie;case df:return ce}return e});var Of=yl?oc:qs,If=ea(Cf),Df=Wl||function(t,e){return ur.setTimeout(t,e)},Rf=ea(Mf),Lf=Ko(function(t){var e=[];return Ie.test(t)&&e.push(\"\"),t.replace(De,function(t,n,r,i){e.push(r?i.replace(He,\"$1\"):n||t)}),e}),Uf=oi(function(t,e){return Zu(t)?Yn(t,er(e,1,Zu,!0)):[]}),Ff=oi(function(t,e){var n=ka(e);return Zu(n)&&(n=it),Zu(t)?Yn(t,er(e,1,Zu,!0),ko(n,2)):[]}),jf=oi(function(t,e){var n=ka(e);return Zu(n)&&(n=it),Zu(t)?Yn(t,er(e,1,Zu,!0),it,n):[]}),Bf=oi(function(t){var e=v(t,Mi);return e.length&&e[0]===t[0]?Er(e):[]}),Wf=oi(function(t){var e=ka(t),n=v(t,Mi);return e===ka(n)?e=it:n.pop(),n.length&&n[0]===t[0]?Er(n,ko(e,2)):[]}),Vf=oi(function(t){var e=ka(t),n=v(t,Mi);return e=\"function\"==typeof e?e:it,e&&n.pop(),n.length&&n[0]===t[0]?Er(n,it,e):[]}),zf=oi(Sa),Hf=bo(function(t,e){var n=null==t?0:t.length,r=Fn(t,e);return ei(t,v(e,function(t){return Fo(t,n)?+t:t}).sort(Li)),r}),qf=oi(function(t){return mi(er(t,1,Zu,!0))}),Yf=oi(function(t){var e=ka(t);return Zu(e)&&(e=it),mi(er(t,1,Zu,!0),ko(e,2))}),Kf=oi(function(t){var e=ka(t);return e=\"function\"==typeof e?e:it,mi(er(t,1,Zu,!0),it,e)}),Gf=oi(function(t,e){return Zu(t)?Yn(t,e):[]}),$f=oi(function(t){return wi(p(t,Zu))}),Xf=oi(function(t){var e=ka(t);return Zu(e)&&(e=it),wi(p(t,Zu),ko(e,2))}),Zf=oi(function(t){var e=ka(t);return e=\"function\"==typeof e?e:it,wi(p(t,Zu),it,e)}),Qf=oi(Xa),Jf=oi(function(t){var e=t.length,n=e>1?t[e-1]:it;return n=\"function\"==typeof n?(t.pop(),n):it,Za(t,n)}),tp=bo(function(t){var e=t.length,n=e?t[0]:0,r=this.__wrapped__,o=function(e){return Fn(e,t)};return!(e>1||this.__actions__.length)&&r instanceof b&&Fo(n)?(r=r.slice(n,+n+(e?1:0)),r.__actions__.push({func:nu,args:[o],thisArg:it}),new i(r,this.__chain__).thru(function(t){return e&&!t.length&&t.push(it),t})):this.thru(o)}),ep=Hi(function(t,e,n){bl.call(t,n)?++t[n]:Un(t,n,1)}),np=Ji(va),rp=Ji(ga),ip=Hi(function(t,e,n){bl.call(t,n)?t[n].push(e):Un(t,n,[e])}),op=oi(function(t,e,n){var r=-1,i=\"function\"==typeof e,o=Xu(t)?al(t.length):[];return _f(t,function(t){o[++r]=i?u(e,t,n):Sr(t,e,n)}),o}),ap=Hi(function(t,e,n){Un(t,n,e)}),up=Hi(function(t,e,n){t[n?0:1].push(e)},function(){return[[],[]]}),cp=oi(function(t,e){if(null==t)return[];var n=e.length;return n>1&&jo(t,e[0],e[1])?e=[]:n>2&&jo(e[0],e[1],e[2])&&(e=[e[0]]),Xr(t,er(e,1),[])}),sp=Bl||function(){return ur.Date.now()},lp=oi(function(t,e,n){var r=mt;if(n.length){var i=G(n,Mo(lp));r|=wt}return po(t,r,e,n,i)}),fp=oi(function(t,e,n){var r=mt|yt;if(n.length){var i=G(n,Mo(fp));r|=wt}return po(e,r,t,n,i)}),pp=oi(function(t,e){return qn(t,1,e)}),hp=oi(function(t,e,n){return qn(t,Sc(e)||0,n)});Ru.Cache=pn;var dp=kf(function(t,e){e=1==e.length&&xp(e[0])?v(e[0],R(ko())):v(er(e,1),R(ko()));var n=e.length;return oi(function(r){for(var i=-1,o=Xl(r.length,n);++i<o;)r[i]=e[i].call(this,r[i]);return u(t,this,r)})}),vp=oi(function(t,e){var n=G(e,Mo(vp));return po(t,wt,it,e,n)}),gp=oi(function(t,e){var n=G(e,Mo(gp));return po(t,Ct,it,e,n)}),mp=bo(function(t,e){return po(t,kt,it,it,it,e)}),yp=co(pr),_p=co(function(t,e){return t>=e}),bp=Pr(function(){return arguments}())?Pr:function(t){return sc(t)&&bl.call(t,\"callee\")&&!Il.call(t,\"callee\")},xp=al.isArray,wp=hr?R(hr):Nr,Cp=ql||qs,Mp=dr?R(dr):Ar,kp=vr?R(vr):Dr,Ep=gr?R(gr):Ur,Tp=mr?R(mr):Fr,Sp=yr?R(yr):jr,Pp=co(zr),Np=co(function(t,e){return t<=e}),Ap=qi(function(t,e){if(Ho(e)||Xu(e))return void Wi(e,Hc(e),t);for(var n in e)bl.call(e,n)&&On(t,n,e[n])}),Op=qi(function(t,e){Wi(e,qc(e),t)}),Ip=qi(function(t,e,n,r){Wi(e,qc(e),t,r)}),Dp=qi(function(t,e,n,r){Wi(e,Hc(e),t,r)}),Rp=bo(Fn),Lp=oi(function(t){return t.push(it,ho),u(Ip,it,t)}),Up=oi(function(t){return t.push(it,vo),u(Vp,it,t)}),Fp=no(function(t,e,n){t[e]=n},Os(Ds)),jp=no(function(t,e,n){bl.call(t,e)?t[e].push(n):t[e]=[n]},ko),Bp=oi(Sr),Wp=qi(function(t,e,n){Kr(t,e,n)}),Vp=qi(function(t,e,n,r){Kr(t,e,n,r)}),zp=bo(function(t,e){var n={};if(null==t)return n;var r=!1;e=v(e,function(e){return e=Ei(e,t),r||(r=e.length>1),e}),Wi(t,wo(t),n),r&&(n=Bn(n,pt|ht|dt,go));for(var i=e.length;i--;)yi(n,e[i]);return n}),Hp=bo(function(t,e){return null==t?{}:Zr(t,e)}),qp=fo(Hc),Yp=fo(qc),Kp=Xi(function(t,e,n){return e=e.toLowerCase(),t+(n?cs(e):e)}),Gp=Xi(function(t,e,n){return t+(n?\"-\":\"\")+e.toLowerCase()}),$p=Xi(function(t,e,n){return t+(n?\" \":\"\")+e.toLowerCase()}),Xp=$i(\"toLowerCase\"),Zp=Xi(function(t,e,n){return t+(n?\"_\":\"\")+e.toLowerCase()}),Qp=Xi(function(t,e,n){return t+(n?\" \":\"\")+th(e)}),Jp=Xi(function(t,e,n){return t+(n?\" \":\"\")+e.toUpperCase()}),th=$i(\"toUpperCase\"),eh=oi(function(t,e){try{return u(t,it,e)}catch(t){return rc(t)?t:new cl(t)}}),nh=bo(function(t,e){return s(e,function(e){e=ra(e),Un(t,e,lp(t[e],t))}),t}),rh=to(),ih=to(!0),oh=oi(function(t,e){return function(n){return Sr(n,t,e)}}),ah=oi(function(t,e){return function(n){return Sr(t,n,e)}}),uh=io(v),ch=io(f),sh=io(_),lh=uo(),fh=uo(!0),ph=ro(function(t,e){return t+e},0),hh=lo(\"ceil\"),dh=ro(function(t,e){return t/e},1),vh=lo(\"floor\"),gh=ro(function(t,e){return t*e},1),mh=lo(\"round\"),yh=ro(function(t,e){return t-e},0);return n.after=Su,n.ary=Pu,n.assign=Ap,n.assignIn=Op,n.assignInWith=Ip,n.assignWith=Dp,n.at=Rp,n.before=Nu,n.bind=lp,n.bindAll=nh,n.bindKey=fp,n.castArray=zu,n.chain=tu,n.chunk=ua,n.compact=ca,n.concat=sa,n.cond=Ns,n.conforms=As,n.constant=Os,n.countBy=ep,n.create=Oc,n.curry=Au,n.curryRight=Ou,n.debounce=Iu,n.defaults=Lp,n.defaultsDeep=Up,n.defer=pp,n.delay=hp,n.difference=Uf,n.differenceBy=Ff,n.differenceWith=jf,n.drop=la,n.dropRight=fa,n.dropRightWhile=pa,n.dropWhile=ha,n.fill=da,n.filter=fu,n.flatMap=pu,n.flatMapDeep=hu,n.flatMapDepth=du,n.flatten=ma,n.flattenDeep=ya,n.flattenDepth=_a,n.flip=Du,n.flow=rh,n.flowRight=ih,n.fromPairs=ba,n.functions=jc,n.functionsIn=Bc,n.groupBy=ip,n.initial=Ca,n.intersection=Bf,n.intersectionBy=Wf,n.intersectionWith=Vf,n.invert=Fp,n.invertBy=jp,n.invokeMap=op,n.iteratee=Rs,n.keyBy=ap,n.keys=Hc,n.keysIn=qc,n.map=yu,n.mapKeys=Yc,n.mapValues=Kc,n.matches=Ls,n.matchesProperty=Us,n.memoize=Ru,n.merge=Wp,n.mergeWith=Vp,n.method=oh,n.methodOf=ah,n.mixin=Fs,n.negate=Lu,n.nthArg=Ws,n.omit=zp,n.omitBy=Gc,n.once=Uu,n.orderBy=_u,n.over=uh,n.overArgs=dp,n.overEvery=ch,n.overSome=sh,n.partial=vp,n.partialRight=gp,n.partition=up,n.pick=Hp,n.pickBy=$c,n.property=Vs,n.propertyOf=zs,n.pull=zf,n.pullAll=Sa,n.pullAllBy=Pa,n.pullAllWith=Na,n.pullAt=Hf,n.range=lh,n.rangeRight=fh,n.rearg=mp,n.reject=wu,n.remove=Aa,n.rest=Fu,n.reverse=Oa,n.sampleSize=Mu,n.set=Zc,n.setWith=Qc,n.shuffle=ku,n.slice=Ia,n.sortBy=cp,n.sortedUniq=Ba,n.sortedUniqBy=Wa,n.split=_s,n.spread=ju,n.tail=Va,n.take=za,n.takeRight=Ha,n.takeRightWhile=qa,n.takeWhile=Ya,n.tap=eu,n.throttle=Bu,n.thru=nu,n.toArray=Mc,n.toPairs=qp,n.toPairsIn=Yp,n.toPath=Xs,n.toPlainObject=Pc,n.transform=Jc,n.unary=Wu,n.union=qf,n.unionBy=Yf,n.unionWith=Kf,n.uniq=Ka,n.uniqBy=Ga,n.uniqWith=$a,n.unset=ts,n.unzip=Xa,n.unzipWith=Za,n.update=es,n.updateWith=ns,n.values=rs,n.valuesIn=is,n.without=Gf,n.words=Ps,n.wrap=Vu,n.xor=$f,n.xorBy=Xf,n.xorWith=Zf,n.zip=Qf,n.zipObject=Qa,n.zipObjectDeep=Ja,n.zipWith=Jf,n.entries=qp,n.entriesIn=Yp,n.extend=Op,n.extendWith=Ip,Fs(n,n),n.add=ph,n.attempt=eh,n.camelCase=Kp,n.capitalize=cs,n.ceil=hh,n.clamp=os,n.clone=Hu,n.cloneDeep=Yu,n.cloneDeepWith=Ku,n.cloneWith=qu,n.conformsTo=Gu,n.deburr=ss,n.defaultTo=Is,n.divide=dh,n.endsWith=ls,n.eq=$u,n.escape=fs,n.escapeRegExp=ps,n.every=lu,n.find=np,n.findIndex=va,n.findKey=Ic,n.findLast=rp,n.findLastIndex=ga,n.findLastKey=Dc,n.floor=vh,n.forEach=vu,n.forEachRight=gu,n.forIn=Rc,n.forInRight=Lc,n.forOwn=Uc,n.forOwnRight=Fc,n.get=Wc,n.gt=yp,n.gte=_p,n.has=Vc,n.hasIn=zc,n.head=xa,n.identity=Ds,n.includes=mu,n.indexOf=wa,n.inRange=as,n.invoke=Bp,n.isArguments=bp,n.isArray=xp,n.isArrayBuffer=wp,n.isArrayLike=Xu,n.isArrayLikeObject=Zu,n.isBoolean=Qu,n.isBuffer=Cp,n.isDate=Mp,n.isElement=Ju,n.isEmpty=tc,n.isEqual=ec,n.isEqualWith=nc,n.isError=rc,n.isFinite=ic,n.isFunction=oc,n.isInteger=ac,n.isLength=uc,n.isMap=kp,n.isMatch=lc,n.isMatchWith=fc,n.isNaN=pc,n.isNative=hc,n.isNil=vc,n.isNull=dc,n.isNumber=gc,n.isObject=cc,n.isObjectLike=sc,n.isPlainObject=mc,n.isRegExp=Ep,n.isSafeInteger=yc,n.isSet=Tp,n.isString=_c,n.isSymbol=bc,n.isTypedArray=Sp,n.isUndefined=xc,n.isWeakMap=wc,n.isWeakSet=Cc,n.join=Ma,n.kebabCase=Gp,n.last=ka,n.lastIndexOf=Ea,n.lowerCase=$p,n.lowerFirst=Xp,n.lt=Pp,n.lte=Np,n.max=Qs,n.maxBy=Js,n.mean=tl,n.meanBy=el,n.min=nl,n.minBy=rl,n.stubArray=Hs,n.stubFalse=qs,n.stubObject=Ys,n.stubString=Ks,n.stubTrue=Gs,n.multiply=gh,n.nth=Ta,n.noConflict=js,n.noop=Bs,n.now=sp,n.pad=hs,n.padEnd=ds,n.padStart=vs,n.parseInt=gs,n.random=us,n.reduce=bu,n.reduceRight=xu,n.repeat=ms,n.replace=ys,n.result=Xc,n.round=mh,n.runInContext=t,n.sample=Cu,n.size=Eu,n.snakeCase=Zp,n.some=Tu,n.sortedIndex=Da,n.sortedIndexBy=Ra,n.sortedIndexOf=La,n.sortedLastIndex=Ua,n.sortedLastIndexBy=Fa,n.sortedLastIndexOf=ja,n.startCase=Qp,n.startsWith=bs,n.subtract=yh,n.sum=il,n.sumBy=ol,n.template=xs,n.times=$s,n.toFinite=kc,n.toInteger=Ec,n.toLength=Tc,n.toLower=ws,n.toNumber=Sc,n.toSafeInteger=Nc,n.toString=Ac,n.toUpper=Cs,n.trim=Ms,n.trimEnd=ks,n.trimStart=Es,n.truncate=Ts,n.unescape=Ss,n.uniqueId=Zs,n.upperCase=Jp,n.upperFirst=th,n.each=vu,n.eachRight=gu,n.first=xa,Fs(n,function(){var t={};return nr(n,function(e,r){bl.call(n.prototype,r)||(t[r]=e)}),t}(),{chain:!1}),n.VERSION=ot,s([\"bind\",\"bindKey\",\"curry\",\"curryRight\",\"partial\",\"partialRight\"],function(t){n[t].placeholder=n}),s([\"drop\",\"take\"],function(t,e){b.prototype[t]=function(n){n=n===it?1:$l(Ec(n),0);var r=this.__filtered__&&!e?new b(this):this.clone();return r.__filtered__?r.__takeCount__=Xl(n,r.__takeCount__):r.__views__.push({size:Xl(n,Ft),type:t+(r.__dir__<0?\"Right\":\"\")}),r},b.prototype[t+\"Right\"]=function(e){return this.reverse()[t](e).reverse()}}),s([\"filter\",\"map\",\"takeWhile\"],function(t,e){var n=e+1,r=n==At||n==It;b.prototype[t]=function(t){var e=this.clone();return e.__iteratees__.push({iteratee:ko(t,3),type:n}),e.__filtered__=e.__filtered__||r,e}}),s([\"head\",\"last\"],function(t,e){var n=\"take\"+(e?\"Right\":\"\");b.prototype[t]=function(){return this[n](1).value()[0]}}),s([\"initial\",\"tail\"],function(t,e){var n=\"drop\"+(e?\"\":\"Right\");b.prototype[t]=function(){return this.__filtered__?new b(this):this[n](1)}}),b.prototype.compact=function(){return this.filter(Ds)},b.prototype.find=function(t){return this.filter(t).head()},b.prototype.findLast=function(t){return this.reverse().find(t)},b.prototype.invokeMap=oi(function(t,e){return\"function\"==typeof t?new b(this):this.map(function(n){return Sr(n,t,e)})}),b.prototype.reject=function(t){return this.filter(Lu(ko(t)))},b.prototype.slice=function(t,e){t=Ec(t);var n=this;return n.__filtered__&&(t>0||e<0)?new b(n):(t<0?n=n.takeRight(-t):t&&(n=n.drop(t)),e!==it&&(e=Ec(e),n=e<0?n.dropRight(-e):n.take(e-t)),n)},b.prototype.takeRightWhile=function(t){return this.reverse().takeWhile(t).reverse()},b.prototype.toArray=function(){return this.take(Ft)},nr(b.prototype,function(t,e){var r=/^(?:filter|find|map|reject)|While$/.test(e),o=/^(?:head|last)$/.test(e),a=n[o?\"take\"+(\"last\"==e?\"Right\":\"\"):e],u=o||/^find/.test(e);a&&(n.prototype[e]=function(){var e=this.__wrapped__,c=o?[1]:arguments,s=e instanceof b,l=c[0],f=s||xp(e),p=function(t){var e=a.apply(n,g([t],c));return o&&h?e[0]:e};f&&r&&\"function\"==typeof l&&1!=l.length&&(s=f=!1);var h=this.__chain__,d=!!this.__actions__.length,v=u&&!h,m=s&&!d;if(!u&&f){e=m?e:new b(this);var y=t.apply(e,c);return y.__actions__.push({func:nu,args:[p],thisArg:it}),new i(y,h)}return v&&m?t.apply(this,c):(y=this.thru(p),v?o?y.value()[0]:y.value():y)})}),s([\"pop\",\"push\",\"shift\",\"sort\",\"splice\",\"unshift\"],function(t){var e=vl[t],r=/^(?:push|sort|unshift)$/.test(t)?\"tap\":\"thru\",i=/^(?:pop|shift)$/.test(t);n.prototype[t]=function(){var t=arguments;if(i&&!this.__chain__){var n=this.value();return e.apply(xp(n)?n:[],t)}return this[r](function(n){return e.apply(xp(n)?n:[],t)})}}),nr(b.prototype,function(t,e){var r=n[e];if(r){var i=r.name+\"\",o=sf[i]||(sf[i]=[]);o.push({name:e,func:r})}}),sf[eo(it,yt).name]=[{name:\"wrapper\",func:it}],b.prototype.clone=P,b.prototype.reverse=Z,b.prototype.value=et,n.prototype.at=tp,n.prototype.chain=ru,n.prototype.commit=iu,n.prototype.next=ou,n.prototype.plant=uu,n.prototype.reverse=cu,n.prototype.toJSON=n.prototype.valueOf=n.prototype.value=su,n.prototype.first=n.prototype.head,Ll&&(n.prototype[Ll]=au),n},Mr=Cr();ur._=Mr,i=function(){return Mr}.call(e,n,e,r),!(i!==it&&(r.exports=i))}).call(this)}).call(e,n(99),n(100)(t))},function(t,e,n){\"use strict\";var r={remove:function(t){t._reactInternalInstance=void 0},get:function(t){return t._reactInternalInstance},has:function(t){return void 0!==t._reactInternalInstance},set:function(t,e){t._reactInternalInstance=e}};t.exports=r},function(t,e,n){\"use strict\";t.exports=n(26)},function(t,e,n){\"use strict\";var r=n(61);e.a=function(t){return t=n.i(r.a)(Math.abs(t)),t?t[1]:NaN}},function(t,e,n){\"use strict\";e.a=function(t,e){return t=+t,e-=t,function(n){return t+e*n}}},function(t,e,n){\"use strict\";var r=n(228);n.d(e,\"a\",function(){return r.a})},function(t,e,n){\"use strict\";function r(t,e){return(e-=t=+t)?function(n){return(n-t)/e}:n.i(h.a)(e)}function i(t){return function(e,n){var r=t(e=+e,n=+n);return function(t){return t<=e?0:t>=n?1:r(t)}}}function o(t){return function(e,n){var r=t(e=+e,n=+n);return function(t){return t<=0?e:t>=1?n:r(t)}}}function a(t,e,n,r){var i=t[0],o=t[1],a=e[0],u=e[1];return o<i?(i=n(o,i),a=r(u,a)):(i=n(i,o),a=r(a,u)),function(t){return a(i(t))}}function u(t,e,r,i){var o=Math.min(t.length,e.length)-1,a=new Array(o),u=new Array(o),c=-1;for(t[o]<t[0]&&(t=t.slice().reverse(),e=e.slice().reverse());++c<o;)a[c]=r(t[c],t[c+1]),u[c]=i(e[c],e[c+1]);return function(e){var r=n.i(l.c)(t,e,1,o)-1;return u[r](a[r](e))}}function c(t,e){return e.domain(t.domain()).range(t.range()).interpolate(t.interpolate()).clamp(t.clamp())}function s(t,e){function n(){return s=Math.min(g.length,m.length)>2?u:a,l=h=null,c}function c(e){return(l||(l=s(g,m,_?i(t):t,y)))(+e)}var s,l,h,g=v,m=v,y=f.b,_=!1;return c.invert=function(t){return(h||(h=s(m,g,r,_?o(e):e)))(+t)},c.domain=function(t){return arguments.length?(g=p.a.call(t,d.a),n()):g.slice()},c.range=function(t){return arguments.length?(m=p.b.call(t),n()):m.slice()},c.rangeRound=function(t){return m=p.b.call(t),y=f.c,n()},c.clamp=function(t){return arguments.length?(_=!!t,n()):_},c.interpolate=function(t){return arguments.length?(y=t,n()):y},n()}var l=n(12),f=n(31),p=n(16),h=n(65),d=n(126);e.b=r,e.c=c,e.a=s;var v=[0,1]},function(t,e,n){\"use strict\";function r(t,e,n){t._context.bezierCurveTo((2*t._x0+t._x1)/3,(2*t._y0+t._y1)/3,(t._x0+2*t._x1)/3,(t._y0+2*t._y1)/3,(t._x0+4*t._x1+e)/6,(t._y0+4*t._y1+n)/6)}function i(t){this._context=t}e.c=r,e.b=i,i.prototype={\n",
       "areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._y0=this._y1=NaN,this._point=0},lineEnd:function(){switch(this._point){case 3:r(this,this._x1,this._y1);case 2:this._context.lineTo(this._x1,this._y1)}(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;break;case 2:this._point=3,this._context.lineTo((5*this._x0+this._x1)/6,(5*this._y0+this._y1)/6);default:r(this,t,e)}this._x0=this._x1,this._x1=t,this._y0=this._y1,this._y1=e}},e.a=function(t){return new i(t)}},function(t,e,n){\"use strict\";function r(t,e,n){t._context.bezierCurveTo(t._x1+t._k*(t._x2-t._x0),t._y1+t._k*(t._y2-t._y0),t._x2+t._k*(t._x1-e),t._y2+t._k*(t._y1-n),t._x2,t._y2)}function i(t,e){this._context=t,this._k=(1-e)/6}e.c=r,e.b=i,i.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._x2=this._y0=this._y1=this._y2=NaN,this._point=0},lineEnd:function(){switch(this._point){case 2:this._context.lineTo(this._x2,this._y2);break;case 3:r(this,this._x1,this._y1)}(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2,this._x1=t,this._y1=e;break;case 2:this._point=3;default:r(this,t,e)}this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return new i(t,e)}return n.tension=function(e){return t(+e)},n}(0)},function(t,e,n){\"use strict\";function r(t){this._context=t}r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._point=0},lineEnd:function(){(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;default:this._context.lineTo(t,e)}}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";e.a=function(){}},function(t,e,n){\"use strict\";function r(t){return\"topMouseUp\"===t||\"topTouchEnd\"===t||\"topTouchCancel\"===t}function i(t){return\"topMouseMove\"===t||\"topTouchMove\"===t}function o(t){return\"topMouseDown\"===t||\"topTouchStart\"===t}function a(t,e,n,r){var i=t.type||\"unknown-event\";t.currentTarget=m.getNodeFromInstance(r),e?v.invokeGuardedCallbackWithCatch(i,n,t):v.invokeGuardedCallback(i,n,t),t.currentTarget=null}function u(t,e){var n=t._dispatchListeners,r=t._dispatchInstances;if(Array.isArray(n))for(var i=0;i<n.length&&!t.isPropagationStopped();i++)a(t,e,n[i],r[i]);else n&&a(t,e,n,r);t._dispatchListeners=null,t._dispatchInstances=null}function c(t){var e=t._dispatchListeners,n=t._dispatchInstances;if(Array.isArray(e)){for(var r=0;r<e.length&&!t.isPropagationStopped();r++)if(e[r](t,n[r]))return n[r]}else if(e&&e(t,n))return n;return null}function s(t){var e=c(t);return t._dispatchInstances=null,t._dispatchListeners=null,e}function l(t){var e=t._dispatchListeners,n=t._dispatchInstances;Array.isArray(e)?d(\"103\"):void 0,t.currentTarget=e?m.getNodeFromInstance(n):null;var r=e?e(t):null;return t.currentTarget=null,t._dispatchListeners=null,t._dispatchInstances=null,r}function f(t){return!!t._dispatchListeners}var p,h,d=n(2),v=n(87),g=(n(0),n(1),{injectComponentTree:function(t){p=t},injectTreeTraversal:function(t){h=t}}),m={isEndish:r,isMoveish:i,isStartish:o,executeDirectDispatch:l,executeDispatchesInOrder:u,executeDispatchesInOrderStopAtTrue:s,hasDispatches:f,getInstanceFromNode:function(t){return p.getInstanceFromNode(t)},getNodeFromInstance:function(t){return p.getNodeFromInstance(t)},isAncestor:function(t,e){return h.isAncestor(t,e)},getLowestCommonAncestor:function(t,e){return h.getLowestCommonAncestor(t,e)},getParentInstance:function(t){return h.getParentInstance(t)},traverseTwoPhase:function(t,e,n){return h.traverseTwoPhase(t,e,n)},traverseEnterLeave:function(t,e,n,r,i){return h.traverseEnterLeave(t,e,n,r,i)},injection:g};t.exports=m},function(t,e,n){\"use strict\";function r(t){return Object.prototype.hasOwnProperty.call(t,v)||(t[v]=h++,f[t[v]]={}),f[t[v]]}var i,o=n(3),a=n(83),u=n(360),c=n(89),s=n(393),l=n(94),f={},p=!1,h=0,d={topAbort:\"abort\",topAnimationEnd:s(\"animationend\")||\"animationend\",topAnimationIteration:s(\"animationiteration\")||\"animationiteration\",topAnimationStart:s(\"animationstart\")||\"animationstart\",topBlur:\"blur\",topCanPlay:\"canplay\",topCanPlayThrough:\"canplaythrough\",topChange:\"change\",topClick:\"click\",topCompositionEnd:\"compositionend\",topCompositionStart:\"compositionstart\",topCompositionUpdate:\"compositionupdate\",topContextMenu:\"contextmenu\",topCopy:\"copy\",topCut:\"cut\",topDoubleClick:\"dblclick\",topDrag:\"drag\",topDragEnd:\"dragend\",topDragEnter:\"dragenter\",topDragExit:\"dragexit\",topDragLeave:\"dragleave\",topDragOver:\"dragover\",topDragStart:\"dragstart\",topDrop:\"drop\",topDurationChange:\"durationchange\",topEmptied:\"emptied\",topEncrypted:\"encrypted\",topEnded:\"ended\",topError:\"error\",topFocus:\"focus\",topInput:\"input\",topKeyDown:\"keydown\",topKeyPress:\"keypress\",topKeyUp:\"keyup\",topLoadedData:\"loadeddata\",topLoadedMetadata:\"loadedmetadata\",topLoadStart:\"loadstart\",topMouseDown:\"mousedown\",topMouseMove:\"mousemove\",topMouseOut:\"mouseout\",topMouseOver:\"mouseover\",topMouseUp:\"mouseup\",topPaste:\"paste\",topPause:\"pause\",topPlay:\"play\",topPlaying:\"playing\",topProgress:\"progress\",topRateChange:\"ratechange\",topScroll:\"scroll\",topSeeked:\"seeked\",topSeeking:\"seeking\",topSelectionChange:\"selectionchange\",topStalled:\"stalled\",topSuspend:\"suspend\",topTextInput:\"textInput\",topTimeUpdate:\"timeupdate\",topTouchCancel:\"touchcancel\",topTouchEnd:\"touchend\",topTouchMove:\"touchmove\",topTouchStart:\"touchstart\",topTransitionEnd:s(\"transitionend\")||\"transitionend\",topVolumeChange:\"volumechange\",topWaiting:\"waiting\",topWheel:\"wheel\"},v=\"_reactListenersID\"+String(Math.random()).slice(2),g=o({},u,{ReactEventListener:null,injection:{injectReactEventListener:function(t){t.setHandleTopLevel(g.handleTopLevel),g.ReactEventListener=t}},setEnabled:function(t){g.ReactEventListener&&g.ReactEventListener.setEnabled(t)},isEnabled:function(){return!(!g.ReactEventListener||!g.ReactEventListener.isEnabled())},listenTo:function(t,e){for(var n=e,i=r(n),o=a.registrationNameDependencies[t],u=0;u<o.length;u++){var c=o[u];i.hasOwnProperty(c)&&i[c]||(\"topWheel\"===c?l(\"wheel\")?g.ReactEventListener.trapBubbledEvent(\"topWheel\",\"wheel\",n):l(\"mousewheel\")?g.ReactEventListener.trapBubbledEvent(\"topWheel\",\"mousewheel\",n):g.ReactEventListener.trapBubbledEvent(\"topWheel\",\"DOMMouseScroll\",n):\"topScroll\"===c?l(\"scroll\",!0)?g.ReactEventListener.trapCapturedEvent(\"topScroll\",\"scroll\",n):g.ReactEventListener.trapBubbledEvent(\"topScroll\",\"scroll\",g.ReactEventListener.WINDOW_HANDLE):\"topFocus\"===c||\"topBlur\"===c?(l(\"focus\",!0)?(g.ReactEventListener.trapCapturedEvent(\"topFocus\",\"focus\",n),g.ReactEventListener.trapCapturedEvent(\"topBlur\",\"blur\",n)):l(\"focusin\")&&(g.ReactEventListener.trapBubbledEvent(\"topFocus\",\"focusin\",n),g.ReactEventListener.trapBubbledEvent(\"topBlur\",\"focusout\",n)),i.topBlur=!0,i.topFocus=!0):d.hasOwnProperty(c)&&g.ReactEventListener.trapBubbledEvent(c,d[c],n),i[c]=!0)}},trapBubbledEvent:function(t,e,n){return g.ReactEventListener.trapBubbledEvent(t,e,n)},trapCapturedEvent:function(t,e,n){return g.ReactEventListener.trapCapturedEvent(t,e,n)},supportsEventPageXY:function(){if(!document.createEvent)return!1;var t=document.createEvent(\"MouseEvent\");return null!=t&&\"pageX\"in t},ensureScrollValueMonitoring:function(){if(void 0===i&&(i=g.supportsEventPageXY()),!i&&!p){var t=c.refreshScrollValues;g.ReactEventListener.monitorScrollValue(t),p=!0}}});t.exports=g},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(25),o=n(89),a=n(92),u={screenX:null,screenY:null,clientX:null,clientY:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,getModifierState:a,button:function(t){var e=t.button;return\"which\"in t?e:2===e?2:4===e?1:0},buttons:null,relatedTarget:function(t){return t.relatedTarget||(t.fromElement===t.srcElement?t.toElement:t.fromElement)},pageX:function(t){return\"pageX\"in t?t.pageX:t.clientX+o.currentScrollLeft},pageY:function(t){return\"pageY\"in t?t.pageY:t.clientY+o.currentScrollTop}};i.augmentClass(r,u),t.exports=r},function(t,e,n){\"use strict\";var r=n(2),i=(n(0),{}),o={reinitializeTransaction:function(){this.transactionWrappers=this.getTransactionWrappers(),this.wrapperInitData?this.wrapperInitData.length=0:this.wrapperInitData=[],this._isInTransaction=!1},_isInTransaction:!1,getTransactionWrappers:null,isInTransaction:function(){return!!this._isInTransaction},perform:function(t,e,n,i,o,a,u,c){this.isInTransaction()?r(\"27\"):void 0;var s,l;try{this._isInTransaction=!0,s=!0,this.initializeAll(0),l=t.call(e,n,i,o,a,u,c),s=!1}finally{try{if(s)try{this.closeAll(0)}catch(t){}else this.closeAll(0)}finally{this._isInTransaction=!1}}return l},initializeAll:function(t){for(var e=this.transactionWrappers,n=t;n<e.length;n++){var r=e[n];try{this.wrapperInitData[n]=i,this.wrapperInitData[n]=r.initialize?r.initialize.call(this):null}finally{if(this.wrapperInitData[n]===i)try{this.initializeAll(n+1)}catch(t){}}}},closeAll:function(t){this.isInTransaction()?void 0:r(\"28\");for(var e=this.transactionWrappers,n=t;n<e.length;n++){var o,a=e[n],u=this.wrapperInitData[n];try{o=!0,u!==i&&a.close&&a.close.call(this,u),o=!1}finally{if(o)try{this.closeAll(n+1)}catch(t){}}}this.wrapperInitData.length=0}};t.exports=o},function(t,e,n){\"use strict\";function r(t){var e=\"\"+t,n=o.exec(e);if(!n)return e;var r,i=\"\",a=0,u=0;for(a=n.index;a<e.length;a++){switch(e.charCodeAt(a)){case 34:r=\"&quot;\";break;case 38:r=\"&amp;\";break;case 39:r=\"&#x27;\";break;case 60:r=\"&lt;\";break;case 62:r=\"&gt;\";break;default:continue}u!==a&&(i+=e.substring(u,a)),u=a+1,i+=r}return u!==a?i+e.substring(u,a):i}function i(t){return\"boolean\"==typeof t||\"number\"==typeof t?\"\"+t:r(t)}var o=/[\"'&<>]/;t.exports=i},function(t,e,n){\"use strict\";var r,i=n(6),o=n(82),a=/^[ \\r\\n\\t\\f]/,u=/<(!--|link|noscript|meta|script|style)[ \\r\\n\\t\\f\\/>]/,c=n(90),s=c(function(t,e){if(t.namespaceURI!==o.svg||\"innerHTML\"in t)t.innerHTML=e;else{r=r||document.createElement(\"div\"),r.innerHTML=\"<svg>\"+e+\"</svg>\";for(var n=r.firstChild;n.firstChild;)t.appendChild(n.firstChild)}});if(i.canUseDOM){var l=document.createElement(\"div\");l.innerHTML=\" \",\"\"===l.innerHTML&&(s=function(t,e){if(t.parentNode&&t.parentNode.replaceChild(t,t),a.test(e)||\"<\"===e[0]&&u.test(e)){t.innerHTML=String.fromCharCode(65279)+e;var n=t.firstChild;1===n.data.length?t.removeChild(n):n.deleteData(0,1)}else t.innerHTML=e}),l=null}t.exports=s},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0}),e.default={colors:{RdBu:[\"rgb(255, 13, 87)\",\"rgb(30, 136, 229)\"],GnPR:[\"rgb(24, 196, 93)\",\"rgb(124, 82, 255)\"],CyPU:[\"#0099C6\",\"#990099\"],PkYg:[\"#DD4477\",\"#66AA00\"],DrDb:[\"#B82E2E\",\"#316395\"],LpLb:[\"#994499\",\"#22AA99\"],YlDp:[\"#AAAA11\",\"#6633CC\"],OrId:[\"#E67300\",\"#3E0099\"]},gray:\"#777\"}},function(t,e,n){\"use strict\";var r=n(29);e.a=function(t,e,n){if(null==n&&(n=r.a),i=t.length){if((e=+e)<=0||i<2)return+n(t[0],0,t);if(e>=1)return+n(t[i-1],i-1,t);var i,o=(i-1)*e,a=Math.floor(o),u=+n(t[a],a,t),c=+n(t[a+1],a+1,t);return u+(c-u)*(o-a)}}},function(t,e,n){\"use strict\";function r(){}function i(t,e){var n=new r;if(t instanceof r)t.each(function(t,e){n.set(e,t)});else if(Array.isArray(t)){var i,o=-1,a=t.length;if(null==e)for(;++o<a;)n.set(o,t[o]);else for(;++o<a;)n.set(e(i=t[o],o,t),i)}else if(t)for(var u in t)n.set(u,t[u]);return n}n.d(e,\"b\",function(){return o});var o=\"$\";r.prototype=i.prototype={constructor:r,has:function(t){return o+t in this},get:function(t){return this[o+t]},set:function(t,e){return this[o+t]=e,this},remove:function(t){var e=o+t;return e in this&&delete this[e]},clear:function(){for(var t in this)t[0]===o&&delete this[t]},keys:function(){var t=[];for(var e in this)e[0]===o&&t.push(e.slice(1));return t},values:function(){var t=[];for(var e in this)e[0]===o&&t.push(this[e]);return t},entries:function(){var t=[];for(var e in this)e[0]===o&&t.push({key:e.slice(1),value:this[e]});return t},size:function(){var t=0;for(var e in this)e[0]===o&&++t;return t},empty:function(){for(var t in this)if(t[0]===o)return!1;return!0},each:function(t){for(var e in this)e[0]===o&&t(this[e],e.slice(1),this)}},e.a=i},function(t,e,n){\"use strict\";function r(){}function i(t){var e;return t=(t+\"\").trim().toLowerCase(),(e=x.exec(t))?(e=parseInt(e[1],16),new s(e>>8&15|e>>4&240,e>>4&15|240&e,(15&e)<<4|15&e,1)):(e=w.exec(t))?o(parseInt(e[1],16)):(e=C.exec(t))?new s(e[1],e[2],e[3],1):(e=M.exec(t))?new s(255*e[1]/100,255*e[2]/100,255*e[3]/100,1):(e=k.exec(t))?a(e[1],e[2],e[3],e[4]):(e=E.exec(t))?a(255*e[1]/100,255*e[2]/100,255*e[3]/100,e[4]):(e=T.exec(t))?l(e[1],e[2]/100,e[3]/100,1):(e=S.exec(t))?l(e[1],e[2]/100,e[3]/100,e[4]):P.hasOwnProperty(t)?o(P[t]):\"transparent\"===t?new s(NaN,NaN,NaN,0):null}function o(t){return new s(t>>16&255,t>>8&255,255&t,1)}function a(t,e,n,r){return r<=0&&(t=e=n=NaN),new s(t,e,n,r)}function u(t){return t instanceof r||(t=i(t)),t?(t=t.rgb(),new s(t.r,t.g,t.b,t.opacity)):new s}function c(t,e,n,r){return 1===arguments.length?u(t):new s(t,e,n,null==r?1:r)}function s(t,e,n,r){this.r=+t,this.g=+e,this.b=+n,this.opacity=+r}function l(t,e,n,r){return r<=0?t=e=n=NaN:n<=0||n>=1?t=e=NaN:e<=0&&(t=NaN),new h(t,e,n,r)}function f(t){if(t instanceof h)return new h(t.h,t.s,t.l,t.opacity);if(t instanceof r||(t=i(t)),!t)return new h;if(t instanceof h)return t;t=t.rgb();var e=t.r/255,n=t.g/255,o=t.b/255,a=Math.min(e,n,o),u=Math.max(e,n,o),c=NaN,s=u-a,l=(u+a)/2;return s?(c=e===u?(n-o)/s+6*(n<o):n===u?(o-e)/s+2:(e-n)/s+4,s/=l<.5?u+a:2-u-a,c*=60):s=l>0&&l<1?0:c,new h(c,s,l,t.opacity)}function p(t,e,n,r){return 1===arguments.length?f(t):new h(t,e,n,null==r?1:r)}function h(t,e,n,r){this.h=+t,this.s=+e,this.l=+n,this.opacity=+r}function d(t,e,n){return 255*(t<60?e+(n-e)*t/60:t<180?n:t<240?e+(n-e)*(240-t)/60:e)}var v=n(60);e.f=r,n.d(e,\"h\",function(){return g}),n.d(e,\"g\",function(){return m}),e.a=i,e.e=u,e.b=c,e.d=s,e.c=p;var g=.7,m=1/g,y=\"\\\\s*([+-]?\\\\d+)\\\\s*\",_=\"\\\\s*([+-]?\\\\d*\\\\.?\\\\d+(?:[eE][+-]?\\\\d+)?)\\\\s*\",b=\"\\\\s*([+-]?\\\\d*\\\\.?\\\\d+(?:[eE][+-]?\\\\d+)?)%\\\\s*\",x=/^#([0-9a-f]{3})$/,w=/^#([0-9a-f]{6})$/,C=new RegExp(\"^rgb\\\\(\"+[y,y,y]+\"\\\\)$\"),M=new RegExp(\"^rgb\\\\(\"+[b,b,b]+\"\\\\)$\"),k=new RegExp(\"^rgba\\\\(\"+[y,y,y,_]+\"\\\\)$\"),E=new RegExp(\"^rgba\\\\(\"+[b,b,b,_]+\"\\\\)$\"),T=new RegExp(\"^hsl\\\\(\"+[_,b,b]+\"\\\\)$\"),S=new RegExp(\"^hsla\\\\(\"+[_,b,b,_]+\"\\\\)$\"),P={aliceblue:15792383,antiquewhite:16444375,aqua:65535,aquamarine:8388564,azure:15794175,beige:16119260,bisque:16770244,black:0,blanchedalmond:16772045,blue:255,blueviolet:9055202,brown:10824234,burlywood:14596231,cadetblue:6266528,chartreuse:8388352,chocolate:13789470,coral:16744272,cornflowerblue:6591981,cornsilk:16775388,crimson:14423100,cyan:65535,darkblue:139,darkcyan:35723,darkgoldenrod:12092939,darkgray:11119017,darkgreen:25600,darkgrey:11119017,darkkhaki:12433259,darkmagenta:9109643,darkolivegreen:5597999,darkorange:16747520,darkorchid:10040012,darkred:9109504,darksalmon:15308410,darkseagreen:9419919,darkslateblue:4734347,darkslategray:3100495,darkslategrey:3100495,darkturquoise:52945,darkviolet:9699539,deeppink:16716947,deepskyblue:49151,dimgray:6908265,dimgrey:6908265,dodgerblue:2003199,firebrick:11674146,floralwhite:16775920,forestgreen:2263842,fuchsia:16711935,gainsboro:14474460,ghostwhite:16316671,gold:16766720,goldenrod:14329120,gray:8421504,green:32768,greenyellow:11403055,grey:8421504,honeydew:15794160,hotpink:16738740,indianred:13458524,indigo:4915330,ivory:16777200,khaki:15787660,lavender:15132410,lavenderblush:16773365,lawngreen:8190976,lemonchiffon:16775885,lightblue:11393254,lightcoral:15761536,lightcyan:14745599,lightgoldenrodyellow:16448210,lightgray:13882323,lightgreen:9498256,lightgrey:13882323,lightpink:16758465,lightsalmon:16752762,lightseagreen:2142890,lightskyblue:8900346,lightslategray:7833753,lightslategrey:7833753,lightsteelblue:11584734,lightyellow:16777184,lime:65280,limegreen:3329330,linen:16445670,magenta:16711935,maroon:8388608,mediumaquamarine:6737322,mediumblue:205,mediumorchid:12211667,mediumpurple:9662683,mediumseagreen:3978097,mediumslateblue:8087790,mediumspringgreen:64154,mediumturquoise:4772300,mediumvioletred:13047173,midnightblue:1644912,mintcream:16121850,mistyrose:16770273,moccasin:16770229,navajowhite:16768685,navy:128,oldlace:16643558,olive:8421376,olivedrab:7048739,orange:16753920,orangered:16729344,orchid:14315734,palegoldenrod:15657130,palegreen:10025880,paleturquoise:11529966,palevioletred:14381203,papayawhip:16773077,peachpuff:16767673,peru:13468991,pink:16761035,plum:14524637,powderblue:11591910,purple:8388736,rebeccapurple:6697881,red:16711680,rosybrown:12357519,royalblue:4286945,saddlebrown:9127187,salmon:16416882,sandybrown:16032864,seagreen:3050327,seashell:16774638,sienna:10506797,silver:12632256,skyblue:8900331,slateblue:6970061,slategray:7372944,slategrey:7372944,snow:16775930,springgreen:65407,steelblue:4620980,tan:13808780,teal:32896,thistle:14204888,tomato:16737095,turquoise:4251856,violet:15631086,wheat:16113331,white:16777215,whitesmoke:16119285,yellow:16776960,yellowgreen:10145074};n.i(v.a)(r,i,{displayable:function(){return this.rgb().displayable()},toString:function(){return this.rgb()+\"\"}}),n.i(v.a)(s,c,n.i(v.b)(r,{brighter:function(t){return t=null==t?m:Math.pow(m,t),new s(this.r*t,this.g*t,this.b*t,this.opacity)},darker:function(t){return t=null==t?g:Math.pow(g,t),new s(this.r*t,this.g*t,this.b*t,this.opacity)},rgb:function(){return this},displayable:function(){return 0<=this.r&&this.r<=255&&0<=this.g&&this.g<=255&&0<=this.b&&this.b<=255&&0<=this.opacity&&this.opacity<=1},toString:function(){var t=this.opacity;return t=isNaN(t)?1:Math.max(0,Math.min(1,t)),(1===t?\"rgb(\":\"rgba(\")+Math.max(0,Math.min(255,Math.round(this.r)||0))+\", \"+Math.max(0,Math.min(255,Math.round(this.g)||0))+\", \"+Math.max(0,Math.min(255,Math.round(this.b)||0))+(1===t?\")\":\", \"+t+\")\")}})),n.i(v.a)(h,p,n.i(v.b)(r,{brighter:function(t){return t=null==t?m:Math.pow(m,t),new h(this.h,this.s,this.l*t,this.opacity)},darker:function(t){return t=null==t?g:Math.pow(g,t),new h(this.h,this.s,this.l*t,this.opacity)},rgb:function(){var t=this.h%360+360*(this.h<0),e=isNaN(t)||isNaN(this.s)?0:this.s,n=this.l,r=n+(n<.5?n:1-n)*e,i=2*n-r;return new s(d(t>=240?t-240:t+120,i,r),d(t,i,r),d(t<120?t+240:t-120,i,r),this.opacity)},displayable:function(){return(0<=this.s&&this.s<=1||isNaN(this.s))&&0<=this.l&&this.l<=1&&0<=this.opacity&&this.opacity<=1}}))},function(t,e,n){\"use strict\";function r(t,e){var n=Object.create(t.prototype);for(var r in e)n[r]=e[r];return n}e.b=r,e.a=function(t,e,n){t.prototype=e.prototype=n,n.constructor=t}},function(t,e,n){\"use strict\";e.a=function(t,e){if((n=(t=e?t.toExponential(e-1):t.toExponential()).indexOf(\"e\"))<0)return null;var n,r=t.slice(0,n);return[r.length>1?r[0]+r.slice(2):r,+t.slice(n+1)]}},function(t,e,n){\"use strict\";function r(t,e,n,r,i){var o=t*t,a=o*t;return((1-3*t+3*o-a)*e+(4-6*o+3*a)*n+(1+3*t+3*o-3*a)*r+a*i)/6}e.b=r,e.a=function(t){var e=t.length-1;return function(n){var i=n<=0?n=0:n>=1?(n=1,e-1):Math.floor(n*e),o=t[i],a=t[i+1],u=i>0?t[i-1]:2*o-a,c=i<e-1?t[i+2]:2*a-o;return r((n-i/e)*e,u,o,a,c)}}},function(t,e,n){\"use strict\";var r=n(10),i=n(123),o=n(118),a=n(121),u=n(43),c=n(122),s=n(124),l=n(120);e.a=function(t,e){var f,p=typeof e;return null==e||\"boolean\"===p?n.i(l.a)(e):(\"number\"===p?u.a:\"string\"===p?(f=n.i(r.color)(e))?(e=f,i.a):s.a:e instanceof r.color?i.a:e instanceof Date?a.a:Array.isArray(e)?o.a:isNaN(e)?c.a:u.a)(t,e)}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(229);n.d(e,\"scaleBand\",function(){return r.a}),n.d(e,\"scalePoint\",function(){return r.b});var i=n(235);n.d(e,\"scaleIdentity\",function(){return i.a});var o=n(34);n.d(e,\"scaleLinear\",function(){return o.a});var a=n(236);n.d(e,\"scaleLog\",function(){return a.a});var u=n(127);n.d(e,\"scaleOrdinal\",function(){return u.a}),n.d(e,\"scaleImplicit\",function(){return u.b});var c=n(237);n.d(e,\"scalePow\",function(){return c.a}),n.d(e,\"scaleSqrt\",function(){return c.b});var s=n(238);n.d(e,\"scaleQuantile\",function(){return s.a});var l=n(239);n.d(e,\"scaleQuantize\",function(){return l.a});var f=n(242);n.d(e,\"scaleThreshold\",function(){return f.a});var p=n(128);n.d(e,\"scaleTime\",function(){return p.a});var h=n(244);n.d(e,\"scaleUtc\",function(){return h.a});var d=n(230);n.d(e,\"schemeCategory10\",function(){return d.a});var v=n(232);n.d(e,\"schemeCategory20b\",function(){return v.a});var g=n(233);n.d(e,\"schemeCategory20c\",function(){return g.a});var m=n(231);n.d(e,\"schemeCategory20\",function(){return m.a});var y=n(234);n.d(e,\"interpolateCubehelixDefault\",function(){return y.a});var _=n(240);n.d(e,\"interpolateRainbow\",function(){return _.a}),n.d(e,\"interpolateWarm\",function(){return _.b}),n.d(e,\"interpolateCool\",function(){return _.c});var b=n(245);n.d(e,\"interpolateViridis\",function(){return b.a}),n.d(e,\"interpolateMagma\",function(){return b.b}),n.d(e,\"interpolateInferno\",function(){return b.c}),n.d(e,\"interpolatePlasma\",function(){return b.d});var x=n(241);n.d(e,\"scaleSequential\",function(){return x.a})},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";function r(t){return function(){var e=this.ownerDocument,n=this.namespaceURI;return n===a.b&&e.documentElement.namespaceURI===a.b?e.createElement(t):e.createElementNS(n,t)}}function i(t){return function(){return this.ownerDocument.createElementNS(t.space,t.local)}}var o=n(67),a=n(68);e.a=function(t){var e=n.i(o.a)(t);return(e.local?i:r)(e)}},function(t,e,n){\"use strict\";var r=n(68);e.a=function(t){var e=t+=\"\",n=e.indexOf(\":\");return n>=0&&\"xmlns\"!==(e=t.slice(0,n))&&(t=t.slice(n+1)),r.a.hasOwnProperty(e)?{space:r.a[e],local:t}:t}},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return r});var r=\"http://www.w3.org/1999/xhtml\";e.a={svg:\"http://www.w3.org/2000/svg\",xhtml:r,xlink:\"http://www.w3.org/1999/xlink\",xml:\"http://www.w3.org/XML/1998/namespace\",xmlns:\"http://www.w3.org/2000/xmlns/\"}},function(t,e,n){\"use strict\";e.a=function(t,e){var n=t.ownerSVGElement||t;if(n.createSVGPoint){var r=n.createSVGPoint();return r.x=e.clientX,r.y=e.clientY,r=r.matrixTransform(t.getScreenCTM().inverse()),[r.x,r.y]}var i=t.getBoundingClientRect();return[e.clientX-i.left-t.clientLeft,e.clientY-i.top-t.clientTop]}},function(t,e,n){\"use strict\";function r(t,e,n){return t=i(t,e,n),function(e){var n=e.relatedTarget;n&&(n===this||8&n.compareDocumentPosition(this))||t.call(this,e)}}function i(t,e,n){return function(r){var i=l;l=r;try{t.call(this,this.__data__,e,n)}finally{l=i}}}function o(t){return t.trim().split(/^|\\s+/).map(function(t){var e=\"\",n=t.indexOf(\".\");return n>=0&&(e=t.slice(n+1),t=t.slice(0,n)),{type:t,name:e}})}function a(t){return function(){var e=this.__on;if(e){for(var n,r=0,i=-1,o=e.length;r<o;++r)n=e[r],t.type&&n.type!==t.type||n.name!==t.name?e[++i]=n:this.removeEventListener(n.type,n.listener,n.capture);++i?e.length=i:delete this.__on}}}function u(t,e,n){var o=s.hasOwnProperty(t.type)?r:i;return function(r,i,a){var u,c=this.__on,s=o(e,i,a);if(c)for(var l=0,f=c.length;l<f;++l)if((u=c[l]).type===t.type&&u.name===t.name)return this.removeEventListener(u.type,u.listener,u.capture),this.addEventListener(u.type,u.listener=s,u.capture=n),void(u.value=e);this.addEventListener(t.type,s,n),u={type:t.type,name:t.name,value:e,listener:s,capture:n},c?c.push(u):this.__on=[u]}}function c(t,e,n,r){var i=l;t.sourceEvent=l,l=t;try{return e.apply(n,r)}finally{l=i}}n.d(e,\"a\",function(){return l}),e.b=c;var s={},l=null;if(\"undefined\"!=typeof document){var f=document.documentElement;\"onmouseenter\"in f||(s={mouseenter:\"mouseover\",mouseleave:\"mouseout\"})}e.c=function(t,e,n){var r,i,c=o(t+\"\"),s=c.length;{if(!(arguments.length<2)){for(l=e?u:a,null==n&&(n=!1),r=0;r<s;++r)this.each(l(c[r],e,n));return this}var l=this.node().__on;if(l)for(var f,p=0,h=l.length;p<h;++p)for(r=0,f=l[p];r<s;++r)if((i=c[r]).type===f.type&&i.name===f.name)return f.value}}},function(t,e,n){\"use strict\";function r(){}e.a=function(t){return null==t?r:function(){return this.querySelector(t)}}},function(t,e,n){\"use strict\";var r=n(70);e.a=function(){for(var t,e=r.a;t=e.sourceEvent;)e=t;return e}},function(t,e,n){\"use strict\";e.a=function(t){return t.ownerDocument&&t.ownerDocument.defaultView||t.document&&t||t.defaultView}},function(t,e,n){\"use strict\";function r(t,e,n){var r=t._x1,i=t._y1,a=t._x2,u=t._y2;if(t._l01_a>o.a){var c=2*t._l01_2a+3*t._l01_a*t._l12_a+t._l12_2a,s=3*t._l01_a*(t._l01_a+t._l12_a);r=(r*c-t._x0*t._l12_2a+t._x2*t._l01_2a)/s,i=(i*c-t._y0*t._l12_2a+t._y2*t._l01_2a)/s}if(t._l23_a>o.a){var l=2*t._l23_2a+3*t._l23_a*t._l12_a+t._l12_2a,f=3*t._l23_a*(t._l23_a+t._l12_a);a=(a*l+t._x1*t._l23_2a-e*t._l12_2a)/f,u=(u*l+t._y1*t._l23_2a-n*t._l12_2a)/f}t._context.bezierCurveTo(r,i,a,u,t._x2,t._y2)}function i(t,e){this._context=t,this._alpha=e}var o=n(35),a=n(47);e.b=r,i.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._x2=this._y0=this._y1=this._y2=NaN,this._l01_a=this._l12_a=this._l23_a=this._l01_2a=this._l12_2a=this._l23_2a=this._point=0},lineEnd:function(){switch(this._point){case 2:this._context.lineTo(this._x2,this._y2);break;case 3:this.point(this._x2,this._y2)}(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){if(t=+t,e=+e,this._point){var n=this._x2-t,i=this._y2-e;this._l23_a=Math.sqrt(this._l23_2a=Math.pow(n*n+i*i,this._alpha))}switch(this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;break;case 2:this._point=3;default:r(this,t,e)}this._l01_a=this._l12_a,this._l12_a=this._l23_a,this._l01_2a=this._l12_2a,this._l12_2a=this._l23_2a,this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return e?new i(t,e):new a.b(t,0)}return n.alpha=function(e){return t(+e)},n}(.5)},function(t,e,n){\"use strict\";var r=n(44),i=n(19),o=n(48),a=n(139);e.a=function(){function t(t){var i,o,a,p=t.length,h=!1;for(null==s&&(f=l(a=n.i(r.a)())),i=0;i<=p;++i)!(i<p&&c(o=t[i],i,t))===h&&((h=!h)?f.lineStart():f.lineEnd()),h&&f.point(+e(o,i,t),+u(o,i,t));if(a)return f=null,a+\"\"||null}var e=a.a,u=a.b,c=n.i(i.a)(!0),s=null,l=o.a,f=null;return t.x=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(i.a)(+r),t):e},t.y=function(e){return arguments.length?(u=\"function\"==typeof e?e:n.i(i.a)(+e),t):u},t.defined=function(e){return arguments.length?(c=\"function\"==typeof e?e:n.i(i.a)(!!e),t):c},t.curve=function(e){return arguments.length?(l=e,null!=s&&(f=l(s)),t):l},t.context=function(e){return arguments.length?(null==e?s=f=null:f=l(s=e),t):s},t}},function(t,e,n){\"use strict\";function r(t){for(var e,n=0,r=-1,i=t.length;++r<i;)(e=+t[r][1])&&(n+=e);return n}var i=n(37);e.b=r,e.a=function(t){var e=t.map(r);return n.i(i.a)(t).sort(function(t,n){return e[t]-e[n]})}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(78);n.d(e,\"timeFormatDefaultLocale\",function(){return r.a}),n.d(e,\"timeFormat\",function(){return r.b}),n.d(e,\"timeParse\",function(){return r.c}),n.d(e,\"utcFormat\",function(){return r.d}),n.d(e,\"utcParse\",function(){return r.e});var i=n(149);n.d(e,\"timeFormatLocale\",function(){return i.a});var o=n(148);n.d(e,\"isoFormat\",function(){return o.a});var a=n(303);n.d(e,\"isoParse\",function(){return a.a})},function(t,e,n){\"use strict\";function r(t){return o=n.i(i.a)(t),a=o.format,u=o.parse,c=o.utcFormat,s=o.utcParse,o}var i=n(149);n.d(e,\"b\",function(){return a}),n.d(e,\"c\",function(){return u}),n.d(e,\"d\",function(){return c}),n.d(e,\"e\",function(){return s}),e.a=r;var o,a,u,c,s;r({dateTime:\"%x, %X\",date:\"%-m/%-d/%Y\",time:\"%-I:%M:%S %p\",periods:[\"AM\",\"PM\"],days:[\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"],shortDays:[\"Sun\",\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\"],months:[\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],shortMonths:[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]})},function(t,e,n){\"use strict\";var r=(n(5),n(306));n.d(e,\"t\",function(){return r.a}),n.d(e,\"n\",function(){return r.a});var i=n(309);n.d(e,\"s\",function(){return i.a}),n.d(e,\"m\",function(){return i.a});var o=n(307);n.d(e,\"r\",function(){return o.a});var a=n(305);n.d(e,\"q\",function(){return a.a});var u=n(304);n.d(e,\"a\",function(){return u.a});var c=n(316);n.d(e,\"p\",function(){return c.a}),n.d(e,\"c\",function(){return c.a}),n.d(e,\"d\",function(){return c.b});var s=n(308);n.d(e,\"o\",function(){return s.a});var l=n(317);n.d(e,\"b\",function(){return l.a});var f=n(312);n.d(e,\"l\",function(){return f.a});var p=n(311);n.d(e,\"k\",function(){return p.a});var h=n(310);n.d(e,\"e\",function(){return h.a});var d=n(314);n.d(e,\"j\",function(){return d.a}),n.d(e,\"g\",function(){return d.a}),n.d(e,\"h\",function(){return d.b});var v=n(313);n.d(e,\"i\",function(){return v.a});var g=n(315);n.d(e,\"f\",function(){return g.a})},function(t,e,n){\"use strict\";function r(t,e){return t===e?0!==t||0!==e||1/t===1/e:t!==t&&e!==e}function i(t,e){if(r(t,e))return!0;if(\"object\"!=typeof t||null===t||\"object\"!=typeof e||null===e)return!1;var n=Object.keys(t),i=Object.keys(e);if(n.length!==i.length)return!1;for(var a=0;a<n.length;a++)if(!o.call(e,n[a])||!r(t[n[a]],e[n[a]]))return!1;return!0}var o=Object.prototype.hasOwnProperty;t.exports=i},function(t,e,n){\"use strict\";function r(t,e){return Array.isArray(e)&&(e=e[1]),e?e.nextSibling:t.firstChild}function i(t,e,n){l.insertTreeBefore(t,e,n)}function o(t,e,n){Array.isArray(e)?u(t,e[0],e[1],n):v(t,e,n)}function a(t,e){if(Array.isArray(e)){var n=e[1];e=e[0],c(t,e,n),t.removeChild(n)}t.removeChild(e)}function u(t,e,n,r){for(var i=e;;){var o=i.nextSibling;if(v(t,i,r),i===n)break;i=o}}function c(t,e,n){for(;;){var r=e.nextSibling;if(r===n)break;t.removeChild(r)}}function s(t,e,n){var r=t.parentNode,i=t.nextSibling;i===e?n&&v(r,document.createTextNode(n),i):n?(d(i,n),c(r,i,e)):c(r,t,e)}var l=n(20),f=n(336),p=(n(4),n(9),n(90)),h=n(55),d=n(171),v=p(function(t,e,n){t.insertBefore(e,n)}),g=f.dangerouslyReplaceNodeWithMarkup,m={dangerouslyReplaceNodeWithMarkup:g,replaceDelimitedText:s,processUpdates:function(t,e){for(var n=0;n<e.length;n++){var u=e[n];switch(u.type){case\"INSERT_MARKUP\":i(t,u.content,r(t,u.afterNode));break;case\"MOVE_EXISTING\":o(t,u.fromNode,r(t,u.afterNode));break;case\"SET_MARKUP\":h(t,u.content);break;case\"TEXT_CONTENT\":d(t,u.content);break;case\"REMOVE_NODE\":a(t,u.fromNode)}}}};t.exports=m},function(t,e,n){\"use strict\";var r={html:\"http://www.w3.org/1999/xhtml\",mathml:\"http://www.w3.org/1998/Math/MathML\",svg:\"http://www.w3.org/2000/svg\"};t.exports=r},function(t,e,n){\"use strict\";function r(){if(u)for(var t in c){var e=c[t],n=u.indexOf(t);if(n>-1?void 0:a(\"96\",t),!s.plugins[n]){e.extractEvents?void 0:a(\"97\",t),s.plugins[n]=e;var r=e.eventTypes;for(var o in r)i(r[o],e,o)?void 0:a(\"98\",o,t)}}}function i(t,e,n){s.eventNameDispatchConfigs.hasOwnProperty(n)?a(\"99\",n):void 0,s.eventNameDispatchConfigs[n]=t;var r=t.phasedRegistrationNames;if(r){for(var i in r)if(r.hasOwnProperty(i)){var u=r[i];o(u,e,n)}return!0}return!!t.registrationName&&(o(t.registrationName,e,n),!0)}function o(t,e,n){s.registrationNameModules[t]?a(\"100\",t):void 0,s.registrationNameModules[t]=e,s.registrationNameDependencies[t]=e.eventTypes[n].dependencies}var a=n(2),u=(n(0),null),c={},s={plugins:[],eventNameDispatchConfigs:{},registrationNameModules:{},registrationNameDependencies:{},possibleRegistrationNames:null,injectEventPluginOrder:function(t){\n",
       "u?a(\"101\"):void 0,u=Array.prototype.slice.call(t),r()},injectEventPluginsByName:function(t){var e=!1;for(var n in t)if(t.hasOwnProperty(n)){var i=t[n];c.hasOwnProperty(n)&&c[n]===i||(c[n]?a(\"102\",n):void 0,c[n]=i,e=!0)}e&&r()},getPluginModuleForEvent:function(t){var e=t.dispatchConfig;if(e.registrationName)return s.registrationNameModules[e.registrationName]||null;if(void 0!==e.phasedRegistrationNames){var n=e.phasedRegistrationNames;for(var r in n)if(n.hasOwnProperty(r)){var i=s.registrationNameModules[n[r]];if(i)return i}}return null},_resetEventPlugins:function(){u=null;for(var t in c)c.hasOwnProperty(t)&&delete c[t];s.plugins.length=0;var e=s.eventNameDispatchConfigs;for(var n in e)e.hasOwnProperty(n)&&delete e[n];var r=s.registrationNameModules;for(var i in r)r.hasOwnProperty(i)&&delete r[i]}};t.exports=s},function(t,e,n){\"use strict\";function r(t){var e=/[=:]/g,n={\"=\":\"=0\",\":\":\"=2\"},r=(\"\"+t).replace(e,function(t){return n[t]});return\"$\"+r}function i(t){var e=/(=0|=2)/g,n={\"=0\":\"=\",\"=2\":\":\"},r=\".\"===t[0]&&\"$\"===t[1]?t.substring(2):t.substring(1);return(\"\"+r).replace(e,function(t){return n[t]})}var o={escape:r,unescape:i};t.exports=o},function(t,e,n){\"use strict\";function r(t){null!=t.checkedLink&&null!=t.valueLink?u(\"87\"):void 0}function i(t){r(t),null!=t.value||null!=t.onChange?u(\"88\"):void 0}function o(t){r(t),null!=t.checked||null!=t.onChange?u(\"89\"):void 0}function a(t){if(t){var e=t.getName();if(e)return\" Check the render method of `\"+e+\"`.\"}return\"\"}var u=n(2),c=n(26),s=n(366),l=(n(0),n(1),{button:!0,checkbox:!0,image:!0,hidden:!0,radio:!0,reset:!0,submit:!0}),f={value:function(t,e,n){return!t[e]||l[t.type]||t.onChange||t.readOnly||t.disabled?null:new Error(\"You provided a `value` prop to a form field without an `onChange` handler. This will render a read-only field. If the field should be mutable use `defaultValue`. Otherwise, set either `onChange` or `readOnly`.\")},checked:function(t,e,n){return!t[e]||t.onChange||t.readOnly||t.disabled?null:new Error(\"You provided a `checked` prop to a form field without an `onChange` handler. This will render a read-only field. If the field should be mutable use `defaultChecked`. Otherwise, set either `onChange` or `readOnly`.\")},onChange:c.PropTypes.func},p={},h={checkPropTypes:function(t,e,n){for(var r in f){if(f.hasOwnProperty(r))var i=f[r](e,r,t,\"prop\",null,s);if(i instanceof Error&&!(i.message in p)){p[i.message]=!0;a(n)}}},getValue:function(t){return t.valueLink?(i(t),t.valueLink.value):t.value},getChecked:function(t){return t.checkedLink?(o(t),t.checkedLink.value):t.checked},executeOnChange:function(t,e){return t.valueLink?(i(t),t.valueLink.requestChange(e.target.value)):t.checkedLink?(o(t),t.checkedLink.requestChange(e.target.checked)):t.onChange?t.onChange.call(void 0,e):void 0}};t.exports=h},function(t,e,n){\"use strict\";var r=n(2),i=(n(0),!1),o={replaceNodeWithMarkup:null,processChildrenUpdates:null,injection:{injectEnvironment:function(t){i?r(\"104\"):void 0,o.replaceNodeWithMarkup=t.replaceNodeWithMarkup,o.processChildrenUpdates=t.processChildrenUpdates,i=!0}}};t.exports=o},function(t,e,n){\"use strict\";function r(t,e,n){try{e(n)}catch(t){null===i&&(i=t)}}var i=null,o={invokeGuardedCallback:r,invokeGuardedCallbackWithCatch:r,rethrowCaughtError:function(){if(i){var t=i;throw i=null,t}}};t.exports=o},function(t,e,n){\"use strict\";function r(t){c.enqueueUpdate(t)}function i(t){var e=typeof t;if(\"object\"!==e)return e;var n=t.constructor&&t.constructor.name||e,r=Object.keys(t);return r.length>0&&r.length<20?n+\" (keys: \"+r.join(\", \")+\")\":n}function o(t,e){var n=u.get(t);if(!n){return null}return n}var a=n(2),u=(n(15),n(40)),c=(n(9),n(11)),s=(n(0),n(1),{isMounted:function(t){var e=u.get(t);return!!e&&!!e._renderedComponent},enqueueCallback:function(t,e,n){s.validateCallback(e,n);var i=o(t);return i?(i._pendingCallbacks?i._pendingCallbacks.push(e):i._pendingCallbacks=[e],void r(i)):null},enqueueCallbackInternal:function(t,e){t._pendingCallbacks?t._pendingCallbacks.push(e):t._pendingCallbacks=[e],r(t)},enqueueForceUpdate:function(t){var e=o(t,\"forceUpdate\");e&&(e._pendingForceUpdate=!0,r(e))},enqueueReplaceState:function(t,e){var n=o(t,\"replaceState\");n&&(n._pendingStateQueue=[e],n._pendingReplaceState=!0,r(n))},enqueueSetState:function(t,e){var n=o(t,\"setState\");if(n){var i=n._pendingStateQueue||(n._pendingStateQueue=[]);i.push(e),r(n)}},enqueueElementInternal:function(t,e,n){t._pendingElement=e,t._context=n,r(t)},validateCallback:function(t,e){t&&\"function\"!=typeof t?a(\"122\",e,i(t)):void 0}});t.exports=s},function(t,e,n){\"use strict\";var r={currentScrollLeft:0,currentScrollTop:0,refreshScrollValues:function(t){r.currentScrollLeft=t.x,r.currentScrollTop=t.y}};t.exports=r},function(t,e,n){\"use strict\";var r=function(t){return\"undefined\"!=typeof MSApp&&MSApp.execUnsafeLocalFunction?function(e,n,r,i){MSApp.execUnsafeLocalFunction(function(){return t(e,n,r,i)})}:t};t.exports=r},function(t,e,n){\"use strict\";function r(t){var e,n=t.keyCode;return\"charCode\"in t?(e=t.charCode,0===e&&13===n&&(e=13)):e=n,e>=32||13===e?e:0}t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=this,n=e.nativeEvent;if(n.getModifierState)return n.getModifierState(t);var r=o[t];return!!r&&!!n[r]}function i(t){return r}var o={Alt:\"altKey\",Control:\"ctrlKey\",Meta:\"metaKey\",Shift:\"shiftKey\"};t.exports=i},function(t,e,n){\"use strict\";function r(t){var e=t.target||t.srcElement||window;return e.correspondingUseElement&&(e=e.correspondingUseElement),3===e.nodeType?e.parentNode:e}t.exports=r},function(t,e,n){\"use strict\";/**\n",
       " * Checks if an event is supported in the current execution environment.\n",
       " *\n",
       " * NOTE: This will not work correctly for non-generic events such as `change`,\n",
       " * `reset`, `load`, `error`, and `select`.\n",
       " *\n",
       " * Borrows from Modernizr.\n",
       " *\n",
       " * @param {string} eventNameSuffix Event name, e.g. \"click\".\n",
       " * @param {?boolean} capture Check if the capture phase is supported.\n",
       " * @return {boolean} True if the event is supported.\n",
       " * @internal\n",
       " * @license Modernizr 3.0.0pre (Custom Build) | MIT\n",
       " */\n",
       "function r(t,e){if(!o.canUseDOM||e&&!(\"addEventListener\"in document))return!1;var n=\"on\"+t,r=n in document;if(!r){var a=document.createElement(\"div\");a.setAttribute(n,\"return;\"),r=\"function\"==typeof a[n]}return!r&&i&&\"wheel\"===t&&(r=document.implementation.hasFeature(\"Events.wheel\",\"3.0\")),r}var i,o=n(6);o.canUseDOM&&(i=document.implementation&&document.implementation.hasFeature&&document.implementation.hasFeature(\"\",\"\")!==!0),t.exports=r},function(t,e,n){\"use strict\";function r(t,e){var n=null===t||t===!1,r=null===e||e===!1;if(n||r)return n===r;var i=typeof t,o=typeof e;return\"string\"===i||\"number\"===i?\"string\"===o||\"number\"===o:\"object\"===o&&t.type===e.type&&t.key===e.key}t.exports=r},function(t,e,n){\"use strict\";var r=(n(3),n(8)),i=(n(1),r);t.exports=i},function(t,e,n){\"use strict\";function r(t,e,n){this.props=t,this.context=e,this.refs=a,this.updater=n||o}var i=n(28),o=n(98),a=(n(176),n(38));n(0),n(1);r.prototype.isReactComponent={},r.prototype.setState=function(t,e){\"object\"!=typeof t&&\"function\"!=typeof t&&null!=t?i(\"85\"):void 0,this.updater.enqueueSetState(this,t),e&&this.updater.enqueueCallback(this,e,\"setState\")},r.prototype.forceUpdate=function(t){this.updater.enqueueForceUpdate(this),t&&this.updater.enqueueCallback(this,t,\"forceUpdate\")};t.exports=r},function(t,e,n){\"use strict\";function r(t,e){}var i=(n(1),{isMounted:function(t){return!1},enqueueCallback:function(t,e){},enqueueForceUpdate:function(t){r(t,\"forceUpdate\")},enqueueReplaceState:function(t,e){r(t,\"replaceState\")},enqueueSetState:function(t,e){r(t,\"setState\")}});t.exports=i},function(t,e){var n;n=function(){return this}();try{n=n||Function(\"return this\")()||(0,eval)(\"this\")}catch(t){\"object\"==typeof window&&(n=window)}t.exports=n},function(t,e){t.exports=function(t){return t.webpackPolyfill||(t.deprecate=function(){},t.paths=[],t.children||(t.children=[]),Object.defineProperty(t,\"loaded\",{enumerable:!0,get:function(){return t.l}}),Object.defineProperty(t,\"id\",{enumerable:!0,get:function(){return t.i}}),t.webpackPolyfill=1),t}},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return i}),n.d(e,\"a\",function(){return o});var r=Array.prototype,i=r.slice,o=r.map},function(t,e,n){\"use strict\";var r=n(18),i=n(103),o=n.i(i.a)(r.a),a=o.right;o.left;e.a=a},function(t,e,n){\"use strict\";function r(t){return function(e,r){return n.i(i.a)(t(e),r)}}var i=n(18);e.a=function(t){return 1===t.length&&(t=r(t)),{left:function(e,n,r,i){for(null==r&&(r=0),null==i&&(i=e.length);r<i;){var o=r+i>>>1;t(e[o],n)<0?r=o+1:i=o}return r},right:function(e,n,r,i){for(null==r&&(r=0),null==i&&(i=e.length);r<i;){var o=r+i>>>1;t(e[o],n)>0?i=o:r=o+1}return r}}}},function(t,e,n){\"use strict\";var r=n(111);e.a=function(t,e){var i=n.i(r.a)(t,e);return i?Math.sqrt(i):i}},function(t,e,n){\"use strict\";e.a=function(t,e){var n,r,i,o=-1,a=t.length;if(null==e){for(;++o<a;)if(null!=(r=t[o])&&r>=r){n=i=r;break}for(;++o<a;)null!=(r=t[o])&&(n>r&&(n=r),i<r&&(i=r))}else{for(;++o<a;)if(null!=(r=e(t[o],o,t))&&r>=r){n=i=r;break}for(;++o<a;)null!=(r=e(t[o],o,t))&&(n>r&&(n=r),i<r&&(i=r))}return[n,i]}},function(t,e,n){\"use strict\";e.a=function(t,e){var n,r,i=-1,o=t.length;if(null==e){for(;++i<o;)if(null!=(r=t[i])&&r>=r){n=r;break}for(;++i<o;)null!=(r=t[i])&&n>r&&(n=r)}else{for(;++i<o;)if(null!=(r=e(t[i],i,t))&&r>=r){n=r;break}for(;++i<o;)null!=(r=e(t[i],i,t))&&n>r&&(n=r)}return n}},function(t,e,n){\"use strict\";e.a=function(t,e,n){t=+t,e=+e,n=(i=arguments.length)<2?(e=t,t=0,1):i<3?1:+n;for(var r=-1,i=0|Math.max(0,Math.ceil((e-t)/n)),o=new Array(i);++r<i;)o[r]=t+r*n;return o}},function(t,e,n){\"use strict\";e.a=function(t){return Math.ceil(Math.log(t.length)/Math.LN2)+1}},function(t,e,n){\"use strict\";function r(t,e,n){var r=Math.abs(e-t)/Math.max(0,n),i=Math.pow(10,Math.floor(Math.log(r)/Math.LN10)),c=r/i;return c>=o?i*=10:c>=a?i*=5:c>=u&&(i*=2),e<t?-i:i}var i=n(107);e.b=r;var o=Math.sqrt(50),a=Math.sqrt(10),u=Math.sqrt(2);e.a=function(t,e,o){var a=r(t,e,o);return n.i(i.a)(Math.ceil(t/a)*a,Math.floor(e/a)*a+a/2,a)}},function(t,e,n){\"use strict\";function r(t){return t.length}var i=n(106);e.a=function(t){if(!(u=t.length))return[];for(var e=-1,o=n.i(i.a)(t,r),a=new Array(o);++e<o;)for(var u,c=-1,s=a[e]=new Array(u);++c<u;)s[c]=t[c][e];return a}},function(t,e,n){\"use strict\";var r=n(29);e.a=function(t,e){var i,o,a=t.length,u=0,c=0,s=-1,l=0;if(null==e)for(;++s<a;)isNaN(i=n.i(r.a)(t[s]))||(o=i-u,u+=o/++l,c+=o*(i-u));else for(;++s<a;)isNaN(i=n.i(r.a)(e(t[s],s,t)))||(o=i-u,u+=o/++l,c+=o*(i-u));if(l>1)return c/(l-1)}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(201);n.d(e,\"axisTop\",function(){return r.a}),n.d(e,\"axisRight\",function(){return r.b}),n.d(e,\"axisBottom\",function(){return r.c}),n.d(e,\"axisLeft\",function(){return r.d})},function(t,e,n){\"use strict\";n.d(e,\"b\",function(){return r}),n.d(e,\"a\",function(){return i});var r=Math.PI/180,i=180/Math.PI},function(t,e,n){\"use strict\";var r=n(61);n.d(e,\"b\",function(){return i});var i;e.a=function(t,e){var o=n.i(r.a)(t,e);if(!o)return t+\"\";var a=o[0],u=o[1],c=u-(i=3*Math.max(-8,Math.min(8,Math.floor(u/3))))+1,s=a.length;return c===s?a:c>s?a+new Array(c-s+1).join(\"0\"):c>0?a.slice(0,c)+\".\"+a.slice(c):\"0.\"+new Array(1-c).join(\"0\")+n.i(r.a)(t,Math.max(0,e+c-1))[0]}},function(t,e,n){\"use strict\";function r(t){if(!(e=o.exec(t)))throw new Error(\"invalid format: \"+t);var e,n=e[1]||\" \",r=e[2]||\">\",a=e[3]||\"-\",u=e[4]||\"\",c=!!e[5],s=e[6]&&+e[6],l=!!e[7],f=e[8]&&+e[8].slice(1),p=e[9]||\"\";\"n\"===p?(l=!0,p=\"g\"):i.a[p]||(p=\"\"),(c||\"0\"===n&&\"=\"===r)&&(c=!0,n=\"0\",r=\"=\"),this.fill=n,this.align=r,this.sign=a,this.symbol=u,this.zero=c,this.width=s,this.comma=l,this.precision=f,this.type=p}var i=n(116),o=/^(?:(.)?([<>=^]))?([+\\-\\( ])?([$#])?(0)?(\\d+)?(,)?(\\.\\d+)?([a-z%])?$/i;e.a=function(t){return new r(t)},r.prototype.toString=function(){return this.fill+this.align+this.sign+this.symbol+(this.zero?\"0\":\"\")+(null==this.width?\"\":Math.max(1,0|this.width))+(this.comma?\",\":\"\")+(null==this.precision?\"\":\".\"+Math.max(0,0|this.precision))+this.type}},function(t,e,n){\"use strict\";var r=n(212),i=n(114),o=n(214);e.a={\"\":r.a,\"%\":function(t,e){return(100*t).toFixed(e)},b:function(t){return Math.round(t).toString(2)},c:function(t){return t+\"\"},d:function(t){return Math.round(t).toString(10)},e:function(t,e){return t.toExponential(e)},f:function(t,e){return t.toFixed(e)},g:function(t,e){return t.toPrecision(e)},o:function(t){return Math.round(t).toString(8)},p:function(t,e){return n.i(o.a)(100*t,e)},r:o.a,s:i.a,X:function(t){return Math.round(t).toString(16).toUpperCase()},x:function(t){return Math.round(t).toString(16)}}},function(t,e,n){\"use strict\";function r(t){return t}var i=n(42),o=n(213),a=n(115),u=n(116),c=n(114),s=[\"y\",\"z\",\"a\",\"f\",\"p\",\"n\",\"Âµ\",\"m\",\"\",\"k\",\"M\",\"G\",\"T\",\"P\",\"E\",\"Z\",\"Y\"];e.a=function(t){function e(t){function e(t){var e,n,a,u=_,l=b;if(\"c\"===y)l=x(t)+l,t=\"\";else{t=+t;var p=(t<0||1/t<0)&&(t*=-1,!0);if(t=x(t,m),p)for(e=-1,n=t.length,p=!1;++e<n;)if(a=t.charCodeAt(e),48<a&&a<58||\"x\"===y&&96<a&&a<103||\"X\"===y&&64<a&&a<71){p=!0;break}if(u=(p?\"(\"===o?o:\"-\":\"-\"===o||\"(\"===o?\"\":o)+u,l=l+(\"s\"===y?s[8+c.b/3]:\"\")+(p&&\"(\"===o?\")\":\"\"),w)for(e=-1,n=t.length;++e<n;)if(a=t.charCodeAt(e),48>a||a>57){l=(46===a?h+t.slice(e+1):t.slice(e))+l,t=t.slice(0,e);break}}g&&!d&&(t=f(t,1/0));var C=u.length+t.length+l.length,M=C<v?new Array(v-C+1).join(r):\"\";switch(g&&d&&(t=f(M+t,M.length?v-l.length:1/0),M=\"\"),i){case\"<\":return u+t+l+M;case\"=\":return u+M+t+l;case\"^\":return M.slice(0,C=M.length>>1)+u+t+l+M.slice(C)}return M+u+t+l}t=n.i(a.a)(t);var r=t.fill,i=t.align,o=t.sign,l=t.symbol,d=t.zero,v=t.width,g=t.comma,m=t.precision,y=t.type,_=\"$\"===l?p[0]:\"#\"===l&&/[boxX]/.test(y)?\"0\"+y.toLowerCase():\"\",b=\"$\"===l?p[1]:/[%p]/.test(y)?\"%\":\"\",x=u.a[y],w=!y||/[defgprs%]/.test(y);return m=null==m?y?6:12:/[gprs]/.test(y)?Math.max(1,Math.min(21,m)):Math.max(0,Math.min(20,m)),e.toString=function(){return t+\"\"},e}function l(t,r){var o=e((t=n.i(a.a)(t),t.type=\"f\",t)),u=3*Math.max(-8,Math.min(8,Math.floor(n.i(i.a)(r)/3))),c=Math.pow(10,-u),l=s[8+u/3];return function(t){return o(c*t)+l}}var f=t.grouping&&t.thousands?n.i(o.a)(t.grouping,t.thousands):r,p=t.currency,h=t.decimal;return{format:e,formatPrefix:l}}},function(t,e,n){\"use strict\";var r=n(63);e.a=function(t,e){var i,o=e?e.length:0,a=t?Math.min(o,t.length):0,u=new Array(o),c=new Array(o);for(i=0;i<a;++i)u[i]=n.i(r.a)(t[i],e[i]);for(;i<o;++i)c[i]=e[i];return function(t){for(i=0;i<a;++i)c[i]=u[i](t);return c}}},function(t,e,n){\"use strict\";var r=n(62);e.a=function(t){var e=t.length;return function(i){var o=Math.floor(((i%=1)<0?++i:i)*e),a=t[(o+e-1)%e],u=t[o%e],c=t[(o+1)%e],s=t[(o+2)%e];return n.i(r.b)((i-o/e)*e,a,u,c,s)}}},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";e.a=function(t,e){var n=new Date;return t=+t,e-=t,function(r){return n.setTime(t+e*r),n}}},function(t,e,n){\"use strict\";var r=n(63);e.a=function(t,e){var i,o={},a={};null!==t&&\"object\"==typeof t||(t={}),null!==e&&\"object\"==typeof e||(e={});for(i in e)i in t?o[i]=n.i(r.a)(t[i],e[i]):a[i]=e[i];return function(t){for(i in o)a[i]=o[i](t);return a}}},function(t,e,n){\"use strict\";function r(t){return function(e){var r,o,a=e.length,u=new Array(a),c=new Array(a),s=new Array(a);for(r=0;r<a;++r)o=n.i(i.rgb)(e[r]),u[r]=o.r||0,c[r]=o.g||0,s[r]=o.b||0;return u=t(u),c=t(c),s=t(s),o.opacity=1,function(t){return o.r=u(t),o.g=c(t),o.b=s(t),o+\"\"}}}var i=n(10),o=n(62),a=n(119),u=n(32);e.a=function t(e){function r(t,e){var r=o((t=n.i(i.rgb)(t)).r,(e=n.i(i.rgb)(e)).r),a=o(t.g,e.g),c=o(t.b,e.b),s=n.i(u.a)(t.opacity,e.opacity);return function(e){return t.r=r(e),t.g=a(e),t.b=c(e),t.opacity=s(e),t+\"\"}}var o=n.i(u.c)(e);return r.gamma=t,r}(1);r(o.a),r(a.a)},function(t,e,n){\"use strict\";function r(t){return function(){return t}}function i(t){return function(e){return t(e)+\"\"}}var o=n(43),a=/[-+]?(?:\\d+\\.?\\d*|\\.?\\d+)(?:[eE][-+]?\\d+)?/g,u=new RegExp(a.source,\"g\");e.a=function(t,e){var c,s,l,f=a.lastIndex=u.lastIndex=0,p=-1,h=[],d=[];for(t+=\"\",e+=\"\";(c=a.exec(t))&&(s=u.exec(e));)(l=s.index)>f&&(l=e.slice(f,l),h[p]?h[p]+=l:h[++p]=l),(c=c[0])===(s=s[0])?h[p]?h[p]+=s:h[++p]=s:(h[++p]=null,d.push({i:p,x:n.i(o.a)(c,s)})),f=u.lastIndex;return f<e.length&&(l=e.slice(f),h[p]?h[p]+=l:h[++p]=l),h.length<2?d[0]?i(d[0].x):r(e):(e=d.length,function(t){for(var n,r=0;r<e;++r)h[(n=d[r]).i]=n.x(t);return h.join(\"\")})}},function(t,e,n){\"use strict\";e.a=function(t,e){t=t.slice();var n,r=0,i=t.length-1,o=t[r],a=t[i];return a<o&&(n=r,r=i,i=n,n=o,o=a,a=n),t[r]=e.floor(o),t[i]=e.ceil(a),t}},function(t,e,n){\"use strict\";e.a=function(t){return+t}},function(t,e,n){\"use strict\";function r(t){function e(e){var n=e+\"\",r=u.get(n);if(!r){if(s!==a)return s;u.set(n,r=c.push(e))}return t[(r-1)%t.length]}var u=n.i(i.a)(),c=[],s=a;return t=null==t?[]:o.b.call(t),e.domain=function(t){if(!arguments.length)return c.slice();c=[],u=n.i(i.a)();for(var r,o,a=-1,s=t.length;++a<s;)u.has(o=(r=t[a])+\"\")||u.set(o,c.push(r));return e},e.range=function(n){return arguments.length?(t=o.b.call(n),e):t.slice()},e.unknown=function(t){return arguments.length?(s=t,e):s},e.copy=function(){return r().domain(c).range(t).unknown(s)},e}var i=n(203),o=n(16);n.d(e,\"b\",function(){return a}),e.a=r;var a={name:\"implicit\"}},function(t,e,n){\"use strict\";function r(t){return new Date(t)}function i(t){return t instanceof Date?+t:+new Date(+t)}function o(t,e,c,s,b,x,w,C,M){function k(n){return(w(n)<n?N:x(n)<n?A:b(n)<n?O:s(n)<n?I:e(n)<n?c(n)<n?D:R:t(n)<n?L:U)(n)}function E(e,r,i,o){if(null==e&&(e=10),\"number\"==typeof e){var u=Math.abs(i-r)/e,c=n.i(a.d)(function(t){return t[2]}).right(F,u);c===F.length?(o=n.i(a.b)(r/_,i/_,e),e=t):c?(c=F[u/F[c-1][2]<F[c][2]/u?c-1:c],o=c[1],e=c[0]):(o=n.i(a.b)(r,i,e),e=C)}return null==o?e:e.every(o)}var T=n.i(f.a)(f.b,u.a),S=T.invert,P=T.domain,N=M(\".%L\"),A=M(\":%S\"),O=M(\"%I:%M\"),I=M(\"%I %p\"),D=M(\"%a %d\"),R=M(\"%b %d\"),L=M(\"%B\"),U=M(\"%Y\"),F=[[w,1,h],[w,5,5*h],[w,15,15*h],[w,30,30*h],[x,1,d],[x,5,5*d],[x,15,15*d],[x,30,30*d],[b,1,v],[b,3,3*v],[b,6,6*v],[b,12,12*v],[s,1,g],[s,2,2*g],[c,1,m],[e,1,y],[e,3,3*y],[t,1,_]];return T.invert=function(t){return new Date(S(t))},T.domain=function(t){return arguments.length?P(l.a.call(t,i)):P().map(r)},T.ticks=function(t,e){var n,r=P(),i=r[0],o=r[r.length-1],a=o<i;return a&&(n=i,i=o,o=n),n=E(t,i,o,e),n=n?n.range(i,o+1):[],a?n.reverse():n},T.tickFormat=function(t,e){return null==e?k:M(e)},T.nice=function(t,e){var r=P();return(t=E(t,r[0],r[r.length-1],e))?P(n.i(p.a)(r,t)):T},T.copy=function(){return n.i(f.c)(T,o(t,e,c,s,b,x,w,C,M))},T}var a=n(12),u=n(31),c=n(79),s=n(77),l=n(16),f=n(45),p=n(125);e.b=o;var h=1e3,d=60*h,v=60*d,g=24*v,m=7*g,y=30*g,_=365*g;e.a=function(){return o(c.b,c.o,c.p,c.a,c.q,c.r,c.s,c.t,s.timeFormat).domain([new Date(2e3,0,1),new Date(2e3,0,2)])}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(66);n.d(e,\"creator\",function(){return r.a});var i=n(247);n.d(e,\"local\",function(){return i.a});var o=n(130);n.d(e,\"matcher\",function(){return o.a});var a=n(248);n.d(e,\"mouse\",function(){return a.a});var u=n(67);n.d(e,\"namespace\",function(){return u.a});var c=n(68);n.d(e,\"namespaces\",function(){return c.a});var s=n(249);n.d(e,\"select\",function(){return s.a});var l=n(250);n.d(e,\"selectAll\",function(){return l.a});var f=n(7);n.d(e,\"selection\",function(){return f.a});var p=n(71);n.d(e,\"selector\",function(){return p.a});var h=n(133);n.d(e,\"selectorAll\",function(){return h.a});var d=n(278);n.d(e,\"touch\",function(){return d.a});var v=n(279);n.d(e,\"touches\",function(){return v.a});var g=n(73);n.d(e,\"window\",function(){return g.a});var m=n(70);n.d(e,\"event\",function(){return m.a}),n.d(e,\"customEvent\",function(){return m.b})},function(t,e,n){\"use strict\";var r=function(t){return function(){return this.matches(t)}};if(\"undefined\"!=typeof document){var i=document.documentElement;if(!i.matches){var o=i.webkitMatchesSelector||i.msMatchesSelector||i.mozMatchesSelector||i.oMatchesSelector;r=function(t){return function(){return o.call(this,t)}}}}e.a=r},function(t,e,n){\"use strict\";function r(t,e){this.ownerDocument=t.ownerDocument,this.namespaceURI=t.namespaceURI,this._next=null,this._parent=t,this.__data__=e}var i=n(132),o=n(7);e.b=r,e.a=function(){return new o.b(this._enter||this._groups.map(i.a),this._parents)},r.prototype={constructor:r,appendChild:function(t){return this._parent.insertBefore(t,this._next)},insertBefore:function(t,e){return this._parent.insertBefore(t,e)},querySelector:function(t){return this._parent.querySelector(t)},querySelectorAll:function(t){return this._parent.querySelectorAll(t)}}},function(t,e,n){\"use strict\";e.a=function(t){return new Array(t.length)}},function(t,e,n){\"use strict\";function r(){return[]}e.a=function(t){return null==t?r:function(){return this.querySelectorAll(t)}}},function(t,e,n){\"use strict\";Object.defineProperty(e,\"__esModule\",{value:!0});var r=n(280);n.d(e,\"arc\",function(){return r.a});var i=n(135);n.d(e,\"area\",function(){return i.a});var o=n(75);n.d(e,\"line\",function(){return o.a});var a=n(299);n.d(e,\"pie\",function(){return a.a});var u=n(300);n.d(e,\"radialArea\",function(){return u.a});var c=n(140);n.d(e,\"radialLine\",function(){return c.a});var s=n(302);n.d(e,\"symbol\",function(){return s.a}),n.d(e,\"symbols\",function(){return s.b});var l=n(141);n.d(e,\"symbolCircle\",function(){return l.a});var f=n(142);n.d(e,\"symbolCross\",function(){return f.a});var p=n(143);n.d(e,\"symbolDiamond\",function(){return p.a});var h=n(144);n.d(e,\"symbolSquare\",function(){return h.a});var d=n(145);n.d(e,\"symbolStar\",function(){return d.a});var v=n(146);n.d(e,\"symbolTriangle\",function(){return v.a});var g=n(147);n.d(e,\"symbolWye\",function(){return g.a});var m=n(282);n.d(e,\"curveBasisClosed\",function(){return m.a});var y=n(283);n.d(e,\"curveBasisOpen\",function(){return y.a});var _=n(46);n.d(e,\"curveBasis\",function(){return _.a});var b=n(284);n.d(e,\"curveBundle\",function(){return b.a});var x=n(136);n.d(e,\"curveCardinalClosed\",function(){return x.a});var w=n(137);n.d(e,\"curveCardinalOpen\",function(){return w.a});var C=n(47);n.d(e,\"curveCardinal\",function(){return C.a});var M=n(285);n.d(e,\"curveCatmullRomClosed\",function(){return M.a});var k=n(286);n.d(e,\"curveCatmullRomOpen\",function(){return k.a});var E=n(74);n.d(e,\"curveCatmullRom\",function(){return E.a});var T=n(287);n.d(e,\"curveLinearClosed\",function(){return T.a});var S=n(48);n.d(e,\"curveLinear\",function(){return S.a});var P=n(288);n.d(e,\"curveMonotoneX\",function(){return P.a}),n.d(e,\"curveMonotoneY\",function(){return P.b});var N=n(289);n.d(e,\"curveNatural\",function(){return N.a});var A=n(290);n.d(e,\"curveStep\",function(){return A.a}),n.d(e,\"curveStepAfter\",function(){return A.b}),n.d(e,\"curveStepBefore\",function(){return A.c});var O=n(301);n.d(e,\"stack\",function(){return O.a});var I=n(293);n.d(e,\"stackOffsetExpand\",function(){return I.a});var D=n(36);n.d(e,\"stackOffsetNone\",function(){return D.a});var R=n(294);n.d(e,\"stackOffsetSilhouette\",function(){return R.a});var L=n(295);n.d(e,\"stackOffsetWiggle\",function(){return L.a});var U=n(76);n.d(e,\"stackOrderAscending\",function(){return U.a});var F=n(296);n.d(e,\"stackOrderDescending\",function(){return F.a});var j=n(297);n.d(e,\"stackOrderInsideOut\",function(){return j.a});var B=n(37);n.d(e,\"stackOrderNone\",function(){return B.a});var W=n(298);n.d(e,\"stackOrderReverse\",function(){return W.a})},function(t,e,n){\"use strict\";var r=n(44),i=n(19),o=n(48),a=n(75),u=n(139);e.a=function(){function t(t){var e,i,o,a,u,g=t.length,m=!1,y=new Array(g),_=new Array(g);for(null==h&&(v=d(u=n.i(r.a)())),e=0;e<=g;++e){if(!(e<g&&p(a=t[e],e,t))===m)if(m=!m)i=e,v.areaStart(),v.lineStart();else{for(v.lineEnd(),v.lineStart(),o=e-1;o>=i;--o)v.point(y[o],_[o]);v.lineEnd(),v.areaEnd()}m&&(y[e]=+c(a,e,t),_[e]=+l(a,e,t),v.point(s?+s(a,e,t):y[e],f?+f(a,e,t):_[e]))}if(u)return v=null,u+\"\"||null}function e(){return n.i(a.a)().defined(p).curve(d).context(h)}var c=u.a,s=null,l=n.i(i.a)(0),f=u.b,p=n.i(i.a)(!0),h=null,d=o.a,v=null;return t.x=function(e){return arguments.length?(c=\"function\"==typeof e?e:n.i(i.a)(+e),s=null,t):c},t.x0=function(e){return arguments.length?(c=\"function\"==typeof e?e:n.i(i.a)(+e),t):c},t.x1=function(e){return arguments.length?(s=null==e?null:\"function\"==typeof e?e:n.i(i.a)(+e),t):s},t.y=function(e){return arguments.length?(l=\"function\"==typeof e?e:n.i(i.a)(+e),f=null,t):l},t.y0=function(e){return arguments.length?(l=\"function\"==typeof e?e:n.i(i.a)(+e),t):l},t.y1=function(e){return arguments.length?(f=null==e?null:\"function\"==typeof e?e:n.i(i.a)(+e),t):f},t.lineX0=t.lineY0=function(){return e().x(c).y(l)},t.lineY1=function(){return e().x(c).y(f)},t.lineX1=function(){return e().x(s).y(l)},t.defined=function(e){return arguments.length?(p=\"function\"==typeof e?e:n.i(i.a)(!!e),t):p},t.curve=function(e){return arguments.length?(d=e,null!=h&&(v=d(h)),t):d},t.context=function(e){return arguments.length?(null==e?h=v=null:v=d(h=e),t):h},t}},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._k=(1-e)/6}var i=n(49),o=n(47);e.b=r,r.prototype={areaStart:i.a,areaEnd:i.a,lineStart:function(){this._x0=this._x1=this._x2=this._x3=this._x4=this._x5=this._y0=this._y1=this._y2=this._y3=this._y4=this._y5=NaN,this._point=0},lineEnd:function(){switch(this._point){case 1:this._context.moveTo(this._x3,this._y3),this._context.closePath();break;case 2:this._context.lineTo(this._x3,this._y3),this._context.closePath();break;case 3:this.point(this._x3,this._y3),this.point(this._x4,this._y4),this.point(this._x5,this._y5)}},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._x3=t,this._y3=e;break;case 1:this._point=2,this._context.moveTo(this._x4=t,this._y4=e);break;case 2:this._point=3,this._x5=t,this._y5=e;break;default:n.i(o.c)(this,t,e)}this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return new r(t,e)}return n.tension=function(e){return t(+e)},n}(0)},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._k=(1-e)/6}var i=n(47);e.b=r,r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._x2=this._y0=this._y1=this._y2=NaN,this._point=0},lineEnd:function(){(this._line||0!==this._line&&3===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1;break;case 1:this._point=2;break;case 2:this._point=3,this._line?this._context.lineTo(this._x2,this._y2):this._context.moveTo(this._x2,this._y2);break;case 3:this._point=4;default:n.i(i.c)(this,t,e)}this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return new r(t,e)}return n.tension=function(e){return t(+e)},n}(0)},function(t,e,n){\"use strict\";function r(t){this._curve=t}function i(t){function e(e){return new r(t(e))}return e._curve=t,e}var o=n(48);n.d(e,\"b\",function(){return a}),e.a=i;var a=i(o.a);r.prototype={areaStart:function(){this._curve.areaStart()},areaEnd:function(){this._curve.areaEnd()},lineStart:function(){this._curve.lineStart()},lineEnd:function(){this._curve.lineEnd()},point:function(t,e){this._curve.point(e*Math.sin(t),e*-Math.cos(t))}}},function(t,e,n){\"use strict\";function r(t){return t[0]}function i(t){return t[1]}e.a=r,e.b=i},function(t,e,n){\"use strict\";function r(t){var e=t.curve;return t.angle=t.x,delete t.x,t.radius=t.y,delete t.y,t.curve=function(t){return arguments.length?e(n.i(i.a)(t)):e()._curve},t}var i=n(138),o=n(75);e.b=r,e.a=function(){return r(n.i(o.a)().curve(i.b))}},function(t,e,n){\"use strict\";var r=n(35);e.a={draw:function(t,e){var n=Math.sqrt(e/r.b);t.moveTo(n,0),t.arc(0,0,n,0,r.c)}}},function(t,e,n){\"use strict\";e.a={draw:function(t,e){var n=Math.sqrt(e/5)/2;t.moveTo(-3*n,-n),t.lineTo(-n,-n),t.lineTo(-n,-3*n),t.lineTo(n,-3*n),t.lineTo(n,-n),t.lineTo(3*n,-n),t.lineTo(3*n,n),t.lineTo(n,n),t.lineTo(n,3*n),t.lineTo(-n,3*n),t.lineTo(-n,n),t.lineTo(-3*n,n),t.closePath()}}},function(t,e,n){\"use strict\";var r=Math.sqrt(1/3),i=2*r;e.a={draw:function(t,e){var n=Math.sqrt(e/i),o=n*r;t.moveTo(0,-n),t.lineTo(o,0),t.lineTo(0,n),t.lineTo(-o,0),t.closePath()}}},function(t,e,n){\"use strict\";e.a={draw:function(t,e){var n=Math.sqrt(e),r=-n/2;t.rect(r,r,n,n)}}},function(t,e,n){\"use strict\";var r=n(35),i=.8908130915292852,o=Math.sin(r.b/10)/Math.sin(7*r.b/10),a=Math.sin(r.c/10)*o,u=-Math.cos(r.c/10)*o;e.a={draw:function(t,e){var n=Math.sqrt(e*i),o=a*n,c=u*n;t.moveTo(0,-n),t.lineTo(o,c);for(var s=1;s<5;++s){var l=r.c*s/5,f=Math.cos(l),p=Math.sin(l);t.lineTo(p*n,-f*n),t.lineTo(f*o-p*c,p*o+f*c)}t.closePath()}}},function(t,e,n){\"use strict\";var r=Math.sqrt(3);e.a={draw:function(t,e){var n=-Math.sqrt(e/(3*r));t.moveTo(0,2*n),t.lineTo(-r*n,-n),t.lineTo(r*n,-n),t.closePath()}}},function(t,e,n){\"use strict\";var r=-.5,i=Math.sqrt(3)/2,o=1/Math.sqrt(12),a=3*(o/2+1);e.a={draw:function(t,e){var n=Math.sqrt(e/a),u=n/2,c=n*o,s=u,l=n*o+n,f=-s,p=l;t.moveTo(u,c),t.lineTo(s,l),t.lineTo(f,p),t.lineTo(r*u-i*c,i*u+r*c),t.lineTo(r*s-i*l,i*s+r*l),t.lineTo(r*f-i*p,i*f+r*p),t.lineTo(r*u+i*c,r*c-i*u),t.lineTo(r*s+i*l,r*l-i*s),t.lineTo(r*f+i*p,r*p-i*f),t.closePath()}}},function(t,e,n){\"use strict\";function r(t){return t.toISOString()}var i=n(78);n.d(e,\"b\",function(){return o});var o=\"%Y-%m-%dT%H:%M:%S.%LZ\",a=Date.prototype.toISOString?r:n.i(i.d)(o);e.a=a},function(t,e,n){\"use strict\";function r(t){if(0<=t.y&&t.y<100){var e=new Date(-1,t.m,t.d,t.H,t.M,t.S,t.L);return e.setFullYear(t.y),e}return new Date(t.y,t.m,t.d,t.H,t.M,t.S,t.L)}function i(t){if(0<=t.y&&t.y<100){var e=new Date(Date.UTC(-1,t.m,t.d,t.H,t.M,t.S,t.L));return e.setUTCFullYear(t.y),e}return new Date(Date.UTC(t.y,t.m,t.d,t.H,t.M,t.S,t.L))}function o(t){return{y:t,m:0,d:1,H:0,M:0,S:0,L:0}}function a(t){function e(t,e){return function(n){var r,i,o,a=[],u=-1,c=0,s=t.length;for(n instanceof Date||(n=new Date(+n));++u<s;)37===t.charCodeAt(u)&&(a.push(t.slice(c,u)),null!=(i=et[r=t.charAt(++u)])?r=t.charAt(++u):i=\"e\"===r?\" \":\"0\",(o=e[r])&&(r=o(n,i)),a.push(r),c=u+1);return a.push(t.slice(c,u)),a.join(\"\")}}function n(t,e){return function(n){var r=o(1900),u=a(r,t,n+=\"\",0);if(u!=n.length)return null;if(\"p\"in r&&(r.H=r.H%12+12*r.p),\"W\"in r||\"U\"in r){\"w\"in r||(r.w=\"W\"in r?1:0);var c=\"Z\"in r?i(o(r.y)).getUTCDay():e(o(r.y)).getDay();r.m=0,r.d=\"W\"in r?(r.w+6)%7+7*r.W-(c+5)%7:r.w+7*r.U-(c+6)%7}return\"Z\"in r?(r.H+=r.Z/100|0,r.M+=r.Z%100,i(r)):e(r)}}function a(t,e,n,r){for(var i,o,a=0,u=e.length,c=n.length;a<u;){if(r>=c)return-1;if(i=e.charCodeAt(a++),37===i){if(i=e.charAt(a++),o=Ut[i in et?e.charAt(a++):i],!o||(r=o(t,n,r))<0)return-1}else if(i!=n.charCodeAt(r++))return-1}return r}function u(t,e,n){var r=kt.exec(e.slice(n));return r?(t.p=Et[r[0].toLowerCase()],n+r[0].length):-1}function c(t,e,n){var r=Pt.exec(e.slice(n));return r?(t.w=Nt[r[0].toLowerCase()],n+r[0].length):-1}function tt(t,e,n){var r=Tt.exec(e.slice(n));return r?(t.w=St[r[0].toLowerCase()],n+r[0].length):-1}function nt(t,e,n){var r=It.exec(e.slice(n));return r?(t.m=Dt[r[0].toLowerCase()],n+r[0].length):-1}function rt(t,e,n){var r=At.exec(e.slice(n));return r?(t.m=Ot[r[0].toLowerCase()],n+r[0].length):-1}function it(t,e,n){return a(t,mt,e,n)}function ot(t,e,n){return a(t,yt,e,n)}function at(t,e,n){return a(t,_t,e,n)}function ut(t){return wt[t.getDay()]}function ct(t){return xt[t.getDay()]}function st(t){return Mt[t.getMonth()]}function lt(t){return Ct[t.getMonth()]}function ft(t){return bt[+(t.getHours()>=12)]}function pt(t){return wt[t.getUTCDay()]}function ht(t){return xt[t.getUTCDay()]}function dt(t){return Mt[t.getUTCMonth()]}function vt(t){return Ct[t.getUTCMonth()]}function gt(t){return bt[+(t.getUTCHours()>=12)]}var mt=t.dateTime,yt=t.date,_t=t.time,bt=t.periods,xt=t.days,wt=t.shortDays,Ct=t.months,Mt=t.shortMonths,kt=s(bt),Et=l(bt),Tt=s(xt),St=l(xt),Pt=s(wt),Nt=l(wt),At=s(Ct),Ot=l(Ct),It=s(Mt),Dt=l(Mt),Rt={a:ut,A:ct,b:st,B:lt,c:null,d:k,e:k,H:E,I:T,j:S,L:P,m:N,M:A,p:ft,S:O,U:I,w:D,W:R,x:null,X:null,y:L,Y:U,Z:F,\"%\":J},Lt={a:pt,A:ht,b:dt,B:vt,c:null,d:j,e:j,H:B,I:W,j:V,L:z,m:H,M:q,p:gt,S:Y,U:K,w:G,W:$,x:null,X:null,y:X,Y:Z,Z:Q,\"%\":J},Ut={a:c,A:tt,b:nt,B:rt,c:it,d:y,e:y,H:b,I:b,j:_,L:C,m:m,M:x,p:u,S:w,U:p,w:f,W:h,x:ot,X:at,y:v,Y:d,Z:g,\"%\":M};return Rt.x=e(yt,Rt),Rt.X=e(_t,Rt),Rt.c=e(mt,Rt),Lt.x=e(yt,Lt),Lt.X=e(_t,Lt),Lt.c=e(mt,Lt),{format:function(t){var n=e(t+=\"\",Rt);return n.toString=function(){return t},n},parse:function(t){var e=n(t+=\"\",r);return e.toString=function(){return t},e},utcFormat:function(t){var n=e(t+=\"\",Lt);return n.toString=function(){return t},n},utcParse:function(t){var e=n(t,i);return e.toString=function(){return t},e}}}function u(t,e,n){var r=t<0?\"-\":\"\",i=(r?-t:t)+\"\",o=i.length;return r+(o<n?new Array(n-o+1).join(e)+i:i)}function c(t){return t.replace(it,\"\\\\$&\")}function s(t){return new RegExp(\"^(?:\"+t.map(c).join(\"|\")+\")\",\"i\")}function l(t){for(var e={},n=-1,r=t.length;++n<r;)e[t[n].toLowerCase()]=n;return e}function f(t,e,n){var r=nt.exec(e.slice(n,n+1));return r?(t.w=+r[0],n+r[0].length):-1}function p(t,e,n){var r=nt.exec(e.slice(n));return r?(t.U=+r[0],n+r[0].length):-1}function h(t,e,n){var r=nt.exec(e.slice(n));return r?(t.W=+r[0],n+r[0].length):-1}function d(t,e,n){var r=nt.exec(e.slice(n,n+4));return r?(t.y=+r[0],n+r[0].length):-1}function v(t,e,n){var r=nt.exec(e.slice(n,n+2));return r?(t.y=+r[0]+(+r[0]>68?1900:2e3),n+r[0].length):-1}function g(t,e,n){var r=/^(Z)|([+-]\\d\\d)(?:\\:?(\\d\\d))?/.exec(e.slice(n,n+6));return r?(t.Z=r[1]?0:-(r[2]+(r[3]||\"00\")),n+r[0].length):-1}function m(t,e,n){var r=nt.exec(e.slice(n,n+2));return r?(t.m=r[0]-1,n+r[0].length):-1}function y(t,e,n){var r=nt.exec(e.slice(n,n+2));return r?(t.d=+r[0],n+r[0].length):-1}function _(t,e,n){var r=nt.exec(e.slice(n,n+3));return r?(t.m=0,t.d=+r[0],n+r[0].length):-1}function b(t,e,n){var r=nt.exec(e.slice(n,n+2));return r?(t.H=+r[0],n+r[0].length):-1}function x(t,e,n){var r=nt.exec(e.slice(n,n+2));return r?(t.M=+r[0],n+r[0].length):-1}function w(t,e,n){var r=nt.exec(e.slice(n,n+2));return r?(t.S=+r[0],n+r[0].length):-1}function C(t,e,n){var r=nt.exec(e.slice(n,n+3));return r?(t.L=+r[0],n+r[0].length):-1}function M(t,e,n){var r=rt.exec(e.slice(n,n+1));return r?n+r[0].length:-1}function k(t,e){return u(t.getDate(),e,2)}function E(t,e){return u(t.getHours(),e,2)}function T(t,e){return u(t.getHours()%12||12,e,2)}function S(t,e){return u(1+tt.a.count(n.i(tt.b)(t),t),e,3)}function P(t,e){return u(t.getMilliseconds(),e,3)}function N(t,e){return u(t.getMonth()+1,e,2)}function A(t,e){return u(t.getMinutes(),e,2)}function O(t,e){return u(t.getSeconds(),e,2)}function I(t,e){return u(tt.c.count(n.i(tt.b)(t),t),e,2)}function D(t){return t.getDay()}function R(t,e){return u(tt.d.count(n.i(tt.b)(t),t),e,2)}function L(t,e){return u(t.getFullYear()%100,e,2)}function U(t,e){return u(t.getFullYear()%1e4,e,4)}function F(t){var e=t.getTimezoneOffset();return(e>0?\"-\":(e*=-1,\"+\"))+u(e/60|0,\"0\",2)+u(e%60,\"0\",2)}function j(t,e){return u(t.getUTCDate(),e,2)}function B(t,e){return u(t.getUTCHours(),e,2)}function W(t,e){return u(t.getUTCHours()%12||12,e,2)}function V(t,e){return u(1+tt.e.count(n.i(tt.f)(t),t),e,3)}function z(t,e){return u(t.getUTCMilliseconds(),e,3)}function H(t,e){return u(t.getUTCMonth()+1,e,2)}function q(t,e){return u(t.getUTCMinutes(),e,2)}function Y(t,e){return u(t.getUTCSeconds(),e,2)}function K(t,e){return u(tt.g.count(n.i(tt.f)(t),t),e,2)}function G(t){return t.getUTCDay()}function $(t,e){return u(tt.h.count(n.i(tt.f)(t),t),e,2)}function X(t,e){return u(t.getUTCFullYear()%100,e,2)}function Z(t,e){return u(t.getUTCFullYear()%1e4,e,4)}function Q(){return\"+0000\"}function J(){return\"%\"}var tt=n(79);e.a=a;var et={\"-\":\"\",_:\" \",0:\"0\"},nt=/^\\s*\\d+/,rt=/^%/,it=/[\\\\\\^\\$\\*\\+\\?\\|\\[\\]\\(\\)\\.\\{\\}]/g},function(t,e,n){\"use strict\";var r=n(8),i={listen:function(t,e,n){return t.addEventListener?(t.addEventListener(e,n,!1),{remove:function(){t.removeEventListener(e,n,!1)}}):t.attachEvent?(t.attachEvent(\"on\"+e,n),{remove:function(){t.detachEvent(\"on\"+e,n)}}):void 0},capture:function(t,e,n){return t.addEventListener?(t.addEventListener(e,n,!0),{remove:function(){t.removeEventListener(e,n,!0)}}):{remove:r}},registerDefault:function(){}};t.exports=i},function(t,e,n){\"use strict\";function r(t){try{t.focus()}catch(t){}}t.exports=r},function(t,e,n){\"use strict\";function r(){if(\"undefined\"==typeof document)return null;try{return document.activeElement||document.body}catch(t){return document.body}}t.exports=r},function(t,e){function n(){throw new Error(\"setTimeout has not been defined\")}function r(){throw new Error(\"clearTimeout has not been defined\")}function i(t){if(l===setTimeout)return setTimeout(t,0);if((l===n||!l)&&setTimeout)return l=setTimeout,setTimeout(t,0);try{return l(t,0)}catch(e){try{return l.call(null,t,0)}catch(e){return l.call(this,t,0)}}}function o(t){if(f===clearTimeout)return clearTimeout(t);if((f===r||!f)&&clearTimeout)return f=clearTimeout,clearTimeout(t);try{return f(t)}catch(e){try{return f.call(null,t)}catch(e){return f.call(this,t)}}}function a(){v&&h&&(v=!1,h.length?d=h.concat(d):g=-1,d.length&&u())}function u(){if(!v){var t=i(a);v=!0;for(var e=d.length;e;){for(h=d,d=[];++g<e;)h&&h[g].run();g=-1,e=d.length}h=null,v=!1,o(t)}}function c(t,e){this.fun=t,this.array=e}function s(){}var l,f,p=t.exports={};!function(){try{l=\"function\"==typeof setTimeout?setTimeout:n}catch(t){l=n}try{f=\"function\"==typeof clearTimeout?clearTimeout:r}catch(t){f=r}}();var h,d=[],v=!1,g=-1;p.nextTick=function(t){var e=new Array(arguments.length-1);if(arguments.length>1)for(var n=1;n<arguments.length;n++)e[n-1]=arguments[n];d.push(new c(t,e)),1!==d.length||v||i(u)},c.prototype.run=function(){this.fun.apply(null,this.array)},p.title=\"browser\",p.browser=!0,p.env={},p.argv=[],p.version=\"\",p.versions={},p.on=s,p.addListener=s,p.once=s,p.off=s,p.removeListener=s,p.removeAllListeners=s,p.emit=s,p.binding=function(t){throw new Error(\"process.binding is not supported\")},p.cwd=function(){return\"/\"},p.chdir=function(t){throw new Error(\"process.chdir is not supported\")},p.umask=function(){\n",
       "return 0}},function(t,e,n){\"use strict\";function r(t,e){return t+e.charAt(0).toUpperCase()+e.substring(1)}var i={animationIterationCount:!0,borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridRow:!0,gridColumn:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},o=[\"Webkit\",\"ms\",\"Moz\",\"O\"];Object.keys(i).forEach(function(t){o.forEach(function(e){i[r(e,t)]=i[t]})});var a={background:{backgroundAttachment:!0,backgroundColor:!0,backgroundImage:!0,backgroundPositionX:!0,backgroundPositionY:!0,backgroundRepeat:!0},backgroundPosition:{backgroundPositionX:!0,backgroundPositionY:!0},border:{borderWidth:!0,borderStyle:!0,borderColor:!0},borderBottom:{borderBottomWidth:!0,borderBottomStyle:!0,borderBottomColor:!0},borderLeft:{borderLeftWidth:!0,borderLeftStyle:!0,borderLeftColor:!0},borderRight:{borderRightWidth:!0,borderRightStyle:!0,borderRightColor:!0},borderTop:{borderTopWidth:!0,borderTopStyle:!0,borderTopColor:!0},font:{fontStyle:!0,fontVariant:!0,fontWeight:!0,fontSize:!0,lineHeight:!0,fontFamily:!0},outline:{outlineWidth:!0,outlineStyle:!0,outlineColor:!0}},u={isUnitlessNumber:i,shorthandPropertyExpansions:a};t.exports=u},function(t,e,n){\"use strict\";function r(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}var i=n(2),o=n(17),a=(n(0),function(){function t(e){r(this,t),this._callbacks=null,this._contexts=null,this._arg=e}return t.prototype.enqueue=function(t,e){this._callbacks=this._callbacks||[],this._callbacks.push(t),this._contexts=this._contexts||[],this._contexts.push(e)},t.prototype.notifyAll=function(){var t=this._callbacks,e=this._contexts,n=this._arg;if(t&&e){t.length!==e.length?i(\"24\"):void 0,this._callbacks=null,this._contexts=null;for(var r=0;r<t.length;r++)t[r].call(e[r],n);t.length=0,e.length=0}},t.prototype.checkpoint=function(){return this._callbacks?this._callbacks.length:0},t.prototype.rollback=function(t){this._callbacks&&this._contexts&&(this._callbacks.length=t,this._contexts.length=t)},t.prototype.reset=function(){this._callbacks=null,this._contexts=null},t.prototype.destructor=function(){this.reset()},t}());t.exports=o.addPoolingTo(a)},function(t,e,n){\"use strict\";function r(t){return!!s.hasOwnProperty(t)||!c.hasOwnProperty(t)&&(u.test(t)?(s[t]=!0,!0):(c[t]=!0,!1))}function i(t,e){return null==e||t.hasBooleanValue&&!e||t.hasNumericValue&&isNaN(e)||t.hasPositiveNumericValue&&e<1||t.hasOverloadedBooleanValue&&e===!1}var o=n(21),a=(n(4),n(9),n(394)),u=(n(1),new RegExp(\"^[\"+o.ATTRIBUTE_NAME_START_CHAR+\"][\"+o.ATTRIBUTE_NAME_CHAR+\"]*$\")),c={},s={},l={createMarkupForID:function(t){return o.ID_ATTRIBUTE_NAME+\"=\"+a(t)},setAttributeForID:function(t,e){t.setAttribute(o.ID_ATTRIBUTE_NAME,e)},createMarkupForRoot:function(){return o.ROOT_ATTRIBUTE_NAME+'=\"\"'},setAttributeForRoot:function(t){t.setAttribute(o.ROOT_ATTRIBUTE_NAME,\"\")},createMarkupForProperty:function(t,e){var n=o.properties.hasOwnProperty(t)?o.properties[t]:null;if(n){if(i(n,e))return\"\";var r=n.attributeName;return n.hasBooleanValue||n.hasOverloadedBooleanValue&&e===!0?r+'=\"\"':r+\"=\"+a(e)}return o.isCustomAttribute(t)?null==e?\"\":t+\"=\"+a(e):null},createMarkupForCustomAttribute:function(t,e){return r(t)&&null!=e?t+\"=\"+a(e):\"\"},setValueForProperty:function(t,e,n){var r=o.properties.hasOwnProperty(e)?o.properties[e]:null;if(r){var a=r.mutationMethod;if(a)a(t,n);else{if(i(r,n))return void this.deleteValueForProperty(t,e);if(r.mustUseProperty)t[r.propertyName]=n;else{var u=r.attributeName,c=r.attributeNamespace;c?t.setAttributeNS(c,u,\"\"+n):r.hasBooleanValue||r.hasOverloadedBooleanValue&&n===!0?t.setAttribute(u,\"\"):t.setAttribute(u,\"\"+n)}}}else if(o.isCustomAttribute(e))return void l.setValueForAttribute(t,e,n)},setValueForAttribute:function(t,e,n){if(r(e)){null==n?t.removeAttribute(e):t.setAttribute(e,\"\"+n)}},deleteValueForAttribute:function(t,e){t.removeAttribute(e)},deleteValueForProperty:function(t,e){var n=o.properties.hasOwnProperty(e)?o.properties[e]:null;if(n){var r=n.mutationMethod;if(r)r(t,void 0);else if(n.mustUseProperty){var i=n.propertyName;n.hasBooleanValue?t[i]=!1:t[i]=\"\"}else t.removeAttribute(n.attributeName)}else o.isCustomAttribute(e)&&t.removeAttribute(e)}};t.exports=l},function(t,e,n){\"use strict\";var r={hasCachedChildNodes:1};t.exports=r},function(t,e,n){\"use strict\";function r(){if(this._rootNodeID&&this._wrapperState.pendingUpdate){this._wrapperState.pendingUpdate=!1;var t=this._currentElement.props,e=u.getValue(t);null!=e&&i(this,Boolean(t.multiple),e)}}function i(t,e,n){var r,i,o=c.getNodeFromInstance(t).options;if(e){for(r={},i=0;i<n.length;i++)r[\"\"+n[i]]=!0;for(i=0;i<o.length;i++){var a=r.hasOwnProperty(o[i].value);o[i].selected!==a&&(o[i].selected=a)}}else{for(r=\"\"+n,i=0;i<o.length;i++)if(o[i].value===r)return void(o[i].selected=!0);o.length&&(o[0].selected=!0)}}function o(t){var e=this._currentElement.props,n=u.executeOnChange(e,t);return this._rootNodeID&&(this._wrapperState.pendingUpdate=!0),s.asap(r,this),n}var a=n(3),u=n(85),c=n(4),s=n(11),l=(n(1),!1),f={getHostProps:function(t,e){return a({},e,{onChange:t._wrapperState.onChange,value:void 0})},mountWrapper:function(t,e){var n=u.getValue(e);t._wrapperState={pendingUpdate:!1,initialValue:null!=n?n:e.defaultValue,listeners:null,onChange:o.bind(t),wasMultiple:Boolean(e.multiple)},void 0===e.value||void 0===e.defaultValue||l||(l=!0)},getSelectValueContext:function(t){return t._wrapperState.initialValue},postUpdateWrapper:function(t){var e=t._currentElement.props;t._wrapperState.initialValue=void 0;var n=t._wrapperState.wasMultiple;t._wrapperState.wasMultiple=Boolean(e.multiple);var r=u.getValue(e);null!=r?(t._wrapperState.pendingUpdate=!1,i(t,Boolean(e.multiple),r)):n!==Boolean(e.multiple)&&(null!=e.defaultValue?i(t,Boolean(e.multiple),e.defaultValue):i(t,Boolean(e.multiple),e.multiple?[]:\"\"))}};t.exports=f},function(t,e,n){\"use strict\";var r,i={injectEmptyComponentFactory:function(t){r=t}},o={create:function(t){return r(t)}};o.injection=i,t.exports=o},function(t,e,n){\"use strict\";var r={logTopLevelRenders:!1};t.exports=r},function(t,e,n){\"use strict\";function r(t){return u?void 0:a(\"111\",t.type),new u(t)}function i(t){return new c(t)}function o(t){return t instanceof c}var a=n(2),u=(n(0),null),c=null,s={injectGenericComponentClass:function(t){u=t},injectTextComponentClass:function(t){c=t}},l={createInternalComponent:r,createInstanceForText:i,isTextComponent:o,injection:s};t.exports=l},function(t,e,n){\"use strict\";function r(t){return o(document.documentElement,t)}var i=n(353),o=n(320),a=n(151),u=n(152),c={hasSelectionCapabilities:function(t){var e=t&&t.nodeName&&t.nodeName.toLowerCase();return e&&(\"input\"===e&&\"text\"===t.type||\"textarea\"===e||\"true\"===t.contentEditable)},getSelectionInformation:function(){var t=u();return{focusedElem:t,selectionRange:c.hasSelectionCapabilities(t)?c.getSelection(t):null}},restoreSelection:function(t){var e=u(),n=t.focusedElem,i=t.selectionRange;e!==n&&r(n)&&(c.hasSelectionCapabilities(n)&&c.setSelection(n,i),a(n))},getSelection:function(t){var e;if(\"selectionStart\"in t)e={start:t.selectionStart,end:t.selectionEnd};else if(document.selection&&t.nodeName&&\"input\"===t.nodeName.toLowerCase()){var n=document.selection.createRange();n.parentElement()===t&&(e={start:-n.moveStart(\"character\",-t.value.length),end:-n.moveEnd(\"character\",-t.value.length)})}else e=i.getOffsets(t);return e||{start:0,end:0}},setSelection:function(t,e){var n=e.start,r=e.end;if(void 0===r&&(r=n),\"selectionStart\"in t)t.selectionStart=n,t.selectionEnd=Math.min(r,t.value.length);else if(document.selection&&t.nodeName&&\"input\"===t.nodeName.toLowerCase()){var o=t.createTextRange();o.collapse(!0),o.moveStart(\"character\",n),o.moveEnd(\"character\",r-n),o.select()}else i.setOffsets(t,e)}};t.exports=c},function(t,e,n){\"use strict\";function r(t,e){for(var n=Math.min(t.length,e.length),r=0;r<n;r++)if(t.charAt(r)!==e.charAt(r))return r;return t.length===e.length?-1:n}function i(t){return t?t.nodeType===D?t.documentElement:t.firstChild:null}function o(t){return t.getAttribute&&t.getAttribute(A)||\"\"}function a(t,e,n,r,i){var o;if(x.logTopLevelRenders){var a=t._currentElement.props.child,u=a.type;o=\"React mount: \"+(\"string\"==typeof u?u:u.displayName||u.name),console.time(o)}var c=M.mountComponent(t,n,null,_(t,e),i,0);o&&console.timeEnd(o),t._renderedComponent._topLevelWrapper=t,j._mountImageIntoNode(c,e,t,r,n)}function u(t,e,n,r){var i=E.ReactReconcileTransaction.getPooled(!n&&b.useCreateElement);i.perform(a,null,t,e,i,n,r),E.ReactReconcileTransaction.release(i)}function c(t,e,n){for(M.unmountComponent(t,n),e.nodeType===D&&(e=e.documentElement);e.lastChild;)e.removeChild(e.lastChild)}function s(t){var e=i(t);if(e){var n=y.getInstanceFromNode(e);return!(!n||!n._hostParent)}}function l(t){return!(!t||t.nodeType!==I&&t.nodeType!==D&&t.nodeType!==R)}function f(t){var e=i(t),n=e&&y.getInstanceFromNode(e);return n&&!n._hostParent?n:null}function p(t){var e=f(t);return e?e._hostContainerInfo._topLevelWrapper:null}var h=n(2),d=n(20),v=n(21),g=n(26),m=n(51),y=(n(15),n(4)),_=n(347),b=n(349),x=n(160),w=n(40),C=(n(9),n(363)),M=n(24),k=n(88),E=n(11),T=n(38),S=n(169),P=(n(0),n(55)),N=n(95),A=(n(1),v.ID_ATTRIBUTE_NAME),O=v.ROOT_ATTRIBUTE_NAME,I=1,D=9,R=11,L={},U=1,F=function(){this.rootID=U++};F.prototype.isReactComponent={},F.prototype.render=function(){return this.props.child},F.isReactTopLevelWrapper=!0;var j={TopLevelWrapper:F,_instancesByReactRootID:L,scrollMonitor:function(t,e){e()},_updateRootComponent:function(t,e,n,r,i){return j.scrollMonitor(r,function(){k.enqueueElementInternal(t,e,n),i&&k.enqueueCallbackInternal(t,i)}),t},_renderNewRootComponent:function(t,e,n,r){l(e)?void 0:h(\"37\"),m.ensureScrollValueMonitoring();var i=S(t,!1);E.batchedUpdates(u,i,e,n,r);var o=i._instance.rootID;return L[o]=i,i},renderSubtreeIntoContainer:function(t,e,n,r){return null!=t&&w.has(t)?void 0:h(\"38\"),j._renderSubtreeIntoContainer(t,e,n,r)},_renderSubtreeIntoContainer:function(t,e,n,r){k.validateCallback(r,\"ReactDOM.render\"),g.isValidElement(e)?void 0:h(\"39\",\"string\"==typeof e?\" Instead of passing a string like 'div', pass React.createElement('div') or <div />.\":\"function\"==typeof e?\" Instead of passing a class like Foo, pass React.createElement(Foo) or <Foo />.\":null!=e&&void 0!==e.props?\" This may be caused by unintentionally loading two independent copies of React.\":\"\");var a,u=g.createElement(F,{child:e});if(t){var c=w.get(t);a=c._processChildContext(c._context)}else a=T;var l=p(n);if(l){var f=l._currentElement,d=f.props.child;if(N(d,e)){var v=l._renderedComponent.getPublicInstance(),m=r&&function(){r.call(v)};return j._updateRootComponent(l,u,a,n,m),v}j.unmountComponentAtNode(n)}var y=i(n),_=y&&!!o(y),b=s(n),x=_&&!l&&!b,C=j._renderNewRootComponent(u,n,x,a)._renderedComponent.getPublicInstance();return r&&r.call(C),C},render:function(t,e,n){return j._renderSubtreeIntoContainer(null,t,e,n)},unmountComponentAtNode:function(t){l(t)?void 0:h(\"40\");var e=p(t);if(!e){s(t),1===t.nodeType&&t.hasAttribute(O);return!1}return delete L[e._instance.rootID],E.batchedUpdates(c,e,t,!1),!0},_mountImageIntoNode:function(t,e,n,o,a){if(l(e)?void 0:h(\"41\"),o){var u=i(e);if(C.canReuseMarkup(t,u))return void y.precacheNode(n,u);var c=u.getAttribute(C.CHECKSUM_ATTR_NAME);u.removeAttribute(C.CHECKSUM_ATTR_NAME);var s=u.outerHTML;u.setAttribute(C.CHECKSUM_ATTR_NAME,c);var f=t,p=r(f,s),v=\" (client) \"+f.substring(p-20,p+20)+\"\\n (server) \"+s.substring(p-20,p+20);e.nodeType===D?h(\"42\",v):void 0}if(e.nodeType===D?h(\"43\"):void 0,a.useCreateElement){for(;e.lastChild;)e.removeChild(e.lastChild);d.insertTreeBefore(e,t,null)}else P(e,t),y.precacheNode(n,e.firstChild)}};t.exports=j},function(t,e,n){\"use strict\";var r=n(2),i=n(26),o=(n(0),{HOST:0,COMPOSITE:1,EMPTY:2,getType:function(t){return null===t||t===!1?o.EMPTY:i.isValidElement(t)?\"function\"==typeof t.type?o.COMPOSITE:o.HOST:void r(\"26\",t)}});t.exports=o},function(t,e,n){\"use strict\";function r(t,e){return null==e?i(\"30\"):void 0,null==t?e:Array.isArray(t)?Array.isArray(e)?(t.push.apply(t,e),t):(t.push(e),t):Array.isArray(e)?[t].concat(e):[t,e]}var i=n(2);n(0);t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n){Array.isArray(t)?t.forEach(e,n):t&&e.call(n,t)}t.exports=r},function(t,e,n){\"use strict\";function r(t){for(var e;(e=t._renderedNodeType)===i.COMPOSITE;)t=t._renderedComponent;return e===i.HOST?t._renderedComponent:e===i.EMPTY?null:void 0}var i=n(164);t.exports=r},function(t,e,n){\"use strict\";function r(){return!o&&i.canUseDOM&&(o=\"textContent\"in document.documentElement?\"textContent\":\"innerText\"),o}var i=n(6),o=null;t.exports=r},function(t,e,n){\"use strict\";function r(t){if(t){var e=t.getName();if(e)return\" Check the render method of `\"+e+\"`.\"}return\"\"}function i(t){return\"function\"==typeof t&&\"undefined\"!=typeof t.prototype&&\"function\"==typeof t.prototype.mountComponent&&\"function\"==typeof t.prototype.receiveComponent}function o(t,e){var n;if(null===t||t===!1)n=s.create(o);else if(\"object\"==typeof t){var u=t,c=u.type;if(\"function\"!=typeof c&&\"string\"!=typeof c){var p=\"\";p+=r(u._owner),a(\"130\",null==c?c:typeof c,p)}\"string\"==typeof u.type?n=l.createInternalComponent(u):i(u.type)?(n=new u.type(u),n.getHostNode||(n.getHostNode=n.getNativeNode)):n=new f(u)}else\"string\"==typeof t||\"number\"==typeof t?n=l.createInstanceForText(t):a(\"131\",typeof t);return n._mountIndex=0,n._mountImage=null,n}var a=n(2),u=n(3),c=n(344),s=n(159),l=n(161),f=(n(391),n(0),n(1),function(t){this.construct(t)});u(f.prototype,c,{_instantiateReactComponent:o}),t.exports=o},function(t,e,n){\"use strict\";function r(t){var e=t&&t.nodeName&&t.nodeName.toLowerCase();return\"input\"===e?!!i[t.type]:\"textarea\"===e}var i={color:!0,date:!0,datetime:!0,\"datetime-local\":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};t.exports=r},function(t,e,n){\"use strict\";var r=n(6),i=n(54),o=n(55),a=function(t,e){if(e){var n=t.firstChild;if(n&&n===t.lastChild&&3===n.nodeType)return void(n.nodeValue=e)}t.textContent=e};r.canUseDOM&&(\"textContent\"in document.documentElement||(a=function(t,e){return 3===t.nodeType?void(t.nodeValue=e):void o(t,i(e))})),t.exports=a},function(t,e,n){\"use strict\";function r(t,e){return t&&\"object\"==typeof t&&null!=t.key?s.escape(t.key):e.toString(36)}function i(t,e,n,o){var p=typeof t;if(\"undefined\"!==p&&\"boolean\"!==p||(t=null),null===t||\"string\"===p||\"number\"===p||\"object\"===p&&t.$$typeof===u)return n(o,t,\"\"===e?l+r(t,0):e),1;var h,d,v=0,g=\"\"===e?l:e+f;if(Array.isArray(t))for(var m=0;m<t.length;m++)h=t[m],d=g+r(h,m),v+=i(h,d,n,o);else{var y=c(t);if(y){var _,b=y.call(t);if(y!==t.entries)for(var x=0;!(_=b.next()).done;)h=_.value,d=g+r(h,x++),v+=i(h,d,n,o);else for(;!(_=b.next()).done;){var w=_.value;w&&(h=w[1],d=g+s.escape(w[0])+f+r(h,0),v+=i(h,d,n,o))}}else if(\"object\"===p){var C=\"\",M=String(t);a(\"31\",\"[object Object]\"===M?\"object with keys {\"+Object.keys(t).join(\", \")+\"}\":M,C)}}return v}function o(t,e,n){return null==t?0:i(t,\"\",e,n)}var a=n(2),u=(n(15),n(359)),c=n(390),s=(n(0),n(84)),l=(n(1),\".\"),f=\":\";t.exports=o},function(t,e,n){\"use strict\";function r(t){var e=Function.prototype.toString,n=Object.prototype.hasOwnProperty,r=RegExp(\"^\"+e.call(n).replace(/[\\\\^$.*+?()[\\]{}|]/g,\"\\\\$&\").replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g,\"$1.*?\")+\"$\");try{var i=e.call(t);return r.test(i)}catch(t){return!1}}function i(t){var e=s(t);if(e){var n=e.childIDs;l(t),n.forEach(i)}}function o(t,e,n){return\"\\n    in \"+(t||\"Unknown\")+(e?\" (at \"+e.fileName.replace(/^.*[\\\\\\/]/,\"\")+\":\"+e.lineNumber+\")\":n?\" (created by \"+n+\")\":\"\")}function a(t){return null==t?\"#empty\":\"string\"==typeof t||\"number\"==typeof t?\"#text\":\"string\"==typeof t.type?t.type:t.type.displayName||t.type.name||\"Unknown\"}function u(t){var e,n=k.getDisplayName(t),r=k.getElement(t),i=k.getOwnerID(t);return i&&(e=k.getDisplayName(i)),o(n,r&&r._source,e)}var c,s,l,f,p,h,d,v=n(28),g=n(15),m=(n(0),n(1),\"function\"==typeof Array.from&&\"function\"==typeof Map&&r(Map)&&null!=Map.prototype&&\"function\"==typeof Map.prototype.keys&&r(Map.prototype.keys)&&\"function\"==typeof Set&&r(Set)&&null!=Set.prototype&&\"function\"==typeof Set.prototype.keys&&r(Set.prototype.keys));if(m){var y=new Map,_=new Set;c=function(t,e){y.set(t,e)},s=function(t){return y.get(t)},l=function(t){y.delete(t)},f=function(){return Array.from(y.keys())},p=function(t){_.add(t)},h=function(t){_.delete(t)},d=function(){return Array.from(_.keys())}}else{var b={},x={},w=function(t){return\".\"+t},C=function(t){return parseInt(t.substr(1),10)};c=function(t,e){var n=w(t);b[n]=e},s=function(t){var e=w(t);return b[e]},l=function(t){var e=w(t);delete b[e]},f=function(){return Object.keys(b).map(C)},p=function(t){var e=w(t);x[e]=!0},h=function(t){var e=w(t);delete x[e]},d=function(){return Object.keys(x).map(C)}}var M=[],k={onSetChildren:function(t,e){var n=s(t);n?void 0:v(\"144\"),n.childIDs=e;for(var r=0;r<e.length;r++){var i=e[r],o=s(i);o?void 0:v(\"140\"),null==o.childIDs&&\"object\"==typeof o.element&&null!=o.element?v(\"141\"):void 0,o.isMounted?void 0:v(\"71\"),null==o.parentID&&(o.parentID=t),o.parentID!==t?v(\"142\",i,o.parentID,t):void 0}},onBeforeMountComponent:function(t,e,n){var r={element:e,parentID:n,text:null,childIDs:[],isMounted:!1,updateCount:0};c(t,r)},onBeforeUpdateComponent:function(t,e){var n=s(t);n&&n.isMounted&&(n.element=e)},onMountComponent:function(t){var e=s(t);e?void 0:v(\"144\"),e.isMounted=!0;var n=0===e.parentID;n&&p(t)},onUpdateComponent:function(t){var e=s(t);e&&e.isMounted&&e.updateCount++},onUnmountComponent:function(t){var e=s(t);if(e){e.isMounted=!1;var n=0===e.parentID;n&&h(t)}M.push(t)},purgeUnmountedComponents:function(){if(!k._preventPurging){for(var t=0;t<M.length;t++){var e=M[t];i(e)}M.length=0}},isMounted:function(t){var e=s(t);return!!e&&e.isMounted},getCurrentStackAddendum:function(t){var e=\"\";if(t){var n=a(t),r=t._owner;e+=o(n,t._source,r&&r.getName())}var i=g.current,u=i&&i._debugID;return e+=k.getStackAddendumByID(u)},getStackAddendumByID:function(t){for(var e=\"\";t;)e+=u(t),t=k.getParentID(t);return e},getChildIDs:function(t){var e=s(t);return e?e.childIDs:[]},getDisplayName:function(t){var e=k.getElement(t);return e?a(e):null},getElement:function(t){var e=s(t);return e?e.element:null},getOwnerID:function(t){var e=k.getElement(t);return e&&e._owner?e._owner._debugID:null},getParentID:function(t){var e=s(t);return e?e.parentID:null},getSource:function(t){var e=s(t),n=e?e.element:null,r=null!=n?n._source:null;return r},getText:function(t){var e=k.getElement(t);return\"string\"==typeof e?e:\"number\"==typeof e?\"\"+e:null},getUpdateCount:function(t){var e=s(t);return e?e.updateCount:0},getRootIDs:d,getRegisteredIDs:f};t.exports=k},function(t,e,n){\"use strict\";var r=\"function\"==typeof Symbol&&Symbol.for&&Symbol.for(\"react.element\")||60103;t.exports=r},function(t,e,n){\"use strict\";var r={};t.exports=r},function(t,e,n){\"use strict\";var r=!1;t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=t&&(i&&t[i]||t[o]);if(\"function\"==typeof e)return e}var i=\"function\"==typeof Symbol&&Symbol.iterator,o=\"@@iterator\";t.exports=r},,function(t,e,n){\"use strict\";function r(t){return t&&t.__esModule?t:{default:t}}function i(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}function o(t,e){if(!t)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return!e||\"object\"!=typeof e&&\"function\"!=typeof e?t:e}function a(t,e){if(\"function\"!=typeof e&&null!==e)throw new TypeError(\"Super expression must either be null or a function, not \"+typeof e);t.prototype=Object.create(e&&e.prototype,{constructor:{value:t,enumerable:!1,writable:!0,configurable:!0}}),e&&(Object.setPrototypeOf?Object.setPrototypeOf(t,e):t.__proto__=e)}Object.defineProperty(e,\"__esModule\",{value:!0});var u=\"function\"==typeof Symbol&&\"symbol\"==typeof Symbol.iterator?function(t){return typeof t}:function(t){return t&&\"function\"==typeof Symbol&&t.constructor===Symbol&&t!==Symbol.prototype?\"symbol\":typeof t},c=function(){function t(t,e){for(var n=0;n<e.length;n++){var r=e[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(t,r.key,r)}}return function(e,n,r){return n&&t(e.prototype,n),r&&t(e,r),e}}(),s=n(41),l=r(s),f=n(129),p=n(64),h=n(30),d=n(77),v=n(112),g=n(134),m=n(10),y=n(39),_=n(56),b=r(_),x=function(t){function e(){i(this,e);var t=o(this,(e.__proto__||Object.getPrototypeOf(e)).call(this));return window.lastAdditiveForceArrayVisualizer=t,t.topOffset=28,t.leftOffset=80,t.height=350,t.effectFormat=(0,h.format)(\".2\"),t.redraw=(0,y.debounce)(function(){return t.draw()},200),t}return a(e,t),c(e,[{key:\"componentDidMount\",value:function(){var t=this;this.mainGroup=this.svg.append(\"g\"),this.onTopGroup=this.svg.append(\"g\"),this.xaxisElement=this.onTopGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-array-xaxis\"),this.yaxisElement=this.onTopGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-array-yaxis\"),this.hoverGroup1=this.svg.append(\"g\"),this.hoverGroup2=this.svg.append(\"g\"),this.baseValueTitle=this.svg.append(\"text\"),this.hoverLine=this.svg.append(\"line\"),this.hoverxOutline=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#fff\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",\"6\").attr(\"font-size\",\"12px\"),this.hoverx=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").attr(\"font-size\",\"12px\"),this.hoverxTitle=this.svg.append(\"text\").attr(\"text-anchor\",\"middle\").attr(\"opacity\",.6).attr(\"font-size\",\"12px\"),this.hoveryOutline=this.svg.append(\"text\").attr(\"text-anchor\",\"end\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#fff\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",\"6\").attr(\"font-size\",\"12px\"),this.hovery=this.svg.append(\"text\").attr(\"text-anchor\",\"end\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").attr(\"font-size\",\"12px\"),this.xlabel=this.wrapper.select(\".additive-force-array-xlabel\"),this.ylabel=this.wrapper.select(\".additive-force-array-ylabel\");var e=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in b.default.colors?e=b.default.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),e=b.default.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(e=this.props.plot_cmap),this.colors=e.map(function(t){return(0,m.hsl)(t)}),this.brighterColors=[1.45,1.6].map(function(e,n){return t.colors[n].brighter(e)});var n=(0,h.format)(\",.4\");if(null!=this.props.ordering_keys&&null!=this.props.ordering_keys_time_format){var r=function(t){return\"object\"==(\"undefined\"==typeof t?\"undefined\":u(t))?this.formatTime(t):n(t)};this.parseTime=(0,d.timeParse)(this.props.ordering_keys_time_format),this.formatTime=(0,d.timeFormat)(this.props.ordering_keys_time_format),this.xtickFormat=r}else this.parseTime=null,this.formatTime=null,this.xtickFormat=n;this.xscale=(0,p.scaleLinear)(),this.xaxis=(0,v.axisBottom)().scale(this.xscale).tickSizeInner(4).tickSizeOuter(0).tickFormat(function(e){return t.xtickFormat(e)}).tickPadding(-18),this.ytickFormat=n,this.yscale=(0,p.scaleLinear)(),this.yaxis=(0,v.axisLeft)().scale(this.yscale).tickSizeInner(4).tickSizeOuter(0).tickFormat(function(e){return t.ytickFormat(t.invLinkFunction(e))}).tickPadding(2),this.xlabel.node().onchange=function(){return t.internalDraw()},this.ylabel.node().onchange=function(){return t.internalDraw()},this.svg.on(\"mousemove\",function(e){return t.mouseMoved(e)}),this.svg.on(\"click\",function(){return alert(\"This original index of the sample you clicked is \"+t.nearestExpIndex)}),this.svg.on(\"mouseout\",function(e){return t.mouseOut(e)}),window.addEventListener(\"resize\",this.redraw),window.setTimeout(this.redraw,50)}},{key:\"componentDidUpdate\",value:function(){this.draw()}},{key:\"mouseOut\",value:function(){this.hoverLine.attr(\"display\",\"none\"),this.hoverx.attr(\"display\",\"none\"),this.hoverxOutline.attr(\"display\",\"none\"),this.hoverxTitle.attr(\"display\",\"none\"),this.hovery.attr(\"display\",\"none\"),this.hoveryOutline.attr(\"display\",\"none\"),this.hoverGroup1.attr(\"display\",\"none\"),this.hoverGroup2.attr(\"display\",\"none\")}},{key:\"mouseMoved\",value:function(){var t=this,e=void 0,n=void 0;this.hoverLine.attr(\"display\",\"\"),this.hoverx.attr(\"display\",\"\"),this.hoverxOutline.attr(\"display\",\"\"),this.hoverxTitle.attr(\"display\",\"\"),this.hovery.attr(\"display\",\"\"),this.hoveryOutline.attr(\"display\",\"\"),this.hoverGroup1.attr(\"display\",\"\"),this.hoverGroup2.attr(\"display\",\"\");var r=(0,f.mouse)(this.svg.node())[0];if(this.props.explanations){for(e=0;e<this.currExplanations.length;++e)(!n||Math.abs(n.xmapScaled-r)>Math.abs(this.currExplanations[e].xmapScaled-r))&&(n=this.currExplanations[e]);this.nearestExpIndex=n.origInd,this.hoverLine.attr(\"x1\",n.xmapScaled).attr(\"x2\",n.xmapScaled).attr(\"y1\",0+this.topOffset).attr(\"y2\",this.height),this.hoverx.attr(\"x\",n.xmapScaled).attr(\"y\",this.topOffset-5).text(this.xtickFormat(n.xmap)),this.hoverxOutline.attr(\"x\",n.xmapScaled).attr(\"y\",this.topOffset-5).text(this.xtickFormat(n.xmap)),this.hoverxTitle.attr(\"x\",n.xmapScaled).attr(\"y\",this.topOffset-18).text(n.count>1?n.count+\" averaged samples\":\"\"),this.hovery.attr(\"x\",this.leftOffset-6).attr(\"y\",n.joinPointy).text(this.ytickFormat(this.invLinkFunction(n.joinPoint))),this.hoveryOutline.attr(\"x\",this.leftOffset-6).attr(\"y\",n.joinPointy).text(this.ytickFormat(this.invLinkFunction(n.joinPoint)));for(var i=[],o=void 0,a=void 0,u=this.currPosOrderedFeatures.length-1;u>=0;--u){var c=this.currPosOrderedFeatures[u],s=n.features[c];a=5+(s.posyTop+s.posyBottom)/2,(!o||a-o>=15)&&s.posyTop-s.posyBottom>=6&&(i.push(s),o=a)}var l=[];o=void 0;var p=!0,h=!1,d=void 0;try{for(var v,g=this.currNegOrderedFeatures[Symbol.iterator]();!(p=(v=g.next()).done);p=!0){var m=v.value,y=n.features[m];a=5+(y.negyTop+y.negyBottom)/2,(!o||o-a>=15)&&y.negyTop-y.negyBottom>=6&&(l.push(y),o=a)}}catch(t){h=!0,d=t}finally{try{!p&&g.return&&g.return()}finally{if(h)throw d}}var _=function(e){var r=\"\";return null!==e.value&&void 0!==e.value&&(r=\" = \"+(isNaN(e.value)?e.value:t.ytickFormat(e.value))),n.count>1?\"mean(\"+t.props.featureNames[e.ind]+\")\"+r:t.props.featureNames[e.ind]+r},b=this.hoverGroup1.selectAll(\".pos-values\").data(i);b.enter().append(\"text\").attr(\"class\",\"pos-values\").merge(b).attr(\"x\",n.xmapScaled+5).attr(\"y\",function(t){return 4+(t.posyTop+t.posyBottom)/2}).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").attr(\"opacity\",1).text(_),b.exit().remove();var x=this.hoverGroup2.selectAll(\".pos-values\").data(i);x.enter().append(\"text\").attr(\"class\",\"pos-values\").merge(x).attr(\"x\",n.xmapScaled+5).attr(\"y\",function(t){return 4+(t.posyTop+t.posyBottom)/2}).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"fill\",this.colors[0]).text(_),x.exit().remove();var w=this.hoverGroup1.selectAll(\".neg-values\").data(l);w.enter().append(\"text\").attr(\"class\",\"neg-values\").merge(w).attr(\"x\",n.xmapScaled+5).attr(\"y\",function(t){return 4+(t.negyTop+t.negyBottom)/2}).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").attr(\"opacity\",1).text(_),w.exit().remove();var C=this.hoverGroup2.selectAll(\".neg-values\").data(l);C.enter().append(\"text\").attr(\"class\",\"neg-values\").merge(C).attr(\"x\",n.xmapScaled+5).attr(\"y\",function(t){return 4+(t.negyTop+t.negyBottom)/2}).attr(\"text-anchor\",\"start\").attr(\"font-size\",12).attr(\"fill\",this.colors[1]).text(_),C.exit().remove()}}},{key:\"draw\",value:function(){var t=this;if(this.props.explanations&&0!==this.props.explanations.length){(0,y.each)(this.props.explanations,function(t,e){return t.origInd=e});var e={},n={},r={},i=!0,o=!1,a=void 0;try{for(var u,c=this.props.explanations[Symbol.iterator]();!(i=(u=c.next()).done);i=!0){var s=u.value;for(var l in s.features)void 0===e[l]&&(e[l]=0,n[l]=0,r[l]=0),s.features[l].effect>0?e[l]+=s.features[l].effect:n[l]-=s.features[l].effect,null!==s.features[l].value&&void 0!==s.features[l].value&&(r[l]+=1)}}catch(t){o=!0,a=t}finally{try{!i&&c.return&&c.return()}finally{if(o)throw a}}this.usedFeatures=(0,y.sortBy)((0,y.keys)(e),function(t){return-(e[t]+n[t])}),console.log(\"found \",this.usedFeatures.length,\" used features\"),this.posOrderedFeatures=(0,y.sortBy)(this.usedFeatures,function(t){return e[t]}),this.negOrderedFeatures=(0,y.sortBy)(this.usedFeatures,function(t){return-n[t]}),this.singleValueFeatures=(0,y.filter)(this.usedFeatures,function(t){return r[t]>0});var f=[\"sample order by similarity\",\"sample order by output value\",\"original sample ordering\"].concat(this.singleValueFeatures.map(function(e){return t.props.featureNames[e]}));null!=this.props.ordering_keys&&f.unshift(\"sample order by key\");var p=this.xlabel.selectAll(\"option\").data(f);p.enter().append(\"option\").merge(p).attr(\"value\",function(t){return t}).text(function(t){return t}),p.exit().remove();var h=this.props.outNames[0]?this.props.outNames[0]:\"model output value\";f=(0,y.map)(this.usedFeatures,function(e){return[t.props.featureNames[e],t.props.featureNames[e]+\" effects\"]}),f.unshift([\"model output value\",h]);var d=this.ylabel.selectAll(\"option\").data(f);d.enter().append(\"option\").merge(d).attr(\"value\",function(t){return t[0]}).text(function(t){return t[1]}),d.exit().remove(),this.ylabel.style(\"top\",(this.height-10-this.topOffset)/2+this.topOffset+\"px\").style(\"left\",10-this.ylabel.node().offsetWidth/2+\"px\"),this.internalDraw()}}},{key:\"internalDraw\",value:function(){var t=this,e=!0,n=!1,r=void 0;try{for(var i,o=this.props.explanations[Symbol.iterator]();!(e=(i=o.next()).done);e=!0){var a=i.value,c=!0,s=!1,l=void 0;try{for(var f,h=this.usedFeatures[Symbol.iterator]();!(c=(f=h.next()).done);c=!0){var d=f.value;a.features.hasOwnProperty(d)||(a.features[d]={effect:0,value:0}),a.features[d].ind=d}}catch(t){s=!0,l=t}finally{try{!c&&h.return&&h.return()}finally{if(s)throw l}}}}catch(t){n=!0,r=t}finally{try{!e&&o.return&&o.return()}finally{if(n)throw r}}var v=void 0,m=this.xlabel.node().value,_=\"sample order by key\"===m&&null!=this.props.ordering_keys_time_format;if(_?this.xscale=(0,p.scaleTime)():this.xscale=(0,p.scaleLinear)(),this.xaxis.scale(this.xscale),\"sample order by similarity\"===m)v=(0,y.sortBy)(this.props.explanations,function(t){return t.simIndex}),(0,y.each)(v,function(t,e){return t.xmap=e});else if(\"sample order by output value\"===m)v=(0,y.sortBy)(this.props.explanations,function(t){return-t.outValue}),(0,y.each)(v,function(t,e){return t.xmap=e});else if(\"original sample ordering\"===m)v=(0,y.sortBy)(this.props.explanations,function(t){return t.origInd}),(0,y.each)(v,function(t,e){return t.xmap=e});else if(\"sample order by key\"===m)v=this.props.explanations,_?(0,y.each)(v,function(e,n){return e.xmap=t.parseTime(t.props.ordering_keys[n])}):(0,y.each)(v,function(e,n){return e.xmap=t.props.ordering_keys[n]}),v=(0,y.sortBy)(v,function(t){return t.xmap});else{var b=function(){var e=(0,y.findKey)(t.props.featureNames,function(t){return t===m});(0,y.each)(t.props.explanations,function(t,n){return t.xmap=t.features[e].value});var n=(0,y.sortBy)(t.props.explanations,function(t){return t.xmap}),r=(0,y.map)(n,function(t){return t.xmap});if(\"string\"==typeof r[0])return alert(\"Ordering by category names is not yet supported.\"),{v:void 0};var i=(0,y.min)(r),o=(0,y.max)(r),a=(o-i)/100;v=[];for(var u=void 0,c=void 0,s=0;s<n.length;++s){var l=n[s];if(u&&!c&&l.xmap-u.xmap<=a||c&&l.xmap-c.xmap<=a){c||(c=(0,y.cloneDeep)(u),c.count=1);var f=!0,p=!1,h=void 0;try{for(var d,g=t.usedFeatures[Symbol.iterator]();!(f=(d=g.next()).done);f=!0){var _=d.value;c.features[_].effect+=l.features[_].effect,c.features[_].value+=l.features[_].value;\n",
       "}}catch(t){p=!0,h=t}finally{try{!f&&g.return&&g.return()}finally{if(p)throw h}}c.count+=1}else if(u)if(c){var b=!0,x=!1,w=void 0;try{for(var C,M=t.usedFeatures[Symbol.iterator]();!(b=(C=M.next()).done);b=!0){var k=C.value;c.features[k].effect/=c.count,c.features[k].value/=c.count}}catch(t){x=!0,w=t}finally{try{!b&&M.return&&M.return()}finally{if(x)throw w}}v.push(c),c=void 0}else v.push(u);u=l}u.xmap-v[v.length-1].xmap>a&&v.push(u)}();if(\"object\"===(\"undefined\"==typeof b?\"undefined\":u(b)))return b.v}this.currUsedFeatures=this.usedFeatures,this.currPosOrderedFeatures=this.posOrderedFeatures,this.currNegOrderedFeatures=this.negOrderedFeatures;var x=this.ylabel.node().value;if(\"model output value\"!==x){var w=v;v=(0,y.cloneDeep)(v);for(var C=(0,y.findKey)(this.props.featureNames,function(t){return t===x}),M=0;M<v.length;++M){var k=v[M].features[C];v[M].features={},v[M].features[C]=k,w[M].remapped_version=v[M]}this.currUsedFeatures=[C],this.currPosOrderedFeatures=[C],this.currNegOrderedFeatures=[C]}this.currExplanations=v,\"identity\"===this.props.link?this.invLinkFunction=function(e){return t.props.baseValue+e}:\"logit\"===this.props.link?this.invLinkFunction=function(e){return 1/(1+Math.exp(-(t.props.baseValue+e)))}:console.log(\"ERROR: Unrecognized link function: \",this.props.link),this.predValues=(0,y.map)(v,function(t){return(0,y.sum)((0,y.map)(t.features,function(t){return t.effect}))});var E=this.wrapper.node().offsetWidth;if(0==E)return setTimeout(function(){return t.draw(v)},500);this.svg.style(\"height\",this.height+\"px\"),this.svg.style(\"width\",E+\"px\");var T=(0,y.map)(v,function(t){return t.xmap});this.xscale.domain([(0,y.min)(T),(0,y.max)(T)]).range([this.leftOffset,E]).clamp(!0),this.xaxisElement.attr(\"transform\",\"translate(0,\"+this.topOffset+\")\").call(this.xaxis);for(var S=0;S<this.currExplanations.length;++S)this.currExplanations[S].xmapScaled=this.xscale(this.currExplanations[S].xmap);for(var P=v.length,N=0,A=0;A<P;++A){var O=v[A].features,I=(0,y.sum)((0,y.map)((0,y.filter)(O,function(t){return t.effect>0}),function(t){return t.effect}))||0,D=(0,y.sum)((0,y.map)((0,y.filter)(O,function(t){return t.effect<0}),function(t){return-t.effect}))||0;N=Math.max(N,2.2*Math.max(I,D))}this.yscale.domain([-N/2,N/2]).range([this.height-10,this.topOffset]),this.yaxisElement.attr(\"transform\",\"translate(\"+this.leftOffset+\",0)\").call(this.yaxis);for(var R=0;R<P;++R){var L=v[R].features,U=(0,y.sum)((0,y.map)((0,y.filter)(L,function(t){return t.effect<0}),function(t){return-t.effect}))||0,F=-U,j=void 0,B=!0,W=!1,V=void 0;try{for(var z,H=this.currPosOrderedFeatures[Symbol.iterator]();!(B=(z=H.next()).done);B=!0)j=z.value,L[j].posyTop=this.yscale(F),L[j].effect>0&&(F+=L[j].effect),L[j].posyBottom=this.yscale(F),L[j].ind=j}catch(t){W=!0,V=t}finally{try{!B&&H.return&&H.return()}finally{if(W)throw V}}var q=F,Y=!0,K=!1,G=void 0;try{for(var $,X=this.currNegOrderedFeatures[Symbol.iterator]();!(Y=($=X.next()).done);Y=!0)j=$.value,L[j].negyTop=this.yscale(F),L[j].effect<0&&(F-=L[j].effect),L[j].negyBottom=this.yscale(F)}catch(t){K=!0,G=t}finally{try{!Y&&X.return&&X.return()}finally{if(K)throw G}}v[R].joinPoint=q,v[R].joinPointy=this.yscale(q)}var Z=(0,g.line)().x(function(t){return t[0]}).y(function(t){return t[1]}),Q=this.mainGroup.selectAll(\".force-bar-array-area-pos\").data(this.currUsedFeatures);Q.enter().append(\"path\").attr(\"class\",\"force-bar-array-area-pos\").merge(Q).attr(\"d\",function(t){var e=(0,y.map)((0,y.range)(P),function(e){return[v[e].xmapScaled,v[e].features[t].posyTop]}),n=(0,y.map)((0,y.rangeRight)(P),function(e){return[v[e].xmapScaled,v[e].features[t].posyBottom]});return Z(e.concat(n))}).attr(\"fill\",this.colors[0]),Q.exit().remove();var J=this.mainGroup.selectAll(\".force-bar-array-area-neg\").data(this.currUsedFeatures);J.enter().append(\"path\").attr(\"class\",\"force-bar-array-area-neg\").merge(J).attr(\"d\",function(t){var e=(0,y.map)((0,y.range)(P),function(e){return[v[e].xmapScaled,v[e].features[t].negyTop]}),n=(0,y.map)((0,y.rangeRight)(P),function(e){return[v[e].xmapScaled,v[e].features[t].negyBottom]});return Z(e.concat(n))}).attr(\"fill\",this.colors[1]),J.exit().remove();var tt=this.mainGroup.selectAll(\".force-bar-array-divider-pos\").data(this.currUsedFeatures);tt.enter().append(\"path\").attr(\"class\",\"force-bar-array-divider-pos\").merge(tt).attr(\"d\",function(t){var e=(0,y.map)((0,y.range)(P),function(e){return[v[e].xmapScaled,v[e].features[t].posyBottom]});return Z(e)}).attr(\"fill\",\"none\").attr(\"stroke-width\",1).attr(\"stroke\",function(){return t.colors[0].brighter(1.2)}),tt.exit().remove();var et=this.mainGroup.selectAll(\".force-bar-array-divider-neg\").data(this.currUsedFeatures);et.enter().append(\"path\").attr(\"class\",\"force-bar-array-divider-neg\").merge(et).attr(\"d\",function(t){var e=(0,y.map)((0,y.range)(P),function(e){return[v[e].xmapScaled,v[e].features[t].negyTop]});return Z(e)}).attr(\"fill\",\"none\").attr(\"stroke-width\",1).attr(\"stroke\",function(){return t.colors[1].brighter(1.5)}),et.exit().remove();for(var nt=function(t,e,n,r,i){var o=void 0,a=void 0;\"pos\"===i?(o=t[n].features[e].posyBottom,a=t[n].features[e].posyTop):(o=t[n].features[e].negyBottom,a=t[n].features[e].negyTop);for(var u=void 0,c=void 0,s=n+1;s<=r;++s)\"pos\"===i?(u=t[s].features[e].posyBottom,c=t[s].features[e].posyTop):(u=t[s].features[e].negyBottom,c=t[s].features[e].negyTop),u>o&&(o=u),c<a&&(a=c);return{top:o,bottom:a}},rt=100,it=20,ot=100,at=[],ut=[\"pos\",\"neg\"],ct=0;ct<ut.length;ct++){var st=ut[ct],lt=!0,ft=!1,pt=void 0;try{for(var ht,dt=this.currUsedFeatures[Symbol.iterator]();!(lt=(ht=dt.next()).done);lt=!0)for(var vt=ht.value,gt=0,mt=0,yt=0,_t={top:0,bottom:0},bt=void 0;mt<P-1;){for(;yt<rt&&mt<P-1;)++mt,yt=v[mt].xmapScaled-v[gt].xmapScaled;for(_t=nt(v,vt,gt,mt,st);_t.bottom-_t.top<it&&gt<mt;)++gt,_t=nt(v,vt,gt,mt,st);if(yt=v[mt].xmapScaled-v[gt].xmapScaled,_t.bottom-_t.top>=it&&yt>=rt){for(;mt<P-1;){if(++mt,bt=nt(v,vt,gt,mt,st),!(bt.bottom-bt.top>it)){--mt;break}_t=bt}yt=v[mt].xmapScaled-v[gt].xmapScaled,at.push([(v[mt].xmapScaled+v[gt].xmapScaled)/2,(_t.top+_t.bottom)/2,this.props.featureNames[vt]]);var xt=v[mt].xmapScaled;for(gt=mt;xt+ot>v[gt].xmapScaled&&gt<P-1;)++gt;mt=gt}}}catch(t){ft=!0,pt=t}finally{try{!lt&&dt.return&&dt.return()}finally{if(ft)throw pt}}}var wt=this.onTopGroup.selectAll(\".force-bar-array-flabels\").data(at);wt.enter().append(\"text\").attr(\"class\",\"force-bar-array-flabels\").merge(wt).attr(\"x\",function(t){return t[0]}).attr(\"y\",function(t){return t[1]+4}).text(function(t){return t[2]}),wt.exit().remove()}},{key:\"componentWillUnmount\",value:function(){window.removeEventListener(\"resize\",this.redraw)}},{key:\"render\",value:function(){var t=this;return l.default.createElement(\"div\",{ref:function(e){return t.wrapper=(0,f.select)(e)},style:{textAlign:\"center\"}},l.default.createElement(\"style\",{dangerouslySetInnerHTML:{__html:\"\\n          .force-bar-array-wrapper {\\n            text-align: center;\\n          }\\n          .force-bar-array-xaxis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-array-xaxis .domain {\\n            opacity: 0;\\n          }\\n          .force-bar-array-xaxis paths {\\n            display: none;\\n          }\\n          .force-bar-array-yaxis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-array-yaxis paths {\\n            display: none;\\n          }\\n          .tick line {\\n            stroke: #000;\\n            stroke-width: 1px;\\n            opacity: 0.4;\\n          }\\n          .tick text {\\n            fill: #000;\\n            opacity: 0.5;\\n            font-size: 12px;\\n            padding: 0px;\\n          }\\n          .force-bar-array-flabels {\\n            font-size: 12px;\\n            fill: #fff;\\n            text-anchor: middle;\\n          }\\n          .additive-force-array-xlabel {\\n            background: none;\\n            border: 1px solid #ccc;\\n            opacity: 0.5;\\n            margin-bottom: 0px;\\n            font-size: 12px;\\n            font-family: arial;\\n            margin-left: 80px;\\n            max-width: 300px;\\n          }\\n          .additive-force-array-xlabel:focus {\\n            outline: none;\\n          }\\n          .additive-force-array-ylabel {\\n            position: relative;\\n            top: 0px;\\n            left: 0px;\\n            transform: rotate(-90deg);\\n            background: none;\\n            border: 1px solid #ccc;\\n            opacity: 0.5;\\n            margin-bottom: 0px;\\n            font-size: 12px;\\n            font-family: arial;\\n            max-width: 150px;\\n          }\\n          .additive-force-array-ylabel:focus {\\n            outline: none;\\n          }\\n          .additive-force-array-hoverLine {\\n            stroke-width: 1px;\\n            stroke: #fff;\\n            opacity: 1;\\n          }\"}}),l.default.createElement(\"select\",{className:\"additive-force-array-xlabel\"}),l.default.createElement(\"div\",{style:{height:\"0px\",textAlign:\"left\"}},l.default.createElement(\"select\",{className:\"additive-force-array-ylabel\"})),l.default.createElement(\"svg\",{ref:function(e){return t.svg=(0,f.select)(e)},style:{userSelect:\"none\",display:\"block\",fontFamily:\"arial\",sansSerif:!0}}))}}]),e}(l.default.Component);x.defaultProps={plot_cmap:\"RdBu\",ordering_keys:null,ordering_keys_time_format:null},e.default=x},function(t,e,n){\"use strict\";function r(t){return t&&t.__esModule?t:{default:t}}function i(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}function o(t,e){if(!t)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return!e||\"object\"!=typeof e&&\"function\"!=typeof e?t:e}function a(t,e){if(\"function\"!=typeof e&&null!==e)throw new TypeError(\"Super expression must either be null or a function, not \"+typeof e);t.prototype=Object.create(e&&e.prototype,{constructor:{value:t,enumerable:!1,writable:!0,configurable:!0}}),e&&(Object.setPrototypeOf?Object.setPrototypeOf(t,e):t.__proto__=e)}Object.defineProperty(e,\"__esModule\",{value:!0});var u=function(){function t(t,e){for(var n=0;n<e.length;n++){var r=e[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(t,r.key,r)}}return function(e,n,r){return n&&t(e.prototype,n),r&&t(e,r),e}}(),c=n(41),s=r(c),l=n(129),f=n(64),p=n(30),h=n(112),d=n(134),v=n(10),g=n(39),m=n(56),y=r(m),b=function(t){function e(){i(this,e);var t=o(this,(e.__proto__||Object.getPrototypeOf(e)).call(this));return window.lastAdditiveForceVisualizer=t,t.effectFormat=(0,p.format)(\".2\"),t.redraw=(0,g.debounce)(function(){return t.draw()},200),t}return a(e,t),u(e,[{key:\"componentDidMount\",value:function(){var t=this;this.mainGroup=this.svg.append(\"g\"),this.axisElement=this.mainGroup.append(\"g\").attr(\"transform\",\"translate(0,35)\").attr(\"class\",\"force-bar-axis\"),this.onTopGroup=this.svg.append(\"g\"),this.baseValueTitle=this.svg.append(\"text\"),this.joinPointLine=this.svg.append(\"line\"),this.joinPointLabelOutline=this.svg.append(\"text\"),this.joinPointLabel=this.svg.append(\"text\"),this.joinPointTitleLeft=this.svg.append(\"text\"),this.joinPointTitleLeftArrow=this.svg.append(\"text\"),this.joinPointTitle=this.svg.append(\"text\"),this.joinPointTitleRightArrow=this.svg.append(\"text\"),this.joinPointTitleRight=this.svg.append(\"text\"),this.hoverLabelBacking=this.svg.append(\"text\").attr(\"x\",10).attr(\"y\",20).attr(\"text-anchor\",\"middle\").attr(\"font-size\",12).attr(\"stroke\",\"#fff\").attr(\"fill\",\"#fff\").attr(\"stroke-width\",\"4\").attr(\"stroke-linejoin\",\"round\").text(\"\").on(\"mouseover\",function(){t.hoverLabel.attr(\"opacity\",1),t.hoverLabelBacking.attr(\"opacity\",1)}).on(\"mouseout\",function(){t.hoverLabel.attr(\"opacity\",0),t.hoverLabelBacking.attr(\"opacity\",0)}),this.hoverLabel=this.svg.append(\"text\").attr(\"x\",10).attr(\"y\",20).attr(\"text-anchor\",\"middle\").attr(\"font-size\",12).attr(\"fill\",\"#0f0\").text(\"\").on(\"mouseover\",function(){t.hoverLabel.attr(\"opacity\",1),t.hoverLabelBacking.attr(\"opacity\",1)}).on(\"mouseout\",function(){t.hoverLabel.attr(\"opacity\",0),t.hoverLabelBacking.attr(\"opacity\",0)});var e=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in y.default.colors?e=y.default.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),e=y.default.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(e=this.props.plot_cmap),this.colors=e.map(function(t){return(0,v.hsl)(t)}),this.brighterColors=[1.45,1.6].map(function(e,n){return t.colors[n].brighter(e)}),this.colors.map(function(e,n){var r=t.svg.append(\"linearGradient\").attr(\"id\",\"linear-grad-\"+n).attr(\"x1\",\"0%\").attr(\"y1\",\"0%\").attr(\"x2\",\"0%\").attr(\"y2\",\"100%\");r.append(\"stop\").attr(\"offset\",\"0%\").attr(\"stop-color\",e).attr(\"stop-opacity\",.6),r.append(\"stop\").attr(\"offset\",\"100%\").attr(\"stop-color\",e).attr(\"stop-opacity\",0);var i=t.svg.append(\"linearGradient\").attr(\"id\",\"linear-backgrad-\"+n).attr(\"x1\",\"0%\").attr(\"y1\",\"0%\").attr(\"x2\",\"0%\").attr(\"y2\",\"100%\");i.append(\"stop\").attr(\"offset\",\"0%\").attr(\"stop-color\",e).attr(\"stop-opacity\",.5),i.append(\"stop\").attr(\"offset\",\"100%\").attr(\"stop-color\",e).attr(\"stop-opacity\",0)}),this.tickFormat=(0,p.format)(\",.4\"),this.scaleCentered=(0,f.scaleLinear)(),this.axis=(0,h.axisBottom)().scale(this.scaleCentered).tickSizeInner(4).tickSizeOuter(0).tickFormat(function(e){return t.tickFormat(t.invLinkFunction(e))}).tickPadding(-18),window.addEventListener(\"resize\",this.redraw),window.setTimeout(this.redraw,50)}},{key:\"componentDidUpdate\",value:function(){this.draw()}},{key:\"draw\",value:function(){var t=this;(0,g.each)(this.props.featureNames,function(e,n){t.props.features[n]&&(t.props.features[n].name=e)}),\"identity\"===this.props.link?this.invLinkFunction=function(e){return t.props.baseValue+e}:\"logit\"===this.props.link?this.invLinkFunction=function(e){return 1/(1+Math.exp(-(t.props.baseValue+e)))}:console.log(\"ERROR: Unrecognized link function: \",this.props.link);var e=this.svg.node().parentNode.offsetWidth;if(0==e)return setTimeout(function(){return t.draw(t.props)},500);this.svg.style(\"height\",\"150px\"),this.svg.style(\"width\",e+\"px\");var n=50,r=(0,g.sortBy)(this.props.features,function(t){return-1/(t.effect+1e-10)}),i=(0,g.sum)((0,g.map)(r,function(t){return Math.abs(t.effect)})),o=(0,g.sum)((0,g.map)((0,g.filter)(r,function(t){return t.effect>0}),function(t){return t.effect}))||0,a=(0,g.sum)((0,g.map)((0,g.filter)(r,function(t){return t.effect<0}),function(t){return-t.effect}))||0;this.domainSize=3*Math.max(o,a);var u=(0,f.scaleLinear)().domain([0,this.domainSize]).range([0,e]),c=e/2-u(a);this.scaleCentered.domain([-this.domainSize/2,this.domainSize/2]).range([0,e]).clamp(!0),this.axisElement.attr(\"transform\",\"translate(0,\"+n+\")\").call(this.axis);var s=0,l=void 0,h=void 0,v=void 0;for(l=0;l<r.length;++l)r[l].x=s,r[l].effect<0&&void 0===h&&(h=s,v=l),s+=Math.abs(r[l].effect);void 0===h&&(h=s,v=l);var m=(0,d.line)().x(function(t){return t[0]}).y(function(t){return t[1]}),y=function(e){return void 0!==e.value&&null!==e.value&&\"\"!==e.value?e.name+\" = \"+(isNaN(e.value)?e.value:t.tickFormat(e.value)):e.name};r=this.props.hideBars?[]:r;var b=this.mainGroup.selectAll(\".force-bar-blocks\").data(r);b.enter().append(\"path\").attr(\"class\",\"force-bar-blocks\").merge(b).attr(\"d\",function(t,e){var r=u(t.x)+c,i=u(Math.abs(t.effect)),o=t.effect<0?-4:4,a=o;return e===v&&(o=0),e===v-1&&(a=0),m([[r,6+n],[r+i,6+n],[r+i+a,14.5+n],[r+i,23+n],[r,23+n],[r+o,14.5+n]])}).attr(\"fill\",function(e){return e.effect>0?t.colors[0]:t.colors[1]}).on(\"mouseover\",function(e){if(u(Math.abs(e.effect))<u(i)/50||u(Math.abs(e.effect))<10){var r=u(e.x)+c,o=u(Math.abs(e.effect));t.hoverLabel.attr(\"opacity\",1).attr(\"x\",r+o/2).attr(\"y\",n+.5).attr(\"fill\",e.effect>0?t.colors[0]:t.colors[1]).text(y(e)),t.hoverLabelBacking.attr(\"opacity\",1).attr(\"x\",r+o/2).attr(\"y\",n+.5).text(y(e))}}).on(\"mouseout\",function(){t.hoverLabel.attr(\"opacity\",0),t.hoverLabelBacking.attr(\"opacity\",0)}),b.exit().remove();var x=_.filter(r,function(t){return u(Math.abs(t.effect))>u(i)/50&&u(Math.abs(t.effect))>10}),w=this.onTopGroup.selectAll(\".force-bar-labels\").data(x);if(w.exit().remove(),w=w.enter().append(\"text\").attr(\"class\",\"force-bar-labels\").attr(\"font-size\",\"12px\").attr(\"y\",48+n).merge(w).text(function(e){return void 0!==e.value&&null!==e.value&&\"\"!==e.value?e.name+\" = \"+(isNaN(e.value)?e.value:t.tickFormat(e.value)):e.name}).attr(\"fill\",function(e){return e.effect>0?t.colors[0]:t.colors[1]}).attr(\"stroke\",function(t){return t.textWidth=Math.max(this.getComputedTextLength(),u(Math.abs(t.effect))-10),t.innerTextWidth=this.getComputedTextLength(),\"none\"}),this.filteredData=x,r.length>0){s=h+u.invert(5);for(var C=v;C<r.length;++C)r[C].textx=s,s+=u.invert(r[C].textWidth+10);s=h-u.invert(5);for(var M=v-1;M>=0;--M)r[M].textx=s,s-=u.invert(r[M].textWidth+10)}w.attr(\"x\",function(t){return u(t.textx)+c+(t.effect>0?-t.textWidth/2:t.textWidth/2)}).attr(\"text-anchor\",\"middle\"),x=(0,g.filter)(x,function(n){return u(n.textx)+c>t.props.labelMargin&&u(n.textx)+c<e-t.props.labelMargin}),this.filteredData2=x;var k=x.slice(),E=(0,g.findIndex)(r,x[0])-1;E>=0&&k.unshift(r[E]);var T=this.mainGroup.selectAll(\".force-bar-labelBacking\").data(x);T.enter().append(\"path\").attr(\"class\",\"force-bar-labelBacking\").attr(\"stroke\",\"none\").attr(\"opacity\",.2).merge(T).attr(\"d\",function(t){return m([[u(t.x)+u(Math.abs(t.effect))+c,23+n],[(t.effect>0?u(t.textx):u(t.textx)+t.textWidth)+c+5,33+n],[(t.effect>0?u(t.textx):u(t.textx)+t.textWidth)+c+5,54+n],[(t.effect>0?u(t.textx)-t.textWidth:u(t.textx))+c-5,54+n],[(t.effect>0?u(t.textx)-t.textWidth:u(t.textx))+c-5,33+n],[u(t.x)+c,23+n]])}).attr(\"fill\",function(t){return\"url(#linear-backgrad-\"+(t.effect>0?0:1)+\")\"}),T.exit().remove();var S=this.mainGroup.selectAll(\".force-bar-labelDividers\").data(x.slice(0,-1));S.enter().append(\"rect\").attr(\"class\",\"force-bar-labelDividers\").attr(\"height\",\"21px\").attr(\"width\",\"1px\").attr(\"y\",33+n).merge(S).attr(\"x\",function(t){return(t.effect>0?u(t.textx):u(t.textx)+t.textWidth)+c+4.5}).attr(\"fill\",function(t){return\"url(#linear-grad-\"+(t.effect>0?0:1)+\")\"}),S.exit().remove();var P=this.mainGroup.selectAll(\".force-bar-labelLinks\").data(x.slice(0,-1));P.enter().append(\"line\").attr(\"class\",\"force-bar-labelLinks\").attr(\"y1\",23+n).attr(\"y2\",33+n).attr(\"stroke-opacity\",.5).attr(\"stroke-width\",1).merge(P).attr(\"x1\",function(t){return u(t.x)+u(Math.abs(t.effect))+c}).attr(\"x2\",function(t){return(t.effect>0?u(t.textx):u(t.textx)+t.textWidth)+c+5}).attr(\"stroke\",function(e){return e.effect>0?t.colors[0]:t.colors[1]}),P.exit().remove();var N=this.mainGroup.selectAll(\".force-bar-blockDividers\").data(r.slice(0,-1));N.enter().append(\"path\").attr(\"class\",\"force-bar-blockDividers\").attr(\"stroke-width\",2).attr(\"fill\",\"none\").merge(N).attr(\"d\",function(t){var e=u(t.x)+u(Math.abs(t.effect))+c;return m([[e,6+n],[e+(t.effect<0?-4:4),14.5+n],[e,23+n]])}).attr(\"stroke\",function(e,n){return v===n+1||Math.abs(e.effect)<1e-8?\"#rgba(0,0,0,0)\":e.effect>0?t.brighterColors[0]:t.brighterColors[1]}),N.exit().remove(),this.joinPointLine.attr(\"x1\",u(h)+c).attr(\"x2\",u(h)+c).attr(\"y1\",0+n).attr(\"y2\",6+n).attr(\"stroke\",\"#F2F2F2\").attr(\"stroke-width\",1).attr(\"opacity\",1),this.joinPointLabelOutline.attr(\"x\",u(h)+c).attr(\"y\",-5+n).attr(\"color\",\"#fff\").attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"stroke\",\"#fff\").attr(\"stroke-width\",6).text((0,p.format)(\",.2f\")(this.invLinkFunction(h-a))).attr(\"opacity\",1),console.log(\"joinPoint\",h,c,n,a),this.joinPointLabel.attr(\"x\",u(h)+c).attr(\"y\",-5+n).attr(\"text-anchor\",\"middle\").attr(\"font-weight\",\"bold\").attr(\"fill\",\"#000\").text((0,p.format)(\",.2f\")(this.invLinkFunction(h-a))).attr(\"opacity\",1),this.joinPointTitle.attr(\"x\",u(h)+c).attr(\"y\",-22+n).attr(\"text-anchor\",\"middle\").attr(\"font-size\",\"12\").attr(\"fill\",\"#000\").text(this.props.outNames[0]).attr(\"opacity\",.5),this.props.hideBars||(this.joinPointTitleLeft.attr(\"x\",u(h)+c-16).attr(\"y\",-38+n).attr(\"text-anchor\",\"end\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[0]).text(\"higher\").attr(\"opacity\",1),this.joinPointTitleRight.attr(\"x\",u(h)+c+16).attr(\"y\",-38+n).attr(\"text-anchor\",\"start\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[1]).text(\"lower\").attr(\"opacity\",1),this.joinPointTitleLeftArrow.attr(\"x\",u(h)+c+7).attr(\"y\",-42+n).attr(\"text-anchor\",\"end\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[0]).text(\"â†’\").attr(\"opacity\",1),this.joinPointTitleRightArrow.attr(\"x\",u(h)+c-7).attr(\"y\",-36+n).attr(\"text-anchor\",\"start\").attr(\"font-size\",\"13\").attr(\"fill\",this.colors[1]).text(\"â†\").attr(\"opacity\",1)),this.props.hideBaseValueLabel||this.baseValueTitle.attr(\"x\",this.scaleCentered(0)).attr(\"y\",-22+n).attr(\"text-anchor\",\"middle\").attr(\"font-size\",\"12\").attr(\"fill\",\"#000\").text(\"base value\").attr(\"opacity\",.5)}},{key:\"componentWillUnmount\",value:function(){window.removeEventListener(\"resize\",this.redraw)}},{key:\"render\",value:function(){var t=this;return s.default.createElement(\"svg\",{ref:function(e){return t.svg=(0,l.select)(e)},style:{userSelect:\"none\",display:\"block\",fontFamily:\"arial\",sansSerif:!0}},s.default.createElement(\"style\",{dangerouslySetInnerHTML:{__html:\"\\n          .force-bar-axis path {\\n            fill: none;\\n            opacity: 0.4;\\n          }\\n          .force-bar-axis paths {\\n            display: none;\\n          }\\n          .tick line {\\n            stroke: #000;\\n            stroke-width: 1px;\\n            opacity: 0.4;\\n          }\\n          .tick text {\\n            fill: #000;\\n            opacity: 0.5;\\n            font-size: 12px;\\n            padding: 0px;\\n          }\"}}))}}]),e}(s.default.Component);b.defaultProps={plot_cmap:\"RdBu\"},e.default=b},function(t,e,n){\"use strict\";function r(t){return t&&t.__esModule?t:{default:t}}function i(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}function o(t,e){if(!t)throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");return!e||\"object\"!=typeof e&&\"function\"!=typeof e?t:e}function a(t,e){if(\"function\"!=typeof e&&null!==e)throw new TypeError(\"Super expression must either be null or a function, not \"+typeof e);t.prototype=Object.create(e&&e.prototype,{constructor:{value:t,enumerable:!1,writable:!0,configurable:!0}}),e&&(Object.setPrototypeOf?Object.setPrototypeOf(t,e):t.__proto__=e)}Object.defineProperty(e,\"__esModule\",{value:!0});var u=function(){function t(t,e){for(var n=0;n<e.length;n++){var r=e[n];r.enumerable=r.enumerable||!1,r.configurable=!0,\"value\"in r&&(r.writable=!0),Object.defineProperty(t,r.key,r)}}return function(e,n,r){return n&&t(e.prototype,n),r&&t(e,r),e}}(),c=n(41),s=r(c),l=n(64),f=n(30),p=n(39),h=n(56),d=r(h),v=function(t){function e(){i(this,e);var t=o(this,(e.__proto__||Object.getPrototypeOf(e)).call(this));return t.width=100,window.lastSimpleListInstance=t,t.effectFormat=(0,f.format)(\".2\"),t}return a(e,t),u(e,[{key:\"render\",value:function(){var t=this,e=void 0;\"string\"==typeof this.props.plot_cmap?this.props.plot_cmap in d.default.colors?e=d.default.colors[this.props.plot_cmap]:(console.log(\"Invalid color map name, reverting to default.\"),e=d.default.colors.RdBu):Array.isArray(this.props.plot_cmap)&&(e=this.props.plot_cmap),console.log(this.props.features,this.props.features),this.scale=(0,l.scaleLinear)().domain([0,(0,p.max)((0,p.map)(this.props.features,function(t){return Math.abs(t.effect)}))]).range([0,this.width]);var n=(0,p.reverse)((0,p.sortBy)(Object.keys(this.props.features),function(e){return Math.abs(t.props.features[e].effect)})),r=n.map(function(n){var r=t.props.features[n],i=t.props.featureNames[n],o={width:t.scale(Math.abs(r.effect)),height:\"20px\",background:r.effect<0?e[0]:e[1],display:\"inline-block\"},a=void 0,u=void 0,c={lineHeight:\"20px\",display:\"inline-block\",width:t.width+40,verticalAlign:\"top\",marginRight:\"5px\",textAlign:\"right\"},l={lineHeight:\"20px\",display:\"inline-block\",width:t.width+40,verticalAlign:\"top\",marginLeft:\"5px\"};return r.effect<0?(u=s.default.createElement(\"span\",{style:l},i),c.width=40+t.width-t.scale(Math.abs(r.effect)),c.textAlign=\"right\",c.color=\"#999\",c.fontSize=\"13px\",a=s.default.createElement(\"span\",{style:c},t.effectFormat(r.effect))):(c.textAlign=\"right\",a=s.default.createElement(\"span\",{style:c},i),l.width=40,l.textAlign=\"left\",l.color=\"#999\",l.fontSize=\"13px\",u=s.default.createElement(\"span\",{style:l},t.effectFormat(r.effect))),s.default.createElement(\"div\",{key:n,style:{marginTop:\"2px\"}},a,s.default.createElement(\"div\",{style:o}),u)});return s.default.createElement(\"span\",null,r)}}]),e}(s.default.Component);v.defaultProps={plot_cmap:\"RdBu\"},e.default=v},function(t,e,n){\"use strict\";t.exports=n(345)},function(t,e,n){var r=(n(0),n(398)),i=!1;t.exports=function(t){t=t||{};var e=t.shouldRejectClick||r;i=!0,n(22).injection.injectEventPluginsByName({TapEventPlugin:n(396)(e)})}},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";n(101),n(102),n(184),n(105),n(187),n(109),n(108)},function(t,e,n){\"use strict\";e.a=function(t){return t}},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";n(29)},function(t,e,n){\"use strict\";n(18),n(29),n(57)},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";n(18)},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";n(101),n(18),n(29),n(57)},function(t,e,n){\"use strict\";n(104)},function(t,e,n){\"use strict\";n(110)},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return r});var r=Array.prototype.slice},function(t,e,n){\"use strict\";function r(t,e,n){var r=t(n);return\"translate(\"+(isFinite(r)?r:e(n))+\",0)\"}function i(t,e,n){var r=t(n);return\"translate(0,\"+(isFinite(r)?r:e(n))+\")\"}function o(t){var e=t.bandwidth()/2;return t.round()&&(e=Math.round(e)),function(n){return t(n)+e}}function a(){return!this.__axis}function u(t,e){function n(n){var p,b=null==c?e.ticks?e.ticks.apply(e,u):e.domain():c,x=null==s?e.tickFormat?e.tickFormat.apply(e,u):h.a:s,w=Math.max(l,0)+_,C=t===d||t===g?r:i,M=e.range(),k=M[0]+.5,E=M[M.length-1]+.5,T=(e.bandwidth?o:h.a)(e.copy()),S=n.selection?n.selection():n,P=S.selectAll(\".domain\").data([null]),N=S.selectAll(\".tick\").data(b,e).order(),A=N.exit(),O=N.enter().append(\"g\").attr(\"class\",\"tick\"),I=N.select(\"line\"),D=N.select(\"text\"),R=t===d||t===m?-1:1,L=t===m||t===v?(p=\"x\",\"y\"):(p=\"y\",\"x\");P=P.merge(P.enter().insert(\"path\",\".tick\").attr(\"class\",\"domain\").attr(\"stroke\",\"#000\")),N=N.merge(O),I=I.merge(O.append(\"line\").attr(\"stroke\",\"#000\").attr(p+\"2\",R*l).attr(L+\"1\",.5).attr(L+\"2\",.5)),D=D.merge(O.append(\"text\").attr(\"fill\",\"#000\").attr(p,R*w).attr(L,.5).attr(\"dy\",t===d?\"0em\":t===g?\"0.71em\":\"0.32em\")),n!==S&&(P=P.transition(n),N=N.transition(n),I=I.transition(n),D=D.transition(n),A=A.transition(n).attr(\"opacity\",y).attr(\"transform\",function(t){return C(T,this.parentNode.__axis||T,t)}),O.attr(\"opacity\",y).attr(\"transform\",function(t){return C(this.parentNode.__axis||T,T,t)})),A.remove(),P.attr(\"d\",t===m||t==v?\"M\"+R*f+\",\"+k+\"H0.5V\"+E+\"H\"+R*f:\"M\"+k+\",\"+R*f+\"V0.5H\"+E+\"V\"+R*f),N.attr(\"opacity\",1).attr(\"transform\",function(t){return C(T,T,t)}),I.attr(p+\"2\",R*l),D.attr(p,R*w).text(x),S.filter(a).attr(\"fill\",\"none\").attr(\"font-size\",10).attr(\"font-family\",\"sans-serif\").attr(\"text-anchor\",t===v?\"start\":t===m?\"end\":\"middle\"),S.each(function(){this.__axis=T})}var u=[],c=null,s=null,l=6,f=6,_=3;return n.scale=function(t){return arguments.length?(e=t,n):e},n.ticks=function(){return u=p.a.call(arguments),n},n.tickArguments=function(t){return arguments.length?(u=null==t?[]:p.a.call(t),n):u.slice()},n.tickValues=function(t){return arguments.length?(c=null==t?null:p.a.call(t),n):c&&c.slice()},n.tickFormat=function(t){return arguments.length?(s=t,n):s},n.tickSize=function(t){return arguments.length?(l=f=+t,n):l},n.tickSizeInner=function(t){return arguments.length?(l=+t,n):l},n.tickSizeOuter=function(t){return arguments.length?(f=+t,n):f},n.tickPadding=function(t){return arguments.length?(_=+t,n):_},n}function c(t){return u(d,t)}function s(t){return u(v,t)}function l(t){return u(g,t)}function f(t){return u(m,t)}var p=n(200),h=n(202);e.a=c,e.b=s,e.c=l,e.d=f;var d=1,v=2,g=3,m=4,y=1e-6},function(t,e,n){\"use strict\";e.a=function(t){return t}},function(t,e,n){\"use strict\";var r=(n(206),n(207),n(58));n.d(e,\"a\",function(){return r.a});n(205),n(208),n(204)},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";n(58)},function(t,e,n){\"use strict\";function r(){}function i(t,e){var n=new r;if(t instanceof r)t.each(function(t){n.add(t)});else if(t){var i=-1,o=t.length;if(null==e)for(;++i<o;)n.add(t[i]);else for(;++i<o;)n.add(e(t[i],i,t))}return n}var o=n(58),a=o.a.prototype;r.prototype=i.prototype={constructor:r,has:a.has,add:function(t){return t+=\"\",this[o.b+t]=t,this},remove:a.remove,clear:a.clear,values:a.keys,size:a.size,empty:a.empty,each:a.each}},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";function r(t){if(t instanceof o)return new o(t.h,t.s,t.l,t.opacity);t instanceof u.d||(t=n.i(u.e)(t));var e=t.r/255,r=t.g/255,i=t.b/255,a=(g*i+d*e-v*r)/(g+d-v),s=i-a,l=(h*(r-a)-f*s)/p,m=Math.sqrt(l*l+s*s)/(h*a*(1-a)),y=m?Math.atan2(l,s)*c.a-120:NaN;return new o(y<0?y+360:y,m,a,t.opacity)}function i(t,e,n,i){return 1===arguments.length?r(t):new o(t,e,n,null==i?1:i)}function o(t,e,n,r){this.h=+t,this.s=+e,this.l=+n,this.opacity=+r}var a=n(60),u=n(59),c=n(113);e.a=i;var s=-.14861,l=1.78277,f=-.29227,p=-.90649,h=1.97294,d=h*p,v=h*l,g=l*f-p*s;n.i(a.a)(o,i,n.i(a.b)(u.f,{brighter:function(t){return t=null==t?u.g:Math.pow(u.g,t),new o(this.h,this.s,this.l*t,this.opacity)},darker:function(t){return t=null==t?u.h:Math.pow(u.h,t),new o(this.h,this.s,this.l*t,this.opacity)},rgb:function(){var t=isNaN(this.h)?0:(this.h+120)*c.b,e=+this.l,n=isNaN(this.s)?0:this.s*e*(1-e),r=Math.cos(t),i=Math.sin(t);return new u.d(255*(e+n*(s*r+l*i)),255*(e+n*(f*r+p*i)),255*(e+n*(h*r)),this.opacity)}}))},function(t,e,n){\"use strict\";function r(t){if(t instanceof o)return new o(t.l,t.a,t.b,t.opacity);if(t instanceof p){var e=t.h*v.b;return new o(t.l,Math.cos(e)*t.c,Math.sin(e)*t.c,t.opacity)}t instanceof d.d||(t=n.i(d.e)(t));var r=s(t.r),i=s(t.g),u=s(t.b),c=a((.4124564*r+.3575761*i+.1804375*u)/m),l=a((.2126729*r+.7151522*i+.072175*u)/y),f=a((.0193339*r+.119192*i+.9503041*u)/_);return new o(116*l-16,500*(c-l),200*(l-f),t.opacity)}function i(t,e,n,i){return 1===arguments.length?r(t):new o(t,e,n,null==i?1:i)}function o(t,e,n,r){this.l=+t,this.a=+e,this.b=+n,this.opacity=+r}function a(t){return t>C?Math.pow(t,1/3):t/w+b}function u(t){return t>x?t*t*t:w*(t-b)}function c(t){return 255*(t<=.0031308?12.92*t:1.055*Math.pow(t,1/2.4)-.055)}function s(t){return(t/=255)<=.04045?t/12.92:Math.pow((t+.055)/1.055,2.4)}function l(t){if(t instanceof p)return new p(t.h,t.c,t.l,t.opacity);t instanceof o||(t=r(t));var e=Math.atan2(t.b,t.a)*v.a;return new p(e<0?e+360:e,Math.sqrt(t.a*t.a+t.b*t.b),t.l,t.opacity)}function f(t,e,n,r){return 1===arguments.length?l(t):new p(t,e,n,null==r?1:r)}function p(t,e,n,r){this.h=+t,this.c=+e,this.l=+n,this.opacity=+r}var h=n(60),d=n(59),v=n(113);e.a=i,e.b=f;var g=18,m=.95047,y=1,_=1.08883,b=4/29,x=6/29,w=3*x*x,C=x*x*x;n.i(h.a)(o,i,n.i(h.b)(d.f,{brighter:function(t){return new o(this.l+g*(null==t?1:t),this.a,this.b,this.opacity)},darker:function(t){return new o(this.l-g*(null==t?1:t),this.a,this.b,this.opacity)},rgb:function(){var t=(this.l+16)/116,e=isNaN(this.a)?t:t+this.a/500,n=isNaN(this.b)?t:t-this.b/200;return t=y*u(t),e=m*u(e),n=_*u(n),new d.d(c(3.2404542*e-1.5371385*t-.4985314*n),c(-.969266*e+1.8760108*t+.041556*n),c(.0556434*e-.2040259*t+1.0572252*n),this.opacity)}})),n.i(h.a)(p,f,n.i(h.b)(d.f,{brighter:function(t){return new p(this.h,this.c,this.l+g*(null==t?1:t),this.opacity)},darker:function(t){return new p(this.h,this.c,this.l-g*(null==t?1:t),this.opacity)},rgb:function(){return r(this).rgb()}}))},function(t,e,n){\"use strict\";function r(t){return o=n.i(i.a)(t),a=o.format,u=o.formatPrefix,o}var i=n(117);n.d(e,\"b\",function(){return a}),n.d(e,\"c\",function(){\n",
       "return u}),e.a=r;var o,a,u;r({decimal:\".\",thousands:\",\",grouping:[3],currency:[\"$\",\"\"]})},function(t,e,n){\"use strict\";e.a=function(t,e){t=t.toPrecision(e);t:for(var n,r=t.length,i=1,o=-1;i<r;++i)switch(t[i]){case\".\":o=n=i;break;case\"0\":0===o&&(o=i),n=i;break;case\"e\":break t;default:o>0&&(o=0)}return o>0?t.slice(0,o)+t.slice(n+1):t}},function(t,e,n){\"use strict\";e.a=function(t,e){return function(n,r){for(var i=n.length,o=[],a=0,u=t[0],c=0;i>0&&u>0&&(c+u+1>r&&(u=Math.max(1,r-c)),o.push(n.substring(i-=u,i+u)),!((c+=u+1)>r));)u=t[a=(a+1)%t.length];return o.reverse().join(e)}}},function(t,e,n){\"use strict\";var r=n(61);e.a=function(t,e){var i=n.i(r.a)(t,e);if(!i)return t+\"\";var o=i[0],a=i[1];return a<0?\"0.\"+new Array(-a).join(\"0\")+o:o.length>a+1?o.slice(0,a+1)+\".\"+o.slice(a+1):o+new Array(a-o.length+2).join(\"0\")}},function(t,e,n){\"use strict\";var r=n(42);e.a=function(t){return Math.max(0,-n.i(r.a)(Math.abs(t)))}},function(t,e,n){\"use strict\";var r=n(42);e.a=function(t,e){return Math.max(0,3*Math.max(-8,Math.min(8,Math.floor(n.i(r.a)(e)/3)))-n.i(r.a)(Math.abs(t)))}},function(t,e,n){\"use strict\";var r=n(42);e.a=function(t,e){return t=Math.abs(t),e=Math.abs(e)-t,Math.max(0,n.i(r.a)(e)-n.i(r.a)(t))+1}},function(t,e,n){\"use strict\";function r(t){return function e(r){function a(e,a){var u=t((e=n.i(i.cubehelix)(e)).h,(a=n.i(i.cubehelix)(a)).h),c=n.i(o.a)(e.s,a.s),s=n.i(o.a)(e.l,a.l),l=n.i(o.a)(e.opacity,a.opacity);return function(t){return e.h=u(t),e.s=c(t),e.l=s(Math.pow(t,r)),e.opacity=l(t),e+\"\"}}return r=+r,a.gamma=e,a}(1)}var i=n(10),o=n(32);n.d(e,\"a\",function(){return a});var a=(r(o.b),r(o.a))},function(t,e,n){\"use strict\";function r(t){return function(e,r){var a=t((e=n.i(i.hcl)(e)).h,(r=n.i(i.hcl)(r)).h),u=n.i(o.a)(e.c,r.c),c=n.i(o.a)(e.l,r.l),s=n.i(o.a)(e.opacity,r.opacity);return function(t){return e.h=a(t),e.c=u(t),e.l=c(t),e.opacity=s(t),e+\"\"}}}var i=n(10),o=n(32);r(o.b),r(o.a)},function(t,e,n){\"use strict\";function r(t){return function(e,r){var a=t((e=n.i(i.hsl)(e)).h,(r=n.i(i.hsl)(r)).h),u=n.i(o.a)(e.s,r.s),c=n.i(o.a)(e.l,r.l),s=n.i(o.a)(e.opacity,r.opacity);return function(t){return e.h=a(t),e.s=u(t),e.l=c(t),e.opacity=s(t),e+\"\"}}}var i=n(10),o=n(32);r(o.b),r(o.a)},function(t,e,n){\"use strict\";n(10),n(32)},function(t,e,n){\"use strict\"},function(t,e,n){\"use strict\";e.a=function(t,e){return t=+t,e-=t,function(n){return Math.round(t+e*n)}}},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return i});var r=180/Math.PI,i={translateX:0,translateY:0,rotate:0,skewX:0,scaleX:1,scaleY:1};e.b=function(t,e,n,i,o,a){var u,c,s;return(u=Math.sqrt(t*t+e*e))&&(t/=u,e/=u),(s=t*n+e*i)&&(n-=t*s,i-=e*s),(c=Math.sqrt(n*n+i*i))&&(n/=c,i/=c,s/=c),t*i<e*n&&(t=-t,e=-e,s=-s,u=-u),{translateX:o,translateY:a,rotate:Math.atan2(e,t)*r,skewX:Math.atan(s)*r,scaleX:u,scaleY:c}}},function(t,e,n){\"use strict\";function r(t,e,r,o){function a(t){return t.length?t.pop()+\" \":\"\"}function u(t,o,a,u,c,s){if(t!==a||o!==u){var l=c.push(\"translate(\",null,e,null,r);s.push({i:l-4,x:n.i(i.a)(t,a)},{i:l-2,x:n.i(i.a)(o,u)})}else(a||u)&&c.push(\"translate(\"+a+e+u+r)}function c(t,e,r,u){t!==e?(t-e>180?e+=360:e-t>180&&(t+=360),u.push({i:r.push(a(r)+\"rotate(\",null,o)-2,x:n.i(i.a)(t,e)})):e&&r.push(a(r)+\"rotate(\"+e+o)}function s(t,e,r,u){t!==e?u.push({i:r.push(a(r)+\"skewX(\",null,o)-2,x:n.i(i.a)(t,e)}):e&&r.push(a(r)+\"skewX(\"+e+o)}function l(t,e,r,o,u,c){if(t!==r||e!==o){var s=u.push(a(u)+\"scale(\",null,\",\",null,\")\");c.push({i:s-4,x:n.i(i.a)(t,r)},{i:s-2,x:n.i(i.a)(e,o)})}else 1===r&&1===o||u.push(a(u)+\"scale(\"+r+\",\"+o+\")\")}return function(e,n){var r=[],i=[];return e=t(e),n=t(n),u(e.translateX,e.translateY,n.translateX,n.translateY,r,i),c(e.rotate,n.rotate,r,i),s(e.skewX,n.skewX,r,i),l(e.scaleX,e.scaleY,n.scaleX,n.scaleY,r,i),e=n=null,function(t){for(var e,n=-1,o=i.length;++n<o;)r[(e=i[n]).i]=e.x(t);return r.join(\"\")}}}var i=n(43),o=n(226);r(o.a,\"px, \",\"px)\",\"deg)\"),r(o.b,\", \",\")\",\")\")},function(t,e,n){\"use strict\";function r(t){return\"none\"===t?o.a:(a||(a=document.createElement(\"DIV\"),u=document.documentElement,c=document.defaultView),a.style.transform=t,t=c.getComputedStyle(u.appendChild(a),null).getPropertyValue(\"transform\"),u.removeChild(a),t=t.slice(7,-1).split(\",\"),n.i(o.b)(+t[0],+t[1],+t[2],+t[3],+t[4],+t[5]))}function i(t){return null==t?o.a:(s||(s=document.createElementNS(\"http://www.w3.org/2000/svg\",\"g\")),s.setAttribute(\"transform\",t),(t=s.transform.baseVal.consolidate())?(t=t.matrix,n.i(o.b)(t.a,t.b,t.c,t.d,t.e,t.f)):o.a)}var o=n(224);e.a=r,e.b=i;var a,u,c,s},function(t,e,n){\"use strict\";Math.SQRT2},function(t,e,n){\"use strict\";function r(){this._x0=this._y0=this._x1=this._y1=null,this._=\"\"}function i(){return new r}var o=Math.PI,a=2*o,u=1e-6,c=a-u;r.prototype=i.prototype={constructor:r,moveTo:function(t,e){this._+=\"M\"+(this._x0=this._x1=+t)+\",\"+(this._y0=this._y1=+e)},closePath:function(){null!==this._x1&&(this._x1=this._x0,this._y1=this._y0,this._+=\"Z\")},lineTo:function(t,e){this._+=\"L\"+(this._x1=+t)+\",\"+(this._y1=+e)},quadraticCurveTo:function(t,e,n,r){this._+=\"Q\"+ +t+\",\"+ +e+\",\"+(this._x1=+n)+\",\"+(this._y1=+r)},bezierCurveTo:function(t,e,n,r,i,o){this._+=\"C\"+ +t+\",\"+ +e+\",\"+ +n+\",\"+ +r+\",\"+(this._x1=+i)+\",\"+(this._y1=+o)},arcTo:function(t,e,n,r,i){t=+t,e=+e,n=+n,r=+r,i=+i;var a=this._x1,c=this._y1,s=n-t,l=r-e,f=a-t,p=c-e,h=f*f+p*p;if(i<0)throw new Error(\"negative radius: \"+i);if(null===this._x1)this._+=\"M\"+(this._x1=t)+\",\"+(this._y1=e);else if(h>u)if(Math.abs(p*s-l*f)>u&&i){var d=n-a,v=r-c,g=s*s+l*l,m=d*d+v*v,y=Math.sqrt(g),_=Math.sqrt(h),b=i*Math.tan((o-Math.acos((g+h-m)/(2*y*_)))/2),x=b/_,w=b/y;Math.abs(x-1)>u&&(this._+=\"L\"+(t+x*f)+\",\"+(e+x*p)),this._+=\"A\"+i+\",\"+i+\",0,0,\"+ +(p*d>f*v)+\",\"+(this._x1=t+w*s)+\",\"+(this._y1=e+w*l)}else this._+=\"L\"+(this._x1=t)+\",\"+(this._y1=e);else;},arc:function(t,e,n,r,i,s){t=+t,e=+e,n=+n;var l=n*Math.cos(r),f=n*Math.sin(r),p=t+l,h=e+f,d=1^s,v=s?r-i:i-r;if(n<0)throw new Error(\"negative radius: \"+n);null===this._x1?this._+=\"M\"+p+\",\"+h:(Math.abs(this._x1-p)>u||Math.abs(this._y1-h)>u)&&(this._+=\"L\"+p+\",\"+h),n&&(v>c?this._+=\"A\"+n+\",\"+n+\",0,1,\"+d+\",\"+(t-l)+\",\"+(e-f)+\"A\"+n+\",\"+n+\",0,1,\"+d+\",\"+(this._x1=p)+\",\"+(this._y1=h):(v<0&&(v=v%a+a),this._+=\"A\"+n+\",\"+n+\",0,\"+ +(v>=o)+\",\"+d+\",\"+(this._x1=t+n*Math.cos(i))+\",\"+(this._y1=e+n*Math.sin(i))))},rect:function(t,e,n,r){this._+=\"M\"+(this._x0=this._x1=+t)+\",\"+(this._y0=this._y1=+e)+\"h\"+ +n+\"v\"+ +r+\"h\"+-n+\"Z\"},toString:function(){return this._}},e.a=i},function(t,e,n){\"use strict\";function r(){function t(){var t=c().length,r=l[1]<l[0],o=l[r-0],u=l[1-r];e=(u-o)/Math.max(1,t-p+2*h),f&&(e=Math.floor(e)),o+=(u-o-e*(t-p))*d,i=e*(1-p),f&&(o=Math.round(o),i=Math.round(i));var v=n.i(a.g)(t).map(function(t){return o+e*t});return s(r?v.reverse():v)}var e,i,o=n.i(u.a)().unknown(void 0),c=o.domain,s=o.range,l=[0,1],f=!1,p=0,h=0,d=.5;return delete o.unknown,o.domain=function(e){return arguments.length?(c(e),t()):c()},o.range=function(e){return arguments.length?(l=[+e[0],+e[1]],t()):l.slice()},o.rangeRound=function(e){return l=[+e[0],+e[1]],f=!0,t()},o.bandwidth=function(){return i},o.step=function(){return e},o.round=function(e){return arguments.length?(f=!!e,t()):f},o.padding=function(e){return arguments.length?(p=h=Math.max(0,Math.min(1,e)),t()):p},o.paddingInner=function(e){return arguments.length?(p=Math.max(0,Math.min(1,e)),t()):p},o.paddingOuter=function(e){return arguments.length?(h=Math.max(0,Math.min(1,e)),t()):h},o.align=function(e){return arguments.length?(d=Math.max(0,Math.min(1,e)),t()):d},o.copy=function(){return r().domain(c()).range(l).round(f).paddingInner(p).paddingOuter(h).align(d)},t()}function i(t){var e=t.copy;return t.padding=t.paddingOuter,delete t.paddingInner,delete t.paddingOuter,t.copy=function(){return i(e())},t}function o(){return i(r().paddingInner(1))}var a=n(12),u=n(127);e.a=r,e.b=o},function(t,e,n){\"use strict\";var r=n(33);e.a=n.i(r.a)(\"1f77b4ff7f0e2ca02cd627289467bd8c564be377c27f7f7fbcbd2217becf\")},function(t,e,n){\"use strict\";var r=n(33);e.a=n.i(r.a)(\"1f77b4aec7e8ff7f0effbb782ca02c98df8ad62728ff98969467bdc5b0d58c564bc49c94e377c2f7b6d27f7f7fc7c7c7bcbd22dbdb8d17becf9edae5\")},function(t,e,n){\"use strict\";var r=n(33);e.a=n.i(r.a)(\"393b795254a36b6ecf9c9ede6379398ca252b5cf6bcedb9c8c6d31bd9e39e7ba52e7cb94843c39ad494ad6616be7969c7b4173a55194ce6dbdde9ed6\")},function(t,e,n){\"use strict\";var r=n(33);e.a=n.i(r.a)(\"3182bd6baed69ecae1c6dbefe6550dfd8d3cfdae6bfdd0a231a35474c476a1d99bc7e9c0756bb19e9ac8bcbddcdadaeb636363969696bdbdbdd9d9d9\")},function(t,e,n){\"use strict\";var r=n(10),i=n(31);e.a=n.i(i.d)(n.i(r.cubehelix)(300,.5,0),n.i(r.cubehelix)(-240,.5,1))},function(t,e,n){\"use strict\";function r(){function t(t){return+t}var e=[0,1];return t.invert=t,t.domain=t.range=function(n){return arguments.length?(e=i.a.call(n,a.a),t):e.slice()},t.copy=function(){return r().domain(e)},n.i(o.b)(t)}var i=n(16),o=n(34),a=n(126);e.a=r},function(t,e,n){\"use strict\";function r(t,e){return(e=Math.log(e/t))?function(n){return Math.log(n/t)/e}:n.i(p.a)(e)}function i(t,e){return t<0?function(n){return-Math.pow(-e,n)*Math.pow(-t,1-n)}:function(n){return Math.pow(e,n)*Math.pow(t,1-n)}}function o(t){return isFinite(t)?+(\"1e\"+t):t<0?0:t}function a(t){return 10===t?o:t===Math.E?Math.exp:function(e){return Math.pow(t,e)}}function u(t){return t===Math.E?Math.log:10===t&&Math.log10||2===t&&Math.log2||(t=Math.log(t),function(e){return Math.log(e)/t})}function c(t){return function(e){return-t(-e)}}function s(){function t(){return v=u(p),g=a(p),o()[0]<0&&(v=c(v),g=c(g)),e}var e=n.i(d.a)(r,i).domain([1,10]),o=e.domain,p=10,v=u(10),g=a(10);return e.base=function(e){return arguments.length?(p=+e,t()):p},e.domain=function(e){return arguments.length?(o(e),t()):o()},e.ticks=function(t){var e,r=o(),i=r[0],a=r[r.length-1];(e=a<i)&&(f=i,i=a,a=f);var u,c,s,f=v(i),h=v(a),d=null==t?10:+t,m=[];if(!(p%1)&&h-f<d){if(f=Math.round(f)-1,h=Math.round(h)+1,i>0){for(;f<h;++f)for(c=1,u=g(f);c<p;++c)if(s=u*c,!(s<i)){if(s>a)break;m.push(s)}}else for(;f<h;++f)for(c=p-1,u=g(f);c>=1;--c)if(s=u*c,!(s<i)){if(s>a)break;m.push(s)}}else m=n.i(l.a)(f,h,Math.min(h-f,d)).map(g);return e?m.reverse():m},e.tickFormat=function(t,r){if(null==r&&(r=10===p?\".0e\":\",\"),\"function\"!=typeof r&&(r=n.i(f.format)(r)),t===1/0)return r;null==t&&(t=10);var i=Math.max(1,p*t/e.ticks().length);return function(t){var e=t/g(Math.round(v(t)));return e*p<p-.5&&(e*=p),e<=i?r(t):\"\"}},e.nice=function(){return o(n.i(h.a)(o(),{floor:function(t){return g(Math.floor(v(t)))},ceil:function(t){return g(Math.ceil(v(t)))}}))},e.copy=function(){return n.i(d.c)(e,s().base(p))},e}var l=n(12),f=n(30),p=n(65),h=n(125),d=n(45);e.a=s},function(t,e,n){\"use strict\";function r(t,e){return t<0?-Math.pow(-t,e):Math.pow(t,e)}function i(){function t(t,e){return(e=r(e,o)-(t=r(t,o)))?function(n){return(r(n,o)-t)/e}:n.i(a.a)(e)}function e(t,e){return e=r(e,o)-(t=r(t,o)),function(n){return r(t+e*n,1/o)}}var o=1,s=n.i(c.a)(t,e),l=s.domain;return s.exponent=function(t){return arguments.length?(o=+t,l(l())):o},s.copy=function(){return n.i(c.c)(s,i().exponent(o))},n.i(u.b)(s)}function o(){return i().exponent(.5)}var a=n(65),u=n(34),c=n(45);e.a=i,e.b=o},function(t,e,n){\"use strict\";function r(){function t(){var t=0,r=Math.max(1,u.length);for(c=new Array(r-1);++t<r;)c[t-1]=n.i(i.e)(a,t/r);return e}function e(t){if(!isNaN(t=+t))return u[n.i(i.c)(c,t)]}var a=[],u=[],c=[];return e.invertExtent=function(t){var e=u.indexOf(t);return e<0?[NaN,NaN]:[e>0?c[e-1]:a[0],e<c.length?c[e]:a[a.length-1]]},e.domain=function(e){if(!arguments.length)return a.slice();a=[];for(var n,r=0,o=e.length;r<o;++r)n=e[r],null==n||isNaN(n=+n)||a.push(n);return a.sort(i.f),t()},e.range=function(e){return arguments.length?(u=o.b.call(e),t()):u.slice()},e.quantiles=function(){return c.slice()},e.copy=function(){return r().domain(a).range(u)},e}var i=n(12),o=n(16);e.a=r},function(t,e,n){\"use strict\";function r(){function t(t){if(t<=t)return f[n.i(i.c)(l,t,0,s)]}function e(){var e=-1;for(l=new Array(s);++e<s;)l[e]=((e+1)*c-(e-s)*u)/(s+1);return t}var u=0,c=1,s=1,l=[.5],f=[0,1];return t.domain=function(t){return arguments.length?(u=+t[0],c=+t[1],e()):[u,c]},t.range=function(t){return arguments.length?(s=(f=o.b.call(t)).length-1,e()):f.slice()},t.invertExtent=function(t){var e=f.indexOf(t);return e<0?[NaN,NaN]:e<1?[u,l[0]]:e>=s?[l[s-1],c]:[l[e-1],l[e]]},t.copy=function(){return r().domain([u,c]).range(f)},n.i(a.b)(t)}var i=n(12),o=n(16),a=n(34);e.a=r},function(t,e,n){\"use strict\";var r=n(10),i=n(31);n.d(e,\"b\",function(){return o}),n.d(e,\"c\",function(){return a});var o=n.i(i.d)(n.i(r.cubehelix)(-100,.75,.35),n.i(r.cubehelix)(80,1.5,.8)),a=n.i(i.d)(n.i(r.cubehelix)(260,.75,.35),n.i(r.cubehelix)(80,1.5,.8)),u=n.i(r.cubehelix)();e.a=function(t){(t<0||t>1)&&(t-=Math.floor(t));var e=Math.abs(t-.5);return u.h=360*t-100,u.s=1.5-1.5*e,u.l=.8-.9*e,u+\"\"}},function(t,e,n){\"use strict\";function r(t){function e(e){var n=(e-o)/(a-o);return t(u?Math.max(0,Math.min(1,n)):n)}var o=0,a=1,u=!1;return e.domain=function(t){return arguments.length?(o=+t[0],a=+t[1],e):[o,a]},e.clamp=function(t){return arguments.length?(u=!!t,e):u},e.interpolator=function(n){return arguments.length?(t=n,e):t},e.copy=function(){return r(t).domain([o,a]).clamp(u)},n.i(i.b)(e)}var i=n(34);e.a=r},function(t,e,n){\"use strict\";function r(){function t(t){if(t<=t)return a[n.i(i.c)(e,t,0,u)]}var e=[.5],a=[0,1],u=1;return t.domain=function(n){return arguments.length?(e=o.b.call(n),u=Math.min(e.length,a.length-1),t):e.slice()},t.range=function(n){return arguments.length?(a=o.b.call(n),u=Math.min(e.length,a.length-1),t):a.slice()},t.invertExtent=function(t){var n=a.indexOf(t);return[e[n-1],e[n]]},t.copy=function(){return r().domain(e).range(a)},t}var i=n(12),o=n(16);e.a=r},function(t,e,n){\"use strict\";var r=n(12),i=n(30);e.a=function(t,e,o){var a,u=t[0],c=t[t.length-1],s=n.i(r.b)(u,c,null==e?10:e);switch(o=n.i(i.formatSpecifier)(null==o?\",f\":o),o.type){case\"s\":var l=Math.max(Math.abs(u),Math.abs(c));return null!=o.precision||isNaN(a=n.i(i.precisionPrefix)(s,l))||(o.precision=a),n.i(i.formatPrefix)(o,l);case\"\":case\"e\":case\"g\":case\"p\":case\"r\":null!=o.precision||isNaN(a=n.i(i.precisionRound)(s,Math.max(Math.abs(u),Math.abs(c))))||(o.precision=a-(\"e\"===o.type));break;case\"f\":case\"%\":null!=o.precision||isNaN(a=n.i(i.precisionFixed)(s))||(o.precision=a-2*(\"%\"===o.type))}return n.i(i.format)(o)}},function(t,e,n){\"use strict\";var r=n(128),i=n(77),o=n(79);e.a=function(){return n.i(r.b)(o.f,o.i,o.j,o.e,o.k,o.l,o.m,o.n,i.utcFormat).domain([Date.UTC(2e3,0,1),Date.UTC(2e3,0,2)])}},function(t,e,n){\"use strict\";function r(t){var e=t.length;return function(n){return t[Math.max(0,Math.min(e-1,Math.floor(n*e)))]}}var i=n(33);n.d(e,\"b\",function(){return o}),n.d(e,\"c\",function(){return a}),n.d(e,\"d\",function(){return u}),e.a=r(n.i(i.a)(\"44015444025645045745055946075a46085c460a5d460b5e470d60470e6147106347116447136548146748166848176948186a481a6c481b6d481c6e481d6f481f70482071482173482374482475482576482677482878482979472a7a472c7a472d7b472e7c472f7d46307e46327e46337f463480453581453781453882443983443a83443b84433d84433e85423f854240864241864142874144874045884046883f47883f48893e49893e4a893e4c8a3d4d8a3d4e8a3c4f8a3c508b3b518b3b528b3a538b3a548c39558c39568c38588c38598c375a8c375b8d365c8d365d8d355e8d355f8d34608d34618d33628d33638d32648e32658e31668e31678e31688e30698e306a8e2f6b8e2f6c8e2e6d8e2e6e8e2e6f8e2d708e2d718e2c718e2c728e2c738e2b748e2b758e2a768e2a778e2a788e29798e297a8e297b8e287c8e287d8e277e8e277f8e27808e26818e26828e26828e25838e25848e25858e24868e24878e23888e23898e238a8d228b8d228c8d228d8d218e8d218f8d21908d21918c20928c20928c20938c1f948c1f958b1f968b1f978b1f988b1f998a1f9a8a1e9b8a1e9c891e9d891f9e891f9f881fa0881fa1881fa1871fa28720a38620a48621a58521a68522a78522a88423a98324aa8325ab8225ac8226ad8127ad8128ae8029af7f2ab07f2cb17e2db27d2eb37c2fb47c31b57b32b67a34b67935b77937b87838b9773aba763bbb753dbc743fbc7340bd7242be7144bf7046c06f48c16e4ac16d4cc26c4ec36b50c46a52c56954c56856c66758c7655ac8645cc8635ec96260ca6063cb5f65cb5e67cc5c69cd5b6ccd5a6ece5870cf5773d05675d05477d1537ad1517cd2507fd34e81d34d84d44b86d54989d5488bd6468ed64590d74393d74195d84098d83e9bd93c9dd93ba0da39a2da37a5db36a8db34aadc32addc30b0dd2fb2dd2db5de2bb8de29bade28bddf26c0df25c2df23c5e021c8e020cae11fcde11dd0e11cd2e21bd5e21ad8e219dae319dde318dfe318e2e418e5e419e7e419eae51aece51befe51cf1e51df4e61ef6e620f8e621fbe723fde725\"));var o=r(n.i(i.a)(\"00000401000501010601010802010902020b02020d03030f03031204041405041606051806051a07061c08071e0907200a08220b09240c09260d0a290e0b2b100b2d110c2f120d31130d34140e36150e38160f3b180f3d19103f1a10421c10441d11471e114920114b21114e22115024125325125527125829115a2a115c2c115f2d11612f116331116533106734106936106b38106c390f6e3b0f703d0f713f0f72400f74420f75440f764510774710784910784a10794c117a4e117b4f127b51127c52137c54137d56147d57157e59157e5a167e5c167f5d177f5f187f601880621980641a80651a80671b80681c816a1c816b1d816d1d816e1e81701f81721f817320817521817621817822817922827b23827c23827e24828025828125818326818426818627818827818928818b29818c29818e2a81902a81912b81932b80942c80962c80982d80992d809b2e7f9c2e7f9e2f7fa02f7fa1307ea3307ea5317ea6317da8327daa337dab337cad347cae347bb0357bb2357bb3367ab5367ab73779b83779ba3878bc3978bd3977bf3a77c03a76c23b75c43c75c53c74c73d73c83e73ca3e72cc3f71cd4071cf4070d0416fd2426fd3436ed5446dd6456cd8456cd9466bdb476adc4869de4968df4a68e04c67e24d66e34e65e44f64e55064e75263e85362e95462ea5661eb5760ec5860ed5a5fee5b5eef5d5ef05f5ef1605df2625df2645cf3655cf4675cf4695cf56b5cf66c5cf66e5cf7705cf7725cf8745cf8765cf9785df9795df97b5dfa7d5efa7f5efa815ffb835ffb8560fb8761fc8961fc8a62fc8c63fc8e64fc9065fd9266fd9467fd9668fd9869fd9a6afd9b6bfe9d6cfe9f6dfea16efea36ffea571fea772fea973feaa74feac76feae77feb078feb27afeb47bfeb67cfeb77efeb97ffebb81febd82febf84fec185fec287fec488fec68afec88cfeca8dfecc8ffecd90fecf92fed194fed395fed597fed799fed89afdda9cfddc9efddea0fde0a1fde2a3fde3a5fde5a7fde7a9fde9aafdebacfcecaefceeb0fcf0b2fcf2b4fcf4b6fcf6b8fcf7b9fcf9bbfcfbbdfcfdbf\")),a=r(n.i(i.a)(\"00000401000501010601010802010a02020c02020e03021004031204031405041706041907051b08051d09061f0a07220b07240c08260d08290e092b10092d110a30120a32140b34150b37160b39180c3c190c3e1b0c411c0c431e0c451f0c48210c4a230c4c240c4f260c51280b53290b552b0b572d0b592f0a5b310a5c320a5e340a5f3609613809623909633b09643d09653e0966400a67420a68440a68450a69470b6a490b6a4a0c6b4c0c6b4d0d6c4f0d6c510e6c520e6d540f6d550f6d57106e59106e5a116e5c126e5d126e5f136e61136e62146e64156e65156e67166e69166e6a176e6c186e6d186e6f196e71196e721a6e741a6e751b6e771c6d781c6d7a1d6d7c1d6d7d1e6d7f1e6c801f6c82206c84206b85216b87216b88226a8a226a8c23698d23698f24699025689225689326679526679727669827669a28659b29649d29649f2a63a02a63a22b62a32c61a52c60a62d60a82e5fa92e5eab2f5ead305dae305cb0315bb1325ab3325ab43359b63458b73557b93556ba3655bc3754bd3853bf3952c03a51c13a50c33b4fc43c4ec63d4dc73e4cc83f4bca404acb4149cc4248ce4347cf4446d04545d24644d34743d44842d54a41d74b3fd84c3ed94d3dda4e3cdb503bdd513ade5238df5337e05536e15635e25734e35933e45a31e55c30e65d2fe75e2ee8602de9612bea632aeb6429eb6628ec6726ed6925ee6a24ef6c23ef6e21f06f20f1711ff1731df2741cf3761bf37819f47918f57b17f57d15f67e14f68013f78212f78410f8850ff8870ef8890cf98b0bf98c0af98e09fa9008fa9207fa9407fb9606fb9706fb9906fb9b06fb9d07fc9f07fca108fca309fca50afca60cfca80dfcaa0ffcac11fcae12fcb014fcb216fcb418fbb61afbb81dfbba1ffbbc21fbbe23fac026fac228fac42afac62df9c72ff9c932f9cb35f8cd37f8cf3af7d13df7d340f6d543f6d746f5d949f5db4cf4dd4ff4df53f4e156f3e35af3e55df2e661f2e865f2ea69f1ec6df1ed71f1ef75f1f179f2f27df2f482f3f586f3f68af4f88ef5f992f6fa96f8fb9af9fc9dfafda1fcffa4\")),u=r(n.i(i.a)(\"0d088710078813078916078a19068c1b068d1d068e20068f2206902406912605912805922a05932c05942e05952f059631059733059735049837049938049a3a049a3c049b3e049c3f049c41049d43039e44039e46039f48039f4903a04b03a14c02a14e02a25002a25102a35302a35502a45601a45801a45901a55b01a55c01a65e01a66001a66100a76300a76400a76600a76700a86900a86a00a86c00a86e00a86f00a87100a87201a87401a87501a87701a87801a87a02a87b02a87d03a87e03a88004a88104a78305a78405a78606a68707a68808a68a09a58b0aa58d0ba58e0ca48f0da4910ea3920fa39410a29511a19613a19814a099159f9a169f9c179e9d189d9e199da01a9ca11b9ba21d9aa31e9aa51f99a62098a72197a82296aa2395ab2494ac2694ad2793ae2892b02991b12a90b22b8fb32c8eb42e8db52f8cb6308bb7318ab83289ba3388bb3488bc3587bd3786be3885bf3984c03a83c13b82c23c81c33d80c43e7fc5407ec6417dc7427cc8437bc9447aca457acb4679cc4778cc4977cd4a76ce4b75cf4c74d04d73d14e72d24f71d35171d45270d5536fd5546ed6556dd7566cd8576bd9586ada5a6ada5b69db5c68dc5d67dd5e66de5f65de6164df6263e06363e16462e26561e26660e3685fe4695ee56a5de56b5de66c5ce76e5be76f5ae87059e97158e97257ea7457eb7556eb7655ec7754ed7953ed7a52ee7b51ef7c51ef7e50f07f4ff0804ef1814df1834cf2844bf3854bf3874af48849f48948f58b47f58c46f68d45f68f44f79044f79143f79342f89441f89540f9973ff9983ef99a3efa9b3dfa9c3cfa9e3bfb9f3afba139fba238fca338fca537fca636fca835fca934fdab33fdac33fdae32fdaf31fdb130fdb22ffdb42ffdb52efeb72dfeb82cfeba2cfebb2bfebd2afebe2afec029fdc229fdc328fdc527fdc627fdc827fdca26fdcb26fccd25fcce25fcd025fcd225fbd324fbd524fbd724fad824fada24f9dc24f9dd25f8df25f8e125f7e225f7e425f6e626f6e826f5e926f5eb27f4ed27f3ee27f3f027f2f227f1f426f1f525f0f724f0f921\"))},function(t,e,n){\"use strict\";e.a=function(t){return function(){return t}}},function(t,e,n){\"use strict\";function r(){return new i}function i(){this._=\"@\"+(++o).toString(36)}e.a=r;var o=0;i.prototype=r.prototype={constructor:i,get:function(t){for(var e=this._;!(e in t);)if(!(t=t.parentNode))return;return t[e]},set:function(t,e){return t[this._]=e},remove:function(t){return this._ in t&&delete t[this._]},toString:function(){return this._}}},function(t,e,n){\"use strict\";var r=n(72),i=n(69);e.a=function(t){var e=n.i(r.a)();return e.changedTouches&&(e=e.changedTouches[0]),n.i(i.a)(t,e)}},function(t,e,n){\"use strict\";var r=n(7);e.a=function(t){return\"string\"==typeof t?new r.b([[document.querySelector(t)]],[document.documentElement]):new r.b([[t]],r.c)}},function(t,e,n){\"use strict\";var r=n(7);e.a=function(t){return\"string\"==typeof t?new r.b([document.querySelectorAll(t)],[document.documentElement]):new r.b([null==t?[]:t],r.c)}},function(t,e,n){\"use strict\";var r=n(66);e.a=function(t){var e=\"function\"==typeof t?t:n.i(r.a)(t);return this.select(function(){return this.appendChild(e.apply(this,arguments))})}},function(t,e,n){\"use strict\";function r(t){return function(){this.removeAttribute(t)}}function i(t){return function(){this.removeAttributeNS(t.space,t.local)}}function o(t,e){return function(){this.setAttribute(t,e)}}function a(t,e){return function(){this.setAttributeNS(t.space,t.local,e)}}function u(t,e){return function(){var n=e.apply(this,arguments);null==n?this.removeAttribute(t):this.setAttribute(t,n)}}function c(t,e){return function(){var n=e.apply(this,arguments);null==n?this.removeAttributeNS(t.space,t.local):this.setAttributeNS(t.space,t.local,n)}}var s=n(67);e.a=function(t,e){var l=n.i(s.a)(t);if(arguments.length<2){var f=this.node();return l.local?f.getAttributeNS(l.space,l.local):f.getAttribute(l)}return this.each((null==e?l.local?i:r:\"function\"==typeof e?l.local?c:u:l.local?a:o)(l,e))}},function(t,e,n){\"use strict\";e.a=function(){var t=arguments[0];return arguments[0]=this,t.apply(null,arguments),this}},function(t,e,n){\"use strict\";function r(t){return t.trim().split(/^|\\s+/)}function i(t){return t.classList||new o(t)}function o(t){this._node=t,this._names=r(t.getAttribute(\"class\")||\"\")}function a(t,e){for(var n=i(t),r=-1,o=e.length;++r<o;)n.add(e[r])}function u(t,e){for(var n=i(t),r=-1,o=e.length;++r<o;)n.remove(e[r])}function c(t){return function(){a(this,t)}}function s(t){return function(){u(this,t)}}function l(t,e){return function(){(e.apply(this,arguments)?a:u)(this,t)}}o.prototype={add:function(t){var e=this._names.indexOf(t);e<0&&(this._names.push(t),this._node.setAttribute(\"class\",this._names.join(\" \")))},remove:function(t){var e=this._names.indexOf(t);e>=0&&(this._names.splice(e,1),this._node.setAttribute(\"class\",this._names.join(\" \")))},contains:function(t){return this._names.indexOf(t)>=0}},e.a=function(t,e){var n=r(t+\"\");if(arguments.length<2){for(var o=i(this.node()),a=-1,u=n.length;++a<u;)if(!o.contains(n[a]))return!1;return!0}return this.each((\"function\"==typeof e?l:e?c:s)(n,e))}},function(t,e,n){\"use strict\";function r(t,e,n,r,i,o){for(var u,c=0,s=e.length,l=o.length;c<l;++c)(u=e[c])?(u.__data__=o[c],r[c]=u):n[c]=new a.b(t,o[c]);for(;c<s;++c)(u=e[c])&&(i[c]=u)}function i(t,e,n,r,i,o,u){var s,l,f,p={},h=e.length,d=o.length,v=new Array(h);for(s=0;s<h;++s)(l=e[s])&&(v[s]=f=c+u.call(l,l.__data__,s,e),f in p?i[s]=l:p[f]=l);for(s=0;s<d;++s)f=c+u.call(t,o[s],s,o),(l=p[f])?(r[s]=l,l.__data__=o[s],p[f]=null):n[s]=new a.b(t,o[s]);for(s=0;s<h;++s)(l=e[s])&&p[v[s]]===l&&(i[s]=l)}var o=n(7),a=n(131),u=n(246),c=\"$\";e.a=function(t,e){if(!t)return y=new Array(this.size()),d=-1,this.each(function(t){y[++d]=t}),y;var a=e?i:r,c=this._parents,s=this._groups;\"function\"!=typeof t&&(t=n.i(u.a)(t));for(var l=s.length,f=new Array(l),p=new Array(l),h=new Array(l),d=0;d<l;++d){var v=c[d],g=s[d],m=g.length,y=t.call(v,v&&v.__data__,d,c),_=y.length,b=p[d]=new Array(_),x=f[d]=new Array(_),w=h[d]=new Array(m);a(v,g,b,x,w,y,e);for(var C,M,k=0,E=0;k<_;++k)if(C=b[k]){for(k>=E&&(E=k+1);!(M=x[E])&&++E<_;);C._next=M||null}}return f=new o.b(f,c),f._enter=p,f._exit=h,f}},function(t,e,n){\"use strict\";e.a=function(t){return arguments.length?this.property(\"__data__\",t):this.node().__data__}},function(t,e,n){\"use strict\";function r(t,e,r){var i=n.i(a.a)(t),o=i.CustomEvent;o?o=new o(e,r):(o=i.document.createEvent(\"Event\"),r?(o.initEvent(e,r.bubbles,r.cancelable),o.detail=r.detail):o.initEvent(e,!1,!1)),t.dispatchEvent(o)}function i(t,e){return function(){return r(this,t,e)}}function o(t,e){return function(){return r(this,t,e.apply(this,arguments))}}var a=n(73);e.a=function(t,e){return this.each((\"function\"==typeof e?o:i)(t,e))}},function(t,e,n){\"use strict\";e.a=function(t){for(var e=this._groups,n=0,r=e.length;n<r;++n)for(var i,o=e[n],a=0,u=o.length;a<u;++a)(i=o[a])&&t.call(i,i.__data__,a,o);return this}},function(t,e,n){\"use strict\";e.a=function(){return!this.node()}},function(t,e,n){\"use strict\";var r=n(132),i=n(7);e.a=function(){return new i.b(this._exit||this._groups.map(r.a),this._parents)}},function(t,e,n){\"use strict\";var r=n(7),i=n(130);e.a=function(t){\"function\"!=typeof t&&(t=n.i(i.a)(t));for(var e=this._groups,o=e.length,a=new Array(o),u=0;u<o;++u)for(var c,s=e[u],l=s.length,f=a[u]=[],p=0;p<l;++p)(c=s[p])&&t.call(c,c.__data__,p,s)&&f.push(c);return new r.b(a,this._parents)}},function(t,e,n){\"use strict\";function r(){this.innerHTML=\"\"}function i(t){return function(){this.innerHTML=t}}function o(t){return function(){var e=t.apply(this,arguments);this.innerHTML=null==e?\"\":e}}e.a=function(t){return arguments.length?this.each(null==t?r:(\"function\"==typeof t?o:i)(t)):this.node().innerHTML}},function(t,e,n){\"use strict\";function r(){return null}var i=n(66),o=n(71);e.a=function(t,e){var a=\"function\"==typeof t?t:n.i(i.a)(t),u=null==e?r:\"function\"==typeof e?e:n.i(o.a)(e);return this.select(function(){return this.insertBefore(a.apply(this,arguments),u.apply(this,arguments)||null)})}},function(t,e,n){\"use strict\";function r(){this.previousSibling&&this.parentNode.insertBefore(this,this.parentNode.firstChild)}e.a=function(){return this.each(r)}},function(t,e,n){\"use strict\";var r=n(7);e.a=function(t){for(var e=this._groups,n=t._groups,i=e.length,o=n.length,a=Math.min(i,o),u=new Array(i),c=0;c<a;++c)for(var s,l=e[c],f=n[c],p=l.length,h=u[c]=new Array(p),d=0;d<p;++d)(s=l[d]||f[d])&&(h[d]=s);for(;c<i;++c)u[c]=e[c];return new r.b(u,this._parents)}},function(t,e,n){\"use strict\";e.a=function(){for(var t=this._groups,e=0,n=t.length;e<n;++e)for(var r=t[e],i=0,o=r.length;i<o;++i){var a=r[i];if(a)return a}return null}},function(t,e,n){\"use strict\";e.a=function(){var t=new Array(this.size()),e=-1;return this.each(function(){t[++e]=this}),t}},function(t,e,n){\"use strict\";e.a=function(){for(var t=this._groups,e=-1,n=t.length;++e<n;)for(var r,i=t[e],o=i.length-1,a=i[o];--o>=0;)(r=i[o])&&(a&&a!==r.nextSibling&&a.parentNode.insertBefore(r,a),a=r);return this}},function(t,e,n){\"use strict\";function r(t){return function(){delete this[t]}}function i(t,e){return function(){this[t]=e}}function o(t,e){return function(){var n=e.apply(this,arguments);null==n?delete this[t]:this[t]=n}}e.a=function(t,e){return arguments.length>1?this.each((null==e?r:\"function\"==typeof e?o:i)(t,e)):this.node()[t]}},function(t,e,n){\"use strict\";function r(){this.nextSibling&&this.parentNode.appendChild(this)}e.a=function(){return this.each(r)}},function(t,e,n){\"use strict\";function r(){var t=this.parentNode;t&&t.removeChild(this)}e.a=function(){return this.each(r)}},function(t,e,n){\"use strict\";var r=n(7),i=n(71);e.a=function(t){\"function\"!=typeof t&&(t=n.i(i.a)(t));for(var e=this._groups,o=e.length,a=new Array(o),u=0;u<o;++u)for(var c,s,l=e[u],f=l.length,p=a[u]=new Array(f),h=0;h<f;++h)(c=l[h])&&(s=t.call(c,c.__data__,h,l))&&(\"__data__\"in c&&(s.__data__=c.__data__),p[h]=s);return new r.b(a,this._parents)}},function(t,e,n){\"use strict\";var r=n(7),i=n(133);e.a=function(t){\"function\"!=typeof t&&(t=n.i(i.a)(t));for(var e=this._groups,o=e.length,a=[],u=[],c=0;c<o;++c)for(var s,l=e[c],f=l.length,p=0;p<f;++p)(s=l[p])&&(a.push(t.call(s,s.__data__,p,l)),u.push(s));return new r.b(a,u)}},function(t,e,n){\"use strict\";e.a=function(){var t=0;return this.each(function(){++t}),t}},function(t,e,n){\"use strict\";function r(t,e){return t<e?-1:t>e?1:t>=e?0:NaN}var i=n(7);e.a=function(t){function e(e,n){return e&&n?t(e.__data__,n.__data__):!e-!n}t||(t=r);for(var n=this._groups,o=n.length,a=new Array(o),u=0;u<o;++u){for(var c,s=n[u],l=s.length,f=a[u]=new Array(l),p=0;p<l;++p)(c=s[p])&&(f[p]=c);f.sort(e)}return new i.b(a,this._parents).order()}},function(t,e,n){\"use strict\";function r(t){return function(){this.style.removeProperty(t)}}function i(t,e,n){return function(){this.style.setProperty(t,e,n)}}function o(t,e,n){return function(){var r=e.apply(this,arguments);null==r?this.style.removeProperty(t):this.style.setProperty(t,r,n)}}var a=n(73);e.a=function(t,e,u){var c;return arguments.length>1?this.each((null==e?r:\"function\"==typeof e?o:i)(t,e,null==u?\"\":u)):n.i(a.a)(c=this.node()).getComputedStyle(c,null).getPropertyValue(t)}},function(t,e,n){\"use strict\";function r(){this.textContent=\"\"}function i(t){return function(){this.textContent=t}}function o(t){return function(){var e=t.apply(this,arguments);this.textContent=null==e?\"\":e}}e.a=function(t){return arguments.length?this.each(null==t?r:(\"function\"==typeof t?o:i)(t)):this.node().textContent}},function(t,e,n){\"use strict\";var r=n(72),i=n(69);e.a=function(t,e,o){arguments.length<3&&(o=e,e=n.i(r.a)().changedTouches);for(var a,u=0,c=e?e.length:0;u<c;++u)if((a=e[u]).identifier===o)return n.i(i.a)(t,a);return null}},function(t,e,n){\"use strict\";var r=n(72),i=n(69);e.a=function(t,e){null==e&&(e=n.i(r.a)().touches);for(var o=0,a=e?e.length:0,u=new Array(a);o<a;++o)u[o]=n.i(i.a)(t,e[o]);return u}},function(t,e,n){\"use strict\";function r(t){return t.innerRadius}function i(t){return t.outerRadius}function o(t){return t.startAngle}function a(t){return t.endAngle}function u(t){return t&&t.padAngle}function c(t){return t>=1?h.d:t<=-1?-h.d:Math.asin(t)}function s(t,e,n,r,i,o,a,u){var c=n-t,s=r-e,l=a-i,f=u-o,p=(l*(e-o)-f*(t-i))/(f*c-l*s);return[t+p*c,e+p*s]}function l(t,e,n,r,i,o,a){var u=t-n,c=e-r,s=(a?o:-o)/Math.sqrt(u*u+c*c),l=s*c,f=-s*u,p=t+l,h=e+f,d=n+l,v=r+f,g=(p+d)/2,m=(h+v)/2,y=d-p,_=v-h,b=y*y+_*_,x=i-o,w=p*v-d*h,C=(_<0?-1:1)*Math.sqrt(Math.max(0,x*x*b-w*w)),M=(w*_-y*C)/b,k=(-w*y-_*C)/b,E=(w*_+y*C)/b,T=(-w*y+_*C)/b,S=M-g,P=k-m,N=E-g,A=T-m;return S*S+P*P>N*N+A*A&&(M=E,k=T),{cx:M,cy:k,x01:-l,y01:-f,x11:M*(i/x-1),y11:k*(i/x-1)}}var f=n(44),p=n(19),h=n(35);e.a=function(){function t(){var t,r,i=+e.apply(this,arguments),o=+d.apply(this,arguments),a=m.apply(this,arguments)-h.d,u=y.apply(this,arguments)-h.d,p=Math.abs(u-a),x=u>a;if(b||(b=t=n.i(f.a)()),o<i&&(r=o,o=i,i=r),o>h.a)if(p>h.c-h.a)b.moveTo(o*Math.cos(a),o*Math.sin(a)),b.arc(0,0,o,a,u,!x),i>h.a&&(b.moveTo(i*Math.cos(u),i*Math.sin(u)),b.arc(0,0,i,u,a,x));else{var w,C,M=a,k=u,E=a,T=u,S=p,P=p,N=_.apply(this,arguments)/2,A=N>h.a&&(g?+g.apply(this,arguments):Math.sqrt(i*i+o*o)),O=Math.min(Math.abs(o-i)/2,+v.apply(this,arguments)),I=O,D=O;\n",
       "if(A>h.a){var R=c(A/i*Math.sin(N)),L=c(A/o*Math.sin(N));(S-=2*R)>h.a?(R*=x?1:-1,E+=R,T-=R):(S=0,E=T=(a+u)/2),(P-=2*L)>h.a?(L*=x?1:-1,M+=L,k-=L):(P=0,M=k=(a+u)/2)}var U=o*Math.cos(M),F=o*Math.sin(M),j=i*Math.cos(T),B=i*Math.sin(T);if(O>h.a){var W=o*Math.cos(k),V=o*Math.sin(k),z=i*Math.cos(E),H=i*Math.sin(E);if(p<h.b){var q=S>h.a?s(U,F,z,H,W,V,j,B):[j,B],Y=U-q[0],K=F-q[1],G=W-q[0],$=V-q[1],X=1/Math.sin(Math.acos((Y*G+K*$)/(Math.sqrt(Y*Y+K*K)*Math.sqrt(G*G+$*$)))/2),Z=Math.sqrt(q[0]*q[0]+q[1]*q[1]);I=Math.min(O,(i-Z)/(X-1)),D=Math.min(O,(o-Z)/(X+1))}}P>h.a?D>h.a?(w=l(z,H,U,F,o,D,x),C=l(W,V,j,B,o,D,x),b.moveTo(w.cx+w.x01,w.cy+w.y01),D<O?b.arc(w.cx,w.cy,D,Math.atan2(w.y01,w.x01),Math.atan2(C.y01,C.x01),!x):(b.arc(w.cx,w.cy,D,Math.atan2(w.y01,w.x01),Math.atan2(w.y11,w.x11),!x),b.arc(0,0,o,Math.atan2(w.cy+w.y11,w.cx+w.x11),Math.atan2(C.cy+C.y11,C.cx+C.x11),!x),b.arc(C.cx,C.cy,D,Math.atan2(C.y11,C.x11),Math.atan2(C.y01,C.x01),!x))):(b.moveTo(U,F),b.arc(0,0,o,M,k,!x)):b.moveTo(U,F),i>h.a&&S>h.a?I>h.a?(w=l(j,B,W,V,i,-I,x),C=l(U,F,z,H,i,-I,x),b.lineTo(w.cx+w.x01,w.cy+w.y01),I<O?b.arc(w.cx,w.cy,I,Math.atan2(w.y01,w.x01),Math.atan2(C.y01,C.x01),!x):(b.arc(w.cx,w.cy,I,Math.atan2(w.y01,w.x01),Math.atan2(w.y11,w.x11),!x),b.arc(0,0,i,Math.atan2(w.cy+w.y11,w.cx+w.x11),Math.atan2(C.cy+C.y11,C.cx+C.x11),x),b.arc(C.cx,C.cy,I,Math.atan2(C.y11,C.x11),Math.atan2(C.y01,C.x01),!x))):b.arc(0,0,i,T,E,x):b.lineTo(j,B)}else b.moveTo(0,0);if(b.closePath(),t)return b=null,t+\"\"||null}var e=r,d=i,v=n.i(p.a)(0),g=null,m=o,y=a,_=u,b=null;return t.centroid=function(){var t=(+e.apply(this,arguments)+ +d.apply(this,arguments))/2,n=(+m.apply(this,arguments)+ +y.apply(this,arguments))/2-h.b/2;return[Math.cos(n)*t,Math.sin(n)*t]},t.innerRadius=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(p.a)(+r),t):e},t.outerRadius=function(e){return arguments.length?(d=\"function\"==typeof e?e:n.i(p.a)(+e),t):d},t.cornerRadius=function(e){return arguments.length?(v=\"function\"==typeof e?e:n.i(p.a)(+e),t):v},t.padRadius=function(e){return arguments.length?(g=null==e?null:\"function\"==typeof e?e:n.i(p.a)(+e),t):g},t.startAngle=function(e){return arguments.length?(m=\"function\"==typeof e?e:n.i(p.a)(+e),t):m},t.endAngle=function(e){return arguments.length?(y=\"function\"==typeof e?e:n.i(p.a)(+e),t):y},t.padAngle=function(e){return arguments.length?(_=\"function\"==typeof e?e:n.i(p.a)(+e),t):_},t.context=function(e){return arguments.length?(b=null==e?null:e,t):b},t}},function(t,e,n){\"use strict\";n.d(e,\"a\",function(){return r});var r=Array.prototype.slice},function(t,e,n){\"use strict\";function r(t){this._context=t}var i=n(49),o=n(46);r.prototype={areaStart:i.a,areaEnd:i.a,lineStart:function(){this._x0=this._x1=this._x2=this._x3=this._x4=this._y0=this._y1=this._y2=this._y3=this._y4=NaN,this._point=0},lineEnd:function(){switch(this._point){case 1:this._context.moveTo(this._x2,this._y2),this._context.closePath();break;case 2:this._context.moveTo((this._x2+2*this._x3)/3,(this._y2+2*this._y3)/3),this._context.lineTo((this._x3+2*this._x2)/3,(this._y3+2*this._y2)/3),this._context.closePath();break;case 3:this.point(this._x2,this._y2),this.point(this._x3,this._y3),this.point(this._x4,this._y4)}},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._x2=t,this._y2=e;break;case 1:this._point=2,this._x3=t,this._y3=e;break;case 2:this._point=3,this._x4=t,this._y4=e,this._context.moveTo((this._x0+4*this._x1+t)/6,(this._y0+4*this._y1+e)/6);break;default:n.i(o.c)(this,t,e)}this._x0=this._x1,this._x1=t,this._y0=this._y1,this._y1=e}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";function r(t){this._context=t}var i=n(46);r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._y0=this._y1=NaN,this._point=0},lineEnd:function(){(this._line||0!==this._line&&3===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1;break;case 1:this._point=2;break;case 2:this._point=3;var r=(this._x0+4*this._x1+t)/6,o=(this._y0+4*this._y1+e)/6;this._line?this._context.lineTo(r,o):this._context.moveTo(r,o);break;case 3:this._point=4;default:n.i(i.c)(this,t,e)}this._x0=this._x1,this._x1=t,this._y0=this._y1,this._y1=e}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";function r(t,e){this._basis=new i.b(t),this._beta=e}var i=n(46);r.prototype={lineStart:function(){this._x=[],this._y=[],this._basis.lineStart()},lineEnd:function(){var t=this._x,e=this._y,n=t.length-1;if(n>0)for(var r,i=t[0],o=e[0],a=t[n]-i,u=e[n]-o,c=-1;++c<=n;)r=c/n,this._basis.point(this._beta*t[c]+(1-this._beta)*(i+r*a),this._beta*e[c]+(1-this._beta)*(o+r*u));this._x=this._y=null,this._basis.lineEnd()},point:function(t,e){this._x.push(+t),this._y.push(+e)}},e.a=function t(e){function n(t){return 1===e?new i.b(t):new r(t,e)}return n.beta=function(e){return t(+e)},n}(.85)},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._alpha=e}var i=n(136),o=n(49),a=n(74);r.prototype={areaStart:o.a,areaEnd:o.a,lineStart:function(){this._x0=this._x1=this._x2=this._x3=this._x4=this._x5=this._y0=this._y1=this._y2=this._y3=this._y4=this._y5=NaN,this._l01_a=this._l12_a=this._l23_a=this._l01_2a=this._l12_2a=this._l23_2a=this._point=0},lineEnd:function(){switch(this._point){case 1:this._context.moveTo(this._x3,this._y3),this._context.closePath();break;case 2:this._context.lineTo(this._x3,this._y3),this._context.closePath();break;case 3:this.point(this._x3,this._y3),this.point(this._x4,this._y4),this.point(this._x5,this._y5)}},point:function(t,e){if(t=+t,e=+e,this._point){var r=this._x2-t,i=this._y2-e;this._l23_a=Math.sqrt(this._l23_2a=Math.pow(r*r+i*i,this._alpha))}switch(this._point){case 0:this._point=1,this._x3=t,this._y3=e;break;case 1:this._point=2,this._context.moveTo(this._x4=t,this._y4=e);break;case 2:this._point=3,this._x5=t,this._y5=e;break;default:n.i(a.b)(this,t,e)}this._l01_a=this._l12_a,this._l12_a=this._l23_a,this._l01_2a=this._l12_2a,this._l12_2a=this._l23_2a,this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return e?new r(t,e):new i.b(t,0)}return n.alpha=function(e){return t(+e)},n}(.5)},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._alpha=e}var i=n(137),o=n(74);r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._x2=this._y0=this._y1=this._y2=NaN,this._l01_a=this._l12_a=this._l23_a=this._l01_2a=this._l12_2a=this._l23_2a=this._point=0},lineEnd:function(){(this._line||0!==this._line&&3===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){if(t=+t,e=+e,this._point){var r=this._x2-t,i=this._y2-e;this._l23_a=Math.sqrt(this._l23_2a=Math.pow(r*r+i*i,this._alpha))}switch(this._point){case 0:this._point=1;break;case 1:this._point=2;break;case 2:this._point=3,this._line?this._context.lineTo(this._x2,this._y2):this._context.moveTo(this._x2,this._y2);break;case 3:this._point=4;default:n.i(o.b)(this,t,e)}this._l01_a=this._l12_a,this._l12_a=this._l23_a,this._l01_2a=this._l12_2a,this._l12_2a=this._l23_2a,this._x0=this._x1,this._x1=this._x2,this._x2=t,this._y0=this._y1,this._y1=this._y2,this._y2=e}},e.a=function t(e){function n(t){return e?new r(t,e):new i.b(t,0)}return n.alpha=function(e){return t(+e)},n}(.5)},function(t,e,n){\"use strict\";function r(t){this._context=t}var i=n(49);r.prototype={areaStart:i.a,areaEnd:i.a,lineStart:function(){this._point=0},lineEnd:function(){this._point&&this._context.closePath()},point:function(t,e){t=+t,e=+e,this._point?this._context.lineTo(t,e):(this._point=1,this._context.moveTo(t,e))}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";function r(t){return t<0?-1:1}function i(t,e,n){var i=t._x1-t._x0,o=e-t._x1,a=(t._y1-t._y0)/(i||o<0&&-0),u=(n-t._y1)/(o||i<0&&-0),c=(a*o+u*i)/(i+o);return(r(a)+r(u))*Math.min(Math.abs(a),Math.abs(u),.5*Math.abs(c))||0}function o(t,e){var n=t._x1-t._x0;return n?(3*(t._y1-t._y0)/n-e)/2:e}function a(t,e,n){var r=t._x0,i=t._y0,o=t._x1,a=t._y1,u=(o-r)/3;t._context.bezierCurveTo(r+u,i+u*e,o-u,a-u*n,o,a)}function u(t){this._context=t}function c(t){this._context=new s(t)}function s(t){this._context=t}function l(t){return new u(t)}function f(t){return new c(t)}e.a=l,e.b=f,u.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x0=this._x1=this._y0=this._y1=this._t0=NaN,this._point=0},lineEnd:function(){switch(this._point){case 2:this._context.lineTo(this._x1,this._y1);break;case 3:a(this,this._t0,o(this,this._t0))}(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line=1-this._line},point:function(t,e){var n=NaN;if(t=+t,e=+e,t!==this._x1||e!==this._y1){switch(this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;break;case 2:this._point=3,a(this,o(this,n=i(this,t,e)),n);break;default:a(this,this._t0,n=i(this,t,e))}this._x0=this._x1,this._x1=t,this._y0=this._y1,this._y1=e,this._t0=n}}},(c.prototype=Object.create(u.prototype)).point=function(t,e){u.prototype.point.call(this,e,t)},s.prototype={moveTo:function(t,e){this._context.moveTo(e,t)},closePath:function(){this._context.closePath()},lineTo:function(t,e){this._context.lineTo(e,t)},bezierCurveTo:function(t,e,n,r,i,o){this._context.bezierCurveTo(e,t,r,n,o,i)}}},function(t,e,n){\"use strict\";function r(t){this._context=t}function i(t){var e,n,r=t.length-1,i=new Array(r),o=new Array(r),a=new Array(r);for(i[0]=0,o[0]=2,a[0]=t[0]+2*t[1],e=1;e<r-1;++e)i[e]=1,o[e]=4,a[e]=4*t[e]+2*t[e+1];for(i[r-1]=2,o[r-1]=7,a[r-1]=8*t[r-1]+t[r],e=1;e<r;++e)n=i[e]/o[e-1],o[e]-=n,a[e]-=n*a[e-1];for(i[r-1]=a[r-1]/o[r-1],e=r-2;e>=0;--e)i[e]=(a[e]-i[e+1])/o[e];for(o[r-1]=(t[r]+i[r-1])/2,e=0;e<r-1;++e)o[e]=2*t[e+1]-i[e+1];return[i,o]}r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x=[],this._y=[]},lineEnd:function(){var t=this._x,e=this._y,n=t.length;if(n)if(this._line?this._context.lineTo(t[0],e[0]):this._context.moveTo(t[0],e[0]),2===n)this._context.lineTo(t[1],e[1]);else for(var r=i(t),o=i(e),a=0,u=1;u<n;++a,++u)this._context.bezierCurveTo(r[0][a],o[0][a],r[1][a],o[1][a],t[u],e[u]);(this._line||0!==this._line&&1===n)&&this._context.closePath(),this._line=1-this._line,this._x=this._y=null},point:function(t,e){this._x.push(+t),this._y.push(+e)}},e.a=function(t){return new r(t)}},function(t,e,n){\"use strict\";function r(t,e){this._context=t,this._t=e}function i(t){return new r(t,0)}function o(t){return new r(t,1)}e.c=i,e.b=o,r.prototype={areaStart:function(){this._line=0},areaEnd:function(){this._line=NaN},lineStart:function(){this._x=this._y=NaN,this._point=0},lineEnd:function(){0<this._t&&this._t<1&&2===this._point&&this._context.lineTo(this._x,this._y),(this._line||0!==this._line&&1===this._point)&&this._context.closePath(),this._line>=0&&(this._t=1-this._t,this._line=1-this._line)},point:function(t,e){switch(t=+t,e=+e,this._point){case 0:this._point=1,this._line?this._context.lineTo(t,e):this._context.moveTo(t,e);break;case 1:this._point=2;default:if(this._t<=0)this._context.lineTo(this._x,e),this._context.lineTo(t,e);else{var n=this._x*(1-this._t)+t*this._t;this._context.lineTo(n,this._y),this._context.lineTo(n,e)}}this._x=t,this._y=e}},e.a=function(t){return new r(t,.5)}},function(t,e,n){\"use strict\";e.a=function(t,e){return e<t?-1:e>t?1:e>=t?0:NaN}},function(t,e,n){\"use strict\";e.a=function(t){return t}},function(t,e,n){\"use strict\";var r=n(36);e.a=function(t,e){if((o=t.length)>0){for(var i,o,a,u=0,c=t[0].length;u<c;++u){for(a=i=0;i<o;++i)a+=t[i][u][1]||0;if(a)for(i=0;i<o;++i)t[i][u][1]/=a}n.i(r.a)(t,e)}}},function(t,e,n){\"use strict\";var r=n(36);e.a=function(t,e){if((i=t.length)>0){for(var i,o=0,a=t[e[0]],u=a.length;o<u;++o){for(var c=0,s=0;c<i;++c)s+=t[c][o][1]||0;a[o][1]+=a[o][0]=-s/2}n.i(r.a)(t,e)}}},function(t,e,n){\"use strict\";var r=n(36);e.a=function(t,e){if((a=t.length)>0&&(o=(i=t[e[0]]).length)>0){for(var i,o,a,u=0,c=1;c<o;++c){for(var s=0,l=0,f=0;s<a;++s){for(var p=t[e[s]],h=p[c][1]||0,d=p[c-1][1]||0,v=(h-d)/2,g=0;g<s;++g){var m=t[e[g]],y=m[c][1]||0,_=m[c-1][1]||0;v+=y-_}l+=h,f+=v*h}i[c-1][1]+=i[c-1][0]=u,l&&(u-=f/l)}i[c-1][1]+=i[c-1][0]=u,n.i(r.a)(t,e)}}},function(t,e,n){\"use strict\";var r=n(76);e.a=function(t){return n.i(r.a)(t).reverse()}},function(t,e,n){\"use strict\";var r=n(37),i=n(76);e.a=function(t){var e,o,a=t.length,u=t.map(i.b),c=n.i(r.a)(t).sort(function(t,e){return u[e]-u[t]}),s=0,l=0,f=[],p=[];for(e=0;e<a;++e)o=c[e],s<l?(s+=u[o],f.push(o)):(l+=u[o],p.push(o));return p.reverse().concat(f)}},function(t,e,n){\"use strict\";var r=n(37);e.a=function(t){return n.i(r.a)(t).reverse()}},function(t,e,n){\"use strict\";var r=n(19),i=n(291),o=n(292),a=n(35);e.a=function(){function t(t){var n,r,i,o,p,h=t.length,d=0,v=new Array(h),g=new Array(h),m=+s.apply(this,arguments),y=Math.min(a.c,Math.max(-a.c,l.apply(this,arguments)-m)),_=Math.min(Math.abs(y)/h,f.apply(this,arguments)),b=_*(y<0?-1:1);for(n=0;n<h;++n)(p=g[v[n]=n]=+e(t[n],n,t))>0&&(d+=p);for(null!=u?v.sort(function(t,e){return u(g[t],g[e])}):null!=c&&v.sort(function(e,n){return c(t[e],t[n])}),n=0,i=d?(y-h*b)/d:0;n<h;++n,m=o)r=v[n],p=g[r],o=m+(p>0?p*i:0)+b,g[r]={data:t[r],index:n,value:p,startAngle:m,endAngle:o,padAngle:_};return g}var e=o.a,u=i.a,c=null,s=n.i(r.a)(0),l=n.i(r.a)(a.c),f=n.i(r.a)(0);return t.value=function(i){return arguments.length?(e=\"function\"==typeof i?i:n.i(r.a)(+i),t):e},t.sortValues=function(e){return arguments.length?(u=e,c=null,t):u},t.sort=function(e){return arguments.length?(c=e,u=null,t):c},t.startAngle=function(e){return arguments.length?(s=\"function\"==typeof e?e:n.i(r.a)(+e),t):s},t.endAngle=function(e){return arguments.length?(l=\"function\"==typeof e?e:n.i(r.a)(+e),t):l},t.padAngle=function(e){return arguments.length?(f=\"function\"==typeof e?e:n.i(r.a)(+e),t):f},t}},function(t,e,n){\"use strict\";var r=n(138),i=n(135),o=n(140);e.a=function(){var t=n.i(i.a)().curve(r.b),e=t.curve,a=t.lineX0,u=t.lineX1,c=t.lineY0,s=t.lineY1;return t.angle=t.x,delete t.x,t.startAngle=t.x0,delete t.x0,t.endAngle=t.x1,delete t.x1,t.radius=t.y,delete t.y,t.innerRadius=t.y0,delete t.y0,t.outerRadius=t.y1,delete t.y1,t.lineStartAngle=function(){return n.i(o.b)(a())},delete t.lineX0,t.lineEndAngle=function(){return n.i(o.b)(u())},delete t.lineX1,t.lineInnerRadius=function(){return n.i(o.b)(c())},delete t.lineY0,t.lineOuterRadius=function(){return n.i(o.b)(s())},delete t.lineY1,t.curve=function(t){return arguments.length?e(n.i(r.a)(t)):e()._curve},t}},function(t,e,n){\"use strict\";function r(t,e){return t[e]}var i=n(281),o=n(19),a=n(36),u=n(37);e.a=function(){function t(t){var n,r,i=e.apply(this,arguments),o=t.length,a=i.length,u=new Array(a);for(n=0;n<a;++n){for(var f,p=i[n],h=u[n]=new Array(o),d=0;d<o;++d)h[d]=f=[0,+l(t[d],p,d,t)],f.data=t[d];h.key=p}for(n=0,r=c(u);n<a;++n)u[r[n]].index=n;return s(u,r),u}var e=n.i(o.a)([]),c=u.a,s=a.a,l=r;return t.keys=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(o.a)(i.a.call(r)),t):e},t.value=function(e){return arguments.length?(l=\"function\"==typeof e?e:n.i(o.a)(+e),t):l},t.order=function(e){return arguments.length?(c=null==e?u.a:\"function\"==typeof e?e:n.i(o.a)(i.a.call(e)),t):c},t.offset=function(e){return arguments.length?(s=null==e?a.a:e,t):s},t}},function(t,e,n){\"use strict\";var r=n(44),i=n(141),o=n(142),a=n(143),u=n(145),c=n(144),s=n(146),l=n(147),f=n(19);n.d(e,\"b\",function(){return p});var p=[i.a,o.a,a.a,c.a,u.a,s.a,l.a];e.a=function(){function t(){var t;if(a||(a=t=n.i(r.a)()),e.apply(this,arguments).draw(a,+o.apply(this,arguments)),t)return a=null,t+\"\"||null}var e=n.i(f.a)(i.a),o=n.i(f.a)(64),a=null;return t.type=function(r){return arguments.length?(e=\"function\"==typeof r?r:n.i(f.a)(r),t):e},t.size=function(e){return arguments.length?(o=\"function\"==typeof e?e:n.i(f.a)(+e),t):o},t.context=function(e){return arguments.length?(a=null==e?null:e,t):a},t}},function(t,e,n){\"use strict\";function r(t){var e=new Date(t);return isNaN(e)?null:e}var i=n(148),o=n(78),a=+new Date(\"2000-01-01T00:00:00.000Z\")?r:n.i(o.e)(i.b);e.a=a},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setHours(0,0,0,0)},function(t,e){t.setDate(t.getDate()+e)},function(t,e){return(e-t-(e.getTimezoneOffset()-t.getTimezoneOffset())*i.d)/i.b},function(t){return t.getDate()-1});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){var e=t.getTimezoneOffset()*i.d%i.c;e<0&&(e+=i.c),t.setTime(Math.floor((+t-e)/i.c)*i.c+e)},function(t,e){t.setTime(+t+e*i.c)},function(t,e){return(e-t)/i.c},function(t){return t.getHours()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(){},function(t,e){t.setTime(+t+e)},function(t,e){return e-t});i.every=function(t){return t=Math.floor(t),isFinite(t)&&t>0?t>1?n.i(r.a)(function(e){e.setTime(Math.floor(e/t)*t)},function(e,n){e.setTime(+e+n*t)},function(e,n){return(n-e)/t}):i:null},e.a=i;i.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setTime(Math.floor(t/i.d)*i.d)},function(t,e){t.setTime(+t+e*i.d)},function(t,e){return(e-t)/i.d},function(t){return t.getMinutes()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(t){t.setDate(1),t.setHours(0,0,0,0)},function(t,e){t.setMonth(t.getMonth()+e)},function(t,e){return e.getMonth()-t.getMonth()+12*(e.getFullYear()-t.getFullYear())},function(t){return t.getMonth()});e.a=i;i.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setTime(Math.floor(t/i.e)*i.e)},function(t,e){t.setTime(+t+e*i.e)},function(t,e){return(e-t)/i.e},function(t){return t.getUTCSeconds()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setUTCHours(0,0,0,0)},function(t,e){t.setUTCDate(t.getUTCDate()+e)},function(t,e){return(e-t)/i.b},function(t){return t.getUTCDate()-1});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setUTCMinutes(0,0,0)},function(t,e){t.setTime(+t+e*i.c)},function(t,e){return(e-t)/i.c},function(t){return t.getUTCHours()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n(13),o=n.i(r.a)(function(t){t.setUTCSeconds(0,0)},function(t,e){t.setTime(+t+e*i.d)},function(t,e){return(e-t)/i.d},function(t){return t.getUTCMinutes()});e.a=o;o.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(t){t.setUTCDate(1),t.setUTCHours(0,0,0,0)},function(t,e){t.setUTCMonth(t.getUTCMonth()+e)},function(t,e){return e.getUTCMonth()-t.getUTCMonth()+12*(e.getUTCFullYear()-t.getUTCFullYear())},function(t){return t.getUTCMonth()});e.a=i;i.range},function(t,e,n){\"use strict\";function r(t){return n.i(i.a)(function(e){e.setUTCDate(e.getUTCDate()-(e.getUTCDay()+7-t)%7),e.setUTCHours(0,0,0,0)},function(t,e){t.setUTCDate(t.getUTCDate()+7*e)},function(t,e){return(e-t)/o.a})}var i=n(5),o=n(13);n.d(e,\"a\",function(){return a}),n.d(e,\"b\",function(){return u});var a=r(0),u=r(1),c=r(2),s=r(3),l=r(4),f=r(5),p=r(6);a.range,u.range,c.range,s.range,l.range,f.range,p.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(t){t.setUTCMonth(0,1),t.setUTCHours(0,0,0,0)},function(t,e){t.setUTCFullYear(t.getUTCFullYear()+e)},function(t,e){return e.getUTCFullYear()-t.getUTCFullYear()},function(t){return t.getUTCFullYear()});i.every=function(t){return isFinite(t=Math.floor(t))&&t>0?n.i(r.a)(function(e){e.setUTCFullYear(Math.floor(e.getUTCFullYear()/t)*t),e.setUTCMonth(0,1),e.setUTCHours(0,0,0,0)},function(e,n){e.setUTCFullYear(e.getUTCFullYear()+n*t)}):null},e.a=i;i.range},function(t,e,n){\"use strict\";function r(t){return n.i(i.a)(function(e){e.setDate(e.getDate()-(e.getDay()+7-t)%7),e.setHours(0,0,0,0)},function(t,e){t.setDate(t.getDate()+7*e)},function(t,e){return(e-t-(e.getTimezoneOffset()-t.getTimezoneOffset())*o.d)/o.a})}var i=n(5),o=n(13);n.d(e,\"a\",function(){return a}),n.d(e,\"b\",function(){return u});var a=r(0),u=r(1),c=r(2),s=r(3),l=r(4),f=r(5),p=r(6);a.range,u.range,c.range,s.range,l.range,f.range,p.range},function(t,e,n){\"use strict\";var r=n(5),i=n.i(r.a)(function(t){t.setMonth(0,1),t.setHours(0,0,0,0)},function(t,e){t.setFullYear(t.getFullYear()+e)},function(t,e){return e.getFullYear()-t.getFullYear()},function(t){return t.getFullYear()});i.every=function(t){return isFinite(t=Math.floor(t))&&t>0?n.i(r.a)(function(e){e.setFullYear(Math.floor(e.getFullYear()/t)*t),e.setMonth(0,1),e.setHours(0,0,0,0)},function(e,n){e.setFullYear(e.getFullYear()+n*t)}):null},e.a=i;i.range},function(t,e,n){\"use strict\";function r(t){return t.replace(i,function(t,e){return e.toUpperCase()})}var i=/-(.)/g;t.exports=r},function(t,e,n){\"use strict\";function r(t){return i(t.replace(o,\"ms-\"))}var i=n(318),o=/^-ms-/;t.exports=r},function(t,e,n){\"use strict\";function r(t,e){return!(!t||!e)&&(t===e||!i(t)&&(i(e)?r(t,e.parentNode):\"contains\"in t?t.contains(e):!!t.compareDocumentPosition&&!!(16&t.compareDocumentPosition(e))))}var i=n(328);t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=t.length;if(Array.isArray(t)||\"object\"!=typeof t&&\"function\"!=typeof t?a(!1):void 0,\"number\"!=typeof e?a(!1):void 0,0===e||e-1 in t?void 0:a(!1),\"function\"==typeof t.callee?a(!1):void 0,t.hasOwnProperty)try{return Array.prototype.slice.call(t)}catch(t){}for(var n=Array(e),r=0;r<e;r++)n[r]=t[r];return n}function i(t){return!!t&&(\"object\"==typeof t||\"function\"==typeof t)&&\"length\"in t&&!(\"setInterval\"in t)&&\"number\"!=typeof t.nodeType&&(Array.isArray(t)||\"callee\"in t||\"item\"in t)}function o(t){return i(t)?Array.isArray(t)?t.slice():r(t):[t]}var a=n(0);t.exports=o},function(t,e,n){\"use strict\";function r(t){var e=t.match(l);return e&&e[1].toLowerCase()}function i(t,e){var n=s;s?void 0:c(!1);var i=r(t),o=i&&u(i);if(o){n.innerHTML=o[1]+t+o[2];for(var l=o[0];l--;)n=n.lastChild}else n.innerHTML=t;var f=n.getElementsByTagName(\"script\");f.length&&(e?void 0:c(!1),a(f).forEach(e));for(var p=Array.from(n.childNodes);n.lastChild;)n.removeChild(n.lastChild);return p}var o=n(6),a=n(321),u=n(323),c=n(0),s=o.canUseDOM?document.createElement(\"div\"):null,l=/^\\s*<(\\w+)/;t.exports=i},function(t,e,n){\"use strict\";function r(t){return a?void 0:o(!1),p.hasOwnProperty(t)||(t=\"*\"),u.hasOwnProperty(t)||(\"*\"===t?a.innerHTML=\"<link />\":a.innerHTML=\"<\"+t+\"></\"+t+\">\",u[t]=!a.firstChild),u[t]?p[t]:null}var i=n(6),o=n(0),a=i.canUseDOM?document.createElement(\"div\"):null,u={},c=[1,'<select multiple=\"true\">',\"</select>\"],s=[1,\"<table>\",\"</table>\"],l=[3,\"<table><tbody><tr>\",\"</tr></tbody></table>\"],f=[1,'<svg xmlns=\"http://www.w3.org/2000/svg\">',\"</svg>\"],p={\"*\":[1,\"?<div>\",\"</div>\"],area:[1,\"<map>\",\"</map>\"],col:[2,\"<table><tbody></tbody><colgroup>\",\"</colgroup></table>\"],legend:[1,\"<fieldset>\",\"</fieldset>\"],param:[1,\"<object>\",\"</object>\"],tr:[2,\"<table><tbody>\",\"</tbody></table>\"],optgroup:c,option:c,caption:s,colgroup:s,tbody:s,tfoot:s,thead:s,td:l,th:l},h=[\"circle\",\"clipPath\",\"defs\",\"ellipse\",\"g\",\"image\",\"line\",\"linearGradient\",\"mask\",\"path\",\"pattern\",\"polygon\",\"polyline\",\"radialGradient\",\"rect\",\"stop\",\"text\",\"tspan\"];h.forEach(function(t){p[t]=f,u[t]=!0}),t.exports=r},function(t,e,n){\"use strict\";function r(t){return t===window?{x:window.pageXOffset||document.documentElement.scrollLeft,y:window.pageYOffset||document.documentElement.scrollTop}:{x:t.scrollLeft,y:t.scrollTop}}t.exports=r},function(t,e,n){\"use strict\";function r(t){return t.replace(i,\"-$1\").toLowerCase()}var i=/([A-Z])/g;t.exports=r},function(t,e,n){\"use strict\";function r(t){return i(t).replace(o,\"-ms-\")}var i=n(325),o=/^ms-/;t.exports=r},function(t,e,n){\"use strict\";function r(t){return!(!t||!(\"function\"==typeof Node?t instanceof Node:\"object\"==typeof t&&\"number\"==typeof t.nodeType&&\"string\"==typeof t.nodeName))}t.exports=r},function(t,e,n){\"use strict\";function r(t){return i(t)&&3==t.nodeType}var i=n(327);t.exports=r},function(t,e,n){\"use strict\";var r=function(t){var e;for(e in t)if(t.hasOwnProperty(e))return e;return null};t.exports=r},function(t,e,n){\"use strict\";function r(t){var e={};return function(n){return e.hasOwnProperty(n)||(e[n]=t.call(this,n)),e[n]}}t.exports=r},function(t,e,n){\"use strict\";var r={Properties:{\"aria-current\":0,\"aria-details\":0,\"aria-disabled\":0,\"aria-hidden\":0,\"aria-invalid\":0,\"aria-keyshortcuts\":0,\"aria-label\":0,\"aria-roledescription\":0,\"aria-autocomplete\":0,\"aria-checked\":0,\"aria-expanded\":0,\"aria-haspopup\":0,\"aria-level\":0,\"aria-modal\":0,\"aria-multiline\":0,\"aria-multiselectable\":0,\"aria-orientation\":0,\"aria-placeholder\":0,\"aria-pressed\":0,\"aria-readonly\":0,\"aria-required\":0,\"aria-selected\":0,\"aria-sort\":0,\"aria-valuemax\":0,\"aria-valuemin\":0,\"aria-valuenow\":0,\"aria-valuetext\":0,\"aria-atomic\":0,\"aria-busy\":0,\"aria-live\":0,\"aria-relevant\":0,\"aria-dropeffect\":0,\"aria-grabbed\":0,\"aria-activedescendant\":0,\"aria-colcount\":0,\"aria-colindex\":0,\"aria-colspan\":0,\"aria-controls\":0,\"aria-describedby\":0,\"aria-errormessage\":0,\"aria-flowto\":0,\"aria-labelledby\":0,\"aria-owns\":0,\"aria-posinset\":0,\"aria-rowcount\":0,\"aria-rowindex\":0,\"aria-rowspan\":0,\"aria-setsize\":0},DOMAttributeNames:{},DOMPropertyNames:{}};t.exports=r},function(t,e,n){\"use strict\";var r=n(4),i=n(151),o={focusDOMComponent:function(){i(r.getNodeFromInstance(this))}};t.exports=o},function(t,e,n){\"use strict\";function r(){var t=window.opera;return\"object\"==typeof t&&\"function\"==typeof t.version&&parseInt(t.version(),10)<=12}function i(t){return(t.ctrlKey||t.altKey||t.metaKey)&&!(t.ctrlKey&&t.altKey)}function o(t){switch(t){case\"topCompositionStart\":return E.compositionStart;case\"topCompositionEnd\":return E.compositionEnd;case\"topCompositionUpdate\":return E.compositionUpdate}}function a(t,e){return\"topKeyDown\"===t&&e.keyCode===_}function u(t,e){switch(t){case\"topKeyUp\":return y.indexOf(e.keyCode)!==-1;case\"topKeyDown\":return e.keyCode!==_;case\"topKeyPress\":case\"topMouseDown\":case\"topBlur\":return!0;default:return!1}}function c(t){var e=t.detail;return\"object\"==typeof e&&\"data\"in e?e.data:null}function s(t,e,n,r){var i,s;if(b?i=o(t):S?u(t,n)&&(i=E.compositionEnd):a(t,n)&&(i=E.compositionStart),!i)return null;C&&(S||i!==E.compositionStart?i===E.compositionEnd&&S&&(s=S.getData()):S=v.getPooled(r));var l=g.getPooled(i,e,n,r);if(s)l.data=s;else{var f=c(n);null!==f&&(l.data=f)}return h.accumulateTwoPhaseDispatches(l),l}function l(t,e){switch(t){case\"topCompositionEnd\":return c(e);case\"topKeyPress\":var n=e.which;return n!==M?null:(T=!0,k);case\"topTextInput\":var r=e.data;return r===k&&T?null:r;default:return null}}function f(t,e){if(S){if(\"topCompositionEnd\"===t||!b&&u(t,e)){var n=S.getData();return v.release(S),S=null,n}return null}switch(t){case\"topPaste\":return null;case\"topKeyPress\":return e.which&&!i(e)?String.fromCharCode(e.which):null;case\"topCompositionEnd\":return C?null:e.data;default:return null}}function p(t,e,n,r){var i;if(i=w?l(t,n):f(t,n),!i)return null;var o=m.getPooled(E.beforeInput,e,n,r);return o.data=i,h.accumulateTwoPhaseDispatches(o),o}var h=n(23),d=n(6),v=n(340),g=n(377),m=n(380),y=[9,13,27,32],_=229,b=d.canUseDOM&&\"CompositionEvent\"in window,x=null;d.canUseDOM&&\"documentMode\"in document&&(x=document.documentMode);var w=d.canUseDOM&&\"TextEvent\"in window&&!x&&!r(),C=d.canUseDOM&&(!b||x&&x>8&&x<=11),M=32,k=String.fromCharCode(M),E={beforeInput:{phasedRegistrationNames:{bubbled:\"onBeforeInput\",captured:\"onBeforeInputCapture\"},dependencies:[\"topCompositionEnd\",\"topKeyPress\",\"topTextInput\",\"topPaste\"]},compositionEnd:{phasedRegistrationNames:{bubbled:\"onCompositionEnd\",captured:\"onCompositionEndCapture\"},dependencies:[\"topBlur\",\"topCompositionEnd\",\"topKeyDown\",\"topKeyPress\",\"topKeyUp\",\"topMouseDown\"]},compositionStart:{phasedRegistrationNames:{bubbled:\"onCompositionStart\",captured:\"onCompositionStartCapture\"},dependencies:[\"topBlur\",\"topCompositionStart\",\"topKeyDown\",\"topKeyPress\",\"topKeyUp\",\"topMouseDown\"]},compositionUpdate:{phasedRegistrationNames:{bubbled:\"onCompositionUpdate\",captured:\"onCompositionUpdateCapture\"},dependencies:[\"topBlur\",\"topCompositionUpdate\",\"topKeyDown\",\"topKeyPress\",\"topKeyUp\",\"topMouseDown\"]}},T=!1,S=null,P={eventTypes:E,extractEvents:function(t,e,n,r){return[s(t,e,n,r),p(t,e,n,r)]}};t.exports=P},function(t,e,n){\"use strict\";var r=n(154),i=n(6),o=(n(9),n(319),n(386)),a=n(326),u=n(330),c=(n(1),u(function(t){return a(t)})),s=!1,l=\"cssFloat\";if(i.canUseDOM){var f=document.createElement(\"div\").style;try{f.font=\"\"}catch(t){s=!0}void 0===document.documentElement.style.cssFloat&&(l=\"styleFloat\")}var p={createMarkupForStyles:function(t,e){var n=\"\";for(var r in t)if(t.hasOwnProperty(r)){var i=t[r];null!=i&&(n+=c(r)+\":\",n+=o(r,i,e)+\";\")}return n||null},setValueForStyles:function(t,e,n){var i=t.style;for(var a in e)if(e.hasOwnProperty(a)){var u=o(a,e[a],n);if(\"float\"!==a&&\"cssFloat\"!==a||(a=l),u)i[a]=u;else{var c=s&&r.shorthandPropertyExpansions[a];if(c)for(var f in c)i[f]=\"\";else i[a]=\"\"}}}};t.exports=p},function(t,e,n){\"use strict\";function r(t){var e=t.nodeName&&t.nodeName.toLowerCase();return\"select\"===e||\"input\"===e&&\"file\"===t.type}function i(t){var e=C.getPooled(T.change,P,t,M(t));_.accumulateTwoPhaseDispatches(e),w.batchedUpdates(o,e)}function o(t){y.enqueueEvents(t),y.processEventQueue(!1)}function a(t,e){S=t,P=e,S.attachEvent(\"onchange\",i)}function u(){S&&(S.detachEvent(\"onchange\",i),S=null,P=null)}function c(t,e){if(\"topChange\"===t)return e}function s(t,e,n){\"topFocus\"===t?(u(),a(e,n)):\"topBlur\"===t&&u()}function l(t,e){S=t,P=e,N=t.value,A=Object.getOwnPropertyDescriptor(t.constructor.prototype,\"value\"),Object.defineProperty(S,\"value\",D),S.attachEvent?S.attachEvent(\"onpropertychange\",p):S.addEventListener(\"propertychange\",p,!1)}function f(){S&&(delete S.value,S.detachEvent?S.detachEvent(\"onpropertychange\",p):S.removeEventListener(\"propertychange\",p,!1),S=null,P=null,N=null,A=null)}function p(t){if(\"value\"===t.propertyName){var e=t.srcElement.value;e!==N&&(N=e,i(t))}}function h(t,e){if(\"topInput\"===t)return e}function d(t,e,n){\"topFocus\"===t?(f(),l(e,n)):\"topBlur\"===t&&f()}function v(t,e){if((\"topSelectionChange\"===t||\"topKeyUp\"===t||\"topKeyDown\"===t)&&S&&S.value!==N)return N=S.value,P}function g(t){return t.nodeName&&\"input\"===t.nodeName.toLowerCase()&&(\"checkbox\"===t.type||\"radio\"===t.type)}function m(t,e){if(\"topClick\"===t)return e}var y=n(22),_=n(23),b=n(6),x=n(4),w=n(11),C=n(14),M=n(93),k=n(94),E=n(170),T={change:{phasedRegistrationNames:{bubbled:\"onChange\",captured:\"onChangeCapture\"},dependencies:[\"topBlur\",\"topChange\",\"topClick\",\"topFocus\",\"topInput\",\"topKeyDown\",\"topKeyUp\",\"topSelectionChange\"]}},S=null,P=null,N=null,A=null,O=!1;b.canUseDOM&&(O=k(\"change\")&&(!document.documentMode||document.documentMode>8));var I=!1;b.canUseDOM&&(I=k(\"input\")&&(!document.documentMode||document.documentMode>11));var D={get:function(){return A.get.call(this)},set:function(t){N=\"\"+t,A.set.call(this,t)}},R={eventTypes:T,extractEvents:function(t,e,n,i){var o,a,u=e?x.getNodeFromInstance(e):window;if(r(u)?O?o=c:a=s:E(u)?I?o=h:(o=v,a=d):g(u)&&(o=m),o){var l=o(t,e);if(l){var f=C.getPooled(T.change,l,n,i);return f.type=\"change\",_.accumulateTwoPhaseDispatches(f),f}}a&&a(t,u,e)}};t.exports=R},function(t,e,n){\"use strict\";var r=n(2),i=n(20),o=n(6),a=n(322),u=n(8),c=(n(0),{dangerouslyReplaceNodeWithMarkup:function(t,e){if(o.canUseDOM?void 0:r(\"56\"),e?void 0:r(\"57\"),\"HTML\"===t.nodeName?r(\"58\"):void 0,\"string\"==typeof e){var n=a(e,u)[0];t.parentNode.replaceChild(n,t)}else i.replaceChildWithTree(t,e)}});t.exports=c},function(t,e,n){\"use strict\";var r=[\"ResponderEventPlugin\",\"SimpleEventPlugin\",\"TapEventPlugin\",\"EnterLeaveEventPlugin\",\"ChangeEventPlugin\",\"SelectEventPlugin\",\"BeforeInputEventPlugin\"];t.exports=r},function(t,e,n){\"use strict\";var r=n(23),i=n(4),o=n(52),a={mouseEnter:{registrationName:\"onMouseEnter\",dependencies:[\"topMouseOut\",\"topMouseOver\"]},mouseLeave:{registrationName:\"onMouseLeave\",dependencies:[\"topMouseOut\",\"topMouseOver\"]}},u={eventTypes:a,extractEvents:function(t,e,n,u){if(\"topMouseOver\"===t&&(n.relatedTarget||n.fromElement))return null;\n",
       "if(\"topMouseOut\"!==t&&\"topMouseOver\"!==t)return null;var c;if(u.window===u)c=u;else{var s=u.ownerDocument;c=s?s.defaultView||s.parentWindow:window}var l,f;if(\"topMouseOut\"===t){l=e;var p=n.relatedTarget||n.toElement;f=p?i.getClosestInstanceFromNode(p):null}else l=null,f=e;if(l===f)return null;var h=null==l?c:i.getNodeFromInstance(l),d=null==f?c:i.getNodeFromInstance(f),v=o.getPooled(a.mouseLeave,l,n,u);v.type=\"mouseleave\",v.target=h,v.relatedTarget=d;var g=o.getPooled(a.mouseEnter,f,n,u);return g.type=\"mouseenter\",g.target=d,g.relatedTarget=h,r.accumulateEnterLeaveDispatches(v,g,l,f),[v,g]}};t.exports=u},function(t,e,n){\"use strict\";var r={topAbort:null,topAnimationEnd:null,topAnimationIteration:null,topAnimationStart:null,topBlur:null,topCanPlay:null,topCanPlayThrough:null,topChange:null,topClick:null,topCompositionEnd:null,topCompositionStart:null,topCompositionUpdate:null,topContextMenu:null,topCopy:null,topCut:null,topDoubleClick:null,topDrag:null,topDragEnd:null,topDragEnter:null,topDragExit:null,topDragLeave:null,topDragOver:null,topDragStart:null,topDrop:null,topDurationChange:null,topEmptied:null,topEncrypted:null,topEnded:null,topError:null,topFocus:null,topInput:null,topInvalid:null,topKeyDown:null,topKeyPress:null,topKeyUp:null,topLoad:null,topLoadedData:null,topLoadedMetadata:null,topLoadStart:null,topMouseDown:null,topMouseMove:null,topMouseOut:null,topMouseOver:null,topMouseUp:null,topPaste:null,topPause:null,topPlay:null,topPlaying:null,topProgress:null,topRateChange:null,topReset:null,topScroll:null,topSeeked:null,topSeeking:null,topSelectionChange:null,topStalled:null,topSubmit:null,topSuspend:null,topTextInput:null,topTimeUpdate:null,topTouchCancel:null,topTouchEnd:null,topTouchMove:null,topTouchStart:null,topTransitionEnd:null,topVolumeChange:null,topWaiting:null,topWheel:null},i={topLevelTypes:r};t.exports=i},function(t,e,n){\"use strict\";function r(t){this._root=t,this._startText=this.getText(),this._fallbackText=null}var i=n(3),o=n(17),a=n(168);i(r.prototype,{destructor:function(){this._root=null,this._startText=null,this._fallbackText=null},getText:function(){return\"value\"in this._root?this._root.value:this._root[a()]},getData:function(){if(this._fallbackText)return this._fallbackText;var t,e,n=this._startText,r=n.length,i=this.getText(),o=i.length;for(t=0;t<r&&n[t]===i[t];t++);var a=r-t;for(e=1;e<=a&&n[r-e]===i[o-e];e++);var u=e>1?1-e:void 0;return this._fallbackText=i.slice(t,u),this._fallbackText}}),o.addPoolingTo(r),t.exports=r},function(t,e,n){\"use strict\";var r=n(21),i=r.injection.MUST_USE_PROPERTY,o=r.injection.HAS_BOOLEAN_VALUE,a=r.injection.HAS_NUMERIC_VALUE,u=r.injection.HAS_POSITIVE_NUMERIC_VALUE,c=r.injection.HAS_OVERLOADED_BOOLEAN_VALUE,s={isCustomAttribute:RegExp.prototype.test.bind(new RegExp(\"^(data|aria)-[\"+r.ATTRIBUTE_NAME_CHAR+\"]*$\")),Properties:{accept:0,acceptCharset:0,accessKey:0,action:0,allowFullScreen:o,allowTransparency:0,alt:0,as:0,async:o,autoComplete:0,autoPlay:o,capture:o,cellPadding:0,cellSpacing:0,charSet:0,challenge:0,checked:i|o,cite:0,classID:0,className:0,cols:u,colSpan:0,content:0,contentEditable:0,contextMenu:0,controls:o,coords:0,crossOrigin:0,data:0,dateTime:0,default:o,defer:o,dir:0,disabled:o,download:c,draggable:0,encType:0,form:0,formAction:0,formEncType:0,formMethod:0,formNoValidate:o,formTarget:0,frameBorder:0,headers:0,height:0,hidden:o,high:0,href:0,hrefLang:0,htmlFor:0,httpEquiv:0,icon:0,id:0,inputMode:0,integrity:0,is:0,keyParams:0,keyType:0,kind:0,label:0,lang:0,list:0,loop:o,low:0,manifest:0,marginHeight:0,marginWidth:0,max:0,maxLength:0,media:0,mediaGroup:0,method:0,min:0,minLength:0,multiple:i|o,muted:i|o,name:0,nonce:0,noValidate:o,open:o,optimum:0,pattern:0,placeholder:0,playsInline:o,poster:0,preload:0,profile:0,radioGroup:0,readOnly:o,referrerPolicy:0,rel:0,required:o,reversed:o,role:0,rows:u,rowSpan:a,sandbox:0,scope:0,scoped:o,scrolling:0,seamless:o,selected:i|o,shape:0,size:u,sizes:0,span:u,spellCheck:0,src:0,srcDoc:0,srcLang:0,srcSet:0,start:a,step:0,style:0,summary:0,tabIndex:0,target:0,title:0,type:0,useMap:0,value:0,width:0,wmode:0,wrap:0,about:0,datatype:0,inlist:0,prefix:0,property:0,resource:0,typeof:0,vocab:0,autoCapitalize:0,autoCorrect:0,autoSave:0,color:0,itemProp:0,itemScope:o,itemType:0,itemID:0,itemRef:0,results:0,security:0,unselectable:0},DOMAttributeNames:{acceptCharset:\"accept-charset\",className:\"class\",htmlFor:\"for\",httpEquiv:\"http-equiv\"},DOMPropertyNames:{}};t.exports=s},function(t,e,n){\"use strict\";(function(e){function r(t,e,n,r){var i=void 0===t[n];null!=e&&i&&(t[n]=o(e,!0))}var i=n(24),o=n(169),a=(n(84),n(95)),u=n(172);n(1);\"undefined\"!=typeof e&&e.env,1;var c={instantiateChildren:function(t,e,n,i){if(null==t)return null;var o={};return u(t,r,o),o},updateChildren:function(t,e,n,r,u,c,s,l,f){if(e||t){var p,h;for(p in e)if(e.hasOwnProperty(p)){h=t&&t[p];var d=h&&h._currentElement,v=e[p];if(null!=h&&a(d,v))i.receiveComponent(h,v,u,l),e[p]=h;else{h&&(r[p]=i.getHostNode(h),i.unmountComponent(h,!1));var g=o(v,!0);e[p]=g;var m=i.mountComponent(g,u,c,s,l,f);n.push(m)}}for(p in t)!t.hasOwnProperty(p)||e&&e.hasOwnProperty(p)||(h=t[p],r[p]=i.getHostNode(h),i.unmountComponent(h,!1))}},unmountChildren:function(t,e){for(var n in t)if(t.hasOwnProperty(n)){var r=t[n];i.unmountComponent(r,e)}}};t.exports=c}).call(e,n(153))},function(t,e,n){\"use strict\";var r=n(81),i=n(350),o={processChildrenUpdates:i.dangerouslyProcessChildrenUpdates,replaceNodeWithMarkup:r.dangerouslyReplaceNodeWithMarkup};t.exports=o},function(t,e,n){\"use strict\";function r(t){}function i(t,e){}function o(t){return!(!t.prototype||!t.prototype.isReactComponent)}function a(t){return!(!t.prototype||!t.prototype.isPureReactComponent)}var u=n(2),c=n(3),s=n(26),l=n(86),f=n(15),p=n(87),h=n(40),d=(n(9),n(164)),v=n(24),g=n(38),m=(n(0),n(80)),y=n(95),_=(n(1),{ImpureClass:0,PureClass:1,StatelessFunctional:2});r.prototype.render=function(){var t=h.get(this)._currentElement.type,e=t(this.props,this.context,this.updater);return i(t,e),e};var b=1,x={construct:function(t){this._currentElement=t,this._rootNodeID=0,this._compositeType=null,this._instance=null,this._hostParent=null,this._hostContainerInfo=null,this._updateBatchNumber=null,this._pendingElement=null,this._pendingStateQueue=null,this._pendingReplaceState=!1,this._pendingForceUpdate=!1,this._renderedNodeType=null,this._renderedComponent=null,this._context=null,this._mountOrder=0,this._topLevelWrapper=null,this._pendingCallbacks=null,this._calledComponentWillUnmount=!1},mountComponent:function(t,e,n,c){this._context=c,this._mountOrder=b++,this._hostParent=e,this._hostContainerInfo=n;var l,f=this._currentElement.props,p=this._processContext(c),d=this._currentElement.type,v=t.getUpdateQueue(),m=o(d),y=this._constructComponent(m,f,p,v);m||null!=y&&null!=y.render?a(d)?this._compositeType=_.PureClass:this._compositeType=_.ImpureClass:(l=y,i(d,l),null===y||y===!1||s.isValidElement(y)?void 0:u(\"105\",d.displayName||d.name||\"Component\"),y=new r(d),this._compositeType=_.StatelessFunctional);y.props=f,y.context=p,y.refs=g,y.updater=v,this._instance=y,h.set(y,this);var x=y.state;void 0===x&&(y.state=x=null),\"object\"!=typeof x||Array.isArray(x)?u(\"106\",this.getName()||\"ReactCompositeComponent\"):void 0,this._pendingStateQueue=null,this._pendingReplaceState=!1,this._pendingForceUpdate=!1;var w;return w=y.unstable_handleError?this.performInitialMountWithErrorHandling(l,e,n,t,c):this.performInitialMount(l,e,n,t,c),y.componentDidMount&&t.getReactMountReady().enqueue(y.componentDidMount,y),w},_constructComponent:function(t,e,n,r){return this._constructComponentWithoutOwner(t,e,n,r)},_constructComponentWithoutOwner:function(t,e,n,r){var i=this._currentElement.type;return t?new i(e,n,r):i(e,n,r)},performInitialMountWithErrorHandling:function(t,e,n,r,i){var o,a=r.checkpoint();try{o=this.performInitialMount(t,e,n,r,i)}catch(u){r.rollback(a),this._instance.unstable_handleError(u),this._pendingStateQueue&&(this._instance.state=this._processPendingState(this._instance.props,this._instance.context)),a=r.checkpoint(),this._renderedComponent.unmountComponent(!0),r.rollback(a),o=this.performInitialMount(t,e,n,r,i)}return o},performInitialMount:function(t,e,n,r,i){var o=this._instance,a=0;o.componentWillMount&&(o.componentWillMount(),this._pendingStateQueue&&(o.state=this._processPendingState(o.props,o.context))),void 0===t&&(t=this._renderValidatedComponent());var u=d.getType(t);this._renderedNodeType=u;var c=this._instantiateReactComponent(t,u!==d.EMPTY);this._renderedComponent=c;var s=v.mountComponent(c,r,e,n,this._processChildContext(i),a);return s},getHostNode:function(){return v.getHostNode(this._renderedComponent)},unmountComponent:function(t){if(this._renderedComponent){var e=this._instance;if(e.componentWillUnmount&&!e._calledComponentWillUnmount)if(e._calledComponentWillUnmount=!0,t){var n=this.getName()+\".componentWillUnmount()\";p.invokeGuardedCallback(n,e.componentWillUnmount.bind(e))}else e.componentWillUnmount();this._renderedComponent&&(v.unmountComponent(this._renderedComponent,t),this._renderedNodeType=null,this._renderedComponent=null,this._instance=null),this._pendingStateQueue=null,this._pendingReplaceState=!1,this._pendingForceUpdate=!1,this._pendingCallbacks=null,this._pendingElement=null,this._context=null,this._rootNodeID=0,this._topLevelWrapper=null,h.remove(e)}},_maskContext:function(t){var e=this._currentElement.type,n=e.contextTypes;if(!n)return g;var r={};for(var i in n)r[i]=t[i];return r},_processContext:function(t){var e=this._maskContext(t);return e},_processChildContext:function(t){var e,n=this._currentElement.type,r=this._instance;if(r.getChildContext&&(e=r.getChildContext()),e){\"object\"!=typeof n.childContextTypes?u(\"107\",this.getName()||\"ReactCompositeComponent\"):void 0;for(var i in e)i in n.childContextTypes?void 0:u(\"108\",this.getName()||\"ReactCompositeComponent\",i);return c({},t,e)}return t},_checkContextTypes:function(t,e,n){},receiveComponent:function(t,e,n){var r=this._currentElement,i=this._context;this._pendingElement=null,this.updateComponent(e,r,t,i,n)},performUpdateIfNecessary:function(t){null!=this._pendingElement?v.receiveComponent(this,this._pendingElement,t,this._context):null!==this._pendingStateQueue||this._pendingForceUpdate?this.updateComponent(t,this._currentElement,this._currentElement,this._context,this._context):this._updateBatchNumber=null},updateComponent:function(t,e,n,r,i){var o=this._instance;null==o?u(\"136\",this.getName()||\"ReactCompositeComponent\"):void 0;var a,c=!1;this._context===i?a=o.context:(a=this._processContext(i),c=!0);var s=e.props,l=n.props;e!==n&&(c=!0),c&&o.componentWillReceiveProps&&o.componentWillReceiveProps(l,a);var f=this._processPendingState(l,a),p=!0;this._pendingForceUpdate||(o.shouldComponentUpdate?p=o.shouldComponentUpdate(l,f,a):this._compositeType===_.PureClass&&(p=!m(s,l)||!m(o.state,f))),this._updateBatchNumber=null,p?(this._pendingForceUpdate=!1,this._performComponentUpdate(n,l,f,a,t,i)):(this._currentElement=n,this._context=i,o.props=l,o.state=f,o.context=a)},_processPendingState:function(t,e){var n=this._instance,r=this._pendingStateQueue,i=this._pendingReplaceState;if(this._pendingReplaceState=!1,this._pendingStateQueue=null,!r)return n.state;if(i&&1===r.length)return r[0];for(var o=c({},i?r[0]:n.state),a=i?1:0;a<r.length;a++){var u=r[a];c(o,\"function\"==typeof u?u.call(n,o,t,e):u)}return o},_performComponentUpdate:function(t,e,n,r,i,o){var a,u,c,s=this._instance,l=Boolean(s.componentDidUpdate);l&&(a=s.props,u=s.state,c=s.context),s.componentWillUpdate&&s.componentWillUpdate(e,n,r),this._currentElement=t,this._context=o,s.props=e,s.state=n,s.context=r,this._updateRenderedComponent(i,o),l&&i.getReactMountReady().enqueue(s.componentDidUpdate.bind(s,a,u,c),s)},_updateRenderedComponent:function(t,e){var n=this._renderedComponent,r=n._currentElement,i=this._renderValidatedComponent(),o=0;if(y(r,i))v.receiveComponent(n,i,t,this._processChildContext(e));else{var a=v.getHostNode(n);v.unmountComponent(n,!1);var u=d.getType(i);this._renderedNodeType=u;var c=this._instantiateReactComponent(i,u!==d.EMPTY);this._renderedComponent=c;var s=v.mountComponent(c,t,this._hostParent,this._hostContainerInfo,this._processChildContext(e),o);this._replaceNodeWithMarkup(a,s,n)}},_replaceNodeWithMarkup:function(t,e,n){l.replaceNodeWithMarkup(t,e,n)},_renderValidatedComponentWithoutOwnerOrContext:function(){var t,e=this._instance;return t=e.render()},_renderValidatedComponent:function(){var t;if(this._compositeType!==_.StatelessFunctional){f.current=this;try{t=this._renderValidatedComponentWithoutOwnerOrContext()}finally{f.current=null}}else t=this._renderValidatedComponentWithoutOwnerOrContext();return null===t||t===!1||s.isValidElement(t)?void 0:u(\"109\",this.getName()||\"ReactCompositeComponent\"),t},attachRef:function(t,e){var n=this.getPublicInstance();null==n?u(\"110\"):void 0;var r=e.getPublicInstance(),i=n.refs===g?n.refs={}:n.refs;i[t]=r},detachRef:function(t){var e=this.getPublicInstance().refs;delete e[t]},getName:function(){var t=this._currentElement.type,e=this._instance&&this._instance.constructor;return t.displayName||e&&e.displayName||t.name||e&&e.name||null},getPublicInstance:function(){var t=this._instance;return this._compositeType===_.StatelessFunctional?null:t},_instantiateReactComponent:null};t.exports=x},function(t,e,n){\"use strict\";var r=n(4),i=n(358),o=n(163),a=n(24),u=n(11),c=n(371),s=n(387),l=n(167),f=n(395);n(1);i.inject();var p={findDOMNode:s,render:o.render,unmountComponentAtNode:o.unmountComponentAtNode,version:c,unstable_batchedUpdates:u.batchedUpdates,unstable_renderSubtreeIntoContainer:f};\"undefined\"!=typeof __REACT_DEVTOOLS_GLOBAL_HOOK__&&\"function\"==typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.inject&&__REACT_DEVTOOLS_GLOBAL_HOOK__.inject({ComponentTree:{getClosestInstanceFromNode:r.getClosestInstanceFromNode,getNodeFromInstance:function(t){return t._renderedComponent&&(t=l(t)),t?r.getNodeFromInstance(t):null}},Mount:o,Reconciler:a});t.exports=p},function(t,e,n){\"use strict\";function r(t){if(t){var e=t._currentElement._owner||null;if(e){var n=e.getName();if(n)return\" This DOM node was rendered by `\"+n+\"`.\"}}return\"\"}function i(t,e){e&&(G[t._tag]&&(null!=e.children||null!=e.dangerouslySetInnerHTML?v(\"137\",t._tag,t._currentElement._owner?\" Check the render method of \"+t._currentElement._owner.getName()+\".\":\"\"):void 0),null!=e.dangerouslySetInnerHTML&&(null!=e.children?v(\"60\"):void 0,\"object\"==typeof e.dangerouslySetInnerHTML&&V in e.dangerouslySetInnerHTML?void 0:v(\"61\")),null!=e.style&&\"object\"!=typeof e.style?v(\"62\",r(t)):void 0)}function o(t,e,n,r){if(!(r instanceof I)){var i=t._hostContainerInfo,o=i._node&&i._node.nodeType===H,u=o?i._node:i._ownerDocument;F(e,u),r.getReactMountReady().enqueue(a,{inst:t,registrationName:e,listener:n})}}function a(){var t=this;C.putListener(t.inst,t.registrationName,t.listener)}function u(){var t=this;S.postMountWrapper(t)}function c(){var t=this;A.postMountWrapper(t)}function s(){var t=this;P.postMountWrapper(t)}function l(){var t=this;t._rootNodeID?void 0:v(\"63\");var e=U(t);switch(e?void 0:v(\"64\"),t._tag){case\"iframe\":case\"object\":t._wrapperState.listeners=[k.trapBubbledEvent(\"topLoad\",\"load\",e)];break;case\"video\":case\"audio\":t._wrapperState.listeners=[];for(var n in q)q.hasOwnProperty(n)&&t._wrapperState.listeners.push(k.trapBubbledEvent(n,q[n],e));break;case\"source\":t._wrapperState.listeners=[k.trapBubbledEvent(\"topError\",\"error\",e)];break;case\"img\":t._wrapperState.listeners=[k.trapBubbledEvent(\"topError\",\"error\",e),k.trapBubbledEvent(\"topLoad\",\"load\",e)];break;case\"form\":t._wrapperState.listeners=[k.trapBubbledEvent(\"topReset\",\"reset\",e),k.trapBubbledEvent(\"topSubmit\",\"submit\",e)];break;case\"input\":case\"select\":case\"textarea\":t._wrapperState.listeners=[k.trapBubbledEvent(\"topInvalid\",\"invalid\",e)]}}function f(){N.postUpdateWrapper(this)}function p(t){Z.call(X,t)||($.test(t)?void 0:v(\"65\",t),X[t]=!0)}function h(t,e){return t.indexOf(\"-\")>=0||null!=e.is}function d(t){var e=t.type;p(e),this._currentElement=t,this._tag=e.toLowerCase(),this._namespaceURI=null,this._renderedChildren=null,this._previousStyle=null,this._previousStyleCopy=null,this._hostNode=null,this._hostParent=null,this._rootNodeID=0,this._domID=0,this._hostContainerInfo=null,this._wrapperState=null,this._topLevelWrapper=null,this._flags=0}var v=n(2),g=n(3),m=n(332),y=n(334),_=n(20),b=n(82),x=n(21),w=n(156),C=n(22),M=n(83),k=n(51),E=n(157),T=n(4),S=n(351),P=n(352),N=n(158),A=n(355),O=(n(9),n(364)),I=n(369),D=(n(8),n(54)),R=(n(0),n(94),n(80),n(96),n(1),E),L=C.deleteListener,U=T.getNodeFromInstance,F=k.listenTo,j=M.registrationNameModules,B={string:!0,number:!0},W=\"style\",V=\"__html\",z={children:null,dangerouslySetInnerHTML:null,suppressContentEditableWarning:null},H=11,q={topAbort:\"abort\",topCanPlay:\"canplay\",topCanPlayThrough:\"canplaythrough\",topDurationChange:\"durationchange\",topEmptied:\"emptied\",topEncrypted:\"encrypted\",topEnded:\"ended\",topError:\"error\",topLoadedData:\"loadeddata\",topLoadedMetadata:\"loadedmetadata\",topLoadStart:\"loadstart\",topPause:\"pause\",topPlay:\"play\",topPlaying:\"playing\",topProgress:\"progress\",topRateChange:\"ratechange\",topSeeked:\"seeked\",topSeeking:\"seeking\",topStalled:\"stalled\",topSuspend:\"suspend\",topTimeUpdate:\"timeupdate\",topVolumeChange:\"volumechange\",topWaiting:\"waiting\"},Y={area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0},K={listing:!0,pre:!0,textarea:!0},G=g({menuitem:!0},Y),$=/^[a-zA-Z][a-zA-Z:_\\.\\-\\d]*$/,X={},Z={}.hasOwnProperty,Q=1;d.displayName=\"ReactDOMComponent\",d.Mixin={mountComponent:function(t,e,n,r){this._rootNodeID=Q++,this._domID=n._idCounter++,this._hostParent=e,this._hostContainerInfo=n;var o=this._currentElement.props;switch(this._tag){case\"audio\":case\"form\":case\"iframe\":case\"img\":case\"link\":case\"object\":case\"source\":case\"video\":this._wrapperState={listeners:null},t.getReactMountReady().enqueue(l,this);break;case\"input\":S.mountWrapper(this,o,e),o=S.getHostProps(this,o),t.getReactMountReady().enqueue(l,this);break;case\"option\":P.mountWrapper(this,o,e),o=P.getHostProps(this,o);break;case\"select\":N.mountWrapper(this,o,e),o=N.getHostProps(this,o),t.getReactMountReady().enqueue(l,this);break;case\"textarea\":A.mountWrapper(this,o,e),o=A.getHostProps(this,o),t.getReactMountReady().enqueue(l,this)}i(this,o);var a,f;null!=e?(a=e._namespaceURI,f=e._tag):n._tag&&(a=n._namespaceURI,f=n._tag),(null==a||a===b.svg&&\"foreignobject\"===f)&&(a=b.html),a===b.html&&(\"svg\"===this._tag?a=b.svg:\"math\"===this._tag&&(a=b.mathml)),this._namespaceURI=a;var p;if(t.useCreateElement){var h,d=n._ownerDocument;if(a===b.html)if(\"script\"===this._tag){var v=d.createElement(\"div\"),g=this._currentElement.type;v.innerHTML=\"<\"+g+\"></\"+g+\">\",h=v.removeChild(v.firstChild)}else h=o.is?d.createElement(this._currentElement.type,o.is):d.createElement(this._currentElement.type);else h=d.createElementNS(a,this._currentElement.type);T.precacheNode(this,h),this._flags|=R.hasCachedChildNodes,this._hostParent||w.setAttributeForRoot(h),this._updateDOMProperties(null,o,t);var y=_(h);this._createInitialChildren(t,o,r,y),p=y}else{var x=this._createOpenTagMarkupAndPutListeners(t,o),C=this._createContentMarkup(t,o,r);p=!C&&Y[this._tag]?x+\"/>\":x+\">\"+C+\"</\"+this._currentElement.type+\">\"}switch(this._tag){case\"input\":t.getReactMountReady().enqueue(u,this),o.autoFocus&&t.getReactMountReady().enqueue(m.focusDOMComponent,this);break;case\"textarea\":t.getReactMountReady().enqueue(c,this),o.autoFocus&&t.getReactMountReady().enqueue(m.focusDOMComponent,this);break;case\"select\":o.autoFocus&&t.getReactMountReady().enqueue(m.focusDOMComponent,this);break;case\"button\":o.autoFocus&&t.getReactMountReady().enqueue(m.focusDOMComponent,this);break;case\"option\":t.getReactMountReady().enqueue(s,this)}return p},_createOpenTagMarkupAndPutListeners:function(t,e){var n=\"<\"+this._currentElement.type;for(var r in e)if(e.hasOwnProperty(r)){var i=e[r];if(null!=i)if(j.hasOwnProperty(r))i&&o(this,r,i,t);else{r===W&&(i&&(i=this._previousStyleCopy=g({},e.style)),i=y.createMarkupForStyles(i,this));var a=null;null!=this._tag&&h(this._tag,e)?z.hasOwnProperty(r)||(a=w.createMarkupForCustomAttribute(r,i)):a=w.createMarkupForProperty(r,i),a&&(n+=\" \"+a)}}return t.renderToStaticMarkup?n:(this._hostParent||(n+=\" \"+w.createMarkupForRoot()),n+=\" \"+w.createMarkupForID(this._domID))},_createContentMarkup:function(t,e,n){var r=\"\",i=e.dangerouslySetInnerHTML;if(null!=i)null!=i.__html&&(r=i.__html);else{var o=B[typeof e.children]?e.children:null,a=null!=o?null:e.children;if(null!=o)r=D(o);else if(null!=a){var u=this.mountChildren(a,t,n);r=u.join(\"\")}}return K[this._tag]&&\"\\n\"===r.charAt(0)?\"\\n\"+r:r},_createInitialChildren:function(t,e,n,r){var i=e.dangerouslySetInnerHTML;if(null!=i)null!=i.__html&&_.queueHTML(r,i.__html);else{var o=B[typeof e.children]?e.children:null,a=null!=o?null:e.children;if(null!=o)\"\"!==o&&_.queueText(r,o);else if(null!=a)for(var u=this.mountChildren(a,t,n),c=0;c<u.length;c++)_.queueChild(r,u[c])}},receiveComponent:function(t,e,n){var r=this._currentElement;this._currentElement=t,this.updateComponent(e,r,t,n)},updateComponent:function(t,e,n,r){var o=e.props,a=this._currentElement.props;switch(this._tag){case\"input\":o=S.getHostProps(this,o),a=S.getHostProps(this,a);break;case\"option\":o=P.getHostProps(this,o),a=P.getHostProps(this,a);break;case\"select\":o=N.getHostProps(this,o),a=N.getHostProps(this,a);break;case\"textarea\":o=A.getHostProps(this,o),a=A.getHostProps(this,a)}switch(i(this,a),this._updateDOMProperties(o,a,t),this._updateDOMChildren(o,a,t,r),this._tag){case\"input\":S.updateWrapper(this);break;case\"textarea\":A.updateWrapper(this);break;case\"select\":t.getReactMountReady().enqueue(f,this)}},_updateDOMProperties:function(t,e,n){var r,i,a;for(r in t)if(!e.hasOwnProperty(r)&&t.hasOwnProperty(r)&&null!=t[r])if(r===W){var u=this._previousStyleCopy;for(i in u)u.hasOwnProperty(i)&&(a=a||{},a[i]=\"\");this._previousStyleCopy=null}else j.hasOwnProperty(r)?t[r]&&L(this,r):h(this._tag,t)?z.hasOwnProperty(r)||w.deleteValueForAttribute(U(this),r):(x.properties[r]||x.isCustomAttribute(r))&&w.deleteValueForProperty(U(this),r);for(r in e){var c=e[r],s=r===W?this._previousStyleCopy:null!=t?t[r]:void 0;if(e.hasOwnProperty(r)&&c!==s&&(null!=c||null!=s))if(r===W)if(c?c=this._previousStyleCopy=g({},c):this._previousStyleCopy=null,s){for(i in s)!s.hasOwnProperty(i)||c&&c.hasOwnProperty(i)||(a=a||{},a[i]=\"\");for(i in c)c.hasOwnProperty(i)&&s[i]!==c[i]&&(a=a||{},a[i]=c[i])}else a=c;else if(j.hasOwnProperty(r))c?o(this,r,c,n):s&&L(this,r);else if(h(this._tag,e))z.hasOwnProperty(r)||w.setValueForAttribute(U(this),r,c);else if(x.properties[r]||x.isCustomAttribute(r)){var l=U(this);null!=c?w.setValueForProperty(l,r,c):w.deleteValueForProperty(l,r)}}a&&y.setValueForStyles(U(this),a,this)},_updateDOMChildren:function(t,e,n,r){var i=B[typeof t.children]?t.children:null,o=B[typeof e.children]?e.children:null,a=t.dangerouslySetInnerHTML&&t.dangerouslySetInnerHTML.__html,u=e.dangerouslySetInnerHTML&&e.dangerouslySetInnerHTML.__html,c=null!=i?null:t.children,s=null!=o?null:e.children,l=null!=i||null!=a,f=null!=o||null!=u;null!=c&&null==s?this.updateChildren(null,n,r):l&&!f&&this.updateTextContent(\"\"),null!=o?i!==o&&this.updateTextContent(\"\"+o):null!=u?a!==u&&this.updateMarkup(\"\"+u):null!=s&&this.updateChildren(s,n,r)},getHostNode:function(){return U(this)},unmountComponent:function(t){switch(this._tag){case\"audio\":case\"form\":case\"iframe\":case\"img\":case\"link\":case\"object\":case\"source\":case\"video\":var e=this._wrapperState.listeners;if(e)for(var n=0;n<e.length;n++)e[n].remove();break;case\"html\":case\"head\":case\"body\":v(\"66\",this._tag)}this.unmountChildren(t),T.uncacheNode(this),C.deleteAllListeners(this),this._rootNodeID=0,this._domID=0,this._wrapperState=null},getPublicInstance:function(){return U(this)}},g(d.prototype,d.Mixin,O.Mixin),t.exports=d},function(t,e,n){\"use strict\";function r(t,e){var n={_topLevelWrapper:t,_idCounter:1,_ownerDocument:e?e.nodeType===i?e:e.ownerDocument:null,_node:e,_tag:e?e.nodeName.toLowerCase():null,_namespaceURI:e?e.namespaceURI:null};return n}var i=(n(96),9);t.exports=r},function(t,e,n){\"use strict\";var r=n(3),i=n(20),o=n(4),a=function(t){this._currentElement=null,this._hostNode=null,this._hostParent=null,this._hostContainerInfo=null,this._domID=0};r(a.prototype,{mountComponent:function(t,e,n,r){var a=n._idCounter++;this._domID=a,this._hostParent=e,this._hostContainerInfo=n;var u=\" react-empty: \"+this._domID+\" \";if(t.useCreateElement){var c=n._ownerDocument,s=c.createComment(u);return o.precacheNode(this,s),i(s)}return t.renderToStaticMarkup?\"\":\"<!--\"+u+\"-->\"},receiveComponent:function(){},getHostNode:function(){return o.getNodeFromInstance(this)},unmountComponent:function(){o.uncacheNode(this)}}),t.exports=a},function(t,e,n){\"use strict\";var r={useCreateElement:!0,useFiber:!1};t.exports=r},function(t,e,n){\"use strict\";var r=n(81),i=n(4),o={dangerouslyProcessChildrenUpdates:function(t,e){var n=i.getNodeFromInstance(t);r.processUpdates(n,e)}};t.exports=o},function(t,e,n){\"use strict\";function r(){this._rootNodeID&&f.updateWrapper(this)}function i(t){var e=this._currentElement.props,n=c.executeOnChange(e,t);l.asap(r,this);var i=e.name;if(\"radio\"===e.type&&null!=i){for(var a=s.getNodeFromInstance(this),u=a;u.parentNode;)u=u.parentNode;for(var f=u.querySelectorAll(\"input[name=\"+JSON.stringify(\"\"+i)+'][type=\"radio\"]'),p=0;p<f.length;p++){var h=f[p];if(h!==a&&h.form===a.form){var d=s.getInstanceFromNode(h);d?void 0:o(\"90\"),l.asap(r,d)}}}return n}var o=n(2),a=n(3),u=n(156),c=n(85),s=n(4),l=n(11),f=(n(0),n(1),{getHostProps:function(t,e){var n=c.getValue(e),r=c.getChecked(e),i=a({type:void 0,step:void 0,min:void 0,max:void 0},e,{defaultChecked:void 0,defaultValue:void 0,value:null!=n?n:t._wrapperState.initialValue,checked:null!=r?r:t._wrapperState.initialChecked,onChange:t._wrapperState.onChange});return i},mountWrapper:function(t,e){var n=e.defaultValue;t._wrapperState={initialChecked:null!=e.checked?e.checked:e.defaultChecked,initialValue:null!=e.value?e.value:n,listeners:null,onChange:i.bind(t)}},updateWrapper:function(t){var e=t._currentElement.props,n=e.checked;null!=n&&u.setValueForProperty(s.getNodeFromInstance(t),\"checked\",n||!1);var r=s.getNodeFromInstance(t),i=c.getValue(e);if(null!=i){var o=\"\"+i;o!==r.value&&(r.value=o)}else null==e.value&&null!=e.defaultValue&&r.defaultValue!==\"\"+e.defaultValue&&(r.defaultValue=\"\"+e.defaultValue),null==e.checked&&null!=e.defaultChecked&&(r.defaultChecked=!!e.defaultChecked)},postMountWrapper:function(t){var e=t._currentElement.props,n=s.getNodeFromInstance(t);switch(e.type){case\"submit\":case\"reset\":break;case\"color\":case\"date\":case\"datetime\":case\"datetime-local\":case\"month\":case\"time\":case\"week\":n.value=\"\",n.value=n.defaultValue;break;default:n.value=n.value}var r=n.name;\"\"!==r&&(n.name=\"\"),n.defaultChecked=!n.defaultChecked,n.defaultChecked=!n.defaultChecked,\"\"!==r&&(n.name=r)}});t.exports=f},function(t,e,n){\"use strict\";function r(t){var e=\"\";return o.Children.forEach(t,function(t){null!=t&&(\"string\"==typeof t||\"number\"==typeof t?e+=t:c||(c=!0))}),e}var i=n(3),o=n(26),a=n(4),u=n(158),c=(n(1),!1),s={mountWrapper:function(t,e,n){var i=null;if(null!=n){var o=n;\"optgroup\"===o._tag&&(o=o._hostParent),null!=o&&\"select\"===o._tag&&(i=u.getSelectValueContext(o))}var a=null;if(null!=i){var c;if(c=null!=e.value?e.value+\"\":r(e.children),a=!1,Array.isArray(i)){for(var s=0;s<i.length;s++)if(\"\"+i[s]===c){a=!0;break}}else a=\"\"+i===c}t._wrapperState={selected:a}},postMountWrapper:function(t){var e=t._currentElement.props;if(null!=e.value){var n=a.getNodeFromInstance(t);n.setAttribute(\"value\",e.value)}},getHostProps:function(t,e){var n=i({selected:void 0,children:void 0},e);null!=t._wrapperState.selected&&(n.selected=t._wrapperState.selected);var o=r(e.children);return o&&(n.children=o),n}};t.exports=s},function(t,e,n){\"use strict\";function r(t,e,n,r){return t===n&&e===r}function i(t){var e=document.selection,n=e.createRange(),r=n.text.length,i=n.duplicate();i.moveToElementText(t),i.setEndPoint(\"EndToStart\",n);var o=i.text.length,a=o+r;return{start:o,end:a}}function o(t){var e=window.getSelection&&window.getSelection();if(!e||0===e.rangeCount)return null;var n=e.anchorNode,i=e.anchorOffset,o=e.focusNode,a=e.focusOffset,u=e.getRangeAt(0);try{u.startContainer.nodeType,u.endContainer.nodeType}catch(t){return null}var c=r(e.anchorNode,e.anchorOffset,e.focusNode,e.focusOffset),s=c?0:u.toString().length,l=u.cloneRange();l.selectNodeContents(t),l.setEnd(u.startContainer,u.startOffset);var f=r(l.startContainer,l.startOffset,l.endContainer,l.endOffset),p=f?0:l.toString().length,h=p+s,d=document.createRange();d.setStart(n,i),d.setEnd(o,a);var v=d.collapsed;return{start:v?h:p,end:v?p:h}}function a(t,e){var n,r,i=document.selection.createRange().duplicate();void 0===e.end?(n=e.start,r=n):e.start>e.end?(n=e.end,r=e.start):(n=e.start,r=e.end),i.moveToElementText(t),i.moveStart(\"character\",n),i.setEndPoint(\"EndToStart\",i),i.moveEnd(\"character\",r-n),i.select()}function u(t,e){if(window.getSelection){var n=window.getSelection(),r=t[l()].length,i=Math.min(e.start,r),o=void 0===e.end?i:Math.min(e.end,r);if(!n.extend&&i>o){var a=o;o=i,i=a}var u=s(t,i),c=s(t,o);if(u&&c){var f=document.createRange();f.setStart(u.node,u.offset),n.removeAllRanges(),i>o?(n.addRange(f),n.extend(c.node,c.offset)):(f.setEnd(c.node,c.offset),n.addRange(f))}}}var c=n(6),s=n(392),l=n(168),f=c.canUseDOM&&\"selection\"in document&&!(\"getSelection\"in window),p={getOffsets:f?i:o,setOffsets:f?a:u};t.exports=p},function(t,e,n){\"use strict\";var r=n(2),i=n(3),o=n(81),a=n(20),u=n(4),c=n(54),s=(n(0),n(96),function(t){this._currentElement=t,this._stringText=\"\"+t,this._hostNode=null,this._hostParent=null,this._domID=0,this._mountIndex=0,this._closingComment=null,this._commentNodes=null});i(s.prototype,{mountComponent:function(t,e,n,r){var i=n._idCounter++,o=\" react-text: \"+i+\" \",s=\" /react-text \";if(this._domID=i,this._hostParent=e,t.useCreateElement){var l=n._ownerDocument,f=l.createComment(o),p=l.createComment(s),h=a(l.createDocumentFragment());return a.queueChild(h,a(f)),this._stringText&&a.queueChild(h,a(l.createTextNode(this._stringText))),a.queueChild(h,a(p)),u.precacheNode(this,f),this._closingComment=p,h}var d=c(this._stringText);return t.renderToStaticMarkup?d:\"<!--\"+o+\"-->\"+d+\"<!--\"+s+\"-->\"},receiveComponent:function(t,e){if(t!==this._currentElement){this._currentElement=t;var n=\"\"+t;if(n!==this._stringText){this._stringText=n;var r=this.getHostNode();o.replaceDelimitedText(r[0],r[1],n)}}},getHostNode:function(){var t=this._commentNodes;if(t)return t;if(!this._closingComment)for(var e=u.getNodeFromInstance(this),n=e.nextSibling;;){if(null==n?r(\"67\",this._domID):void 0,8===n.nodeType&&\" /react-text \"===n.nodeValue){this._closingComment=n;break}n=n.nextSibling}return t=[this._hostNode,this._closingComment],this._commentNodes=t,t},unmountComponent:function(){this._closingComment=null,this._commentNodes=null,u.uncacheNode(this)}}),t.exports=s},function(t,e,n){\"use strict\";function r(){this._rootNodeID&&l.updateWrapper(this)}function i(t){var e=this._currentElement.props,n=u.executeOnChange(e,t);return s.asap(r,this),n}var o=n(2),a=n(3),u=n(85),c=n(4),s=n(11),l=(n(0),n(1),{getHostProps:function(t,e){null!=e.dangerouslySetInnerHTML?o(\"91\"):void 0;var n=a({},e,{value:void 0,defaultValue:void 0,children:\"\"+t._wrapperState.initialValue,onChange:t._wrapperState.onChange});return n},mountWrapper:function(t,e){var n=u.getValue(e),r=n;if(null==n){var a=e.defaultValue,c=e.children;null!=c&&(null!=a?o(\"92\"):void 0,Array.isArray(c)&&(c.length<=1?void 0:o(\"93\"),c=c[0]),a=\"\"+c),null==a&&(a=\"\"),r=a}t._wrapperState={initialValue:\"\"+r,listeners:null,onChange:i.bind(t)}},updateWrapper:function(t){var e=t._currentElement.props,n=c.getNodeFromInstance(t),r=u.getValue(e);if(null!=r){var i=\"\"+r;i!==n.value&&(n.value=i),null==e.defaultValue&&(n.defaultValue=i)}null!=e.defaultValue&&(n.defaultValue=e.defaultValue)},postMountWrapper:function(t){var e=c.getNodeFromInstance(t),n=e.textContent;\n",
       "n===t._wrapperState.initialValue&&(e.value=n)}});t.exports=l},function(t,e,n){\"use strict\";function r(t,e){\"_hostNode\"in t?void 0:c(\"33\"),\"_hostNode\"in e?void 0:c(\"33\");for(var n=0,r=t;r;r=r._hostParent)n++;for(var i=0,o=e;o;o=o._hostParent)i++;for(;n-i>0;)t=t._hostParent,n--;for(;i-n>0;)e=e._hostParent,i--;for(var a=n;a--;){if(t===e)return t;t=t._hostParent,e=e._hostParent}return null}function i(t,e){\"_hostNode\"in t?void 0:c(\"35\"),\"_hostNode\"in e?void 0:c(\"35\");for(;e;){if(e===t)return!0;e=e._hostParent}return!1}function o(t){return\"_hostNode\"in t?void 0:c(\"36\"),t._hostParent}function a(t,e,n){for(var r=[];t;)r.push(t),t=t._hostParent;var i;for(i=r.length;i-- >0;)e(r[i],\"captured\",n);for(i=0;i<r.length;i++)e(r[i],\"bubbled\",n)}function u(t,e,n,i,o){for(var a=t&&e?r(t,e):null,u=[];t&&t!==a;)u.push(t),t=t._hostParent;for(var c=[];e&&e!==a;)c.push(e),e=e._hostParent;var s;for(s=0;s<u.length;s++)n(u[s],\"bubbled\",i);for(s=c.length;s-- >0;)n(c[s],\"captured\",o)}var c=n(2);n(0);t.exports={isAncestor:i,getLowestCommonAncestor:r,getParentInstance:o,traverseTwoPhase:a,traverseEnterLeave:u}},function(t,e,n){\"use strict\";function r(){this.reinitializeTransaction()}var i=n(3),o=n(11),a=n(53),u=n(8),c={initialize:u,close:function(){p.isBatchingUpdates=!1}},s={initialize:u,close:o.flushBatchedUpdates.bind(o)},l=[s,c];i(r.prototype,a,{getTransactionWrappers:function(){return l}});var f=new r,p={isBatchingUpdates:!1,batchedUpdates:function(t,e,n,r,i,o){var a=p.isBatchingUpdates;return p.isBatchingUpdates=!0,a?t(e,n,r,i,o):f.perform(t,null,e,n,r,i,o)}};t.exports=p},function(t,e,n){\"use strict\";function r(){C||(C=!0,y.EventEmitter.injectReactEventListener(m),y.EventPluginHub.injectEventPluginOrder(u),y.EventPluginUtils.injectComponentTree(p),y.EventPluginUtils.injectTreeTraversal(d),y.EventPluginHub.injectEventPluginsByName({SimpleEventPlugin:w,EnterLeaveEventPlugin:c,ChangeEventPlugin:a,SelectEventPlugin:x,BeforeInputEventPlugin:o}),y.HostComponent.injectGenericComponentClass(f),y.HostComponent.injectTextComponentClass(v),y.DOMProperty.injectDOMPropertyConfig(i),y.DOMProperty.injectDOMPropertyConfig(s),y.DOMProperty.injectDOMPropertyConfig(b),y.EmptyComponent.injectEmptyComponentFactory(function(t){return new h(t)}),y.Updates.injectReconcileTransaction(_),y.Updates.injectBatchingStrategy(g),y.Component.injectEnvironment(l))}var i=n(331),o=n(333),a=n(335),u=n(337),c=n(338),s=n(341),l=n(343),f=n(346),p=n(4),h=n(348),d=n(356),v=n(354),g=n(357),m=n(361),y=n(362),_=n(367),b=n(372),x=n(373),w=n(374),C=!1;t.exports={inject:r}},function(t,e,n){\"use strict\";var r=\"function\"==typeof Symbol&&Symbol.for&&Symbol.for(\"react.element\")||60103;t.exports=r},function(t,e,n){\"use strict\";function r(t){i.enqueueEvents(t),i.processEventQueue(!1)}var i=n(22),o={handleTopLevel:function(t,e,n,o){var a=i.extractEvents(t,e,n,o);r(a)}};t.exports=o},function(t,e,n){\"use strict\";function r(t){for(;t._hostParent;)t=t._hostParent;var e=f.getNodeFromInstance(t),n=e.parentNode;return f.getClosestInstanceFromNode(n)}function i(t,e){this.topLevelType=t,this.nativeEvent=e,this.ancestors=[]}function o(t){var e=h(t.nativeEvent),n=f.getClosestInstanceFromNode(e),i=n;do t.ancestors.push(i),i=i&&r(i);while(i);for(var o=0;o<t.ancestors.length;o++)n=t.ancestors[o],v._handleTopLevel(t.topLevelType,n,t.nativeEvent,h(t.nativeEvent))}function a(t){var e=d(window);t(e)}var u=n(3),c=n(150),s=n(6),l=n(17),f=n(4),p=n(11),h=n(93),d=n(324);u(i.prototype,{destructor:function(){this.topLevelType=null,this.nativeEvent=null,this.ancestors.length=0}}),l.addPoolingTo(i,l.twoArgumentPooler);var v={_enabled:!0,_handleTopLevel:null,WINDOW_HANDLE:s.canUseDOM?window:null,setHandleTopLevel:function(t){v._handleTopLevel=t},setEnabled:function(t){v._enabled=!!t},isEnabled:function(){return v._enabled},trapBubbledEvent:function(t,e,n){return n?c.listen(n,e,v.dispatchEvent.bind(null,t)):null},trapCapturedEvent:function(t,e,n){return n?c.capture(n,e,v.dispatchEvent.bind(null,t)):null},monitorScrollValue:function(t){var e=a.bind(null,t);c.listen(window,\"scroll\",e)},dispatchEvent:function(t,e){if(v._enabled){var n=i.getPooled(t,e);try{p.batchedUpdates(o,n)}finally{i.release(n)}}}};t.exports=v},function(t,e,n){\"use strict\";var r=n(21),i=n(22),o=n(50),a=n(86),u=n(159),c=n(51),s=n(161),l=n(11),f={Component:a.injection,DOMProperty:r.injection,EmptyComponent:u.injection,EventPluginHub:i.injection,EventPluginUtils:o.injection,EventEmitter:c.injection,HostComponent:s.injection,Updates:l.injection};t.exports=f},function(t,e,n){\"use strict\";var r=n(385),i=/\\/?>/,o=/^<\\!\\-\\-/,a={CHECKSUM_ATTR_NAME:\"data-react-checksum\",addChecksumToMarkup:function(t){var e=r(t);return o.test(t)?t:t.replace(i,\" \"+a.CHECKSUM_ATTR_NAME+'=\"'+e+'\"$&')},canReuseMarkup:function(t,e){var n=e.getAttribute(a.CHECKSUM_ATTR_NAME);n=n&&parseInt(n,10);var i=r(t);return i===n}};t.exports=a},function(t,e,n){\"use strict\";function r(t,e,n){return{type:\"INSERT_MARKUP\",content:t,fromIndex:null,fromNode:null,toIndex:n,afterNode:e}}function i(t,e,n){return{type:\"MOVE_EXISTING\",content:null,fromIndex:t._mountIndex,fromNode:p.getHostNode(t),toIndex:n,afterNode:e}}function o(t,e){return{type:\"REMOVE_NODE\",content:null,fromIndex:t._mountIndex,fromNode:e,toIndex:null,afterNode:null}}function a(t){return{type:\"SET_MARKUP\",content:t,fromIndex:null,fromNode:null,toIndex:null,afterNode:null}}function u(t){return{type:\"TEXT_CONTENT\",content:t,fromIndex:null,fromNode:null,toIndex:null,afterNode:null}}function c(t,e){return e&&(t=t||[],t.push(e)),t}function s(t,e){f.processChildrenUpdates(t,e)}var l=n(2),f=n(86),p=(n(40),n(9),n(15),n(24)),h=n(342),d=(n(8),n(388)),v=(n(0),{Mixin:{_reconcilerInstantiateChildren:function(t,e,n){return h.instantiateChildren(t,e,n)},_reconcilerUpdateChildren:function(t,e,n,r,i,o){var a,u=0;return a=d(e,u),h.updateChildren(t,a,n,r,i,this,this._hostContainerInfo,o,u),a},mountChildren:function(t,e,n){var r=this._reconcilerInstantiateChildren(t,e,n);this._renderedChildren=r;var i=[],o=0;for(var a in r)if(r.hasOwnProperty(a)){var u=r[a],c=0,s=p.mountComponent(u,e,this,this._hostContainerInfo,n,c);u._mountIndex=o++,i.push(s)}return i},updateTextContent:function(t){var e=this._renderedChildren;h.unmountChildren(e,!1);for(var n in e)e.hasOwnProperty(n)&&l(\"118\");var r=[u(t)];s(this,r)},updateMarkup:function(t){var e=this._renderedChildren;h.unmountChildren(e,!1);for(var n in e)e.hasOwnProperty(n)&&l(\"118\");var r=[a(t)];s(this,r)},updateChildren:function(t,e,n){this._updateChildren(t,e,n)},_updateChildren:function(t,e,n){var r=this._renderedChildren,i={},o=[],a=this._reconcilerUpdateChildren(r,t,o,i,e,n);if(a||r){var u,l=null,f=0,h=0,d=0,v=null;for(u in a)if(a.hasOwnProperty(u)){var g=r&&r[u],m=a[u];g===m?(l=c(l,this.moveChild(g,v,f,h)),h=Math.max(g._mountIndex,h),g._mountIndex=f):(g&&(h=Math.max(g._mountIndex,h)),l=c(l,this._mountChildAtIndex(m,o[d],v,f,e,n)),d++),f++,v=p.getHostNode(m)}for(u in i)i.hasOwnProperty(u)&&(l=c(l,this._unmountChild(r[u],i[u])));l&&s(this,l),this._renderedChildren=a}},unmountChildren:function(t){var e=this._renderedChildren;h.unmountChildren(e,t),this._renderedChildren=null},moveChild:function(t,e,n,r){if(t._mountIndex<r)return i(t,e,n)},createChild:function(t,e,n){return r(n,e,t._mountIndex)},removeChild:function(t,e){return o(t,e)},_mountChildAtIndex:function(t,e,n,r,i,o){return t._mountIndex=r,this.createChild(t,n,e)},_unmountChild:function(t,e){var n=this.removeChild(t,e);return t._mountIndex=null,n}}});t.exports=v},function(t,e,n){\"use strict\";function r(t){return!(!t||\"function\"!=typeof t.attachRef||\"function\"!=typeof t.detachRef)}var i=n(2),o=(n(0),{addComponentAsRefTo:function(t,e,n){r(n)?void 0:i(\"119\"),n.attachRef(e,t)},removeComponentAsRefFrom:function(t,e,n){r(n)?void 0:i(\"120\");var o=n.getPublicInstance();o&&o.refs[e]===t.getPublicInstance()&&n.detachRef(e)}});t.exports=o},function(t,e,n){\"use strict\";var r=\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\";t.exports=r},function(t,e,n){\"use strict\";function r(t){this.reinitializeTransaction(),this.renderToStaticMarkup=!1,this.reactMountReady=o.getPooled(null),this.useCreateElement=t}var i=n(3),o=n(155),a=n(17),u=n(51),c=n(162),s=(n(9),n(53)),l=n(88),f={initialize:c.getSelectionInformation,close:c.restoreSelection},p={initialize:function(){var t=u.isEnabled();return u.setEnabled(!1),t},close:function(t){u.setEnabled(t)}},h={initialize:function(){this.reactMountReady.reset()},close:function(){this.reactMountReady.notifyAll()}},d=[f,p,h],v={getTransactionWrappers:function(){return d},getReactMountReady:function(){return this.reactMountReady},getUpdateQueue:function(){return l},checkpoint:function(){return this.reactMountReady.checkpoint()},rollback:function(t){this.reactMountReady.rollback(t)},destructor:function(){o.release(this.reactMountReady),this.reactMountReady=null}};i(r.prototype,s,v),a.addPoolingTo(r),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n){\"function\"==typeof t?t(e.getPublicInstance()):o.addComponentAsRefTo(e,t,n)}function i(t,e,n){\"function\"==typeof t?t(null):o.removeComponentAsRefFrom(e,t,n)}var o=n(365),a={};a.attachRefs=function(t,e){if(null!==e&&\"object\"==typeof e){var n=e.ref;null!=n&&r(n,t,e._owner)}},a.shouldUpdateRefs=function(t,e){var n=null,r=null;null!==t&&\"object\"==typeof t&&(n=t.ref,r=t._owner);var i=null,o=null;return null!==e&&\"object\"==typeof e&&(i=e.ref,o=e._owner),n!==i||\"string\"==typeof i&&o!==r},a.detachRefs=function(t,e){if(null!==e&&\"object\"==typeof e){var n=e.ref;null!=n&&i(n,t,e._owner)}},t.exports=a},function(t,e,n){\"use strict\";function r(t){this.reinitializeTransaction(),this.renderToStaticMarkup=t,this.useCreateElement=!1,this.updateQueue=new u(this)}var i=n(3),o=n(17),a=n(53),u=(n(9),n(370)),c=[],s={enqueue:function(){}},l={getTransactionWrappers:function(){return c},getReactMountReady:function(){return s},getUpdateQueue:function(){return this.updateQueue},destructor:function(){},checkpoint:function(){},rollback:function(){}};i(r.prototype,a,l),o.addPoolingTo(r),t.exports=r},function(t,e,n){\"use strict\";function r(t,e){if(!(t instanceof e))throw new TypeError(\"Cannot call a class as a function\")}function i(t,e){}var o=n(88),a=(n(1),function(){function t(e){r(this,t),this.transaction=e}return t.prototype.isMounted=function(t){return!1},t.prototype.enqueueCallback=function(t,e,n){this.transaction.isInTransaction()&&o.enqueueCallback(t,e,n)},t.prototype.enqueueForceUpdate=function(t){this.transaction.isInTransaction()?o.enqueueForceUpdate(t):i(t,\"forceUpdate\")},t.prototype.enqueueReplaceState=function(t,e){this.transaction.isInTransaction()?o.enqueueReplaceState(t,e):i(t,\"replaceState\")},t.prototype.enqueueSetState=function(t,e){this.transaction.isInTransaction()?o.enqueueSetState(t,e):i(t,\"setState\")},t}());t.exports=a},function(t,e,n){\"use strict\";t.exports=\"15.4.2\"},function(t,e,n){\"use strict\";var r={xlink:\"http://www.w3.org/1999/xlink\",xml:\"http://www.w3.org/XML/1998/namespace\"},i={accentHeight:\"accent-height\",accumulate:0,additive:0,alignmentBaseline:\"alignment-baseline\",allowReorder:\"allowReorder\",alphabetic:0,amplitude:0,arabicForm:\"arabic-form\",ascent:0,attributeName:\"attributeName\",attributeType:\"attributeType\",autoReverse:\"autoReverse\",azimuth:0,baseFrequency:\"baseFrequency\",baseProfile:\"baseProfile\",baselineShift:\"baseline-shift\",bbox:0,begin:0,bias:0,by:0,calcMode:\"calcMode\",capHeight:\"cap-height\",clip:0,clipPath:\"clip-path\",clipRule:\"clip-rule\",clipPathUnits:\"clipPathUnits\",colorInterpolation:\"color-interpolation\",colorInterpolationFilters:\"color-interpolation-filters\",colorProfile:\"color-profile\",colorRendering:\"color-rendering\",contentScriptType:\"contentScriptType\",contentStyleType:\"contentStyleType\",cursor:0,cx:0,cy:0,d:0,decelerate:0,descent:0,diffuseConstant:\"diffuseConstant\",direction:0,display:0,divisor:0,dominantBaseline:\"dominant-baseline\",dur:0,dx:0,dy:0,edgeMode:\"edgeMode\",elevation:0,enableBackground:\"enable-background\",end:0,exponent:0,externalResourcesRequired:\"externalResourcesRequired\",fill:0,fillOpacity:\"fill-opacity\",fillRule:\"fill-rule\",filter:0,filterRes:\"filterRes\",filterUnits:\"filterUnits\",floodColor:\"flood-color\",floodOpacity:\"flood-opacity\",focusable:0,fontFamily:\"font-family\",fontSize:\"font-size\",fontSizeAdjust:\"font-size-adjust\",fontStretch:\"font-stretch\",fontStyle:\"font-style\",fontVariant:\"font-variant\",fontWeight:\"font-weight\",format:0,from:0,fx:0,fy:0,g1:0,g2:0,glyphName:\"glyph-name\",glyphOrientationHorizontal:\"glyph-orientation-horizontal\",glyphOrientationVertical:\"glyph-orientation-vertical\",glyphRef:\"glyphRef\",gradientTransform:\"gradientTransform\",gradientUnits:\"gradientUnits\",hanging:0,horizAdvX:\"horiz-adv-x\",horizOriginX:\"horiz-origin-x\",ideographic:0,imageRendering:\"image-rendering\",in:0,in2:0,intercept:0,k:0,k1:0,k2:0,k3:0,k4:0,kernelMatrix:\"kernelMatrix\",kernelUnitLength:\"kernelUnitLength\",kerning:0,keyPoints:\"keyPoints\",keySplines:\"keySplines\",keyTimes:\"keyTimes\",lengthAdjust:\"lengthAdjust\",letterSpacing:\"letter-spacing\",lightingColor:\"lighting-color\",limitingConeAngle:\"limitingConeAngle\",local:0,markerEnd:\"marker-end\",markerMid:\"marker-mid\",markerStart:\"marker-start\",markerHeight:\"markerHeight\",markerUnits:\"markerUnits\",markerWidth:\"markerWidth\",mask:0,maskContentUnits:\"maskContentUnits\",maskUnits:\"maskUnits\",mathematical:0,mode:0,numOctaves:\"numOctaves\",offset:0,opacity:0,operator:0,order:0,orient:0,orientation:0,origin:0,overflow:0,overlinePosition:\"overline-position\",overlineThickness:\"overline-thickness\",paintOrder:\"paint-order\",panose1:\"panose-1\",pathLength:\"pathLength\",patternContentUnits:\"patternContentUnits\",patternTransform:\"patternTransform\",patternUnits:\"patternUnits\",pointerEvents:\"pointer-events\",points:0,pointsAtX:\"pointsAtX\",pointsAtY:\"pointsAtY\",pointsAtZ:\"pointsAtZ\",preserveAlpha:\"preserveAlpha\",preserveAspectRatio:\"preserveAspectRatio\",primitiveUnits:\"primitiveUnits\",r:0,radius:0,refX:\"refX\",refY:\"refY\",renderingIntent:\"rendering-intent\",repeatCount:\"repeatCount\",repeatDur:\"repeatDur\",requiredExtensions:\"requiredExtensions\",requiredFeatures:\"requiredFeatures\",restart:0,result:0,rotate:0,rx:0,ry:0,scale:0,seed:0,shapeRendering:\"shape-rendering\",slope:0,spacing:0,specularConstant:\"specularConstant\",specularExponent:\"specularExponent\",speed:0,spreadMethod:\"spreadMethod\",startOffset:\"startOffset\",stdDeviation:\"stdDeviation\",stemh:0,stemv:0,stitchTiles:\"stitchTiles\",stopColor:\"stop-color\",stopOpacity:\"stop-opacity\",strikethroughPosition:\"strikethrough-position\",strikethroughThickness:\"strikethrough-thickness\",string:0,stroke:0,strokeDasharray:\"stroke-dasharray\",strokeDashoffset:\"stroke-dashoffset\",strokeLinecap:\"stroke-linecap\",strokeLinejoin:\"stroke-linejoin\",strokeMiterlimit:\"stroke-miterlimit\",strokeOpacity:\"stroke-opacity\",strokeWidth:\"stroke-width\",surfaceScale:\"surfaceScale\",systemLanguage:\"systemLanguage\",tableValues:\"tableValues\",targetX:\"targetX\",targetY:\"targetY\",textAnchor:\"text-anchor\",textDecoration:\"text-decoration\",textRendering:\"text-rendering\",textLength:\"textLength\",to:0,transform:0,u1:0,u2:0,underlinePosition:\"underline-position\",underlineThickness:\"underline-thickness\",unicode:0,unicodeBidi:\"unicode-bidi\",unicodeRange:\"unicode-range\",unitsPerEm:\"units-per-em\",vAlphabetic:\"v-alphabetic\",vHanging:\"v-hanging\",vIdeographic:\"v-ideographic\",vMathematical:\"v-mathematical\",values:0,vectorEffect:\"vector-effect\",version:0,vertAdvY:\"vert-adv-y\",vertOriginX:\"vert-origin-x\",vertOriginY:\"vert-origin-y\",viewBox:\"viewBox\",viewTarget:\"viewTarget\",visibility:0,widths:0,wordSpacing:\"word-spacing\",writingMode:\"writing-mode\",x:0,xHeight:\"x-height\",x1:0,x2:0,xChannelSelector:\"xChannelSelector\",xlinkActuate:\"xlink:actuate\",xlinkArcrole:\"xlink:arcrole\",xlinkHref:\"xlink:href\",xlinkRole:\"xlink:role\",xlinkShow:\"xlink:show\",xlinkTitle:\"xlink:title\",xlinkType:\"xlink:type\",xmlBase:\"xml:base\",xmlns:0,xmlnsXlink:\"xmlns:xlink\",xmlLang:\"xml:lang\",xmlSpace:\"xml:space\",y:0,y1:0,y2:0,yChannelSelector:\"yChannelSelector\",z:0,zoomAndPan:\"zoomAndPan\"},o={Properties:{},DOMAttributeNamespaces:{xlinkActuate:r.xlink,xlinkArcrole:r.xlink,xlinkHref:r.xlink,xlinkRole:r.xlink,xlinkShow:r.xlink,xlinkTitle:r.xlink,xlinkType:r.xlink,xmlBase:r.xml,xmlLang:r.xml,xmlSpace:r.xml},DOMAttributeNames:{}};Object.keys(i).forEach(function(t){o.Properties[t]=0,i[t]&&(o.DOMAttributeNames[t]=i[t])}),t.exports=o},function(t,e,n){\"use strict\";function r(t){if(\"selectionStart\"in t&&c.hasSelectionCapabilities(t))return{start:t.selectionStart,end:t.selectionEnd};if(window.getSelection){var e=window.getSelection();return{anchorNode:e.anchorNode,anchorOffset:e.anchorOffset,focusNode:e.focusNode,focusOffset:e.focusOffset}}if(document.selection){var n=document.selection.createRange();return{parentElement:n.parentElement(),text:n.text,top:n.boundingTop,left:n.boundingLeft}}}function i(t,e){if(y||null==v||v!==l())return null;var n=r(v);if(!m||!p(m,n)){m=n;var i=s.getPooled(d.select,g,t,e);return i.type=\"select\",i.target=v,o.accumulateTwoPhaseDispatches(i),i}return null}var o=n(23),a=n(6),u=n(4),c=n(162),s=n(14),l=n(152),f=n(170),p=n(80),h=a.canUseDOM&&\"documentMode\"in document&&document.documentMode<=11,d={select:{phasedRegistrationNames:{bubbled:\"onSelect\",captured:\"onSelectCapture\"},dependencies:[\"topBlur\",\"topContextMenu\",\"topFocus\",\"topKeyDown\",\"topKeyUp\",\"topMouseDown\",\"topMouseUp\",\"topSelectionChange\"]}},v=null,g=null,m=null,y=!1,_=!1,b={eventTypes:d,extractEvents:function(t,e,n,r){if(!_)return null;var o=e?u.getNodeFromInstance(e):window;switch(t){case\"topFocus\":(f(o)||\"true\"===o.contentEditable)&&(v=o,g=e,m=null);break;case\"topBlur\":v=null,g=null,m=null;break;case\"topMouseDown\":y=!0;break;case\"topContextMenu\":case\"topMouseUp\":return y=!1,i(n,r);case\"topSelectionChange\":if(h)break;case\"topKeyDown\":case\"topKeyUp\":return i(n,r)}return null},didPutListener:function(t,e,n){\"onSelect\"===e&&(_=!0)}};t.exports=b},function(t,e,n){\"use strict\";function r(t){return\".\"+t._rootNodeID}function i(t){return\"button\"===t||\"input\"===t||\"select\"===t||\"textarea\"===t}var o=n(2),a=n(150),u=n(23),c=n(4),s=n(375),l=n(376),f=n(14),p=n(379),h=n(381),d=n(52),v=n(378),g=n(382),m=n(383),y=n(25),_=n(384),b=n(8),x=n(91),w=(n(0),{}),C={};[\"abort\",\"animationEnd\",\"animationIteration\",\"animationStart\",\"blur\",\"canPlay\",\"canPlayThrough\",\"click\",\"contextMenu\",\"copy\",\"cut\",\"doubleClick\",\"drag\",\"dragEnd\",\"dragEnter\",\"dragExit\",\"dragLeave\",\"dragOver\",\"dragStart\",\"drop\",\"durationChange\",\"emptied\",\"encrypted\",\"ended\",\"error\",\"focus\",\"input\",\"invalid\",\"keyDown\",\"keyPress\",\"keyUp\",\"load\",\"loadedData\",\"loadedMetadata\",\"loadStart\",\"mouseDown\",\"mouseMove\",\"mouseOut\",\"mouseOver\",\"mouseUp\",\"paste\",\"pause\",\"play\",\"playing\",\"progress\",\"rateChange\",\"reset\",\"scroll\",\"seeked\",\"seeking\",\"stalled\",\"submit\",\"suspend\",\"timeUpdate\",\"touchCancel\",\"touchEnd\",\"touchMove\",\"touchStart\",\"transitionEnd\",\"volumeChange\",\"waiting\",\"wheel\"].forEach(function(t){var e=t[0].toUpperCase()+t.slice(1),n=\"on\"+e,r=\"top\"+e,i={phasedRegistrationNames:{bubbled:n,captured:n+\"Capture\"},dependencies:[r]};w[t]=i,C[r]=i});var M={},k={eventTypes:w,extractEvents:function(t,e,n,r){var i=C[t];if(!i)return null;var a;switch(t){case\"topAbort\":case\"topCanPlay\":case\"topCanPlayThrough\":case\"topDurationChange\":case\"topEmptied\":case\"topEncrypted\":case\"topEnded\":case\"topError\":case\"topInput\":case\"topInvalid\":case\"topLoad\":case\"topLoadedData\":case\"topLoadedMetadata\":case\"topLoadStart\":case\"topPause\":case\"topPlay\":case\"topPlaying\":case\"topProgress\":case\"topRateChange\":case\"topReset\":case\"topSeeked\":case\"topSeeking\":case\"topStalled\":case\"topSubmit\":case\"topSuspend\":case\"topTimeUpdate\":case\"topVolumeChange\":case\"topWaiting\":a=f;break;case\"topKeyPress\":if(0===x(n))return null;case\"topKeyDown\":case\"topKeyUp\":a=h;break;case\"topBlur\":case\"topFocus\":a=p;break;case\"topClick\":if(2===n.button)return null;case\"topDoubleClick\":case\"topMouseDown\":case\"topMouseMove\":case\"topMouseUp\":case\"topMouseOut\":case\"topMouseOver\":case\"topContextMenu\":a=d;break;case\"topDrag\":case\"topDragEnd\":case\"topDragEnter\":case\"topDragExit\":case\"topDragLeave\":case\"topDragOver\":case\"topDragStart\":case\"topDrop\":a=v;break;case\"topTouchCancel\":case\"topTouchEnd\":case\"topTouchMove\":case\"topTouchStart\":a=g;break;case\"topAnimationEnd\":case\"topAnimationIteration\":case\"topAnimationStart\":a=s;break;case\"topTransitionEnd\":a=m;break;case\"topScroll\":a=y;break;case\"topWheel\":a=_;break;case\"topCopy\":case\"topCut\":case\"topPaste\":a=l}a?void 0:o(\"86\",t);var c=a.getPooled(i,e,n,r);return u.accumulateTwoPhaseDispatches(c),c},didPutListener:function(t,e,n){if(\"onClick\"===e&&!i(t._tag)){var o=r(t),u=c.getNodeFromInstance(t);M[o]||(M[o]=a.listen(u,\"click\",b))}},willDeleteListener:function(t,e){if(\"onClick\"===e&&!i(t._tag)){var n=r(t);M[n].remove(),delete M[n]}}};t.exports=k},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={animationName:null,elapsedTime:null,pseudoElement:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={clipboardData:function(t){return\"clipboardData\"in t?t.clipboardData:window.clipboardData}};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={data:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(52),o={dataTransfer:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(25),o={relatedTarget:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={data:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(25),o=n(91),a=n(389),u=n(92),c={key:a,location:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,repeat:null,locale:null,getModifierState:u,charCode:function(t){return\"keypress\"===t.type?o(t):0},keyCode:function(t){return\"keydown\"===t.type||\"keyup\"===t.type?t.keyCode:0},which:function(t){return\"keypress\"===t.type?o(t):\"keydown\"===t.type||\"keyup\"===t.type?t.keyCode:0}};i.augmentClass(r,c),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(25),o=n(92),a={touches:null,targetTouches:null,changedTouches:null,altKey:null,metaKey:null,ctrlKey:null,shiftKey:null,getModifierState:o};i.augmentClass(r,a),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(14),o={propertyName:null,elapsedTime:null,pseudoElement:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n,r){return i.call(this,t,e,n,r)}var i=n(52),o={deltaX:function(t){return\"deltaX\"in t?t.deltaX:\"wheelDeltaX\"in t?-t.wheelDeltaX:0},deltaY:function(t){return\"deltaY\"in t?t.deltaY:\"wheelDeltaY\"in t?-t.wheelDeltaY:\"wheelDelta\"in t?-t.wheelDelta:0},deltaZ:null,deltaMode:null};i.augmentClass(r,o),t.exports=r},function(t,e,n){\"use strict\";function r(t){for(var e=1,n=0,r=0,o=t.length,a=o&-4;r<a;){for(var u=Math.min(r+4096,a);r<u;r+=4)n+=(e+=t.charCodeAt(r))+(e+=t.charCodeAt(r+1))+(e+=t.charCodeAt(r+2))+(e+=t.charCodeAt(r+3));e%=i,n%=i}for(;r<o;r++)n+=e+=t.charCodeAt(r);return e%=i,n%=i,e|n<<16}var i=65521;t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n){var r=null==e||\"boolean\"==typeof e||\"\"===e;if(r)return\"\";var i=isNaN(e);if(i||0===e||o.hasOwnProperty(t)&&o[t])return\"\"+e;if(\"string\"==typeof e){e=e.trim()}return e+\"px\"}var i=n(154),o=(n(1),i.isUnitlessNumber);t.exports=r},function(t,e,n){\"use strict\";function r(t){if(null==t)return null;if(1===t.nodeType)return t;var e=a.get(t);return e?(e=u(e),e?o.getNodeFromInstance(e):null):void(\"function\"==typeof t.render?i(\"44\"):i(\"45\",Object.keys(t)))}var i=n(2),o=(n(15),n(4)),a=n(40),u=n(167);n(0),n(1);t.exports=r},function(t,e,n){\"use strict\";(function(e){function r(t,e,n,r){if(t&&\"object\"==typeof t){var i=t,o=void 0===i[n];o&&null!=e&&(i[n]=e)}}function i(t,e){if(null==t)return t;var n={};return o(t,r,n),n}var o=(n(84),n(172));n(1);\"undefined\"!=typeof e&&e.env,1,t.exports=i}).call(e,n(153))},function(t,e,n){\"use strict\";function r(t){if(t.key){var e=o[t.key]||t.key;if(\"Unidentified\"!==e)return e}if(\"keypress\"===t.type){var n=i(t);return 13===n?\"Enter\":String.fromCharCode(n)}return\"keydown\"===t.type||\"keyup\"===t.type?a[t.keyCode]||\"Unidentified\":\"\"}var i=n(91),o={Esc:\"Escape\",Spacebar:\" \",Left:\"ArrowLeft\",Up:\"ArrowUp\",Right:\"ArrowRight\",Down:\"ArrowDown\",Del:\"Delete\",Win:\"OS\",Menu:\"ContextMenu\",Apps:\"ContextMenu\",Scroll:\"ScrollLock\",MozPrintableKey:\"Unidentified\"},a={8:\"Backspace\",9:\"Tab\",12:\"Clear\",13:\"Enter\",16:\"Shift\",17:\"Control\",18:\"Alt\",19:\"Pause\",20:\"CapsLock\",27:\"Escape\",32:\" \",33:\"PageUp\",34:\"PageDown\",35:\"End\",36:\"Home\",37:\"ArrowLeft\",38:\"ArrowUp\",39:\"ArrowRight\",40:\"ArrowDown\",45:\"Insert\",46:\"Delete\",112:\"F1\",113:\"F2\",114:\"F3\",115:\"F4\",116:\"F5\",117:\"F6\",118:\"F7\",119:\"F8\",120:\"F9\",121:\"F10\",122:\"F11\",123:\"F12\",144:\"NumLock\",145:\"ScrollLock\",224:\"Meta\"};t.exports=r},function(t,e,n){\"use strict\";function r(t){var e=t&&(i&&t[i]||t[o]);if(\"function\"==typeof e)return e}var i=\"function\"==typeof Symbol&&Symbol.iterator,o=\"@@iterator\";t.exports=r},function(t,e,n){\"use strict\";function r(){return i++}var i=1;t.exports=r},function(t,e,n){\"use strict\";function r(t){for(;t&&t.firstChild;)t=t.firstChild;return t}function i(t){for(;t;){if(t.nextSibling)return t.nextSibling;t=t.parentNode}}function o(t,e){for(var n=r(t),o=0,a=0;n;){if(3===n.nodeType){if(a=o+n.textContent.length,o<=e&&a>=e)return{node:n,offset:e-o};o=a}n=r(i(n))}}t.exports=o},function(t,e,n){\"use strict\";function r(t,e){var n={};return n[t.toLowerCase()]=e.toLowerCase(),n[\"Webkit\"+t]=\"webkit\"+e,n[\"Moz\"+t]=\"moz\"+e,n[\"ms\"+t]=\"MS\"+e,n[\"O\"+t]=\"o\"+e.toLowerCase(),n}function i(t){if(u[t])return u[t];if(!a[t])return t;var e=a[t];for(var n in e)if(e.hasOwnProperty(n)&&n in c)return u[t]=e[n];return\"\"}var o=n(6),a={animationend:r(\"Animation\",\"AnimationEnd\"),animationiteration:r(\"Animation\",\"AnimationIteration\"),animationstart:r(\"Animation\",\"AnimationStart\"),transitionend:r(\"Transition\",\"TransitionEnd\")},u={},c={};o.canUseDOM&&(c=document.createElement(\"div\").style,\"AnimationEvent\"in window||(delete a.animationend.animation,delete a.animationiteration.animation,delete a.animationstart.animation),\"TransitionEvent\"in window||delete a.transitionend.transition),t.exports=i},function(t,e,n){\"use strict\";function r(t){return'\"'+i(t)+'\"'}var i=n(54);t.exports=r},function(t,e,n){\"use strict\";var r=n(163);t.exports=r.renderSubtreeIntoContainer},function(t,e,n){\"use strict\";function r(t,e){var n=l.extractSingleTouch(e);return n?n[t.page]:t.page in e?e[t.page]:e[t.client]+f[t.envScroll]}function i(t,e){var n=r(b.x,e),i=r(b.y,e);return Math.pow(Math.pow(n-t.x,2)+Math.pow(i-t.y,2),.5)}function o(t){return{tapMoveThreshold:g,ignoreMouseThreshold:m,eventTypes:C,extractEvents:function(e,n,o,a){if(!h(e)&&!d(e))return null;if(v(e))_=M();else if(t(_,M()))return null;var u=null,l=i(y,o);return d(e)&&l<g&&(u=s.getPooled(C.touchTap,n,o,a)),h(e)?(y.x=r(b.x,o),y.y=r(b.y,o)):d(e)&&(y.x=0,y.y=0),c.accumulateTwoPhaseDispatches(u),u}}}var a=n(339),u=n(50),c=n(23),s=n(25),l=n(397),f=n(89),p=n(329),h=(a.topLevelTypes,u.isStartish),d=u.isEndish,v=function(t){var e=[\"topTouchCancel\",\"topTouchEnd\",\"topTouchStart\",\"topTouchMove\"];return e.indexOf(t)>=0},g=10,m=750,y={x:null,y:null},_=null,b={x:{page:\"pageX\",client:\"clientX\",envScroll:\"currentPageScrollLeft\"},y:{page:\"pageY\",client:\"clientY\",envScroll:\"currentPageScrollTop\"}},x=[\"topTouchStart\",\"topTouchCancel\",\"topTouchEnd\",\"topTouchMove\"],w=[\"topMouseDown\",\"topMouseMove\",\"topMouseUp\"].concat(x),C={touchTap:{phasedRegistrationNames:{bubbled:p({onTouchTap:null}),captured:p({onTouchTapCapture:null})},dependencies:w}},M=function(){return Date.now?Date.now:function(){return+new Date}}();t.exports=o},function(t,e){var n={extractSingleTouch:function(t){var e=t.touches,n=t.changedTouches,r=e&&e.length>0,i=n&&n.length>0;return!r&&i?n[0]:r?e[0]:t}};t.exports=n},function(t,e){t.exports=function(t,e){if(t&&e-t<750)return!0}},function(t,e,n){\"use strict\";function r(t){var e=/[=:]/g,n={\"=\":\"=0\",\":\":\"=2\"},r=(\"\"+t).replace(e,function(t){return n[t]});return\"$\"+r}function i(t){var e=/(=0|=2)/g,n={\"=0\":\"=\",\"=2\":\":\"},r=\".\"===t[0]&&\"$\"===t[1]?t.substring(2):t.substring(1);return(\"\"+r).replace(e,function(t){return n[t]})}var o={escape:r,unescape:i};t.exports=o},function(t,e,n){\"use strict\";var r=n(28),i=(n(0),function(t){var e=this;if(e.instancePool.length){var n=e.instancePool.pop();return e.call(n,t),n}return new e(t)}),o=function(t,e){var n=this;if(n.instancePool.length){var r=n.instancePool.pop();return n.call(r,t,e),r}return new n(t,e)},a=function(t,e,n){var r=this;if(r.instancePool.length){var i=r.instancePool.pop();return r.call(i,t,e,n),i}return new r(t,e,n)},u=function(t,e,n,r){var i=this;if(i.instancePool.length){var o=i.instancePool.pop();return i.call(o,t,e,n,r),o}return new i(t,e,n,r)},c=function(t){var e=this;t instanceof e?void 0:r(\"25\"),t.destructor(),e.instancePool.length<e.poolSize&&e.instancePool.push(t)},s=10,l=i,f=function(t,e){var n=t;return n.instancePool=[],n.getPooled=e||l,n.poolSize||(n.poolSize=s),n.release=c,n},p={addPoolingTo:f,oneArgumentPooler:i,twoArgumentPooler:o,threeArgumentPooler:a,fourArgumentPooler:u};t.exports=p},function(t,e,n){\"use strict\";function r(t){return(\"\"+t).replace(b,\"$&/\")}function i(t,e){this.func=t,this.context=e,this.count=0}function o(t,e,n){var r=t.func,i=t.context;r.call(i,e,t.count++)}function a(t,e,n){if(null==t)return t;var r=i.getPooled(e,n);m(t,o,r),i.release(r)}function u(t,e,n,r){this.result=t,this.keyPrefix=e,this.func=n,this.context=r,this.count=0}function c(t,e,n){var i=t.result,o=t.keyPrefix,a=t.func,u=t.context,c=a.call(u,e,t.count++);Array.isArray(c)?s(c,i,n,g.thatReturnsArgument):null!=c&&(v.isValidElement(c)&&(c=v.cloneAndReplaceKey(c,o+(!c.key||e&&e.key===c.key?\"\":r(c.key)+\"/\")+n)),i.push(c))}function s(t,e,n,i,o){var a=\"\";null!=n&&(a=r(n)+\"/\");var s=u.getPooled(e,a,i,o);m(t,c,s),u.release(s)}function l(t,e,n){if(null==t)return t;var r=[];return s(t,r,null,e,n),r}function f(t,e,n){return null}function p(t,e){return m(t,f,null)}function h(t){var e=[];return s(t,e,null,g.thatReturnsArgument),e}var d=n(400),v=n(27),g=n(8),m=n(409),y=d.twoArgumentPooler,_=d.fourArgumentPooler,b=/\\/+/g;i.prototype.destructor=function(){this.func=null,this.context=null,this.count=0},d.addPoolingTo(i,y),u.prototype.destructor=function(){this.result=null,this.keyPrefix=null,this.func=null,this.context=null,this.count=0},d.addPoolingTo(u,_);var x={forEach:a,map:l,mapIntoWithKeyPrefixInternal:s,count:p,toArray:h};t.exports=x},function(t,e,n){\"use strict\";function r(t){return t}function i(t,e){var n=b.hasOwnProperty(e)?b[e]:null;w.hasOwnProperty(e)&&(\"OVERRIDE_BASE\"!==n?p(\"73\",e):void 0),t&&(\"DEFINE_MANY\"!==n&&\"DEFINE_MANY_MERGED\"!==n?p(\"74\",e):void 0)}function o(t,e){if(e){\"function\"==typeof e?p(\"75\"):void 0,v.isValidElement(e)?p(\"76\"):void 0;var n=t.prototype,r=n.__reactAutoBindPairs;e.hasOwnProperty(y)&&x.mixins(t,e.mixins);for(var o in e)if(e.hasOwnProperty(o)&&o!==y){var a=e[o],u=n.hasOwnProperty(o);if(i(u,o),x.hasOwnProperty(o))x[o](t,a);else{var l=b.hasOwnProperty(o),f=\"function\"==typeof a,h=f&&!l&&!u&&e.autobind!==!1;if(h)r.push(o,a),n[o]=a;else if(u){var d=b[o];!l||\"DEFINE_MANY_MERGED\"!==d&&\"DEFINE_MANY\"!==d?p(\"77\",d,o):void 0,\"DEFINE_MANY_MERGED\"===d?n[o]=c(n[o],a):\"DEFINE_MANY\"===d&&(n[o]=s(n[o],a))}else n[o]=a}}}else;}function a(t,e){if(e)for(var n in e){var r=e[n];if(e.hasOwnProperty(n)){var i=n in x;i?p(\"78\",n):void 0;var o=n in t;o?p(\"79\",n):void 0,t[n]=r}}}function u(t,e){t&&e&&\"object\"==typeof t&&\"object\"==typeof e?void 0:p(\"80\");for(var n in e)e.hasOwnProperty(n)&&(void 0!==t[n]?p(\"81\",n):void 0,t[n]=e[n]);return t}function c(t,e){return function(){var n=t.apply(this,arguments),r=e.apply(this,arguments);if(null==n)return r;if(null==r)return n;var i={};return u(i,n),u(i,r),i}}function s(t,e){return function(){t.apply(this,arguments),e.apply(this,arguments)}}function l(t,e){var n=e.bind(t);return n;\n",
       "}function f(t){for(var e=t.__reactAutoBindPairs,n=0;n<e.length;n+=2){var r=e[n],i=e[n+1];t[r]=l(t,i)}}var p=n(28),h=n(3),d=n(97),v=n(27),g=(n(175),n(98)),m=n(38),y=(n(0),n(1),\"mixins\"),_=[],b={mixins:\"DEFINE_MANY\",statics:\"DEFINE_MANY\",propTypes:\"DEFINE_MANY\",contextTypes:\"DEFINE_MANY\",childContextTypes:\"DEFINE_MANY\",getDefaultProps:\"DEFINE_MANY_MERGED\",getInitialState:\"DEFINE_MANY_MERGED\",getChildContext:\"DEFINE_MANY_MERGED\",render:\"DEFINE_ONCE\",componentWillMount:\"DEFINE_MANY\",componentDidMount:\"DEFINE_MANY\",componentWillReceiveProps:\"DEFINE_MANY\",shouldComponentUpdate:\"DEFINE_ONCE\",componentWillUpdate:\"DEFINE_MANY\",componentDidUpdate:\"DEFINE_MANY\",componentWillUnmount:\"DEFINE_MANY\",updateComponent:\"OVERRIDE_BASE\"},x={displayName:function(t,e){t.displayName=e},mixins:function(t,e){if(e)for(var n=0;n<e.length;n++)o(t,e[n])},childContextTypes:function(t,e){t.childContextTypes=h({},t.childContextTypes,e)},contextTypes:function(t,e){t.contextTypes=h({},t.contextTypes,e)},getDefaultProps:function(t,e){t.getDefaultProps?t.getDefaultProps=c(t.getDefaultProps,e):t.getDefaultProps=e},propTypes:function(t,e){t.propTypes=h({},t.propTypes,e)},statics:function(t,e){a(t,e)},autobind:function(){}},w={replaceState:function(t,e){this.updater.enqueueReplaceState(this,t),e&&this.updater.enqueueCallback(this,e,\"replaceState\")},isMounted:function(){return this.updater.isMounted(this)}},C=function(){};h(C.prototype,d.prototype,w);var M={createClass:function(t){var e=r(function(t,n,r){this.__reactAutoBindPairs.length&&f(this),this.props=t,this.context=n,this.refs=m,this.updater=r||g,this.state=null;var i=this.getInitialState?this.getInitialState():null;\"object\"!=typeof i||Array.isArray(i)?p(\"82\",e.displayName||\"ReactCompositeComponent\"):void 0,this.state=i});e.prototype=new C,e.prototype.constructor=e,e.prototype.__reactAutoBindPairs=[],_.forEach(o.bind(null,e)),o(e,t),e.getDefaultProps&&(e.defaultProps=e.getDefaultProps()),e.prototype.render?void 0:p(\"83\");for(var n in b)e.prototype[n]||(e.prototype[n]=null);return e},injection:{injectMixin:function(t){_.push(t)}}};t.exports=M},function(t,e,n){\"use strict\";var r=n(27),i=r.createFactory,o={a:i(\"a\"),abbr:i(\"abbr\"),address:i(\"address\"),area:i(\"area\"),article:i(\"article\"),aside:i(\"aside\"),audio:i(\"audio\"),b:i(\"b\"),base:i(\"base\"),bdi:i(\"bdi\"),bdo:i(\"bdo\"),big:i(\"big\"),blockquote:i(\"blockquote\"),body:i(\"body\"),br:i(\"br\"),button:i(\"button\"),canvas:i(\"canvas\"),caption:i(\"caption\"),cite:i(\"cite\"),code:i(\"code\"),col:i(\"col\"),colgroup:i(\"colgroup\"),data:i(\"data\"),datalist:i(\"datalist\"),dd:i(\"dd\"),del:i(\"del\"),details:i(\"details\"),dfn:i(\"dfn\"),dialog:i(\"dialog\"),div:i(\"div\"),dl:i(\"dl\"),dt:i(\"dt\"),em:i(\"em\"),embed:i(\"embed\"),fieldset:i(\"fieldset\"),figcaption:i(\"figcaption\"),figure:i(\"figure\"),footer:i(\"footer\"),form:i(\"form\"),h1:i(\"h1\"),h2:i(\"h2\"),h3:i(\"h3\"),h4:i(\"h4\"),h5:i(\"h5\"),h6:i(\"h6\"),head:i(\"head\"),header:i(\"header\"),hgroup:i(\"hgroup\"),hr:i(\"hr\"),html:i(\"html\"),i:i(\"i\"),iframe:i(\"iframe\"),img:i(\"img\"),input:i(\"input\"),ins:i(\"ins\"),kbd:i(\"kbd\"),keygen:i(\"keygen\"),label:i(\"label\"),legend:i(\"legend\"),li:i(\"li\"),link:i(\"link\"),main:i(\"main\"),map:i(\"map\"),mark:i(\"mark\"),menu:i(\"menu\"),menuitem:i(\"menuitem\"),meta:i(\"meta\"),meter:i(\"meter\"),nav:i(\"nav\"),noscript:i(\"noscript\"),object:i(\"object\"),ol:i(\"ol\"),optgroup:i(\"optgroup\"),option:i(\"option\"),output:i(\"output\"),p:i(\"p\"),param:i(\"param\"),picture:i(\"picture\"),pre:i(\"pre\"),progress:i(\"progress\"),q:i(\"q\"),rp:i(\"rp\"),rt:i(\"rt\"),ruby:i(\"ruby\"),s:i(\"s\"),samp:i(\"samp\"),script:i(\"script\"),section:i(\"section\"),select:i(\"select\"),small:i(\"small\"),source:i(\"source\"),span:i(\"span\"),strong:i(\"strong\"),style:i(\"style\"),sub:i(\"sub\"),summary:i(\"summary\"),sup:i(\"sup\"),table:i(\"table\"),tbody:i(\"tbody\"),td:i(\"td\"),textarea:i(\"textarea\"),tfoot:i(\"tfoot\"),th:i(\"th\"),thead:i(\"thead\"),time:i(\"time\"),title:i(\"title\"),tr:i(\"tr\"),track:i(\"track\"),u:i(\"u\"),ul:i(\"ul\"),var:i(\"var\"),video:i(\"video\"),wbr:i(\"wbr\"),circle:i(\"circle\"),clipPath:i(\"clipPath\"),defs:i(\"defs\"),ellipse:i(\"ellipse\"),g:i(\"g\"),image:i(\"image\"),line:i(\"line\"),linearGradient:i(\"linearGradient\"),mask:i(\"mask\"),path:i(\"path\"),pattern:i(\"pattern\"),polygon:i(\"polygon\"),polyline:i(\"polyline\"),radialGradient:i(\"radialGradient\"),rect:i(\"rect\"),stop:i(\"stop\"),svg:i(\"svg\"),text:i(\"text\"),tspan:i(\"tspan\")};t.exports=o},function(t,e,n){\"use strict\";function r(t,e){return t===e?0!==t||1/t===1/e:t!==t&&e!==e}function i(t){this.message=t,this.stack=\"\"}function o(t){function e(e,n,r,o,a,u,c){o=o||E,u=u||r;if(null==n[r]){var s=w[a];return e?new i(null===n[r]?\"The \"+s+\" `\"+u+\"` is marked as required \"+(\"in `\"+o+\"`, but its value is `null`.\"):\"The \"+s+\" `\"+u+\"` is marked as required in \"+(\"`\"+o+\"`, but its value is `undefined`.\")):null}return t(n,r,o,a,u)}var n=e.bind(null,!1);return n.isRequired=e.bind(null,!0),n}function a(t){function e(e,n,r,o,a,u){var c=e[n],s=y(c);if(s!==t){var l=w[o],f=_(c);return new i(\"Invalid \"+l+\" `\"+a+\"` of type \"+(\"`\"+f+\"` supplied to `\"+r+\"`, expected \")+(\"`\"+t+\"`.\"))}return null}return o(e)}function u(){return o(M.thatReturns(null))}function c(t){function e(e,n,r,o,a){if(\"function\"!=typeof t)return new i(\"Property `\"+a+\"` of component `\"+r+\"` has invalid PropType notation inside arrayOf.\");var u=e[n];if(!Array.isArray(u)){var c=w[o],s=y(u);return new i(\"Invalid \"+c+\" `\"+a+\"` of type \"+(\"`\"+s+\"` supplied to `\"+r+\"`, expected an array.\"))}for(var l=0;l<u.length;l++){var f=t(u,l,r,o,a+\"[\"+l+\"]\",C);if(f instanceof Error)return f}return null}return o(e)}function s(){function t(t,e,n,r,o){var a=t[e];if(!x.isValidElement(a)){var u=w[r],c=y(a);return new i(\"Invalid \"+u+\" `\"+o+\"` of type \"+(\"`\"+c+\"` supplied to `\"+n+\"`, expected a single ReactElement.\"))}return null}return o(t)}function l(t){function e(e,n,r,o,a){if(!(e[n]instanceof t)){var u=w[o],c=t.name||E,s=b(e[n]);return new i(\"Invalid \"+u+\" `\"+a+\"` of type \"+(\"`\"+s+\"` supplied to `\"+r+\"`, expected \")+(\"instance of `\"+c+\"`.\"))}return null}return o(e)}function f(t){function e(e,n,o,a,u){for(var c=e[n],s=0;s<t.length;s++)if(r(c,t[s]))return null;var l=w[a],f=JSON.stringify(t);return new i(\"Invalid \"+l+\" `\"+u+\"` of value `\"+c+\"` \"+(\"supplied to `\"+o+\"`, expected one of \"+f+\".\"))}return Array.isArray(t)?o(e):M.thatReturnsNull}function p(t){function e(e,n,r,o,a){if(\"function\"!=typeof t)return new i(\"Property `\"+a+\"` of component `\"+r+\"` has invalid PropType notation inside objectOf.\");var u=e[n],c=y(u);if(\"object\"!==c){var s=w[o];return new i(\"Invalid \"+s+\" `\"+a+\"` of type \"+(\"`\"+c+\"` supplied to `\"+r+\"`, expected an object.\"))}for(var l in u)if(u.hasOwnProperty(l)){var f=t(u,l,r,o,a+\".\"+l,C);if(f instanceof Error)return f}return null}return o(e)}function h(t){function e(e,n,r,o,a){for(var u=0;u<t.length;u++){var c=t[u];if(null==c(e,n,r,o,a,C))return null}var s=w[o];return new i(\"Invalid \"+s+\" `\"+a+\"` supplied to \"+(\"`\"+r+\"`.\"))}return Array.isArray(t)?o(e):M.thatReturnsNull}function d(){function t(t,e,n,r,o){if(!g(t[e])){var a=w[r];return new i(\"Invalid \"+a+\" `\"+o+\"` supplied to \"+(\"`\"+n+\"`, expected a ReactNode.\"))}return null}return o(t)}function v(t){function e(e,n,r,o,a){var u=e[n],c=y(u);if(\"object\"!==c){var s=w[o];return new i(\"Invalid \"+s+\" `\"+a+\"` of type `\"+c+\"` \"+(\"supplied to `\"+r+\"`, expected `object`.\"))}for(var l in t){var f=t[l];if(f){var p=f(u,l,r,o,a+\".\"+l,C);if(p)return p}}return null}return o(e)}function g(t){switch(typeof t){case\"number\":case\"string\":case\"undefined\":return!0;case\"boolean\":return!t;case\"object\":if(Array.isArray(t))return t.every(g);if(null===t||x.isValidElement(t))return!0;var e=k(t);if(!e)return!1;var n,r=e.call(t);if(e!==t.entries){for(;!(n=r.next()).done;)if(!g(n.value))return!1}else for(;!(n=r.next()).done;){var i=n.value;if(i&&!g(i[1]))return!1}return!0;default:return!1}}function m(t,e){return\"symbol\"===t||(\"Symbol\"===e[\"@@toStringTag\"]||\"function\"==typeof Symbol&&e instanceof Symbol)}function y(t){var e=typeof t;return Array.isArray(t)?\"array\":t instanceof RegExp?\"object\":m(e,t)?\"symbol\":e}function _(t){var e=y(t);if(\"object\"===e){if(t instanceof Date)return\"date\";if(t instanceof RegExp)return\"regexp\"}return e}function b(t){return t.constructor&&t.constructor.name?t.constructor.name:E}var x=n(27),w=n(175),C=n(405),M=n(8),k=n(177),E=(n(1),\"<<anonymous>>\"),T={array:a(\"array\"),bool:a(\"boolean\"),func:a(\"function\"),number:a(\"number\"),object:a(\"object\"),string:a(\"string\"),symbol:a(\"symbol\"),any:u(),arrayOf:c,element:s(),instanceOf:l,node:d(),objectOf:p,oneOf:f,oneOfType:h,shape:v};i.prototype=Error.prototype,t.exports=T},function(t,e,n){\"use strict\";var r=\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\";t.exports=r},function(t,e,n){\"use strict\";function r(t,e,n){this.props=t,this.context=e,this.refs=c,this.updater=n||u}function i(){}var o=n(3),a=n(97),u=n(98),c=n(38);i.prototype=a.prototype,r.prototype=new i,r.prototype.constructor=r,o(r.prototype,a.prototype),r.prototype.isPureReactComponent=!0,t.exports=r},function(t,e,n){\"use strict\";t.exports=\"15.4.2\"},function(t,e,n){\"use strict\";function r(t){return o.isValidElement(t)?void 0:i(\"143\"),t}var i=n(28),o=n(27);n(0);t.exports=r},function(t,e,n){\"use strict\";function r(t,e){return t&&\"object\"==typeof t&&null!=t.key?s.escape(t.key):e.toString(36)}function i(t,e,n,o){var p=typeof t;if(\"undefined\"!==p&&\"boolean\"!==p||(t=null),null===t||\"string\"===p||\"number\"===p||\"object\"===p&&t.$$typeof===u)return n(o,t,\"\"===e?l+r(t,0):e),1;var h,d,v=0,g=\"\"===e?l:e+f;if(Array.isArray(t))for(var m=0;m<t.length;m++)h=t[m],d=g+r(h,m),v+=i(h,d,n,o);else{var y=c(t);if(y){var _,b=y.call(t);if(y!==t.entries)for(var x=0;!(_=b.next()).done;)h=_.value,d=g+r(h,x++),v+=i(h,d,n,o);else for(;!(_=b.next()).done;){var w=_.value;w&&(h=w[1],d=g+s.escape(w[0])+f+r(h,0),v+=i(h,d,n,o))}}else if(\"object\"===p){var C=\"\",M=String(t);a(\"31\",\"[object Object]\"===M?\"object with keys {\"+Object.keys(t).join(\", \")+\"}\":M,C)}}return v}function o(t,e,n){return null==t?0:i(t,\"\",e,n)}var a=n(28),u=(n(15),n(174)),c=n(177),s=(n(0),n(399)),l=(n(1),\".\"),f=\":\";t.exports=o},function(t,e,n){\"use strict\";function r(t){return t&&t.__esModule?t:{default:t}}var i=n(41),o=r(i),a=n(182),u=r(a),c=n(183),s=r(c),l=n(181),f=r(l),p=n(180),h=r(p),d=n(179),v=r(d);(0,s.default)(),window.SHAP={SimpleListVisualizer:f.default,AdditiveForceVisualizer:h.default,AdditiveForceArrayVisualizer:v.default,React:o.default,ReactDom:u.default}}]);</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x684 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "explainer = shap.TreeExplainer(model_xgb)\n",
    "shap_values = explainer.shap_values(X_train.head(100))\n",
    "shap.initjs()\n",
    "plt.clf()\n",
    "shap.summary_plot(shap_values,features=X_train.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:13.414826Z",
     "iopub.status.busy": "2021-12-31T15:41:13.414538Z",
     "iopub.status.idle": "2021-12-31T15:41:13.420701Z",
     "shell.execute_reply": "2021-12-31T15:41:13.419765Z",
     "shell.execute_reply.started": "2021-12-31T15:41:13.414791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5741245"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:13.422187Z",
     "iopub.status.busy": "2021-12-31T15:41:13.421978Z",
     "iopub.status.idle": "2021-12-31T15:41:13.462265Z",
     "shell.execute_reply": "2021-12-31T15:41:13.461313Z",
     "shell.execute_reply.started": "2021-12-31T15:41:13.422161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1850040749796251"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(model_xgb.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:13.463958Z",
     "iopub.status.busy": "2021-12-31T15:41:13.463462Z",
     "iopub.status.idle": "2021-12-31T15:41:13.976074Z",
     "shell.execute_reply": "2021-12-31T15:41:13.975200Z",
     "shell.execute_reply.started": "2021-12-31T15:41:13.463920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x468 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ShapObject:\n",
    "    \n",
    "    def __init__(self, base_values, data, values, feature_names):\n",
    "        self.base_values = base_values # Single value\n",
    "        self.data = data # Raw feature values for 1 row of data\n",
    "        self.values = values # SHAP values for the same row of data\n",
    "        self.feature_names = feature_names # Column names\n",
    "        \n",
    "\n",
    "shap_object = ShapObject(base_values = explainer.expected_value,\n",
    "                         values = shap_values[0,:],\n",
    "                         feature_names = X_train.columns,\n",
    "                         data = X_train.iloc[0,:])\n",
    "\n",
    "shap.waterfall_plot(shap_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:13.977978Z",
     "iopub.status.busy": "2021-12-31T15:41:13.977719Z",
     "iopub.status.idle": "2021-12-31T15:41:13.987354Z",
     "shell.execute_reply": "2021-12-31T15:41:13.986550Z",
     "shell.execute_reply.started": "2021-12-31T15:41:13.977945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id='iHBRPOIG8F1CBFNO6B9M8'>\n",
       "<div style='color: #900; text-align: center;'>\n",
       "  <b>Visualization omitted, Javascript library not loaded!</b><br>\n",
       "  Have you run `initjs()` in this notebook? If this notebook was from another\n",
       "  user you must also trust this notebook (File -> Trust notebook). If you are viewing\n",
       "  this notebook on github the Javascript has been stripped for security. If you are using\n",
       "  JupyterLab this error is because a JupyterLab extension has not yet been written.\n",
       "</div></div>\n",
       " <script>\n",
       "   if (window.SHAP) SHAP.ReactDom.render(\n",
       "    SHAP.React.createElement(SHAP.AdditiveForceVisualizer, {\"outNames\": [\"f(x)\"], \"baseValue\": -1.5741244554519653, \"outValue\": -4.116451263427734, \"link\": \"identity\", \"featureNames\": [\"Feature 0\", \"Feature 1\", \"Feature 2\", \"Feature 3\", \"Feature 4\", \"Feature 5\", \"Feature 6\", \"Feature 7\", \"Feature 8\", \"Feature 9\", \"Feature 10\", \"Feature 11\", \"Feature 12\", \"Feature 13\", \"Feature 14\", \"Feature 15\", \"Feature 16\", \"Feature 17\", \"Feature 18\", \"Feature 19\", \"Feature 20\", \"Feature 21\", \"Feature 22\", \"Feature 23\", \"Feature 24\", \"Feature 25\", \"Feature 26\", \"Feature 27\", \"Feature 28\", \"Feature 29\", \"Feature 30\", \"Feature 31\", \"Feature 32\", \"Feature 33\", \"Feature 34\", \"Feature 35\", \"Feature 36\", \"Feature 37\", \"Feature 38\", \"Feature 39\", \"Feature 40\", \"Feature 41\", \"Feature 42\", \"Feature 43\", \"Feature 44\", \"Feature 45\", \"Feature 46\", \"Feature 47\", \"Feature 48\", \"Feature 49\", \"Feature 50\", \"Feature 51\", \"Feature 52\", \"Feature 53\", \"Feature 54\", \"Feature 55\", \"Feature 56\", \"Feature 57\", \"Feature 58\", \"Feature 59\", \"Feature 60\", \"Feature 61\", \"Feature 62\", \"Feature 63\", \"Feature 64\", \"Feature 65\", \"Feature 66\", \"Feature 67\", \"Feature 68\", \"Feature 69\", \"Feature 70\", \"Feature 71\", \"Feature 72\", \"Feature 73\", \"Feature 74\", \"Feature 75\", \"Feature 76\", \"Feature 77\", \"Feature 78\", \"Feature 79\", \"Feature 80\", \"Feature 81\", \"Feature 82\", \"Feature 83\", \"Feature 84\", \"Feature 85\", \"Feature 86\", \"Feature 87\", \"Feature 88\", \"Feature 89\", \"Feature 90\", \"Feature 91\", \"Feature 92\", \"Feature 93\", \"Feature 94\", \"Feature 95\", \"Feature 96\", \"Feature 97\", \"Feature 98\", \"Feature 99\", \"Feature 100\", \"Feature 101\", \"Feature 102\", \"Feature 103\", \"Feature 104\", \"Feature 105\", \"Feature 106\", \"Feature 107\", \"Feature 108\", \"Feature 109\", \"Feature 110\", \"Feature 111\", \"Feature 112\", \"Feature 113\", \"Feature 114\", \"Feature 115\", \"Feature 116\", \"Feature 117\", \"Feature 118\", \"Feature 119\", \"Feature 120\", \"Feature 121\", \"Feature 122\", \"Feature 123\", \"Feature 124\", \"Feature 125\", \"Feature 126\", \"Feature 127\", \"Feature 128\", \"Feature 129\", \"Feature 130\", \"Feature 131\", \"Feature 132\", \"Feature 133\", \"Feature 134\", \"Feature 135\", \"Feature 136\", \"Feature 137\", \"Feature 138\", \"Feature 139\", \"Feature 140\", \"Feature 141\", \"Feature 142\", \"Feature 143\", \"Feature 144\", \"Feature 145\", \"Feature 146\", \"Feature 147\", \"Feature 148\", \"Feature 149\", \"Feature 150\", \"Feature 151\", \"Feature 152\", \"Feature 153\", \"Feature 154\", \"Feature 155\", \"Feature 156\", \"Feature 157\", \"Feature 158\", \"Feature 159\", \"Feature 160\", \"Feature 161\", \"Feature 162\"], \"features\": {\"1\": {\"effect\": -0.00021806242875754833, \"value\": \"\"}, \"7\": {\"effect\": -0.048049651086330414, \"value\": \"\"}, \"8\": {\"effect\": -6.577042950084433e-05, \"value\": \"\"}, \"17\": {\"effect\": 7.50882099964656e-05, \"value\": \"\"}, \"20\": {\"effect\": -0.0004399444442242384, \"value\": \"\"}, \"22\": {\"effect\": 0.018158460035920143, \"value\": \"\"}, \"23\": {\"effect\": 0.0029610334895551205, \"value\": \"\"}, \"29\": {\"effect\": 0.0006380841950885952, \"value\": \"\"}, \"32\": {\"effect\": -0.0004966573906131089, \"value\": \"\"}, \"33\": {\"effect\": -0.0041608745232224464, \"value\": \"\"}, \"37\": {\"effect\": -0.0034173880703747272, \"value\": \"\"}, \"38\": {\"effect\": 0.0007578306831419468, \"value\": \"\"}, \"41\": {\"effect\": -0.00155984191223979, \"value\": \"\"}, \"42\": {\"effect\": 0.0007119273650459945, \"value\": \"\"}, \"43\": {\"effect\": -0.002171780914068222, \"value\": \"\"}, \"44\": {\"effect\": 0.00151733192615211, \"value\": \"\"}, \"46\": {\"effect\": -0.010398223996162415, \"value\": \"\"}, \"47\": {\"effect\": 0.001188894035294652, \"value\": \"\"}, \"49\": {\"effect\": -0.00023149422486312687, \"value\": \"\"}, \"51\": {\"effect\": -0.002131467219442129, \"value\": \"\"}, \"53\": {\"effect\": -0.02694789692759514, \"value\": \"\"}, \"54\": {\"effect\": -0.0002987586776725948, \"value\": \"\"}, \"55\": {\"effect\": -0.032199036329984665, \"value\": \"\"}, \"56\": {\"effect\": -0.2606284022331238, \"value\": \"\"}, \"57\": {\"effect\": -0.030457649379968643, \"value\": \"\"}, \"59\": {\"effect\": -0.011689313687384129, \"value\": \"\"}, \"60\": {\"effect\": -0.012653701938688755, \"value\": \"\"}, \"61\": {\"effect\": 0.0003528716624714434, \"value\": \"\"}, \"62\": {\"effect\": -0.021784840151667595, \"value\": \"\"}, \"63\": {\"effect\": -0.0009714406332932413, \"value\": \"\"}, \"64\": {\"effect\": 0.0005405874690040946, \"value\": \"\"}, \"65\": {\"effect\": -0.010070817545056343, \"value\": \"\"}, \"66\": {\"effect\": -0.06117980182170868, \"value\": \"\"}, \"69\": {\"effect\": -0.03933783620595932, \"value\": \"\"}, \"70\": {\"effect\": -0.0942937359213829, \"value\": \"\"}, \"71\": {\"effect\": -0.12619295716285706, \"value\": \"\"}, \"73\": {\"effect\": -0.7798808813095093, \"value\": \"\"}, \"76\": {\"effect\": -0.001502971164882183, \"value\": \"\"}, \"77\": {\"effect\": -0.003081850241869688, \"value\": \"\"}, \"78\": {\"effect\": 0.0001575076166773215, \"value\": \"\"}, \"79\": {\"effect\": -0.001968748401850462, \"value\": \"\"}, \"84\": {\"effect\": -0.007333796937018633, \"value\": \"\"}, \"85\": {\"effect\": -0.0026742189656943083, \"value\": \"\"}, \"86\": {\"effect\": -0.00020751057309098542, \"value\": \"\"}, \"88\": {\"effect\": 0.03568202629685402, \"value\": \"\"}, \"89\": {\"effect\": 0.015710119158029556, \"value\": \"\"}, \"90\": {\"effect\": 0.03347951918840408, \"value\": \"\"}, \"92\": {\"effect\": -0.008104139007627964, \"value\": \"\"}, \"93\": {\"effect\": 0.00042863123235292733, \"value\": \"\"}, \"95\": {\"effect\": -0.0006087656365707517, \"value\": \"\"}, \"96\": {\"effect\": -0.03652267903089523, \"value\": \"\"}, \"97\": {\"effect\": -0.04647932946681976, \"value\": \"\"}, \"98\": {\"effect\": -0.029079997912049294, \"value\": \"\"}, \"99\": {\"effect\": -0.07623223215341568, \"value\": \"\"}, \"100\": {\"effect\": 5.143752787262201e-06, \"value\": \"\"}, \"102\": {\"effect\": -0.0006507638609036803, \"value\": \"\"}, \"104\": {\"effect\": -0.24944588541984558, \"value\": \"\"}, \"105\": {\"effect\": 0.01783435046672821, \"value\": \"\"}, \"106\": {\"effect\": 0.0035205883905291557, \"value\": \"\"}, \"107\": {\"effect\": 0.005518914666026831, \"value\": \"\"}, \"108\": {\"effect\": -0.000590556301176548, \"value\": \"\"}, \"109\": {\"effect\": 0.0006060633459128439, \"value\": \"\"}, \"110\": {\"effect\": -0.00017064332496374846, \"value\": \"\"}, \"111\": {\"effect\": -0.0011173150269314647, \"value\": \"\"}, \"114\": {\"effect\": -0.02332722395658493, \"value\": \"\"}, \"115\": {\"effect\": -0.003538845106959343, \"value\": \"\"}, \"116\": {\"effect\": 3.7493697163881734e-05, \"value\": \"\"}, \"117\": {\"effect\": -0.007659653667360544, \"value\": \"\"}, \"119\": {\"effect\": 0.001829274813644588, \"value\": \"\"}, \"120\": {\"effect\": 0.00036256195744499564, \"value\": \"\"}, \"121\": {\"effect\": -0.013644090853631496, \"value\": \"\"}, \"122\": {\"effect\": -0.0011648579966276884, \"value\": \"\"}, \"123\": {\"effect\": 0.030465982854366302, \"value\": \"\"}, \"125\": {\"effect\": -0.010365737602114677, \"value\": \"\"}, \"126\": {\"effect\": -0.0030288957059383392, \"value\": \"\"}, \"129\": {\"effect\": -0.0020841832738369703, \"value\": \"\"}, \"130\": {\"effect\": -0.010598713532090187, \"value\": \"\"}, \"131\": {\"effect\": 0.00014617081615142524, \"value\": \"\"}, \"132\": {\"effect\": -0.00031129480339586735, \"value\": \"\"}, \"133\": {\"effect\": 0.0050887190736830235, \"value\": \"\"}, \"134\": {\"effect\": -0.00026646017795428634, \"value\": \"\"}, \"136\": {\"effect\": -0.0003119075845461339, \"value\": \"\"}, \"137\": {\"effect\": -0.0022298404946923256, \"value\": \"\"}, \"138\": {\"effect\": -0.00026975496439263225, \"value\": \"\"}, \"139\": {\"effect\": -0.008262159302830696, \"value\": \"\"}, \"141\": {\"effect\": -0.009588091634213924, \"value\": \"\"}, \"143\": {\"effect\": -0.00030854775104671717, \"value\": \"\"}, \"144\": {\"effect\": -0.1784665286540985, \"value\": \"\"}, \"145\": {\"effect\": 0.011546245776116848, \"value\": \"\"}, \"146\": {\"effect\": 0.005127806216478348, \"value\": \"\"}, \"148\": {\"effect\": -0.022369053214788437, \"value\": \"\"}, \"149\": {\"effect\": -0.0020349910482764244, \"value\": \"\"}, \"150\": {\"effect\": -0.00030159010202623904, \"value\": \"\"}, \"151\": {\"effect\": -6.87796127749607e-05, \"value\": \"\"}, \"152\": {\"effect\": 0.001206807210110128, \"value\": \"\"}, \"154\": {\"effect\": 0.00013301509898155928, \"value\": \"\"}, \"155\": {\"effect\": 0.0003451960510574281, \"value\": \"\"}, \"156\": {\"effect\": -0.005047863349318504, \"value\": \"\"}, \"157\": {\"effect\": -0.0008922575507313013, \"value\": \"\"}, \"158\": {\"effect\": -0.00022311384964268655, \"value\": \"\"}, \"159\": {\"effect\": -0.3392602503299713, \"value\": \"\"}, \"160\": {\"effect\": -0.0062523591332137585, \"value\": \"\"}, \"161\": {\"effect\": -0.03614981099963188, \"value\": \"\"}, \"162\": {\"effect\": -0.0027345754206180573, \"value\": \"\"}}, \"plot_cmap\": \"RdBu\", \"labelMargin\": 20}),\n",
       "    document.getElementById('iHBRPOIG8F1CBFNO6B9M8')\n",
       "  );\n",
       "</script>"
      ],
      "text/plain": [
       "<shap.plots._force.AdditiveForceVisualizer at 0x7f0fdb6fcaf0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap.plots.force(explainer.expected_value,shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:13.989516Z",
     "iopub.status.busy": "2021-12-31T15:41:13.988849Z",
     "iopub.status.idle": "2021-12-31T15:41:17.059724Z",
     "shell.execute_reply": "2021-12-31T15:41:17.058568Z",
     "shell.execute_reply.started": "2021-12-31T15:41:13.989469Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure(dpi=180)\n",
    "# ax = plt.subplot(1,1,1)\n",
    "\n",
    "# plot_tree(model_xgb, num_trees=0, ax = ax)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:17.062772Z",
     "iopub.status.busy": "2021-12-31T15:41:17.061761Z",
     "iopub.status.idle": "2021-12-31T15:41:17.085503Z",
     "shell.execute_reply": "2021-12-31T15:41:17.084882Z",
     "shell.execute_reply.started": "2021-12-31T15:41:17.062722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature importance</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097677</td>\n",
       "      <td>Feature - comfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.075507</td>\n",
       "      <td>Feature - easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069151</td>\n",
       "      <td>Feature - use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043065</td>\n",
       "      <td>Feature - install</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.024753</td>\n",
       "      <td>Feature - easier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.002129</td>\n",
       "      <td>Feature - im</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.002073</td>\n",
       "      <td>Feature - box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.002012</td>\n",
       "      <td>Feature - sturdy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.001992</td>\n",
       "      <td>Feature - come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.001738</td>\n",
       "      <td>Feature - clamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature importance                Feature\n",
       "0              0.097677  Feature - comfortable\n",
       "1              0.075507         Feature - easy\n",
       "2              0.069151          Feature - use\n",
       "3              0.043065      Feature - install\n",
       "4              0.024753       Feature - easier\n",
       "..                  ...                    ...\n",
       "99             0.002129           Feature - im\n",
       "100            0.002073          Feature - box\n",
       "101            0.002012       Feature - sturdy\n",
       "102            0.001992         Feature - come\n",
       "103            0.001738        Feature - clamp\n",
       "\n",
       "[104 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame(model_xgb.feature_importances_)\n",
    "temp['Feature'] = X_train.columns.tolist()\n",
    "temp.columns = ['Feature importance','Feature']\n",
    "temp[temp['Feature importance']>0][['Feature importance','Feature']].sort_values(by = 'Feature importance', ascending = False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:17.087170Z",
     "iopub.status.busy": "2021-12-31T15:41:17.086564Z",
     "iopub.status.idle": "2021-12-31T15:41:30.392196Z",
     "shell.execute_reply": "2021-12-31T15:41:30.391216Z",
     "shell.execute_reply.started": "2021-12-31T15:41:17.087133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:31:25] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"boosting\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:31:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Entire data log loss: 0.1485334672109677\n",
      "Saving model ..  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['XGBoost_model_full_data.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_full_data = xgb.XGBClassifier(**study.best_params, random_state=SEED)\n",
    "model_xgb_full_data.fit(pd.concat([X_train,X_valid], axis = 0), pd.concat([y_train,y_valid], axis = 0))\n",
    "\n",
    "y_predicted = model_xgb_full_data.predict_proba(pd.concat([X_train,X_valid], axis = 0))[:,1]\n",
    "print('Entire data log loss:', log_loss(pd.concat([y_train, y_valid], axis = 0), y_predicted))\n",
    "\n",
    "print(\"Saving model .. \",end=\" \")\n",
    "joblib.dump(model_xgb_full_data,\"XGBoost_model_full_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:41:30.394579Z",
     "iopub.status.busy": "2021-12-31T15:41:30.394020Z",
     "iopub.status.idle": "2021-12-31T15:41:30.648065Z",
     "shell.execute_reply": "2021-12-31T15:41:30.647145Z",
     "shell.execute_reply.started": "2021-12-31T15:41:30.394536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2631, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Usability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.013899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.973770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.017699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.022398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Usability\n",
       "0   0   0.017657\n",
       "1   1   0.013899\n",
       "2   2   0.973770\n",
       "3   3   0.017699\n",
       "4   4   0.022398"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2631, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Usability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.014070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.013884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.975364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.020812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Usability\n",
       "0   0   0.014070\n",
       "1   1   0.013884\n",
       "2   2   0.975364\n",
       "3   3   0.016876\n",
       "4   4   0.020812"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = pd.DataFrame(vectorizer.transform(test_data['Review cleaned for tf-idf']).todense())\n",
    "X_test.columns = ['Feature - ' + inv_map[x] for x in X_test.columns]\n",
    "\n",
    "xgboost_pred = model_xgb.predict_proba(X_test[X_train.columns.tolist()])[:,1]\n",
    "# xgboost_pred = [1 if x>=t else 0 for x in xgboost_pred]\n",
    "\n",
    "submission_data = test_data[['Id']]\n",
    "submission_data[category] = xgboost_pred\n",
    "submission_data.to_csv(output_filepath + category.replace(' ','_') + '_submission_xgboost.csv', index=False)\n",
    "print(submission_data.shape)\n",
    "display(submission_data.head())\n",
    "\n",
    "xgboost_pred = model_xgb_full_data.predict_proba(X_test[X_train.columns.tolist()])[:,1]\n",
    "# xgboost_pred = [1 if x>=t else 0 for x in xgboost_pred]\n",
    "\n",
    "submission_data = test_data[['Id']]\n",
    "submission_data[category] = xgboost_pred\n",
    "submission_data.to_csv(output_filepath + category.replace(' ','_') + '_submission_xgboost_full_data_train.csv', index=False)\n",
    "print(submission_data.shape)\n",
    "display(submission_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H20.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:58:31.694726Z",
     "iopub.status.busy": "2021-12-31T15:58:31.694406Z",
     "iopub.status.idle": "2021-12-31T15:58:41.598603Z",
     "shell.execute_reply": "2021-12-31T15:58:41.597473Z",
     "shell.execute_reply.started": "2021-12-31T15:58:31.694683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA - 0</th>\n",
       "      <th>PCA - 1</th>\n",
       "      <th>PCA - 2</th>\n",
       "      <th>PCA - 3</th>\n",
       "      <th>PCA - 4</th>\n",
       "      <th>PCA - 5</th>\n",
       "      <th>PCA - 6</th>\n",
       "      <th>PCA - 7</th>\n",
       "      <th>PCA - 8</th>\n",
       "      <th>PCA - 9</th>\n",
       "      <th>...</th>\n",
       "      <th>PCA - 490</th>\n",
       "      <th>PCA - 491</th>\n",
       "      <th>PCA - 492</th>\n",
       "      <th>PCA - 493</th>\n",
       "      <th>PCA - 494</th>\n",
       "      <th>PCA - 495</th>\n",
       "      <th>PCA - 496</th>\n",
       "      <th>PCA - 497</th>\n",
       "      <th>PCA - 498</th>\n",
       "      <th>PCA - 499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.041646</td>\n",
       "      <td>-0.080712</td>\n",
       "      <td>0.033904</td>\n",
       "      <td>0.032722</td>\n",
       "      <td>-0.038233</td>\n",
       "      <td>-0.020024</td>\n",
       "      <td>-0.200216</td>\n",
       "      <td>0.081064</td>\n",
       "      <td>-0.033132</td>\n",
       "      <td>0.044063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.036982</td>\n",
       "      <td>-0.025651</td>\n",
       "      <td>0.053070</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>-0.000624</td>\n",
       "      <td>-0.001160</td>\n",
       "      <td>0.022311</td>\n",
       "      <td>-0.029065</td>\n",
       "      <td>-0.020798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.158496</td>\n",
       "      <td>0.371309</td>\n",
       "      <td>-0.297177</td>\n",
       "      <td>0.269914</td>\n",
       "      <td>0.030916</td>\n",
       "      <td>0.521685</td>\n",
       "      <td>0.068578</td>\n",
       "      <td>-0.248325</td>\n",
       "      <td>-0.077062</td>\n",
       "      <td>-0.054536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002968</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>-0.003176</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>-0.003385</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>-0.009674</td>\n",
       "      <td>0.003755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.072638</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>0.079080</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>-0.019635</td>\n",
       "      <td>-0.017076</td>\n",
       "      <td>-0.029879</td>\n",
       "      <td>0.067680</td>\n",
       "      <td>0.086410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004901</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>-0.007944</td>\n",
       "      <td>-0.010794</td>\n",
       "      <td>0.006101</td>\n",
       "      <td>-0.003176</td>\n",
       "      <td>-0.012056</td>\n",
       "      <td>-0.031261</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>-0.040366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.145436</td>\n",
       "      <td>-0.039918</td>\n",
       "      <td>-0.069726</td>\n",
       "      <td>0.081624</td>\n",
       "      <td>-0.060566</td>\n",
       "      <td>-0.091155</td>\n",
       "      <td>-0.010074</td>\n",
       "      <td>-0.146854</td>\n",
       "      <td>0.017126</td>\n",
       "      <td>0.196201</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017832</td>\n",
       "      <td>-0.007211</td>\n",
       "      <td>-0.011688</td>\n",
       "      <td>-0.021286</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.022734</td>\n",
       "      <td>0.013961</td>\n",
       "      <td>-0.012356</td>\n",
       "      <td>0.010793</td>\n",
       "      <td>0.007684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.043084</td>\n",
       "      <td>0.027176</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.026430</td>\n",
       "      <td>0.070938</td>\n",
       "      <td>0.033849</td>\n",
       "      <td>-0.028300</td>\n",
       "      <td>0.058087</td>\n",
       "      <td>0.030560</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021048</td>\n",
       "      <td>0.070562</td>\n",
       "      <td>0.029454</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>-0.001032</td>\n",
       "      <td>0.055203</td>\n",
       "      <td>0.008530</td>\n",
       "      <td>-0.016844</td>\n",
       "      <td>-0.022329</td>\n",
       "      <td>0.001234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PCA - 0   PCA - 1   PCA - 2   PCA - 3   PCA - 4   PCA - 5   PCA - 6  \\\n",
       "0 -0.041646 -0.080712  0.033904  0.032722 -0.038233 -0.020024 -0.200216   \n",
       "1  0.158496  0.371309 -0.297177  0.269914  0.030916  0.521685  0.068578   \n",
       "2 -0.072638  0.013650  0.079080  0.023285  0.008711 -0.019635 -0.017076   \n",
       "3 -0.145436 -0.039918 -0.069726  0.081624 -0.060566 -0.091155 -0.010074   \n",
       "4 -0.043084  0.027176  0.005135  0.026430  0.070938  0.033849 -0.028300   \n",
       "\n",
       "    PCA - 7   PCA - 8   PCA - 9  ...  PCA - 490  PCA - 491  PCA - 492  \\\n",
       "0  0.081064 -0.033132  0.044063  ...   0.005740   0.036982  -0.025651   \n",
       "1 -0.248325 -0.077062 -0.054536  ...  -0.002968   0.001757  -0.003176   \n",
       "2 -0.029879  0.067680  0.086410  ...  -0.004901   0.016260  -0.007944   \n",
       "3 -0.146854  0.017126  0.196201  ...  -0.017832  -0.007211  -0.011688   \n",
       "4  0.058087  0.030560  0.012002  ...  -0.021048   0.070562   0.029454   \n",
       "\n",
       "   PCA - 493  PCA - 494  PCA - 495  PCA - 496  PCA - 497  PCA - 498  PCA - 499  \n",
       "0   0.053070   0.002425  -0.000624  -0.001160   0.022311  -0.029065  -0.020798  \n",
       "1   0.002502   0.001072  -0.003385   0.002186   0.000812  -0.009674   0.003755  \n",
       "2  -0.010794   0.006101  -0.003176  -0.012056  -0.031261   0.028200  -0.040366  \n",
       "3  -0.021286   0.002254   0.022734   0.013961  -0.012356   0.010793   0.007684  \n",
       "4   0.007901  -0.001032   0.055203   0.008530  -0.016844  -0.022329   0.001234  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate_bert_embeddings(train_data,'Review cleaned for transformers','emilyalsentzer/bert-base-uncased')\n",
    "vectorizer = TfidfVectorizer(stop_words='english',ngram_range=(1, 1))\n",
    "\n",
    "train_df, valid_df  = sk_model_selection.train_test_split(\n",
    "    train_data, \n",
    "    test_size=0.2, \n",
    "    random_state=SEED,\n",
    "    stratify = train_data[category])\n",
    "\n",
    "X_train = train_df['Review cleaned for tf-idf'].reset_index(drop = True)\n",
    "y_train = train_df[[category]].reset_index(drop = True)\n",
    "X_valid = valid_df['Review cleaned for tf-idf'].reset_index(drop = True)\n",
    "y_valid = valid_df[[category]].reset_index(drop = True)\n",
    "\n",
    "X_train = pd.DataFrame(vectorizer.fit_transform(X_train).todense())\n",
    "X_valid = pd.DataFrame(vectorizer.transform(X_valid).todense())\n",
    "\n",
    "inv_map = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "X_train.columns = ['Feature - ' + inv_map[x] for x in X_train.columns]\n",
    "X_valid.columns = ['Feature - ' + inv_map[x] for x in X_valid.columns]\n",
    "\n",
    "# PCA - Alternatives include TSNE, UMAP, Autoencoder\n",
    "pca = PCA(500,random_state=SEED)  \n",
    "projected_df = pca.fit_transform(X_train)\n",
    "\n",
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "#\n",
    "# Cumulative sum of eigenvalues; This will be used to create step plot\n",
    "# for visualizing the variance explained by each principal component.\n",
    "#\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "#\n",
    "# Create the visualization plot\n",
    "#\n",
    "plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "X_train = pd.DataFrame(pca.transform(X_train))\n",
    "X_train.columns = ['PCA - ' + str(x) for x in X_train.columns]\n",
    "display(X_train.head())\n",
    "\n",
    "X_valid = pd.DataFrame(pca.transform(X_valid))\n",
    "X_valid.columns = ['PCA - ' + str(x) for x in X_valid.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:58:41.608822Z",
     "iopub.status.busy": "2021-12-31T15:58:41.605578Z",
     "iopub.status.idle": "2021-12-31T15:58:41.676489Z",
     "shell.execute_reply": "2021-12-31T15:58:41.675639Z",
     "shell.execute_reply.started": "2021-12-31T15:58:41.608743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.11\" 2021-04-20; OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04); OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n",
      "  Starting server from /home/ubuntu/.local/lib/python3.8/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpcmhbicxb\n",
      "  JVM stdout: /tmp/tmpcmhbicxb/h2o_ubuntu_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpcmhbicxb/h2o_ubuntu_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.34.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>12 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_ubuntu_qesh0a</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>12 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>30</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>30</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.34.0.7\n",
       "H2O_cluster_version_age:    12 days\n",
       "H2O_cluster_name:           H2O_from_python_ubuntu_qesh0a\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    12 Gb\n",
       "H2O_cluster_total_cores:    30\n",
       "H2O_cluster_allowed_cores:  30\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.8.8 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(\n",
    "    nthreads=-1,     # number of threads when launching a new H2O server\n",
    "    max_mem_size=12  # in gigabytes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:58:41.683455Z",
     "iopub.status.busy": "2021-12-31T15:58:41.678075Z",
     "iopub.status.idle": "2021-12-31T15:58:41.692543Z",
     "shell.execute_reply": "2021-12-31T15:58:41.691348Z",
     "shell.execute_reply.started": "2021-12-31T15:58:41.683377Z"
    }
   },
   "outputs": [],
   "source": [
    "def _convert_h2oframe_to_numeric(h2o_frame, training_columns):\n",
    "    for column in training_columns:\n",
    "        h2o_frame[column] = h2o_frame[column].asnumeric()\n",
    "    return h2o_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T15:58:41.695788Z",
     "iopub.status.busy": "2021-12-31T15:58:41.695112Z",
     "iopub.status.idle": "2021-12-31T16:16:12.399018Z",
     "shell.execute_reply": "2021-12-31T16:16:12.398070Z",
     "shell.execute_reply.started": "2021-12-31T15:58:41.695726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
      "AutoML progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
      "Export File progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "X_y_train_h = h2o.H2OFrame(\n",
    "    pd.concat(\n",
    "        [pd.concat([X_train, X_valid], axis = 0), pd.concat([y_train, y_valid], axis = 0)],\n",
    "        axis='columns'\n",
    "    )\n",
    ")\n",
    "\n",
    "feature_cols = X_train.columns.tolist()\n",
    "\n",
    "X_y_train_h = _convert_h2oframe_to_numeric(X_y_train_h, feature_cols)\n",
    "X_y_train_h[category] = X_y_train_h[category].asfactor()\n",
    "\n",
    "aml = H2OAutoML(\n",
    "    max_runtime_secs=(int(3600 * 2)),  # hours\n",
    "    max_models=None,  # no limit\n",
    "    balance_classes=True,\n",
    "    seed=SEED)\n",
    "\n",
    "aml.train(\n",
    "    x=feature_cols,\n",
    "    y=category,\n",
    "    training_frame=X_y_train_h)\n",
    "\n",
    "lb = aml.leaderboard\n",
    "model_ids = list(lb['model_id'].as_data_frame().iloc[:,0])\n",
    "out_path = \".\"\n",
    "\n",
    "for m_id in model_ids:\n",
    "    mdl = h2o.get_model(m_id)\n",
    "    h2o.save_model(model=mdl, path=out_path, force=True)\n",
    "\n",
    "h2o.export_file(lb, os.path.join(out_path, 'aml_leaderboard.h2o'), force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T16:16:12.403981Z",
     "iopub.status.busy": "2021-12-31T16:16:12.403579Z",
     "iopub.status.idle": "2021-12-31T16:16:12.710387Z",
     "shell.execute_reply": "2021-12-31T16:16:12.709615Z",
     "shell.execute_reply.started": "2021-12-31T16:16:12.403929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                                                </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_3_AutoML_1_20220103_113345                    </td><td style=\"text-align: right;\">0.945851</td><td style=\"text-align: right;\"> 0.215475</td><td style=\"text-align: right;\">0.865898</td><td style=\"text-align: right;\">              0.134808</td><td style=\"text-align: right;\">0.249508</td><td style=\"text-align: right;\">0.0622542</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_4_AutoML_1_20220103_113345                    </td><td style=\"text-align: right;\">0.945432</td><td style=\"text-align: right;\"> 0.216048</td><td style=\"text-align: right;\">0.864583</td><td style=\"text-align: right;\">              0.144968</td><td style=\"text-align: right;\">0.249555</td><td style=\"text-align: right;\">0.0622776</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_7_AutoML_1_20220103_113345                    </td><td style=\"text-align: right;\">0.945258</td><td style=\"text-align: right;\"> 0.215927</td><td style=\"text-align: right;\">0.865279</td><td style=\"text-align: right;\">              0.140903</td><td style=\"text-align: right;\">0.249532</td><td style=\"text-align: right;\">0.062266 </td></tr>\n",
       "<tr><td>StackedEnsemble_Best1000_1_AutoML_1_20220103_113345                     </td><td style=\"text-align: right;\">0.944677</td><td style=\"text-align: right;\"> 0.216674</td><td style=\"text-align: right;\">0.864236</td><td style=\"text-align: right;\">              0.135722</td><td style=\"text-align: right;\">0.249598</td><td style=\"text-align: right;\">0.0622993</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_1_AutoML_1_20220103_113345                    </td><td style=\"text-align: right;\">0.943796</td><td style=\"text-align: right;\"> 0.219703</td><td style=\"text-align: right;\">0.859596</td><td style=\"text-align: right;\">              0.127602</td><td style=\"text-align: right;\">0.251247</td><td style=\"text-align: right;\">0.0631248</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_2_AutoML_1_20220103_113345                    </td><td style=\"text-align: right;\">0.943627</td><td style=\"text-align: right;\"> 0.219684</td><td style=\"text-align: right;\">0.859938</td><td style=\"text-align: right;\">              0.140401</td><td style=\"text-align: right;\">0.251146</td><td style=\"text-align: right;\">0.0630742</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_7_AutoML_1_20220103_113345                 </td><td style=\"text-align: right;\">0.943579</td><td style=\"text-align: right;\"> 0.220102</td><td style=\"text-align: right;\">0.859175</td><td style=\"text-align: right;\">              0.137658</td><td style=\"text-align: right;\">0.251309</td><td style=\"text-align: right;\">0.0631563</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_3_AutoML_1_20220103_113345                 </td><td style=\"text-align: right;\">0.943482</td><td style=\"text-align: right;\"> 0.219791</td><td style=\"text-align: right;\">0.859495</td><td style=\"text-align: right;\">              0.135116</td><td style=\"text-align: right;\">0.251035</td><td style=\"text-align: right;\">0.0630184</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_1_AutoML_1_20220103_113345                 </td><td style=\"text-align: right;\">0.942981</td><td style=\"text-align: right;\"> 0.220869</td><td style=\"text-align: right;\">0.858253</td><td style=\"text-align: right;\">              0.139588</td><td style=\"text-align: right;\">0.251764</td><td style=\"text-align: right;\">0.063385 </td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_4_AutoML_1_20220103_113345                 </td><td style=\"text-align: right;\">0.94294 </td><td style=\"text-align: right;\"> 0.220886</td><td style=\"text-align: right;\">0.858468</td><td style=\"text-align: right;\">              0.13329 </td><td style=\"text-align: right;\">0.251733</td><td style=\"text-align: right;\">0.0633693</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_2_AutoML_1_20220103_113345                 </td><td style=\"text-align: right;\">0.942795</td><td style=\"text-align: right;\"> 0.221222</td><td style=\"text-align: right;\">0.85777 </td><td style=\"text-align: right;\">              0.13928 </td><td style=\"text-align: right;\">0.251954</td><td style=\"text-align: right;\">0.063481 </td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_6_AutoML_1_20220103_113345                    </td><td style=\"text-align: right;\">0.941749</td><td style=\"text-align: right;\"> 0.224495</td><td style=\"text-align: right;\">0.853402</td><td style=\"text-align: right;\">              0.145179</td><td style=\"text-align: right;\">0.253954</td><td style=\"text-align: right;\">0.0644928</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_5_AutoML_1_20220103_113345                    </td><td style=\"text-align: right;\">0.938657</td><td style=\"text-align: right;\"> 0.268313</td><td style=\"text-align: right;\">0.851845</td><td style=\"text-align: right;\">              0.147312</td><td style=\"text-align: right;\">0.262611</td><td style=\"text-align: right;\">0.0689647</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_6_AutoML_1_20220103_113345                 </td><td style=\"text-align: right;\">0.936439</td><td style=\"text-align: right;\"> 0.230117</td><td style=\"text-align: right;\">0.845223</td><td style=\"text-align: right;\">              0.143964</td><td style=\"text-align: right;\">0.256797</td><td style=\"text-align: right;\">0.0659445</td></tr>\n",
       "<tr><td>GLM_1_AutoML_1_20220103_113345                                          </td><td style=\"text-align: right;\">0.934608</td><td style=\"text-align: right;\"> 0.237855</td><td style=\"text-align: right;\">0.840454</td><td style=\"text-align: right;\">              0.152606</td><td style=\"text-align: right;\">0.261812</td><td style=\"text-align: right;\">0.0685456</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_5_AutoML_1_20220103_113345                 </td><td style=\"text-align: right;\">0.930587</td><td style=\"text-align: right;\"> 0.249063</td><td style=\"text-align: right;\">0.838826</td><td style=\"text-align: right;\">              0.147841</td><td style=\"text-align: right;\">0.264629</td><td style=\"text-align: right;\">0.0700285</td></tr>\n",
       "<tr><td>XGBoost_lr_search_selection_AutoML_1_20220103_113345_select_grid_model_4</td><td style=\"text-align: right;\">0.92726 </td><td style=\"text-align: right;\"> 0.253333</td><td style=\"text-align: right;\">0.829472</td><td style=\"text-align: right;\">              0.163493</td><td style=\"text-align: right;\">0.270296</td><td style=\"text-align: right;\">0.0730599</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220103_113345_model_9                    </td><td style=\"text-align: right;\">0.925983</td><td style=\"text-align: right;\"> 0.345569</td><td style=\"text-align: right;\">0.820811</td><td style=\"text-align: right;\">              0.158725</td><td style=\"text-align: right;\">0.282324</td><td style=\"text-align: right;\">0.0797067</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220103_113345_model_10                   </td><td style=\"text-align: right;\">0.923758</td><td style=\"text-align: right;\"> 0.426589</td><td style=\"text-align: right;\">0.825656</td><td style=\"text-align: right;\">              0.165529</td><td style=\"text-align: right;\">0.284561</td><td style=\"text-align: right;\">0.0809752</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_1_20220103_113345_model_5                    </td><td style=\"text-align: right;\">0.921784</td><td style=\"text-align: right;\"> 0.430621</td><td style=\"text-align: right;\">0.812416</td><td style=\"text-align: right;\">              0.16471 </td><td style=\"text-align: right;\">0.28863 </td><td style=\"text-align: right;\">0.0833075</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_path = \".\"\n",
    "lb = h2o.import_file(path=os.path.join(models_path, \"aml_leaderboard.h2o\"))\n",
    "lb.head(rows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logloss_on_valid_data['H2O.ai'] = lb.head(1).as_data_frame()['logloss'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T16:16:12.712604Z",
     "iopub.status.busy": "2021-12-31T16:16:12.712046Z",
     "iopub.status.idle": "2021-12-31T16:16:13.282815Z",
     "shell.execute_reply": "2021-12-31T16:16:13.281860Z",
     "shell.execute_reply.started": "2021-12-31T16:16:12.712546Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = test_data['Review cleaned for tf-idf'].reset_index(drop = True)\n",
    "X_test = pd.DataFrame(vectorizer.transform(X_test).todense())\n",
    "X_test.columns = ['Feature - ' + inv_map[x] for x in X_test.columns]\n",
    "X_test = pd.DataFrame(pca.transform(X_test))\n",
    "X_test.columns = ['PCA - ' + str(x) for x in X_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T16:16:13.285105Z",
     "iopub.status.busy": "2021-12-31T16:16:13.284748Z",
     "iopub.status.idle": "2021-12-31T16:18:37.496272Z",
     "shell.execute_reply": "2021-12-31T16:18:37.495555Z",
     "shell.execute_reply.started": "2021-12-31T16:16:13.285059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n",
      "stackedensemble prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "test_data_for_h2o = _convert_h2oframe_to_numeric(h2o.H2OFrame(X_test), feature_cols)\n",
    "h20ai_best_model_pred = aml.leader.predict(test_data_for_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-31T16:18:37.499794Z",
     "iopub.status.busy": "2021-12-31T16:18:37.499132Z",
     "iopub.status.idle": "2021-12-31T16:18:37.551041Z",
     "shell.execute_reply": "2021-12-31T16:18:37.550395Z",
     "shell.execute_reply.started": "2021-12-31T16:18:37.499741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2631, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Usability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.010803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Usability\n",
       "0   0   0.005591\n",
       "1   1   0.003641\n",
       "2   2   0.999235\n",
       "3   3   0.010803\n",
       "4   4   0.003290"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data = test_data[['Id']]\n",
    "submission_data[category] = list(h20ai_best_model_pred.as_data_frame()['p1'])\n",
    "submission_data.to_csv(output_filepath + category.replace(' ','_') + '_h20_ai_best_model.csv', index=False)\n",
    "print(submission_data.shape)\n",
    "submission_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a99ecf3d",
    "papermill": {
     "duration": 0.028899,
     "end_time": "2021-12-27T11:31:49.921415",
     "exception": false,
     "start_time": "2021-12-27T11:31:49.892516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Binary GAN-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.005913Z",
     "iopub.status.idle": "2021-12-31T15:58:26.006425Z",
     "shell.execute_reply": "2021-12-31T15:58:26.006254Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.006232Z"
    },
    "id": "7c009c06",
    "outputId": "d72a91a8-c41e-4080-ffbc-37a776d3e8fa",
    "papermill": {
     "duration": 0.030123,
     "end_time": "2021-12-27T11:31:49.980126",
     "exception": false,
     "start_time": "2021-12-27T11:31:49.950003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.008033Z",
     "iopub.status.idle": "2021-12-31T15:58:26.008348Z",
     "shell.execute_reply": "2021-12-31T15:58:26.008200Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.008178Z"
    },
    "id": "3ba44779",
    "papermill": {
     "duration": 0.029294,
     "end_time": "2021-12-27T11:31:50.038049",
     "exception": false,
     "start_time": "2021-12-27T11:31:50.008755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#  Transformer parameters\n",
    "#--------------------------------\n",
    "max_seq_length = 512\n",
    "batch_size = 8\n",
    "\n",
    "#--------------------------------\n",
    "#  GAN-BERT specific parameters\n",
    "#--------------------------------\n",
    "# number of hidden layers in the generator, \n",
    "# each of the size of the output space\n",
    "num_hidden_layers_g = 1; \n",
    "# number of hidden layers in the discriminator, \n",
    "# each of the size of the input space\n",
    "num_hidden_layers_d = 1; \n",
    "# size of the generator's input noisy vectors\n",
    "noise_size = 100\n",
    "# dropout to be applied to discriminator's input vectors\n",
    "out_dropout_rate = 0.3\n",
    "\n",
    "# Replicate labeled data to balance poorly represented datasets, \n",
    "# e.g., less than 1% of labeled material\n",
    "apply_balance = True\n",
    "\n",
    "#--------------------------------\n",
    "#  Optimization parameters\n",
    "#--------------------------------\n",
    "learning_rate_discriminator = 5e-5\n",
    "learning_rate_generator = 5e-5\n",
    "epsilon = 1e-8\n",
    "# num_train_epochs = 5\n",
    "multi_gpu = True\n",
    "# Scheduler\n",
    "apply_scheduler = False\n",
    "warmup_proportion = 0.1\n",
    "# Print\n",
    "print_each_n_step = 5\n",
    "\n",
    "#--------------------------------\n",
    "#  Adopted Tranformer model\n",
    "#--------------------------------\n",
    "# Since this version is compatible with Huggingface transformers, you can uncomment\n",
    "# (or add) transformer models compatible with GAN\n",
    "\n",
    "# model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "model_name = \"bert-base-uncased\"\n",
    "#model_name = \"roberta-base\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "#model_name = \"xlm-roberta-base\"\n",
    "#model_name = \"amazon/bort\"\n",
    "\n",
    "#--------------------------------\n",
    "#  Retrieve the TREC QC Dataset\n",
    "#--------------------------------\n",
    "# ! git clone https://github.com/crux82/ganbert\n",
    "\n",
    "# #  NOTE: in this setting 50 classes are involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.009190Z",
     "iopub.status.idle": "2021-12-31T15:58:26.009780Z",
     "shell.execute_reply": "2021-12-31T15:58:26.009500Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.009466Z"
    },
    "id": "7145880d",
    "outputId": "31c5aa37-0c88-496f-e226-d607cc2924f7",
    "papermill": {
     "duration": 0.028376,
     "end_time": "2021-12-27T11:31:50.096363",
     "exception": false,
     "start_time": "2021-12-27T11:31:50.067987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "transformer = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.011400Z",
     "iopub.status.idle": "2021-12-31T15:58:26.011781Z",
     "shell.execute_reply": "2021-12-31T15:58:26.011628Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.011605Z"
    },
    "id": "yyrGoYAvXPmc",
    "outputId": "3b751f28-3aae-4c55-8876-7bc87194fe95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Components',\n",
       " 'Delivery and Customer Support',\n",
       " 'Design and Aesthetics',\n",
       " 'Dimensions',\n",
       " 'Features',\n",
       " 'Functionality',\n",
       " 'Installation',\n",
       " 'Material',\n",
       " 'Price',\n",
       " 'Quality',\n",
       " 'Usability']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.013046Z",
     "iopub.status.idle": "2021-12-31T15:58:26.013379Z",
     "shell.execute_reply": "2021-12-31T15:58:26.013228Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.013207Z"
    },
    "id": "pRibNqb5XStq"
   },
   "outputs": [],
   "source": [
    "data = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.014555Z",
     "iopub.status.idle": "2021-12-31T15:58:26.014927Z",
     "shell.execute_reply": "2021-12-31T15:58:26.014783Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.014761Z"
    },
    "id": "454e626f",
    "papermill": {
     "duration": 0.028136,
     "end_time": "2021-12-27T11:31:50.210476",
     "exception": false,
     "start_time": "2021-12-27T11:31:50.18234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test,train=train_test_split(data,test_size=0.8,stratify=data[category],random_state=SEED)\n",
    "\n",
    "# Filter for only protocol related queries\n",
    "# train = train[train['Protocol/ Non-protocol Query']=='Protocol Query'].reset_index(drop = True)\n",
    "# test = test[test['Protocol/ Non-protocol Query']=='Protocol Query'].reset_index(drop = True)\n",
    "\n",
    "train_list=[]\n",
    "test_list=[]\n",
    "real_test_list = []\n",
    "\n",
    "for ind,row in train.iterrows(): \n",
    "    text=row['Review cleaned for transformers']\n",
    "    for i in [category]:\n",
    "        if row[i]==1:\n",
    "            train_list.append((text,'positive'))\n",
    "        else:\n",
    "            train_list.append((text,'negative'))\n",
    "            \n",
    "for ind,row in test.iterrows(): \n",
    "    text=row['Review cleaned for transformers']\n",
    "    for i in [category]:\n",
    "        if row[i]==1:\n",
    "            test_list.append((text,'positive'))\n",
    "        else:\n",
    "            test_list.append((text,'negative'))\n",
    "            \n",
    "actual_test_data = test_data.copy()\n",
    "for ind,row in actual_test_data.iterrows(): \n",
    "    text=row['Review cleaned for transformers']\n",
    "    for i in [category]:\n",
    "        real_test_list.append((text,'positive'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2631, 17), (2631, 17))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_test_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.015819Z",
     "iopub.status.idle": "2021-12-31T15:58:26.016125Z",
     "shell.execute_reply": "2021-12-31T15:58:26.015983Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.015961Z"
    },
    "id": "44116ae7",
    "outputId": "78d4ca96-dfe3-4d69-f7c6-9c901fabf546",
    "papermill": {
     "duration": 0.029409,
     "end_time": "2021-12-27T11:31:50.26953",
     "exception": false,
     "start_time": "2021-12-27T11:31:50.240121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4909, 1227, 2631)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list),len(test_list), len(real_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.017515Z",
     "iopub.status.idle": "2021-12-31T15:58:26.017873Z",
     "shell.execute_reply": "2021-12-31T15:58:26.017717Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.017695Z"
    },
    "id": "2237bb9f",
    "papermill": {
     "duration": 0.028554,
     "end_time": "2021-12-27T11:31:50.327967",
     "exception": false,
     "start_time": "2021-12-27T11:31:50.299413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
    "    '''\n",
    "    Generate a Dataloader given the input examples, eventually masked if they are \n",
    "    to be considered NOT labeled.\n",
    "    '''\n",
    "    examples = []\n",
    "\n",
    "    # Count the percentage of labeled examples  \n",
    "    num_labeled_examples = 0\n",
    "    for label_mask in label_masks:\n",
    "        if label_mask: \n",
    "            num_labeled_examples += 1\n",
    "    label_mask_rate = num_labeled_examples/len(input_examples)\n",
    "\n",
    "    # if required it applies the balance\n",
    "    for index, ex in enumerate(input_examples): \n",
    "        if label_mask_rate == 1 or not balance_label_examples:\n",
    "            examples.append((ex, label_masks[index]))\n",
    "        else:\n",
    "          # IT SIMULATE A LABELED EXAMPLE\n",
    "          if label_masks[index]:\n",
    "            balance = int(1/label_mask_rate)\n",
    "            balance = int(math.log(balance,2))\n",
    "            if balance < 1:\n",
    "                balance = 1\n",
    "            for b in range(0, int(balance)):\n",
    "                examples.append((ex, label_masks[index]))\n",
    "            else:\n",
    "                examples.append((ex, label_masks[index]))\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # Generate input examples to the Transformer\n",
    "    #-----------------------------------------------\n",
    "    input_ids = []\n",
    "    input_mask_array = []\n",
    "    label_mask_array = []\n",
    "    label_id_array = []\n",
    "\n",
    "    # Tokenization \n",
    "    for (text, label_mask) in examples:\n",
    "        encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "        input_ids.append(encoded_sent)\n",
    "        label_id_array.append(label_map[text[1]])\n",
    "        label_mask_array.append(label_mask)\n",
    "\n",
    "    # Attention to token (to ignore padded input wordpieces)\n",
    "    for sent in input_ids:\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "        input_mask_array.append(att_mask)\n",
    "    # Convertion to Tensor\n",
    "    input_ids = torch.tensor(input_ids) \n",
    "    input_mask_array = torch.tensor(input_mask_array)\n",
    "    label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "    label_mask_array = torch.tensor(label_mask_array)\n",
    "\n",
    "    # Building the TensorDataset\n",
    "    dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
    "\n",
    "    if do_shuffle:\n",
    "        sampler = RandomSampler\n",
    "    else:\n",
    "        sampler = SequentialSampler\n",
    "\n",
    "    # Building the DataLoader\n",
    "    return DataLoader(\n",
    "              dataset,  # The training samples.\n",
    "              sampler = sampler(dataset), \n",
    "              batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.019144Z",
     "iopub.status.idle": "2021-12-31T15:58:26.019449Z",
     "shell.execute_reply": "2021-12-31T15:58:26.019311Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.019289Z"
    },
    "id": "25ee9904",
    "papermill": {
     "duration": 0.028653,
     "end_time": "2021-12-27T11:31:50.386128",
     "exception": false,
     "start_time": "2021-12-27T11:31:50.357475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_list=['negative','positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.020515Z",
     "iopub.status.idle": "2021-12-31T15:58:26.021055Z",
     "shell.execute_reply": "2021-12-31T15:58:26.020868Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.020843Z"
    },
    "id": "b28d8850",
    "papermill": {
     "duration": 0.028352,
     "end_time": "2021-12-27T11:31:50.443757",
     "exception": false,
     "start_time": "2021-12-27T11:31:50.415405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_map = {}\n",
    "for (i, label) in enumerate(label_list):\n",
    "    label_map[label] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.022354Z",
     "iopub.status.idle": "2021-12-31T15:58:26.022709Z",
     "shell.execute_reply": "2021-12-31T15:58:26.022532Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.022510Z"
    },
    "id": "6123d5e7",
    "outputId": "439f3ee0-a5fa-4f13-d843-71a7e088cf8d",
    "papermill": {
     "duration": 0.028439,
     "end_time": "2021-12-27T11:31:50.500897",
     "exception": false,
     "start_time": "2021-12-27T11:31:50.472458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negative': 0, 'positive': 1}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.025133Z",
     "iopub.status.idle": "2021-12-31T15:58:26.025579Z",
     "shell.execute_reply": "2021-12-31T15:58:26.025402Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.025381Z"
    },
    "id": "abb3bf8e",
    "papermill": {
     "duration": 0.029237,
     "end_time": "2021-12-27T11:31:50.561744",
     "exception": false,
     "start_time": "2021-12-27T11:31:50.532507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_label_masks = np.ones(len(train_list), dtype=bool)\n",
    "train_dataloader = generate_data_loader(train_list, train_label_masks, label_map, do_shuffle = True, balance_label_examples = False)\n",
    "\n",
    "test_label_masks = np.ones(len(test_list), dtype=bool)\n",
    "test_dataloader = generate_data_loader(test_list, test_label_masks, label_map, do_shuffle = True, balance_label_examples = False)\n",
    "\n",
    "real_test_label_masks = np.ones(len(real_test_list), dtype=bool)\n",
    "real_test_dataloader = generate_data_loader(real_test_list, real_test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.027033Z",
     "iopub.status.idle": "2021-12-31T15:58:26.027371Z",
     "shell.execute_reply": "2021-12-31T15:58:26.027224Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.027202Z"
    },
    "id": "b5cd6f9c",
    "papermill": {
     "duration": 0.028076,
     "end_time": "2021-12-27T11:31:50.61824",
     "exception": false,
     "start_time": "2021-12-27T11:31:50.590164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#   The Generator as in \n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n",
    "        super(Generator, self).__init__()\n",
    "        layers = []\n",
    "        hidden_sizes = [noise_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        output_rep = self.layers(noise)\n",
    "        return output_rep\n",
    "\n",
    "#------------------------------\n",
    "#   The Discriminator\n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
    "        layers = []\n",
    "        hidden_sizes = [input_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        self.layers = nn.Sequential(*layers) #per il flatten\n",
    "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_rep):\n",
    "        input_rep = self.input_dropout(input_rep)\n",
    "        last_rep = self.layers(input_rep)\n",
    "        logits = self.logit(last_rep)\n",
    "        probs = self.softmax(logits)\n",
    "        return last_rep, logits, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.028926Z",
     "iopub.status.idle": "2021-12-31T15:58:26.029249Z",
     "shell.execute_reply": "2021-12-31T15:58:26.029099Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.029078Z"
    },
    "id": "XYh3alyhYoDi"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.030463Z",
     "iopub.status.idle": "2021-12-31T15:58:26.030990Z",
     "shell.execute_reply": "2021-12-31T15:58:26.030816Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.030793Z"
    },
    "id": "B0fPiFQZYoFy"
   },
   "outputs": [],
   "source": [
    "# The config file is required to get the dimension of the vector produced by \n",
    "# the underlying transformer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "hidden_size = int(config.hidden_size)\n",
    "# Define the number and width of hidden layers\n",
    "hidden_levels_g = [hidden_size for i in range(0, num_hidden_layers_g)]\n",
    "hidden_levels_d = [hidden_size for i in range(0, num_hidden_layers_d)]\n",
    "\n",
    "#-------------------------------------------------\n",
    "#   Instantiate the Generator and Discriminator\n",
    "#-------------------------------------------------\n",
    "generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n",
    "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
    "\n",
    "# Put everything in the GPU if available\n",
    "if torch.cuda.is_available():    \n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    transformer.cuda()\n",
    "    if multi_gpu:\n",
    "        transformer = torch.nn.DataParallel(transformer)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.032089Z",
     "iopub.status.idle": "2021-12-31T15:58:26.032371Z",
     "shell.execute_reply": "2021-12-31T15:58:26.032239Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.032224Z"
    },
    "id": "N4X4PSELYoIa",
    "outputId": "62848f4c-6e7c-4b77-9cda-a170e6648e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "  Batch     5  of    614.    Elapsed: 0:00:28.\n",
      "  Batch    10  of    614.    Elapsed: 0:00:30.\n",
      "  Batch    15  of    614.    Elapsed: 0:00:31.\n",
      "  Batch    20  of    614.    Elapsed: 0:00:33.\n",
      "  Batch    25  of    614.    Elapsed: 0:00:35.\n",
      "  Batch    30  of    614.    Elapsed: 0:00:36.\n",
      "  Batch    35  of    614.    Elapsed: 0:00:37.\n",
      "  Batch    40  of    614.    Elapsed: 0:00:39.\n",
      "  Batch    45  of    614.    Elapsed: 0:00:41.\n",
      "  Batch    50  of    614.    Elapsed: 0:00:42.\n",
      "  Batch    55  of    614.    Elapsed: 0:00:44.\n",
      "  Batch    60  of    614.    Elapsed: 0:00:45.\n",
      "  Batch    65  of    614.    Elapsed: 0:00:46.\n",
      "  Batch    70  of    614.    Elapsed: 0:00:48.\n",
      "  Batch    75  of    614.    Elapsed: 0:00:50.\n",
      "  Batch    80  of    614.    Elapsed: 0:00:51.\n",
      "  Batch    85  of    614.    Elapsed: 0:00:53.\n",
      "  Batch    90  of    614.    Elapsed: 0:00:54.\n",
      "  Batch    95  of    614.    Elapsed: 0:00:56.\n",
      "  Batch   100  of    614.    Elapsed: 0:00:57.\n",
      "  Batch   105  of    614.    Elapsed: 0:00:59.\n",
      "  Batch   110  of    614.    Elapsed: 0:01:00.\n",
      "  Batch   115  of    614.    Elapsed: 0:01:02.\n",
      "  Batch   120  of    614.    Elapsed: 0:01:03.\n",
      "  Batch   125  of    614.    Elapsed: 0:01:05.\n",
      "  Batch   130  of    614.    Elapsed: 0:01:06.\n",
      "  Batch   135  of    614.    Elapsed: 0:01:08.\n",
      "  Batch   140  of    614.    Elapsed: 0:01:09.\n",
      "  Batch   145  of    614.    Elapsed: 0:01:11.\n",
      "  Batch   150  of    614.    Elapsed: 0:01:12.\n",
      "  Batch   155  of    614.    Elapsed: 0:01:14.\n",
      "  Batch   160  of    614.    Elapsed: 0:01:15.\n",
      "  Batch   165  of    614.    Elapsed: 0:01:16.\n",
      "  Batch   170  of    614.    Elapsed: 0:01:18.\n",
      "  Batch   175  of    614.    Elapsed: 0:01:19.\n",
      "  Batch   180  of    614.    Elapsed: 0:01:21.\n",
      "  Batch   185  of    614.    Elapsed: 0:01:22.\n",
      "  Batch   190  of    614.    Elapsed: 0:01:24.\n",
      "  Batch   195  of    614.    Elapsed: 0:01:25.\n",
      "  Batch   200  of    614.    Elapsed: 0:01:27.\n",
      "  Batch   205  of    614.    Elapsed: 0:01:28.\n",
      "  Batch   210  of    614.    Elapsed: 0:01:30.\n",
      "  Batch   215  of    614.    Elapsed: 0:01:31.\n",
      "  Batch   220  of    614.    Elapsed: 0:01:33.\n",
      "  Batch   225  of    614.    Elapsed: 0:01:34.\n",
      "  Batch   230  of    614.    Elapsed: 0:01:35.\n",
      "  Batch   235  of    614.    Elapsed: 0:01:37.\n",
      "  Batch   240  of    614.    Elapsed: 0:01:38.\n",
      "  Batch   245  of    614.    Elapsed: 0:01:40.\n",
      "  Batch   250  of    614.    Elapsed: 0:01:41.\n",
      "  Batch   255  of    614.    Elapsed: 0:01:43.\n",
      "  Batch   260  of    614.    Elapsed: 0:01:44.\n",
      "  Batch   265  of    614.    Elapsed: 0:01:46.\n",
      "  Batch   270  of    614.    Elapsed: 0:01:47.\n",
      "  Batch   275  of    614.    Elapsed: 0:01:49.\n",
      "  Batch   280  of    614.    Elapsed: 0:01:50.\n",
      "  Batch   285  of    614.    Elapsed: 0:01:52.\n",
      "  Batch   290  of    614.    Elapsed: 0:01:53.\n",
      "  Batch   295  of    614.    Elapsed: 0:01:54.\n",
      "  Batch   300  of    614.    Elapsed: 0:01:56.\n",
      "  Batch   305  of    614.    Elapsed: 0:01:57.\n",
      "  Batch   310  of    614.    Elapsed: 0:01:59.\n",
      "  Batch   315  of    614.    Elapsed: 0:02:01.\n",
      "  Batch   320  of    614.    Elapsed: 0:02:02.\n",
      "  Batch   325  of    614.    Elapsed: 0:02:03.\n",
      "  Batch   330  of    614.    Elapsed: 0:02:05.\n",
      "  Batch   335  of    614.    Elapsed: 0:02:07.\n",
      "  Batch   340  of    614.    Elapsed: 0:02:08.\n",
      "  Batch   345  of    614.    Elapsed: 0:02:09.\n",
      "  Batch   350  of    614.    Elapsed: 0:02:11.\n",
      "  Batch   355  of    614.    Elapsed: 0:02:12.\n",
      "  Batch   360  of    614.    Elapsed: 0:02:14.\n",
      "  Batch   365  of    614.    Elapsed: 0:02:15.\n",
      "  Batch   370  of    614.    Elapsed: 0:02:17.\n",
      "  Batch   375  of    614.    Elapsed: 0:02:18.\n",
      "  Batch   380  of    614.    Elapsed: 0:02:20.\n",
      "  Batch   385  of    614.    Elapsed: 0:02:21.\n",
      "  Batch   390  of    614.    Elapsed: 0:02:23.\n",
      "  Batch   395  of    614.    Elapsed: 0:02:24.\n",
      "  Batch   400  of    614.    Elapsed: 0:02:26.\n",
      "  Batch   405  of    614.    Elapsed: 0:02:27.\n",
      "  Batch   410  of    614.    Elapsed: 0:02:29.\n",
      "  Batch   415  of    614.    Elapsed: 0:02:30.\n",
      "  Batch   420  of    614.    Elapsed: 0:02:32.\n",
      "  Batch   425  of    614.    Elapsed: 0:02:33.\n",
      "  Batch   430  of    614.    Elapsed: 0:02:35.\n",
      "  Batch   435  of    614.    Elapsed: 0:02:37.\n",
      "  Batch   440  of    614.    Elapsed: 0:02:38.\n",
      "  Batch   445  of    614.    Elapsed: 0:02:40.\n",
      "  Batch   450  of    614.    Elapsed: 0:02:41.\n",
      "  Batch   455  of    614.    Elapsed: 0:02:43.\n",
      "  Batch   460  of    614.    Elapsed: 0:02:44.\n",
      "  Batch   465  of    614.    Elapsed: 0:02:46.\n",
      "  Batch   470  of    614.    Elapsed: 0:02:47.\n",
      "  Batch   475  of    614.    Elapsed: 0:02:49.\n",
      "  Batch   480  of    614.    Elapsed: 0:02:50.\n",
      "  Batch   485  of    614.    Elapsed: 0:02:52.\n",
      "  Batch   490  of    614.    Elapsed: 0:02:53.\n",
      "  Batch   495  of    614.    Elapsed: 0:02:55.\n",
      "  Batch   500  of    614.    Elapsed: 0:02:56.\n",
      "  Batch   505  of    614.    Elapsed: 0:02:58.\n",
      "  Batch   510  of    614.    Elapsed: 0:02:59.\n",
      "  Batch   515  of    614.    Elapsed: 0:03:01.\n",
      "  Batch   520  of    614.    Elapsed: 0:03:02.\n",
      "  Batch   525  of    614.    Elapsed: 0:03:04.\n",
      "  Batch   530  of    614.    Elapsed: 0:03:05.\n",
      "  Batch   535  of    614.    Elapsed: 0:03:07.\n",
      "  Batch   540  of    614.    Elapsed: 0:03:08.\n",
      "  Batch   545  of    614.    Elapsed: 0:03:10.\n",
      "  Batch   550  of    614.    Elapsed: 0:03:11.\n",
      "  Batch   555  of    614.    Elapsed: 0:03:13.\n",
      "  Batch   560  of    614.    Elapsed: 0:03:14.\n",
      "  Batch   565  of    614.    Elapsed: 0:03:15.\n",
      "  Batch   570  of    614.    Elapsed: 0:03:17.\n",
      "  Batch   575  of    614.    Elapsed: 0:03:19.\n",
      "  Batch   580  of    614.    Elapsed: 0:03:20.\n",
      "  Batch   585  of    614.    Elapsed: 0:03:21.\n",
      "  Batch   590  of    614.    Elapsed: 0:03:23.\n",
      "  Batch   595  of    614.    Elapsed: 0:03:25.\n",
      "  Batch   600  of    614.    Elapsed: 0:03:26.\n",
      "  Batch   605  of    614.    Elapsed: 0:03:27.\n",
      "  Batch   610  of    614.    Elapsed: 0:03:29.\n",
      "\n",
      "  Average training loss generetor: 0.720\n",
      "  Average training loss discriminator: 0.988\n",
      "  Training epoch took: 0:03:30\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.952\n",
      "  Test Loss: 0.136\n",
      "  Test took: 0:00:20\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "  Batch     5  of    614.    Elapsed: 0:00:01.\n",
      "  Batch    10  of    614.    Elapsed: 0:00:03.\n",
      "  Batch    15  of    614.    Elapsed: 0:00:05.\n",
      "  Batch    20  of    614.    Elapsed: 0:00:06.\n",
      "  Batch    25  of    614.    Elapsed: 0:00:07.\n",
      "  Batch    30  of    614.    Elapsed: 0:00:09.\n",
      "  Batch    35  of    614.    Elapsed: 0:00:10.\n",
      "  Batch    40  of    614.    Elapsed: 0:00:12.\n",
      "  Batch    45  of    614.    Elapsed: 0:00:13.\n",
      "  Batch    50  of    614.    Elapsed: 0:00:15.\n",
      "  Batch    55  of    614.    Elapsed: 0:00:16.\n",
      "  Batch    60  of    614.    Elapsed: 0:00:18.\n",
      "  Batch    65  of    614.    Elapsed: 0:00:19.\n",
      "  Batch    70  of    614.    Elapsed: 0:00:21.\n",
      "  Batch    75  of    614.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    614.    Elapsed: 0:00:24.\n",
      "  Batch    85  of    614.    Elapsed: 0:00:25.\n",
      "  Batch    90  of    614.    Elapsed: 0:00:26.\n",
      "  Batch    95  of    614.    Elapsed: 0:00:28.\n",
      "  Batch   100  of    614.    Elapsed: 0:00:30.\n",
      "  Batch   105  of    614.    Elapsed: 0:00:31.\n",
      "  Batch   110  of    614.    Elapsed: 0:00:32.\n",
      "  Batch   115  of    614.    Elapsed: 0:00:34.\n",
      "  Batch   120  of    614.    Elapsed: 0:00:35.\n",
      "  Batch   125  of    614.    Elapsed: 0:00:37.\n",
      "  Batch   130  of    614.    Elapsed: 0:00:38.\n",
      "  Batch   135  of    614.    Elapsed: 0:00:40.\n",
      "  Batch   140  of    614.    Elapsed: 0:00:41.\n",
      "  Batch   145  of    614.    Elapsed: 0:00:43.\n",
      "  Batch   150  of    614.    Elapsed: 0:00:44.\n",
      "  Batch   155  of    614.    Elapsed: 0:00:46.\n",
      "  Batch   160  of    614.    Elapsed: 0:00:47.\n",
      "  Batch   165  of    614.    Elapsed: 0:00:49.\n",
      "  Batch   170  of    614.    Elapsed: 0:00:50.\n",
      "  Batch   175  of    614.    Elapsed: 0:00:52.\n",
      "  Batch   180  of    614.    Elapsed: 0:00:53.\n",
      "  Batch   185  of    614.    Elapsed: 0:00:55.\n",
      "  Batch   190  of    614.    Elapsed: 0:00:56.\n",
      "  Batch   195  of    614.    Elapsed: 0:00:58.\n",
      "  Batch   200  of    614.    Elapsed: 0:00:59.\n",
      "  Batch   205  of    614.    Elapsed: 0:01:01.\n",
      "  Batch   210  of    614.    Elapsed: 0:01:02.\n",
      "  Batch   215  of    614.    Elapsed: 0:01:04.\n",
      "  Batch   220  of    614.    Elapsed: 0:01:05.\n",
      "  Batch   225  of    614.    Elapsed: 0:01:07.\n",
      "  Batch   230  of    614.    Elapsed: 0:01:08.\n",
      "  Batch   235  of    614.    Elapsed: 0:01:10.\n",
      "  Batch   240  of    614.    Elapsed: 0:01:11.\n",
      "  Batch   245  of    614.    Elapsed: 0:01:13.\n",
      "  Batch   250  of    614.    Elapsed: 0:01:14.\n",
      "  Batch   255  of    614.    Elapsed: 0:01:16.\n",
      "  Batch   260  of    614.    Elapsed: 0:01:17.\n",
      "  Batch   265  of    614.    Elapsed: 0:01:18.\n",
      "  Batch   270  of    614.    Elapsed: 0:01:20.\n",
      "  Batch   275  of    614.    Elapsed: 0:01:22.\n",
      "  Batch   280  of    614.    Elapsed: 0:01:23.\n",
      "  Batch   285  of    614.    Elapsed: 0:01:24.\n",
      "  Batch   290  of    614.    Elapsed: 0:01:26.\n",
      "  Batch   295  of    614.    Elapsed: 0:01:27.\n",
      "  Batch   300  of    614.    Elapsed: 0:01:29.\n",
      "  Batch   305  of    614.    Elapsed: 0:01:30.\n",
      "  Batch   310  of    614.    Elapsed: 0:01:32.\n",
      "  Batch   315  of    614.    Elapsed: 0:01:33.\n",
      "  Batch   320  of    614.    Elapsed: 0:01:35.\n",
      "  Batch   325  of    614.    Elapsed: 0:01:36.\n",
      "  Batch   330  of    614.    Elapsed: 0:01:38.\n",
      "  Batch   335  of    614.    Elapsed: 0:01:39.\n",
      "  Batch   340  of    614.    Elapsed: 0:01:40.\n",
      "  Batch   345  of    614.    Elapsed: 0:01:42.\n",
      "  Batch   350  of    614.    Elapsed: 0:01:43.\n",
      "  Batch   355  of    614.    Elapsed: 0:01:45.\n",
      "  Batch   360  of    614.    Elapsed: 0:01:46.\n",
      "  Batch   365  of    614.    Elapsed: 0:01:48.\n",
      "  Batch   370  of    614.    Elapsed: 0:01:49.\n",
      "  Batch   375  of    614.    Elapsed: 0:01:51.\n",
      "  Batch   380  of    614.    Elapsed: 0:01:52.\n",
      "  Batch   385  of    614.    Elapsed: 0:01:53.\n",
      "  Batch   390  of    614.    Elapsed: 0:01:55.\n",
      "  Batch   395  of    614.    Elapsed: 0:01:56.\n",
      "  Batch   400  of    614.    Elapsed: 0:01:58.\n",
      "  Batch   405  of    614.    Elapsed: 0:01:59.\n",
      "  Batch   410  of    614.    Elapsed: 0:02:01.\n",
      "  Batch   415  of    614.    Elapsed: 0:02:02.\n",
      "  Batch   420  of    614.    Elapsed: 0:02:03.\n",
      "  Batch   425  of    614.    Elapsed: 0:02:05.\n",
      "  Batch   430  of    614.    Elapsed: 0:02:07.\n",
      "  Batch   435  of    614.    Elapsed: 0:02:08.\n",
      "  Batch   440  of    614.    Elapsed: 0:02:09.\n",
      "  Batch   445  of    614.    Elapsed: 0:02:11.\n",
      "  Batch   450  of    614.    Elapsed: 0:02:12.\n",
      "  Batch   455  of    614.    Elapsed: 0:02:14.\n",
      "  Batch   460  of    614.    Elapsed: 0:02:15.\n",
      "  Batch   465  of    614.    Elapsed: 0:02:17.\n",
      "  Batch   470  of    614.    Elapsed: 0:02:18.\n",
      "  Batch   475  of    614.    Elapsed: 0:02:20.\n",
      "  Batch   480  of    614.    Elapsed: 0:02:21.\n",
      "  Batch   485  of    614.    Elapsed: 0:02:22.\n",
      "  Batch   490  of    614.    Elapsed: 0:02:24.\n",
      "  Batch   495  of    614.    Elapsed: 0:02:25.\n",
      "  Batch   500  of    614.    Elapsed: 0:02:27.\n",
      "  Batch   505  of    614.    Elapsed: 0:02:28.\n",
      "  Batch   510  of    614.    Elapsed: 0:02:29.\n",
      "  Batch   515  of    614.    Elapsed: 0:02:31.\n",
      "  Batch   520  of    614.    Elapsed: 0:02:33.\n",
      "  Batch   525  of    614.    Elapsed: 0:02:34.\n",
      "  Batch   530  of    614.    Elapsed: 0:02:35.\n",
      "  Batch   535  of    614.    Elapsed: 0:02:37.\n",
      "  Batch   540  of    614.    Elapsed: 0:02:38.\n",
      "  Batch   545  of    614.    Elapsed: 0:02:40.\n",
      "  Batch   550  of    614.    Elapsed: 0:02:41.\n",
      "  Batch   555  of    614.    Elapsed: 0:02:42.\n",
      "  Batch   560  of    614.    Elapsed: 0:02:44.\n",
      "  Batch   565  of    614.    Elapsed: 0:02:46.\n",
      "  Batch   570  of    614.    Elapsed: 0:02:47.\n",
      "  Batch   575  of    614.    Elapsed: 0:02:48.\n",
      "  Batch   580  of    614.    Elapsed: 0:02:50.\n",
      "  Batch   585  of    614.    Elapsed: 0:02:51.\n",
      "  Batch   590  of    614.    Elapsed: 0:02:53.\n",
      "  Batch   595  of    614.    Elapsed: 0:02:54.\n",
      "  Batch   600  of    614.    Elapsed: 0:02:55.\n",
      "  Batch   605  of    614.    Elapsed: 0:02:57.\n",
      "  Batch   610  of    614.    Elapsed: 0:02:58.\n",
      "\n",
      "  Average training loss generetor: 0.714\n",
      "  Average training loss discriminator: 0.864\n",
      "  Training epoch took: 0:02:59\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.957\n",
      "  Test Loss: 0.152\n",
      "  Test took: 0:00:21\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "  Batch     5  of    614.    Elapsed: 0:00:01.\n",
      "  Batch    10  of    614.    Elapsed: 0:00:03.\n",
      "  Batch    15  of    614.    Elapsed: 0:00:04.\n",
      "  Batch    20  of    614.    Elapsed: 0:00:05.\n",
      "  Batch    25  of    614.    Elapsed: 0:00:07.\n",
      "  Batch    30  of    614.    Elapsed: 0:00:09.\n",
      "  Batch    35  of    614.    Elapsed: 0:00:10.\n",
      "  Batch    40  of    614.    Elapsed: 0:00:11.\n",
      "  Batch    45  of    614.    Elapsed: 0:00:13.\n",
      "  Batch    50  of    614.    Elapsed: 0:00:14.\n",
      "  Batch    55  of    614.    Elapsed: 0:00:16.\n",
      "  Batch    60  of    614.    Elapsed: 0:00:17.\n",
      "  Batch    65  of    614.    Elapsed: 0:00:19.\n",
      "  Batch    70  of    614.    Elapsed: 0:00:20.\n",
      "  Batch    75  of    614.    Elapsed: 0:00:22.\n",
      "  Batch    80  of    614.    Elapsed: 0:00:23.\n",
      "  Batch    85  of    614.    Elapsed: 0:00:25.\n",
      "  Batch    90  of    614.    Elapsed: 0:00:27.\n",
      "  Batch    95  of    614.    Elapsed: 0:00:29.\n",
      "  Batch   100  of    614.    Elapsed: 0:00:30.\n",
      "  Batch   105  of    614.    Elapsed: 0:00:31.\n",
      "  Batch   110  of    614.    Elapsed: 0:00:33.\n",
      "  Batch   115  of    614.    Elapsed: 0:00:35.\n",
      "  Batch   120  of    614.    Elapsed: 0:00:36.\n",
      "  Batch   125  of    614.    Elapsed: 0:00:37.\n",
      "  Batch   130  of    614.    Elapsed: 0:00:39.\n",
      "  Batch   135  of    614.    Elapsed: 0:00:41.\n",
      "  Batch   140  of    614.    Elapsed: 0:00:42.\n",
      "  Batch   145  of    614.    Elapsed: 0:00:43.\n",
      "  Batch   150  of    614.    Elapsed: 0:00:45.\n",
      "  Batch   155  of    614.    Elapsed: 0:00:47.\n",
      "  Batch   160  of    614.    Elapsed: 0:00:48.\n",
      "  Batch   165  of    614.    Elapsed: 0:00:49.\n",
      "  Batch   170  of    614.    Elapsed: 0:00:51.\n",
      "  Batch   175  of    614.    Elapsed: 0:00:53.\n",
      "  Batch   180  of    614.    Elapsed: 0:00:54.\n",
      "  Batch   185  of    614.    Elapsed: 0:00:55.\n",
      "  Batch   190  of    614.    Elapsed: 0:00:57.\n",
      "  Batch   195  of    614.    Elapsed: 0:00:58.\n",
      "  Batch   200  of    614.    Elapsed: 0:01:00.\n",
      "  Batch   205  of    614.    Elapsed: 0:01:01.\n",
      "  Batch   210  of    614.    Elapsed: 0:01:03.\n",
      "  Batch   215  of    614.    Elapsed: 0:01:04.\n",
      "  Batch   220  of    614.    Elapsed: 0:01:06.\n",
      "  Batch   225  of    614.    Elapsed: 0:01:07.\n",
      "  Batch   230  of    614.    Elapsed: 0:01:09.\n",
      "  Batch   235  of    614.    Elapsed: 0:01:10.\n",
      "  Batch   240  of    614.    Elapsed: 0:01:12.\n",
      "  Batch   245  of    614.    Elapsed: 0:01:13.\n",
      "  Batch   250  of    614.    Elapsed: 0:01:15.\n",
      "  Batch   255  of    614.    Elapsed: 0:01:16.\n",
      "  Batch   260  of    614.    Elapsed: 0:01:18.\n",
      "  Batch   265  of    614.    Elapsed: 0:01:19.\n",
      "  Batch   270  of    614.    Elapsed: 0:01:21.\n",
      "  Batch   275  of    614.    Elapsed: 0:01:22.\n",
      "  Batch   280  of    614.    Elapsed: 0:01:24.\n",
      "  Batch   285  of    614.    Elapsed: 0:01:25.\n",
      "  Batch   290  of    614.    Elapsed: 0:01:27.\n",
      "  Batch   295  of    614.    Elapsed: 0:01:28.\n",
      "  Batch   300  of    614.    Elapsed: 0:01:29.\n",
      "  Batch   305  of    614.    Elapsed: 0:01:31.\n",
      "  Batch   310  of    614.    Elapsed: 0:01:33.\n",
      "  Batch   315  of    614.    Elapsed: 0:01:34.\n",
      "  Batch   320  of    614.    Elapsed: 0:01:35.\n",
      "  Batch   325  of    614.    Elapsed: 0:01:37.\n",
      "  Batch   330  of    614.    Elapsed: 0:01:38.\n",
      "  Batch   335  of    614.    Elapsed: 0:01:40.\n",
      "  Batch   340  of    614.    Elapsed: 0:01:41.\n",
      "  Batch   345  of    614.    Elapsed: 0:01:43.\n",
      "  Batch   350  of    614.    Elapsed: 0:01:44.\n",
      "  Batch   355  of    614.    Elapsed: 0:01:46.\n",
      "  Batch   360  of    614.    Elapsed: 0:01:47.\n",
      "  Batch   365  of    614.    Elapsed: 0:01:49.\n",
      "  Batch   370  of    614.    Elapsed: 0:01:50.\n",
      "  Batch   375  of    614.    Elapsed: 0:01:52.\n",
      "  Batch   380  of    614.    Elapsed: 0:01:53.\n",
      "  Batch   385  of    614.    Elapsed: 0:01:54.\n",
      "  Batch   390  of    614.    Elapsed: 0:01:56.\n",
      "  Batch   395  of    614.    Elapsed: 0:01:57.\n",
      "  Batch   400  of    614.    Elapsed: 0:01:59.\n",
      "  Batch   405  of    614.    Elapsed: 0:02:01.\n",
      "  Batch   410  of    614.    Elapsed: 0:02:02.\n",
      "  Batch   415  of    614.    Elapsed: 0:02:03.\n",
      "  Batch   420  of    614.    Elapsed: 0:02:05.\n",
      "  Batch   425  of    614.    Elapsed: 0:02:07.\n",
      "  Batch   430  of    614.    Elapsed: 0:02:08.\n",
      "  Batch   435  of    614.    Elapsed: 0:02:09.\n",
      "  Batch   440  of    614.    Elapsed: 0:02:11.\n",
      "  Batch   445  of    614.    Elapsed: 0:02:12.\n",
      "  Batch   450  of    614.    Elapsed: 0:02:14.\n",
      "  Batch   455  of    614.    Elapsed: 0:02:15.\n",
      "  Batch   460  of    614.    Elapsed: 0:02:16.\n",
      "  Batch   465  of    614.    Elapsed: 0:02:18.\n",
      "  Batch   470  of    614.    Elapsed: 0:02:20.\n",
      "  Batch   475  of    614.    Elapsed: 0:02:21.\n",
      "  Batch   480  of    614.    Elapsed: 0:02:22.\n",
      "  Batch   485  of    614.    Elapsed: 0:02:24.\n",
      "  Batch   490  of    614.    Elapsed: 0:02:25.\n",
      "  Batch   495  of    614.    Elapsed: 0:02:27.\n",
      "  Batch   500  of    614.    Elapsed: 0:02:28.\n",
      "  Batch   505  of    614.    Elapsed: 0:02:30.\n",
      "  Batch   510  of    614.    Elapsed: 0:02:32.\n",
      "  Batch   515  of    614.    Elapsed: 0:02:33.\n",
      "  Batch   520  of    614.    Elapsed: 0:02:34.\n",
      "  Batch   525  of    614.    Elapsed: 0:02:36.\n",
      "  Batch   530  of    614.    Elapsed: 0:02:37.\n",
      "  Batch   535  of    614.    Elapsed: 0:02:39.\n",
      "  Batch   540  of    614.    Elapsed: 0:02:40.\n",
      "  Batch   545  of    614.    Elapsed: 0:02:42.\n",
      "  Batch   550  of    614.    Elapsed: 0:02:43.\n",
      "  Batch   555  of    614.    Elapsed: 0:02:45.\n",
      "  Batch   560  of    614.    Elapsed: 0:02:46.\n",
      "  Batch   565  of    614.    Elapsed: 0:02:47.\n",
      "  Batch   570  of    614.    Elapsed: 0:02:49.\n",
      "  Batch   575  of    614.    Elapsed: 0:02:51.\n",
      "  Batch   580  of    614.    Elapsed: 0:02:52.\n",
      "  Batch   585  of    614.    Elapsed: 0:02:54.\n",
      "  Batch   590  of    614.    Elapsed: 0:02:55.\n",
      "  Batch   595  of    614.    Elapsed: 0:02:57.\n",
      "  Batch   600  of    614.    Elapsed: 0:02:58.\n",
      "  Batch   605  of    614.    Elapsed: 0:02:59.\n",
      "  Batch   610  of    614.    Elapsed: 0:03:01.\n",
      "\n",
      "  Average training loss generetor: 0.711\n",
      "  Average training loss discriminator: 0.821\n",
      "  Training epoch took: 0:03:02\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.951\n",
      "  Test Loss: 0.147\n",
      "  Test took: 0:00:21\n"
     ]
    }
   ],
   "source": [
    "num_train_epochs = 3\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "#models parameters\n",
    "transformer_vars = [i for i in transformer.parameters()]\n",
    "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
    "g_vars = [v for v in generator.parameters()]\n",
    "\n",
    "#optimizer\n",
    "dis_optimizer = torch.optim.Adam(d_vars, lr=learning_rate_discriminator)\n",
    "gen_optimizer = torch.optim.Adam(g_vars, lr=learning_rate_generator) \n",
    "\n",
    "#scheduler\n",
    "if apply_scheduler:\n",
    "    num_train_examples = len(train_examples)\n",
    "    num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
    "    num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "\n",
    "    scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "    scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, num_train_epochs):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    tr_g_loss = 0\n",
    "    tr_d_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    transformer.train() \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every print_each_n_step batches.\n",
    "        if step % print_each_n_step == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        b_label_mask = batch[3].to(device)\n",
    "     \n",
    "        # Encode real data in the Transformer\n",
    "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "        hidden_states = model_outputs[-1]\n",
    "        \n",
    "        # Generate fake data that should have the same distribution of the ones\n",
    "        # encoded by the transformer. \n",
    "        # First noisy input are used in input to the Generator\n",
    "        noise = torch.zeros(b_input_ids.shape[0],noise_size, device=device).uniform_(0, 1)\n",
    "        # Gnerate Fake data\n",
    "        gen_rep = generator(noise)\n",
    "\n",
    "        # Generate the output of the Discriminator for real and fake data.\n",
    "        # First, we put together the output of the tranformer and the generator\n",
    "        disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n",
    "        # Then, we select the output of the disciminator\n",
    "        features, logits, probs = discriminator(disciminator_input)\n",
    "\n",
    "        # Finally, we separate the discriminator's output for the real and fake\n",
    "        # data\n",
    "        features_list = torch.split(features, len(hidden_states))\n",
    "        D_real_features = features_list[0]\n",
    "        D_fake_features = features_list[1]\n",
    "      \n",
    "        logits_list = torch.split(logits, len(hidden_states))\n",
    "        D_real_logits = logits_list[0]\n",
    "        D_fake_logits = logits_list[1]\n",
    "        \n",
    "        probs_list = torch.split(probs, len(hidden_states))\n",
    "        D_real_probs = probs_list[0]\n",
    "        D_fake_probs = probs_list[1]\n",
    "\n",
    "        #---------------------------------\n",
    "        #  LOSS evaluation\n",
    "        #---------------------------------\n",
    "        # Generator's LOSS estimation\n",
    "        g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
    "        g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
    "        g_loss = g_loss_d + g_feat_reg\n",
    "  \n",
    "        # Disciminator's LOSS estimation\n",
    "        logits = D_real_logits[:,0:-1]\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        # The discriminator provides an output for labeled and unlabeled real data\n",
    "        # so the loss evaluated for unlabeled data is ignored (masked)\n",
    "        label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n",
    "        per_example_loss = -torch.sum(label2one_hot.float() * log_probs, dim=-1)\n",
    "#         per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
    "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
    "\n",
    "        # It may be the case that a batch does not contain labeled examples, \n",
    "        # so the \"supervised loss\" in this case is not evaluated\n",
    "        if labeled_example_count == 0:\n",
    "            D_L_Supervised = 0\n",
    "        else:\n",
    "            D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
    "                 \n",
    "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
    "        D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
    "        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
    "\n",
    "        #---------------------------------\n",
    "        #  OPTIMIZATION\n",
    "        #---------------------------------\n",
    "        # Avoid gradient accumulation\n",
    "        gen_optimizer.zero_grad()\n",
    "        dis_optimizer.zero_grad()\n",
    "\n",
    "        # Calculate weigth updates\n",
    "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        d_loss.backward() \n",
    "        \n",
    "        # Apply modifications\n",
    "        gen_optimizer.step()\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        # A detail log of the individual losses\n",
    "        #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
    "        #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
    "        #             g_loss_d, g_feat_reg))\n",
    "\n",
    "        # Save the losses to print them later\n",
    "        tr_g_loss += g_loss.item()\n",
    "        tr_d_loss += d_loss.item()\n",
    "\n",
    "        # Update the learning rate with the scheduler\n",
    "        if apply_scheduler:\n",
    "            scheduler_d.step()\n",
    "            scheduler_g.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
    "    avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
    "    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #     TEST ON THE EVALUATION DATASET\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our test set.\n",
    "    print(\"\")\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    transformer.eval() #maybe redundant\n",
    "    discriminator.eval()\n",
    "    generator.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_test_accuracy = 0\n",
    "   \n",
    "    total_test_loss = 0\n",
    "    nb_test_steps = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels_ids = []\n",
    "\n",
    "    #loss\n",
    "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "            hidden_states = model_outputs[-1]\n",
    "            _, logits, probs = discriminator(hidden_states)\n",
    "            ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "            filtered_logits = logits[:,0:-1]\n",
    "            # Accumulate the test loss.\n",
    "            total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "            \n",
    "        # Accumulate the predictions and the input labels\n",
    "        _, preds = torch.max(filtered_logits, 1)\n",
    "        all_preds += preds.detach().tolist()\n",
    "        all_labels_ids += b_labels.detach().tolist()\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels_ids = np.array(all_labels_ids)\n",
    "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    avg_test_loss = avg_test_loss.item()\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    test_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss generator': avg_train_loss_g,\n",
    "            'Training Loss discriminator': avg_train_loss_d,\n",
    "            'Valid. Loss': avg_test_loss,\n",
    "            'Valid. Accur.': test_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Test Time': test_time\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.033423Z",
     "iopub.status.idle": "2021-12-31T15:58:26.033751Z",
     "shell.execute_reply": "2021-12-31T15:58:26.033595Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.033561Z"
    },
    "id": "IHTytloVYoK4"
   },
   "outputs": [],
   "source": [
    "# # To load previously fine-tuned trained model\n",
    "# model_upd_nm = model_name.replace('-','_')\n",
    "# c_tokenizer = AutoTokenizer.from_pretrained(f\"./Model Data/{model_upd_nm}/\")\n",
    "# transformer = AutoModel.from_pretrained(model_name)\n",
    "# transformer.load_state_dict(torch.load(f'./Model Data/{model_upd_nm}/'))\n",
    "\n",
    "# generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n",
    "# discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
    "\n",
    "# generator.load_state_dict(torch.load(f'Model Data/GAN_BERT_binary_generator_{category}.pth')['model_state_dict'])\n",
    "# discriminator.load_state_dict(torch.load(f'Model Data/GAN_BERT_binary_discriminator_{category}.pth')['model_state_dict'])\n",
    "\n",
    "# # Put everything in the GPU if available\n",
    "# if torch.cuda.is_available():    \n",
    "#     generator.cuda()\n",
    "#     discriminator.cuda()\n",
    "#     transformer.cuda()\n",
    "#     if multi_gpu:\n",
    "#         transformer = torch.nn.DataParallel(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.034793Z",
     "iopub.status.idle": "2021-12-31T15:58:26.035088Z",
     "shell.execute_reply": "2021-12-31T15:58:26.034951Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.034930Z"
    },
    "id": "01pS94CDYoNb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.951\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Running Test...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Put the model in evaluation mode--the dropout layers behave differently\n",
    "# during evaluation.\n",
    "transformer.eval() #maybe redundant\n",
    "discriminator.eval()\n",
    "generator.eval()\n",
    "\n",
    "# Tracking variables \n",
    "total_test_accuracy = 0\n",
    "\n",
    "total_test_loss = 0\n",
    "nb_test_steps = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels_ids = []\n",
    "pred_prob=[]\n",
    "\n",
    "#loss\n",
    "nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "for batch in test_dataloader:\n",
    "\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "        hidden_states = model_outputs[-1]\n",
    "        _, logits, probs = discriminator(hidden_states)\n",
    "        ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "        filtered_logits = logits[:,0:-1]\n",
    "        # Accumulate the test loss.\n",
    "        total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "\n",
    "    # Accumulate the predictions and the input labels\n",
    "    pred_prob += probs[:,0:-1].detach().tolist()\n",
    "    _, preds = torch.max(filtered_logits, 1)\n",
    "    all_preds += preds.detach().tolist()\n",
    "    all_labels_ids += b_labels.detach().tolist()\n",
    "    \n",
    "# Report the final accuracy for this validation run.\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels_ids = np.array(all_labels_ids)\n",
    "test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "print(\"  Accuracy: {0:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.036069Z",
     "iopub.status.idle": "2021-12-31T15:58:26.036379Z",
     "shell.execute_reply": "2021-12-31T15:58:26.036241Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.036220Z"
    },
    "id": "1jByApYZYoQw"
   },
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(all_preds,columns=['Predicted'])\n",
    "y_true=pd.DataFrame(all_labels_ids,columns=['Actual'])\n",
    "for i in range(len(label_list)):\n",
    "    y_pred[label_list[i]]=[1 if x==i else 0 for x in all_preds]\n",
    "    y_true[label_list[i]]=[1 if x==i else 0 for x in all_labels_ids]\n",
    "    \n",
    "y_pred=y_pred['positive']\n",
    "y_true=y_true['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.037817Z",
     "iopub.status.idle": "2021-12-31T15:58:26.038137Z",
     "shell.execute_reply": "2021-12-31T15:58:26.037998Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.037976Z"
    },
    "id": "mP76nhTbZtAl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.039605Z",
     "iopub.status.idle": "2021-12-31T15:58:26.039932Z",
     "shell.execute_reply": "2021-12-31T15:58:26.039790Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.039768Z"
    },
    "id": "sBwbc-1gZtDE"
   },
   "outputs": [],
   "source": [
    "test_reports=[]\n",
    "# train_reports=[]\n",
    "\n",
    "try:\n",
    "    report_test,t=classification_metrics(y_true.tolist(), y_pred.tolist())\n",
    "    test_reports.append(pd.DataFrame(report_test,[label_list[i]]))\n",
    "except:\n",
    "    print(label_list[i])\n",
    "        \n",
    "try:\n",
    "    test_df=pd.concat(test_reports)\n",
    "except:\n",
    "    test_df = pd.DataFrame(report_test,[label_list[i]])\n",
    "# train_df=pd.concat(train_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logloss_on_valid_data['Binary GAN-BERT'] = log_loss(y_true,[x[1] for x in pred_prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.041650Z",
     "iopub.status.idle": "2021-12-31T15:58:26.041989Z",
     "shell.execute_reply": "2021-12-31T15:58:26.041846Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.041824Z"
    },
    "id": "R494ZbWrZtFN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Train...\n",
      "  Accuracy: 0.969\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Running Train...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Put the model in evaluation mode--the dropout layers behave differently\n",
    "# during evaluation.\n",
    "transformer.eval() #maybe redundant\n",
    "discriminator.eval()\n",
    "generator.eval()\n",
    "\n",
    "# Tracking variables \n",
    "total_test_accuracy = 0\n",
    "\n",
    "total_test_loss = 0\n",
    "nb_test_steps = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels_ids = []\n",
    "pred_prob=[]\n",
    "\n",
    "#loss\n",
    "nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "for batch in train_dataloader:\n",
    "\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "        hidden_states = model_outputs[-1]\n",
    "        _, logits, probs = discriminator(hidden_states)\n",
    "        ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "        filtered_logits = logits[:,0:-1]\n",
    "        # Accumulate the test loss.\n",
    "        total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "\n",
    "    # Accumulate the predictions and the input labels\n",
    "    pred_prob += probs[:,0:-1].detach().tolist()\n",
    "    _, preds = torch.max(filtered_logits, 1)\n",
    "    all_preds += preds.detach().tolist()\n",
    "    all_labels_ids += b_labels.detach().tolist()\n",
    "    \n",
    "# Report the final accuracy for this validation run.\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels_ids = np.array(all_labels_ids)\n",
    "test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "y_pred=pd.DataFrame(all_preds,columns=['Predicted'])\n",
    "y_true=pd.DataFrame(all_labels_ids,columns=['Actual'])\n",
    "\n",
    "for i in range(len(label_list)):\n",
    "    y_pred[label_list[i]]=[1 if x==i else 0 for x in all_preds]\n",
    "    y_true[label_list[i]]=[1 if x==i else 0 for x in all_labels_ids]\n",
    "    \n",
    "y_pred=y_pred['positive']\n",
    "y_true=y_true['positive']\n",
    "\n",
    "train_reports=[]\n",
    "\n",
    "try:\n",
    "    report_test,t=classification_metrics(y_true.tolist(), y_pred.tolist())\n",
    "    train_reports.append(pd.DataFrame(report_test,[label_list[i]]))\n",
    "except:\n",
    "    print(label_list[i])\n",
    "        \n",
    "try:\n",
    "    train_df=pd.concat(train_reports)\n",
    "except:\n",
    "    train_df = pd.DataFrame(report_test,[label_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.042851Z",
     "iopub.status.idle": "2021-12-31T15:58:26.043151Z",
     "shell.execute_reply": "2021-12-31T15:58:26.043013Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.042991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4909.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.240842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.363065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.005776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.008863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.018067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.371101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.982835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted probability\n",
       "count            4909.000000\n",
       "mean                0.240842\n",
       "std                 0.363065\n",
       "min                 0.005776\n",
       "25%                 0.008863\n",
       "50%                 0.018067\n",
       "75%                 0.371101\n",
       "max                 0.982835"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([x[1] for x in pred_prob]).rename(columns = {0:'Predicted probability'}).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.044342Z",
     "iopub.status.idle": "2021-12-31T15:58:26.044687Z",
     "shell.execute_reply": "2021-12-31T15:58:26.044502Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.044481Z"
    },
    "id": "TuyaYvy_ZtG-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True_negatives</th>\n",
       "      <th>False_positives</th>\n",
       "      <th>False_negatives</th>\n",
       "      <th>True_positives</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Kappa Score</th>\n",
       "      <th>binary_cross_entropy</th>\n",
       "      <th>target_imbalance</th>\n",
       "      <th>target_size</th>\n",
       "      <th>optimal_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>939</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>228</td>\n",
       "      <td>0.9511</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.797326</td>\n",
       "      <td>0.942008</td>\n",
       "      <td>0.852846</td>\n",
       "      <td>1.688965</td>\n",
       "      <td>0.200489</td>\n",
       "      <td>1227</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          True_negatives  False_positives  False_negatives  True_positives  \\\n",
       "positive             939               42               18             228   \n",
       "\n",
       "          Accuracy    Recall  Precision  f1_score    PR_AUC   ROC_AUC  \\\n",
       "positive    0.9511  0.926829   0.844444  0.883721  0.797326  0.942008   \n",
       "\n",
       "          Kappa Score  binary_cross_entropy  target_imbalance  target_size  \\\n",
       "positive     0.852846              1.688965          0.200489         1227   \n",
       "\n",
       "          optimal_threshold  \n",
       "positive                  1  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.045577Z",
     "iopub.status.idle": "2021-12-31T15:58:26.045922Z",
     "shell.execute_reply": "2021-12-31T15:58:26.045780Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.045758Z"
    },
    "id": "F9_DyVMSZtKY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True_negatives</th>\n",
       "      <th>False_positives</th>\n",
       "      <th>False_negatives</th>\n",
       "      <th>True_positives</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Kappa Score</th>\n",
       "      <th>binary_cross_entropy</th>\n",
       "      <th>target_imbalance</th>\n",
       "      <th>target_size</th>\n",
       "      <th>optimal_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>3816</td>\n",
       "      <td>110</td>\n",
       "      <td>41</td>\n",
       "      <td>942</td>\n",
       "      <td>0.96924</td>\n",
       "      <td>0.958291</td>\n",
       "      <td>0.895437</td>\n",
       "      <td>0.925799</td>\n",
       "      <td>0.866441</td>\n",
       "      <td>0.965136</td>\n",
       "      <td>0.906425</td>\n",
       "      <td>1.062425</td>\n",
       "      <td>0.200244</td>\n",
       "      <td>4909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          True_negatives  False_positives  False_negatives  True_positives  \\\n",
       "positive            3816              110               41             942   \n",
       "\n",
       "          Accuracy    Recall  Precision  f1_score    PR_AUC   ROC_AUC  \\\n",
       "positive   0.96924  0.958291   0.895437  0.925799  0.866441  0.965136   \n",
       "\n",
       "          Kappa Score  binary_cross_entropy  target_imbalance  target_size  \\\n",
       "positive     0.906425              1.062425          0.200244         4909   \n",
       "\n",
       "          optimal_threshold  \n",
       "positive                  1  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running model on actual test data...\n",
      "  Accuracy: 0.219\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Running model on actual test data...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Put the model in evaluation mode--the dropout layers behave differently\n",
    "# during evaluation.\n",
    "transformer.eval() #maybe redundant\n",
    "discriminator.eval()\n",
    "generator.eval()\n",
    "\n",
    "# Tracking variables \n",
    "total_test_accuracy = 0\n",
    "\n",
    "total_test_loss = 0\n",
    "nb_test_steps = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels_ids = []\n",
    "pred_prob=[]\n",
    "\n",
    "#loss\n",
    "nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "for batch in real_test_dataloader:\n",
    "\n",
    "    # Unpack this training batch from our dataloader. \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    # Tell pytorch not to bother with constructing the compute graph during\n",
    "    # the forward pass, since this is only needed for backprop (training).\n",
    "    with torch.no_grad():        \n",
    "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "        hidden_states = model_outputs[-1]\n",
    "        _, logits, probs = discriminator(hidden_states)\n",
    "        ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "        filtered_logits = logits[:,0:-1]\n",
    "        # Accumulate the test loss.\n",
    "        total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "\n",
    "    # Accumulate the predictions and the input labels\n",
    "    pred_prob += probs[:,0:-1].detach().tolist()\n",
    "    _, preds = torch.max(filtered_logits, 1)\n",
    "    all_preds += preds.detach().tolist()\n",
    "    all_labels_ids += b_labels.detach().tolist()\n",
    "    \n",
    "# Report the final accuracy for this validation run.\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels_ids = np.array(all_labels_ids)\n",
    "test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "print(\"  Accuracy: {0:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2631, 2631)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels_ids), len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(all_preds,columns=['Predicted'])\n",
    "y_true=pd.DataFrame(all_labels_ids,columns=['Actual'])\n",
    "for i in range(len(label_list)):\n",
    "    y_pred[label_list[i]]=[1 if x==i else 0 for x in all_preds]\n",
    "    y_true[label_list[i]]=[1 if x==i else 0 for x in all_labels_ids]\n",
    "    \n",
    "y_pred=y_pred['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = test_data[['Id']]\n",
    "submission_df[category] = [x[1] for x in pred_prob]\n",
    "submission_df.to_csv(output_filepath + category.replace(' ','_') + '_submission_binary_ganbert.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Usability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.979786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.008669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.007927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Usability\n",
       "0   0   0.009347\n",
       "1   1   0.008499\n",
       "2   2   0.979786\n",
       "3   3   0.008669\n",
       "4   4   0.007927"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-31T15:58:26.046813Z",
     "iopub.status.idle": "2021-12-31T15:58:26.047117Z",
     "shell.execute_reply": "2021-12-31T15:58:26.046977Z",
     "shell.execute_reply.started": "2021-12-31T15:58:26.046957Z"
    },
    "id": "53fff942",
    "papermill": {
     "duration": 0.029275,
     "end_time": "2021-12-27T11:31:50.677515",
     "exception": false,
     "start_time": "2021-12-27T11:31:50.64824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save model\n",
    "\n",
    "# #Save config\n",
    "# model_upd_nm = model_name.replace('-','_')\n",
    "# temp = AutoModel.from_pretrained(model_name)\n",
    "# temp.save_pretrained(f'./Model Data/{model_upd_nm}/')\n",
    "\n",
    "# torch.save(transformer.module.state_dict(), f\"./Model Data/{model_upd_nm}.pth\")\n",
    "# tokenizer.save_pretrained(f\"./Model Data/{model_name.replace('-','_')}/\")\n",
    "\n",
    "# torch.save(\n",
    "#     {\n",
    "#         \"model_state_dict\": generator.state_dict()\n",
    "#     },\n",
    "#     f'Model Data/GAN_BERT_binary_generator_{category}.pth',\n",
    "# )\n",
    "# torch.save(\n",
    "#     {\n",
    "#         \"model_state_dict\": discriminator.state_dict()\n",
    "#     },\n",
    "#     f'Model Data/GAN_BERT_binary_discriminator_{category}.pth',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'bert-base-uncased'\n",
    "# # train_data_with_embeddings = generate_bert_embeddings_all_tokens(train_data,'Review cleaned for transformers', model_name)[0]\n",
    "# # train_data_with_embeddings = np.array(train_data_with_embeddings).astype(float)\n",
    "# # joblib.dump(train_data_with_embeddings, output_filepath + 'bert_base_uncased_all_token_embeddings.pkl')\n",
    "\n",
    "# train_data_with_embeddings = joblib.load(output_filepath + 'bert_base_uncased_all_token_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, valid_df = sk_model_selection.train_test_split(\n",
    "#     train_data, \n",
    "#     test_size=0.2, \n",
    "#     random_state=SEED,\n",
    "#     stratify = train_data[category])\n",
    "\n",
    "# y_train = train_df[category]\n",
    "# y_valid = valid_df[category]\n",
    "\n",
    "# X_train = train_data_with_embeddings[train_df['Id'].tolist(),:,:]\n",
    "# X_valid = train_data_with_embeddings[valid_df['Id'].tolist(),:,:]\n",
    "\n",
    "# print(X_train.shape, len(y_train), X_valid.shape, len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['Review length'] = train_data['Review cleaned for transformers'].apply(lambda x: len(x.split(' ')))\n",
    "# test_data['Review length'] = test_data['Review cleaned for transformers'].apply(lambda x: len(x.split(' ')))\n",
    "# id_with_max_len = train_data[train_data['Review length'] == train_data['Review length'].max()]['Id'].iloc[0]\n",
    "# print(train_data['Review length'].max(), test_data['Review length'].max(), id_with_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 100\n",
    "# BATCH_SIZE = 16\n",
    "\n",
    "# def lstm_model():\n",
    "    \n",
    "#     x_input = Input(shape=(X_train.shape[-2:]))\n",
    "    \n",
    "#     x1 = Bidirectional(LSTM(units=64, return_sequences=True))(x_input)\n",
    "#     x2 = Bidirectional(LSTM(units=64, return_sequences=False))(x1)\n",
    "#     x2 = BatchNormalization()(x2)\n",
    "    \n",
    "#     x3 = Dense(units=20, activation='selu')(x2)\n",
    "#     x3 = BatchNormalization()(x3)\n",
    "    \n",
    "#     x_output = Dense(units=1, activation = 'sigmoid')(x3)\n",
    "    \n",
    "#     model = Model(inputs=x_input, outputs=x_output, \n",
    "#                   name='LSTM_Model')\n",
    "#     return model\n",
    "\n",
    "# model = lstm_model()\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "# es = EarlyStopping(monitor=\"val_loss\", patience=10,\n",
    "#                    verbose=2, mode=\"min\", \n",
    "#                    restore_best_weights=True)\n",
    "\n",
    "# save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "# chk_point = ModelCheckpoint(f'./LSTM_model.h5', options=save_locally, \n",
    "#                             monitor='val_loss', verbose=2, \n",
    "#                             save_best_only=True, mode='min')\n",
    "\n",
    "# history = model.fit(X_train, y_train, \n",
    "#           validation_data=(X_valid, y_valid), \n",
    "#           epochs=EPOCHS,\n",
    "#           verbose=2,\n",
    "#           batch_size=BATCH_SIZE, \n",
    "#           callbacks=[chk_point, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'][:])\n",
    "# plt.plot(history.history['val_loss'][:])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'val'], loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = sk_model_selection.train_test_split(\n",
    "    train_data, \n",
    "    test_size=0.2, \n",
    "    random_state=SEED,\n",
    "    stratify = train_data[category])\n",
    "\n",
    "X_train = train_df['Review cleaned for transformers']\n",
    "X_valid = valid_df['Review cleaned for transformers']\n",
    "y_train = train_df[category]\n",
    "y_valid = valid_df[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "valid_sequences = tok.texts_to_sequences(valid_df['Review cleaned for transformers'])\n",
    "valid_sequences_matrix = sequence.pad_sequences(valid_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 150, 200)          200000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 150, 64)           67840     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 301,921\n",
      "Trainable params: 301,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "embedding_vector_features=200\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Embedding(max_words,embedding_vector_features,input_length=max_len))\n",
    "\n",
    "model.add(LSTM(64,input_shape=(embedding_vector_features, max_len),activation='relu',return_sequences=True))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(64,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(16,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 - 32s - loss: 0.5113 - accuracy: 0.7995 - val_loss: 0.4263 - val_accuracy: 0.7997\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.42625, saving model to ./LSTM_model.h5\n",
      "Epoch 2/100\n",
      "77/77 - 28s - loss: 9509964611584.0000 - accuracy: 0.8036 - val_loss: 449144.7500 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.42625\n",
      "Epoch 3/100\n",
      "77/77 - 28s - loss: 64844939264.0000 - accuracy: 0.7812 - val_loss: 0.5659 - val_accuracy: 0.8217\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.42625\n",
      "Epoch 4/100\n",
      "77/77 - 28s - loss: 0.7501 - accuracy: 0.8160 - val_loss: 0.4764 - val_accuracy: 0.8086\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.42625\n",
      "Epoch 5/100\n",
      "77/77 - 28s - loss: 13.0097 - accuracy: 0.8113 - val_loss: 0.4387 - val_accuracy: 0.8078\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.42625\n",
      "Epoch 6/100\n",
      "77/77 - 28s - loss: 69317.8281 - accuracy: 0.8085 - val_loss: 0.4221 - val_accuracy: 0.8070\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.42625 to 0.42210, saving model to ./LSTM_model.h5\n",
      "Epoch 7/100\n",
      "77/77 - 28s - loss: 0.4008 - accuracy: 0.8085 - val_loss: 0.4197 - val_accuracy: 0.8070\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42210 to 0.41969, saving model to ./LSTM_model.h5\n",
      "Epoch 8/100\n",
      "77/77 - 28s - loss: 7.2657 - accuracy: 0.8089 - val_loss: 0.4117 - val_accuracy: 0.8078\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41969 to 0.41173, saving model to ./LSTM_model.h5\n",
      "Epoch 9/100\n",
      "77/77 - 28s - loss: 894647872.0000 - accuracy: 0.8097 - val_loss: 1.3716 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.41173\n",
      "Epoch 10/100\n",
      "77/77 - 28s - loss: 4428.8604 - accuracy: 0.8093 - val_loss: 0.4255 - val_accuracy: 0.8005\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41173\n",
      "Epoch 11/100\n",
      "77/77 - 28s - loss: 0.4287 - accuracy: 0.8056 - val_loss: 377.6936 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.41173\n",
      "Epoch 12/100\n",
      "77/77 - 28s - loss: 1.8159 - accuracy: 0.8083 - val_loss: 1734.4188 - val_accuracy: 0.8037\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.41173\n",
      "Epoch 13/100\n",
      "77/77 - 28s - loss: 0.3905 - accuracy: 0.8126 - val_loss: 6817.5361 - val_accuracy: 0.8037\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.41173\n",
      "Epoch 14/100\n",
      "77/77 - 28s - loss: 0.3848 - accuracy: 0.8140 - val_loss: 15097.4023 - val_accuracy: 0.8062\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.41173\n",
      "Epoch 15/100\n",
      "77/77 - 28s - loss: 0.6616 - accuracy: 0.8140 - val_loss: 22966.1113 - val_accuracy: 0.8070\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.41173\n",
      "Epoch 16/100\n",
      "77/77 - 28s - loss: 0.3767 - accuracy: 0.8160 - val_loss: 19718.5293 - val_accuracy: 0.8029\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.41173\n",
      "Epoch 17/100\n",
      "77/77 - 28s - loss: 3.1570 - accuracy: 0.8207 - val_loss: 42632.0469 - val_accuracy: 0.8029\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.41173\n",
      "Epoch 18/100\n",
      "77/77 - 28s - loss: 0.3721 - accuracy: 0.8172 - val_loss: 38969.0430 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.41173\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", patience=10,\n",
    "                   verbose=2, mode=\"min\", \n",
    "                   restore_best_weights=True)\n",
    "\n",
    "save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "chk_point = ModelCheckpoint(f'./LSTM_model.h5', options=save_locally, \n",
    "                            monitor='val_loss', verbose=2, \n",
    "                            save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(sequences_matrix, y_train, \n",
    "          validation_data=(valid_sequences_matrix, y_valid), \n",
    "          epochs=EPOCHS,\n",
    "          verbose=2,\n",
    "          batch_size=BATCH_SIZE, \n",
    "          callbacks=[chk_point, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'][:])\n",
    "plt.plot(history.history['val_loss'][:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log loss:  nan\n",
      "Train log loss:  nan\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(f'./LSTM_model.h5', compile = False)\n",
    "print('Valid log loss: ', log_loss(y_valid, model.predict(valid_sequences_matrix)))\n",
    "print('Train log loss: ', log_loss(y_train, model.predict(sequences_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logloss_on_valid_data['LSTM'] = log_loss(y_valid, model.predict(valid_sequences_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2631, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Usability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.485793e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.450278e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.068671e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.717711e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id     Usability\n",
       "0   0  0.000000e+00\n",
       "1   1  1.485793e-07\n",
       "2   2  4.450278e-01\n",
       "3   3  2.068671e-01\n",
       "4   4  2.717711e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sequences = tok.texts_to_sequences(test_data['Review cleaned for transformers'])\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "preds = model.predict(test_sequences_matrix)\n",
    "preds = [x[0] for x in preds]\n",
    "submission_df = test_data[['Id']]\n",
    "submission_df[category] = preds\n",
    "submission_df.to_csv(output_filepath + category.replace(' ','_') + '_submission_LSTM.csv', index=False)\n",
    "print(submission_df.shape)\n",
    "display(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Text Classification with fastText\n",
    "# # NLP Preprocessing\n",
    "\n",
    "# train_df, valid_df = sk_model_selection.train_test_split(\n",
    "#     train_data, \n",
    "#     test_size=0.2, \n",
    "#     random_state=SEED,\n",
    "#     stratify = train_data[category])\n",
    "\n",
    "# train_ids = train_df['Id'].tolist()\n",
    "# valid_ids = valid_df['Id'].tolist()\n",
    "\n",
    "# train_df = train_df[['Review cleaned for transformers', category]]\n",
    "# valid_df = valid_df[['Review cleaned for transformers', category]]\n",
    "\n",
    "# # # NLP Preprocess\n",
    "# train_df.iloc[:, 0] = train_df.iloc[:, 0].apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "# valid_df.iloc[:, 0] = valid_df.iloc[:, 0].apply(lambda x: ' '.join(simple_preprocess(x)))\n",
    "\n",
    "# # Prefixing each row of the category column with '__label__'\n",
    "# train_df.iloc[:, 1] = train_df.iloc[:, 1].apply(lambda x: '__label__' + str(x))\n",
    "# valid_df.iloc[:, 1] = valid_df.iloc[:, 1].apply(lambda x: '__label__' + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving the CSV file as a text file to train/test the classifier\n",
    "# train_df.to_csv(output_filepath + 'fastText_train.txt', \n",
    "#                   index = False, \n",
    "#                   sep = ' ',\n",
    "#                   header = None, \n",
    "#                   quoting = csv.QUOTE_NONE, \n",
    "#                   quotechar = \"\", \n",
    "#                   escapechar = \" \")\n",
    "\n",
    "# valid_df.to_csv(output_filepath + 'fastText_valid.txt', \n",
    "#                  index = False, \n",
    "#                  sep = ' ',\n",
    "#                  header = None, \n",
    "#                  quoting = csv.QUOTE_NONE, \n",
    "#                  quotechar = \"\", \n",
    "#                  escapechar = \" \")\n",
    "\n",
    "\n",
    "# # Training the fastText classifier\n",
    "# model = fasttext.train_supervised(output_filepath + 'fastText_train.txt', wordNgrams = 2, epoch=1000)\n",
    "\n",
    "# # Save the trained model\n",
    "# model.save_model('fastText_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predicting on a single input\n",
    "# model.predict(valid_df.iloc[2, 0]), model.predict(valid_df.iloc[10, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluating performance on the entire test file\n",
    "# model.test(output_filepath + 'fastText_valid.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_prob = []\n",
    "# for i in range(0, len(valid_df)):\n",
    "#     pred_prob.append(model.predict(valid_df.iloc[i, 0])[1][0])\n",
    "# log_loss(train_data[train_data['Id'].isin(valid_ids)][category], pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(pred_prob), min(pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "# train_data_with_embeddings = generate_bert_embeddings(train_data,'Review cleaned for transformers', model_name)\n",
    "# train_data_with_embeddings = train_data_with_embeddings.astype(float)\n",
    "# joblib.dump(train_data_with_embeddings, output_filepath + 'bert_base_uncased_CLS_token_embeddings.pkl')\n",
    "\n",
    "train_data_with_embeddings = joblib.load(output_filepath + 'bert_base_uncased_CLS_token_embeddings.pkl')\n",
    "train_data_with_embeddings = pd.concat([train_data[['Id']], train_data_with_embeddings], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4908, 768) 4908 (1228, 768) 1228\n"
     ]
    }
   ],
   "source": [
    "train_df, valid_df = sk_model_selection.train_test_split(\n",
    "    train_data, \n",
    "    test_size=0.2, \n",
    "    random_state=SEED,\n",
    "    stratify = train_data[category])\n",
    "\n",
    "y_train = train_df[category]\n",
    "y_valid = valid_df[category]\n",
    "\n",
    "X_train = train_data_with_embeddings[train_data_with_embeddings['Id'].isin(train_df['Id'].tolist())].reset_index(drop = True).iloc[:,1:]\n",
    "X_valid = train_data_with_embeddings[train_data_with_embeddings['Id'].isin(valid_df['Id'].tolist())].reset_index(drop = True).iloc[:,1:]\n",
    "\n",
    "print(X_train.shape, len(y_train), X_valid.shape, len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"NN_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 110,273\n",
      "Trainable params: 109,793\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def simple_nn():\n",
    "    x_input = Input(shape=(X_train.shape[1]))\n",
    "    \n",
    "    x = Dense(units=128, activation='relu',\n",
    "    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(x_input)\n",
    "    x1 = BatchNormalization()(x)\n",
    "    \n",
    "    x2 = Dense(units=64, activation='relu',\n",
    "    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(x1)\n",
    "    x3 = BatchNormalization()(x2)\n",
    "    \n",
    "    x4 = Dense(units=32, activation='relu',\n",
    "    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(x3)\n",
    "    x5 = BatchNormalization()(x4)\n",
    "    \n",
    "    x6 = Dense(units=16, activation='relu',\n",
    "    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(x5)\n",
    "    x7 = BatchNormalization()(x6)\n",
    "    \n",
    "    x_output = Dense(units=1, activation='sigmoid',\n",
    "    kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(x7)\n",
    "    \n",
    "    model = Model(inputs=x_input, outputs=x_output, \n",
    "                  name='NN_Model')\n",
    "    return model\n",
    "\n",
    "model = simple_nn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "307/307 - 3s - loss: 0.7040 - accuracy: 0.7031 - val_loss: 0.6053 - val_accuracy: 0.7997\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60532, saving model to ./nn_model.h5\n",
      "Epoch 2/100\n",
      "307/307 - 1s - loss: 0.5844 - accuracy: 0.7991 - val_loss: 0.6210 - val_accuracy: 0.7598\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.60532\n",
      "Epoch 3/100\n",
      "307/307 - 1s - loss: 0.5750 - accuracy: 0.7989 - val_loss: 0.5934 - val_accuracy: 0.7989\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.60532 to 0.59339, saving model to ./nn_model.h5\n",
      "Epoch 4/100\n",
      "307/307 - 1s - loss: 0.5679 - accuracy: 0.7999 - val_loss: 0.5938 - val_accuracy: 0.7948\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.59339\n",
      "Epoch 5/100\n",
      "307/307 - 1s - loss: 0.5559 - accuracy: 0.7997 - val_loss: 0.5982 - val_accuracy: 0.7899\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.59339\n",
      "Epoch 6/100\n",
      "307/307 - 1s - loss: 0.5537 - accuracy: 0.7979 - val_loss: 0.6038 - val_accuracy: 0.7956\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.59339\n",
      "Epoch 7/100\n",
      "307/307 - 1s - loss: 0.5451 - accuracy: 0.8005 - val_loss: 0.6035 - val_accuracy: 0.7915\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.59339\n",
      "Epoch 8/100\n",
      "307/307 - 1s - loss: 0.5414 - accuracy: 0.8011 - val_loss: 0.6071 - val_accuracy: 0.7875\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.59339\n",
      "Epoch 9/100\n",
      "307/307 - 1s - loss: 0.5321 - accuracy: 0.8046 - val_loss: 0.6182 - val_accuracy: 0.7793\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.59339\n",
      "Epoch 10/100\n",
      "307/307 - 1s - loss: 0.5217 - accuracy: 0.8066 - val_loss: 0.6313 - val_accuracy: 0.7834\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.59339\n",
      "Epoch 11/100\n",
      "307/307 - 1s - loss: 0.5108 - accuracy: 0.8087 - val_loss: 0.7029 - val_accuracy: 0.7068\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.59339\n",
      "Epoch 12/100\n",
      "307/307 - 1s - loss: 0.5096 - accuracy: 0.8052 - val_loss: 0.6654 - val_accuracy: 0.7508\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.59339\n",
      "Epoch 13/100\n",
      "307/307 - 1s - loss: 0.5027 - accuracy: 0.8126 - val_loss: 0.6656 - val_accuracy: 0.7834\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.59339\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=\"accuracy\")\n",
    "\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=10,\n",
    "                   verbose=2, mode=\"min\", \n",
    "                   restore_best_weights=True)\n",
    "\n",
    "save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "chk_point = ModelCheckpoint(f'./nn_model.h5', options=save_locally, \n",
    "                            monitor='val_loss', verbose=2, \n",
    "                            save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid), \n",
    "          epochs=EPOCHS,\n",
    "          verbose=2,\n",
    "          batch_size=BATCH_SIZE, \n",
    "          callbacks=[chk_point, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(f'./nn_model.h5', compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'][:])\n",
    "plt.plot(history.history['val_loss'][:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train log loss:  0.48036654159872993\n"
     ]
    }
   ],
   "source": [
    "print('Train log loss: ', log_loss(y_train, model.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid log loss:  0.5141409725733466\n"
     ]
    }
   ],
   "source": [
    "print('Valid log loss: ', log_loss(y_valid, model.predict(X_valid)))\n",
    "model_logloss_on_valid_data['Perceptron'] = log_loss(y_valid, model.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_with_embeddings = generate_bert_embeddings(test_data,'Review cleaned for transformers', model_name)\n",
    "# test_data_with_embeddings = test_data_with_embeddings.astype(float)\n",
    "# joblib.dump(test_data_with_embeddings, output_filepath + 'bert_base_uncased_CLS_token_embeddings_test_data.pkl')\n",
    "test_data_with_embeddings = joblib.load(output_filepath + 'bert_base_uncased_CLS_token_embeddings_test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2631, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Usability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.296136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.219781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.109278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.200865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.125854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Usability\n",
       "0   0   0.296136\n",
       "1   1   0.219781\n",
       "2   2   0.109278\n",
       "3   3   0.200865\n",
       "4   4   0.125854"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(test_data_with_embeddings)\n",
    "preds = [x[0] for x in preds]\n",
    "submission_df = test_data[['Id']]\n",
    "submission_df[category] = preds\n",
    "submission_df.to_csv(output_filepath + category.replace(' ','_') + '_submission_perceptron.csv', index=False)\n",
    "print(submission_df.shape)\n",
    "display(submission_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic regression': 0.25372128365146596,\n",
       " 'SVM': 0.31119568740257436,\n",
       " 'XGBoost': 0.1987134065002761,\n",
       " 'H2O.ai': 0.2154746999084045,\n",
       " 'Binary GAN-BERT': 0.14669816084774237,\n",
       " 'LSTM': nan,\n",
       " 'Perceptron': 0.5141409725733466}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_logloss_on_valid_data, output_filepath + category.replace(' ','_') + '_model_logloss_on_valid_data.pkl')\n",
    "model_logloss_on_valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_logloss = 999999999\n",
    "for k,v in model_logloss_on_valid_data.items():\n",
    "    if min_logloss > model_logloss_on_valid_data[k]:\n",
    "        best_model = k\n",
    "        min_logloss = model_logloss_on_valid_data[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Binary GAN-BERT', 0.14669816084774237)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model, min_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2631, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Usability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.008499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.979786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.008669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.007927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Usability\n",
       "0   0   0.009347\n",
       "1   1   0.008499\n",
       "2   2   0.979786\n",
       "3   3   0.008669\n",
       "4   4   0.007927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_to_filename = {'logistic regression': category.replace(' ','_') + '_submission_lr.csv',\n",
    "                    'SVM': category.replace(' ','_') + '_submission_svm.csv',\n",
    "                    'XGBoost':category.replace(' ','_') + '_submission_xgboost_full_data_train.csv',\n",
    "                    'H2O.ai': category.replace(' ','_') + '_h20_ai_best_model.csv',\n",
    "                    'Binary GAN-BERT': category.replace(' ','_') + '_submission_binary_ganbert.csv',\n",
    "                    'LSTM': category.replace(' ','_') + '_submission_LSTM.csv',\n",
    "                    'Perceptron': category.replace(' ','_') + '_submission_perceptron.csv'}\n",
    "\n",
    "submission_df = pd.read_csv(output_filepath + model_to_filename[best_model], encoding = 'utf-8-sig')\n",
    "submission_df.to_csv(output_filepath + category.replace(' ','_') + '_best_submission.csv', index=False)\n",
    "print(submission_df.shape)\n",
    "display(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# output_filepath = './Outputs/'\n",
    "# category = 'Delivery and Customer Support'\n",
    "# dummy = joblib.load(output_filepath + category.replace(' ','_') + '_model_logloss_on_valid_data.pkl')\n",
    "# dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components H2O.ai 0.1274006790186054 \n",
      "\n",
      "Delivery and Customer Support SVM 0.04280020554583495 \n",
      "\n",
      "Design and Aesthetics Binary GAN-BERT 0.14935191097746925 \n",
      "\n",
      "Dimensions H2O.ai 0.1807273161785255 \n",
      "\n",
      "Features SVM 0.12805174387042348 \n",
      "\n",
      "Functionality Binary GAN-BERT 0.3184886866145328 \n",
      "\n",
      "Installation XGBoost 0.1075445180146421 \n",
      "\n",
      "Material XGBoost 0.059886435952708005 \n",
      "\n",
      "Price XGBoost 0.10597329546548791 \n",
      "\n",
      "Quality Binary GAN-BERT 0.30159055013282104 \n",
      "\n",
      "Usability Binary GAN-BERT 0.14669816084774237 \n",
      "\n",
      "Polarity Binary GAN-BERT 0.19519009056693812 \n",
      "\n",
      "Total log loss: 1.8637035931857313\n"
     ]
    }
   ],
   "source": [
    "total_logloss = 0\n",
    "submission_df = pd.DataFrame(data = None, columns = categories + [polarity])\n",
    "for col in categories + [polarity]:\n",
    "    model_logloss_on_valid_data = joblib.load(output_filepath + col.replace(' ','_') + '_model_logloss_on_valid_data.pkl')\n",
    "    min_logloss = 999999999\n",
    "    for k,v in model_logloss_on_valid_data.items():\n",
    "        if min_logloss > model_logloss_on_valid_data[k]:\n",
    "            best_model = k\n",
    "            min_logloss = model_logloss_on_valid_data[k]\n",
    "    print(col, best_model, min_logloss,'\\n')\n",
    "    total_logloss += min_logloss\n",
    "    model_to_filename = {'logistic regression': col.replace(' ','_') + '_submission_lr.csv',\n",
    "                    'SVM': col.replace(' ','_') + '_submission_svm.csv',\n",
    "                    'XGBoost':col.replace(' ','_') + '_submission_xgboost_full_data_train.csv',\n",
    "                    'H2O.ai': col.replace(' ','_') + '_h20_ai_best_model.csv',\n",
    "                    'Binary GAN-BERT': col.replace(' ','_') + '_submission_binary_ganbert.csv',\n",
    "                    'LSTM': col.replace(' ','_') + '_submission_LSTM.csv',\n",
    "                    'Perceptron': col.replace(' ','_') + '_submission_perceptron.csv'}\n",
    "    best_submission = pd.read_csv(output_filepath + model_to_filename[best_model], encoding = 'utf-8-sig')\n",
    "    submission_df[col] = best_submission[col]\n",
    "print('Total log loss:',total_logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2631, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Components</th>\n",
       "      <th>Delivery and Customer Support</th>\n",
       "      <th>Design and Aesthetics</th>\n",
       "      <th>Dimensions</th>\n",
       "      <th>Features</th>\n",
       "      <th>Functionality</th>\n",
       "      <th>Installation</th>\n",
       "      <th>Material</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Usability</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295181</td>\n",
       "      <td>0.015660</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>0.022736</td>\n",
       "      <td>0.018071</td>\n",
       "      <td>0.458985</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.271053</td>\n",
       "      <td>0.045069</td>\n",
       "      <td>0.108402</td>\n",
       "      <td>0.009347</td>\n",
       "      <td>0.003040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.008573</td>\n",
       "      <td>0.014971</td>\n",
       "      <td>0.011082</td>\n",
       "      <td>0.031580</td>\n",
       "      <td>0.979622</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.005703</td>\n",
       "      <td>0.021448</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.990240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007460</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>0.009576</td>\n",
       "      <td>0.008460</td>\n",
       "      <td>0.008164</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.056959</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.012164</td>\n",
       "      <td>0.022227</td>\n",
       "      <td>0.979786</td>\n",
       "      <td>0.990694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031427</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>0.975616</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.008669</td>\n",
       "      <td>0.990556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>0.013138</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>0.037882</td>\n",
       "      <td>0.024769</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.984618</td>\n",
       "      <td>0.007927</td>\n",
       "      <td>0.990475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Components  Delivery and Customer Support  Design and Aesthetics  \\\n",
       "0    0.295181                       0.015660               0.012007   \n",
       "1    0.003602                       0.008573               0.014971   \n",
       "2    0.007460                       0.010540               0.009576   \n",
       "3    0.031427                       0.002102               0.008498   \n",
       "4    0.008238                       0.004462               0.013138   \n",
       "\n",
       "   Dimensions  Features  Functionality  Installation  Material     Price  \\\n",
       "0    0.022736  0.018071       0.458985      0.006110  0.271053  0.045069   \n",
       "1    0.011082  0.031580       0.979622      0.003692  0.005703  0.021448   \n",
       "2    0.008460  0.008164       0.006029      0.056959  0.003337  0.012164   \n",
       "3    0.009135  0.014243       0.975616      0.002869  0.003517  0.015300   \n",
       "4    0.005704  0.037882       0.024769      0.003692  0.005549  0.015300   \n",
       "\n",
       "    Quality  Usability  Polarity  \n",
       "0  0.108402   0.009347  0.003040  \n",
       "1  0.007149   0.008499  0.990240  \n",
       "2  0.022227   0.979786  0.990694  \n",
       "3  0.004216   0.008669  0.990556  \n",
       "4  0.984618   0.007927  0.990475  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission_df.to_csv(output_filepath + 'final_submission_' + str(datetime.datetime.today().strftime('%Y-%m-%d-%H-%M-%S')).replace('-','_') + '.csv', index=False)\n",
    "print(submission_df.shape)\n",
    "display(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
